{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load SpanBERT Tokenizer and Model\n",
    "tokenizer = AutoTokenizer.from_pretrained('SpanBERT/spanbert-large-cased')\n",
    "model = AutoModel.from_pretrained('SpanBERT/spanbert-large-cased')\n",
    "\n",
    "annotation_dict = utils.load_data(\"./Data/qed-train.jsonlines\")\n",
    "M = annotation_dict[-3193270267191507653]\n",
    "text = M.passage\n",
    "question = M.question\n",
    "coreference = M.aligned_nps\n",
    "\n",
    "encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "encoded_question = tokenizer(question, return_tensors=\"pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 196,\n",
       " 'end': 370,\n",
       " 'string': 'She married Tucker Jones in 1995 , but their marriage encountered difficulties in 2007 , due to her commitments as both a parent to son Tuck and to her career as a surgeon . '}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.selected_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_ls = M.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 100, 196, 370]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.sentence_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entity(start_offset=208, end_offset=220, type='context', text='Tucker Jones', normalized_text='tucker jones')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 94])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_embeddings = model(**encoded_text).last_hidden_state\n",
    "    question_embeddings = model(**encoded_question).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Entity(start_offset=7, end_offset=11, type='question', text='tuck', normalized_text='tuck'),\n",
       "  Entity(start_offset=328, end_offset=336, type='context', text='son Tuck', normalized_text='son tuck'))]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[coreference[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import SpanBERT\n",
    "model = SpanBERT.Model(hidden_size=1024, device='cpu')\n",
    "def get_encoded_span(sents, coreference, type=0): # 0 for 'question'; 1 for 'context'\n",
    "    start = coreference[0][type].start_offset\n",
    "    end = coreference[0][type].end_offset\n",
    "    span = list(sents)[start:end]\n",
    "    span = ''.join(span)\n",
    "    return span\n",
    "question_span = get_encoded_span(question, [coreference[0]], type=0)\n",
    "encoded_question_span = model.tokenize(question_span)\n",
    "encoded_question = model.tokenize(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1150,  1110,   189, 21515,  1401,  1107,  5583,   112,   188,\n",
       "         19768,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  189, 8474,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_start, question_end = SpanBERT.find_start_end_pos(encoded_question, encoded_question_span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(question_start, question_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1150,  1110,   189, 21515,  1401,  1107,  5583,   112,   188,\n",
       "         19768,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuck'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 177, 1024])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = text_embeddings[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 177, 1024])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Entity(start_offset=22, end_offset=30, type='question', text='fortnite', normalized_text='fortnite'),\n",
       "  Entity(start_offset=268, end_offset=276, type='context', text='Fortnite', normalized_text='fortnite'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1931, 1934, 1940 - - 1942 ).'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = torch.tensor([3916,  117, 3729,  117, 3020,  118,  118, 2889,  114,  119])\n",
    "tokenizer.decode(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings[:, 1:5].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who got the first nobel prize in physics'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1150, 1400, 1103, 1148, 1185, 8511, 4716, 1107, 7094,  102]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_start = coreference[0][0].start_offset\n",
    "question_end = coreference[0][0].end_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_span = list(question)[question_start:question_end]\n",
    "question_span = ''.join(question_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 1103, 1148, 1185, 8511, 4716, 1107, 7094,  102]])\n"
     ]
    }
   ],
   "source": [
    "encoded_question_span = tokenizer(question_span, return_tensors=\"pt\")\n",
    "print(encoded_question_span['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 1150, 1400, 1103, 1148, 1185, 8511, 4716, 1107, 7094,  102])\n",
      "tensor([1103, 1148, 1185, 8511, 4716, 1107, 7094])\n"
     ]
    }
   ],
   "source": [
    "X = encoded_question['input_ids'][0, :]\n",
    "Y = encoded_question_span['input_ids'][0, 1:-1]\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 3, End: 9\n"
     ]
    }
   ],
   "source": [
    "def find_sequence_positions_tensor(list1, list2):\n",
    "    len_list2 = list2.size(0)\n",
    "    for i in range(list1.size(0) - len_list2 + 1):\n",
    "        if torch.equal(list1[i:i+len_list2], list2):\n",
    "            return i, i + len_list2 - 1\n",
    "    return -1, -1\n",
    "\n",
    "start, end = find_sequence_positions_tensor(X, Y)\n",
    "print(f\"Start: {start}, End: {end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomQA(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.question_att = nn.Linear(hidden_size, hidden_size)\n",
    "        self.context_att = nn.Linear(hidden_size, hidden_size)\n",
    "        self.qa_outputs = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, question_hidden, context_hidden):\n",
    "        # Apply linear layers\n",
    "        question_att = self.question_att(question_hidden)\n",
    "        context_att = self.context_att(context_hidden)\n",
    "\n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.matmul(context_att, question_att.transpose(-1, -2))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        # Apply attention weights\n",
    "        attended_question = torch.matmul(attn_weights, question_hidden)\n",
    "\n",
    "        # Combine question and attended context\n",
    "        combined_hidden = context_hidden + attended_question\n",
    "\n",
    "        # Predicting start and end logits\n",
    "        logits = self.qa_outputs(combined_hidden)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        return start_logits.squeeze(-1), end_logits.squeeze(-1)\n",
    "\n",
    "# Example usage\n",
    "hidden_size = 768  # Example hidden size\n",
    "model = CustomQA(hidden_size)\n",
    "\n",
    "# Assuming question_hidden and context_hidden are your hidden states with different sequence lengths\n",
    "question_hidden = torch.rand(10, hidden_size)  # Example tensor for question\n",
    "context_hidden = torch.rand(20, hidden_size)   # Example tensor for context\n",
    "\n",
    "start_logits, end_logits = model(question_hidden, context_hidden)\n",
    "# Post-processing to find the best answer span\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6141, 1.0137, 0.3670, 0.5621, 0.2945, 0.8588, 1.0265, 0.9420, 0.7214,\n",
      "        0.4058, 0.6825, 0.7306, 0.5026, 0.6067, 0.4712, 1.0268, 0.7138, 0.7195,\n",
      "        0.6596, 0.1748], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(start_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3923, -0.3350, -0.3085, -0.4993, -0.3972, -0.6594, -0.6419, -0.8392,\n",
      "        -0.1374, -0.4528, -0.1867, -0.3284, -0.5838, -0.1934, -0.3745, -0.3120,\n",
      "        -0.5929, -0.1950, -0.1439, -0.4104], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(start_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
