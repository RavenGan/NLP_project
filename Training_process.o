Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
train_coreference_f1=0.24378781271856426 train_answer_f1=0.03717477987904737 train_sents_acc=0.41884355738186085
dev_coreference_f1=0.20235311189455119 dev_answer_f1=0.04527057692224735 dev_sents_acc=0.3779527559055118
[1] train_loss=-4419.112042546272 dev_loss=-822.464583158493
train_coreference_f1=0.24164081907850754 train_answer_f1=0.036810244181133676 train_sents_acc=0.41561491047842675
dev_coreference_f1=0.20409256284849905 dev_answer_f1=0.04969722624197034 dev_sents_acc=0.3905511811023622
[2] train_loss=-4415.536666154861 dev_loss=-824.0746123790741
train_coreference_f1=0.24030887441409018 train_answer_f1=0.03802788074948549 train_sents_acc=0.4158105860483319
dev_coreference_f1=0.19890290290657553 dev_answer_f1=0.045162601184540484 dev_sents_acc=0.3905511811023622
[3] train_loss=-4418.79760992527 dev_loss=-827.9266809225082
train_coreference_f1=0.2396466018200022 train_answer_f1=0.038055241578093014 train_sents_acc=0.41722923393014383
dev_coreference_f1=0.2014404105241806 dev_answer_f1=0.04594137841999704 dev_sents_acc=0.37480314960629924
[4] train_loss=-4428.76339584589 dev_loss=-825.22880256176
train_coreference_f1=0.23985548336617066 train_answer_f1=0.038220294048544795 train_sents_acc=0.4163193425300851
dev_coreference_f1=0.2087738774001989 dev_answer_f1=0.04007149721364706 dev_sents_acc=0.37480314960629924
[5] train_loss=-4415.618683218956 dev_loss=-828.7812691926956
train_coreference_f1=0.24020047128547284 train_answer_f1=0.037822446128101546 train_sents_acc=0.41698463946776243
dev_coreference_f1=0.2058914353849479 dev_answer_f1=0.048481358530912046 dev_sents_acc=0.3732283464566929
[6] train_loss=-4415.794069290161 dev_loss=-828.9609854221344
train_coreference_f1=0.23999053260218195 train_answer_f1=0.03774260459140828 train_sents_acc=0.41653738102226506
dev_coreference_f1=0.21001590911830953 dev_answer_f1=0.05143784271959976 dev_sents_acc=0.38110236220472443
[7] train_loss=-4421.035825252533 dev_loss=-819.1965935230255
train_coreference_f1=0.23996110533405607 train_answer_f1=0.0376784668914856 train_sents_acc=0.4163853830349281
dev_coreference_f1=0.21177049415971763 dev_answer_f1=0.053628790972866824 dev_sents_acc=0.38740157480314963
[8] train_loss=-4423.3791300058365 dev_loss=-830.2993949651718
train_coreference_f1=0.23992155656542985 train_answer_f1=0.03815145711972238 train_sents_acc=0.41600626161823695
dev_coreference_f1=0.20854461832729873 dev_answer_f1=0.04330768408515766 dev_sents_acc=0.3779527559055118
[9] train_loss=-4420.3652030825615 dev_loss=-829.0881978273392
train_coreference_f1=0.24061915877775183 train_answer_f1=0.038163895475337106 train_sents_acc=0.41643674787202817
dev_coreference_f1=0.20374039417257017 dev_answer_f1=0.04604116512581785 dev_sents_acc=0.3795275590551181
[10] train_loss=-4418.5956473350525 dev_loss=-830.168713092804
train_coreference_f1=0.2407469269667233 train_answer_f1=0.03834096172189238 train_sents_acc=0.4167355978333378
dev_coreference_f1=0.19880244775869887 dev_answer_f1=0.04686570352358816 dev_sents_acc=0.3826771653543307
[11] train_loss=-4420.152987957001 dev_loss=-825.9030178785324
train_coreference_f1=0.2408337657716157 train_answer_f1=0.03859218718566061 train_sents_acc=0.41769396340866843
dev_coreference_f1=0.2077548590119503 dev_answer_f1=0.049651683414071494 dev_sents_acc=0.3905511811023622
[12] train_loss=-4425.836914539337 dev_loss=-829.792817234993
train_coreference_f1=0.24079769238706855 train_answer_f1=0.0385463828366644 train_sents_acc=0.41726310085570434
dev_coreference_f1=0.2042476550109142 dev_answer_f1=0.042304660411494194 dev_sents_acc=0.3763779527559055
[13] train_loss=-4407.004466891289 dev_loss=-826.8372167348862
train_coreference_f1=0.24078751623573547 train_answer_f1=0.038605224214266314 train_sents_acc=0.4176485387227976
dev_coreference_f1=0.20064114881370376 dev_answer_f1=0.05951598330507116 dev_sents_acc=0.3858267716535433
[14] train_loss=-4412.981505990028 dev_loss=-831.6583806276321
train_coreference_f1=0.24066543492024442 train_answer_f1=0.03863038183688915 train_sents_acc=0.4173564230505821
dev_coreference_f1=0.20258789397502097 dev_answer_f1=0.036265321775820196 dev_sents_acc=0.4015748031496063
[15] train_loss=-4417.193620324135 dev_loss=-831.6473463773727
train_coreference_f1=0.24052945527440053 train_answer_f1=0.038479706116143785 train_sents_acc=0.4173943351922512
dev_coreference_f1=0.19946092231227383 dev_answer_f1=0.05118536703327462 dev_sents_acc=0.38740157480314963
[16] train_loss=-4418.325988173485 dev_loss=-826.9073034524918
train_coreference_f1=0.24057832061385767 train_answer_f1=0.03867644262973261 train_sents_acc=0.41742778708195927
dev_coreference_f1=0.1932501012322903 dev_answer_f1=0.043549887608401915 dev_sents_acc=0.3795275590551181
[17] train_loss=-4421.035596847534 dev_loss=-830.0998530387878
train_coreference_f1=0.240483548109495 train_answer_f1=0.03863086329225096 train_sents_acc=0.417799954342367
dev_coreference_f1=0.19835553332602 dev_answer_f1=0.050928045982233425 dev_sents_acc=0.3795275590551181
[18] train_loss=-4417.864149570465 dev_loss=-831.0583847761154
train_coreference_f1=0.24048895900277695 train_answer_f1=0.038635263935517805 train_sents_acc=0.4178548808181299
dev_coreference_f1=0.20214443678041083 dev_answer_f1=0.050701193184307464 dev_sents_acc=0.3889763779527559
[19] train_loss=-4415.553287267685 dev_loss=-828.672278881073
train_coreference_f1=0.2405147412117788 train_answer_f1=0.038481092580402006 train_sents_acc=0.4177428823011447
dev_coreference_f1=0.202019251245168 dev_answer_f1=0.039281206229595106 dev_sents_acc=0.3937007874015748
[20] train_loss=-4421.265583992004 dev_loss=-826.7182506322861
lr=0.00015
lr=7.5e-05
lr=3.75e-05
lr=1.875e-05
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
lr=9.375e-06
