{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "annotation_dict = utils.load_data(\"./Data/qed-dev.jsonlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-3290814144789249484: QEDExample(example_id=-3290814144789249484, title='List of Nobel laureates in Physics', question='who got the first nobel prize in physics', passage='The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . John Bardeen is the only laureate to win the prize twice -- in 1956 and 1972 . Maria Skłodowska - Curie also won two Nobel Prizes , for physics in 1903 and chemistry in 1911 . William Lawrence Bragg was , until October 2014 , the youngest ever Nobel laureate ; he won the prize in 1915 at the age of 25 . Two women have won the prize : Curie and Maria Goeppert - Mayer ( 1963 ) . As of 2017 , the prize has been awarded to 206 individuals . There have been six years in which the Nobel Prize in Physics was not awarded ( 1916 , 1931 , 1934 , 1940 -- 1942 ) .', sentence_starts=[0, 172, 251, 348, 477, 552, 613], selected_sent={'start': 0, 'end': 172, 'string': 'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . '}, answer=[Entity(start_offset=56, end_offset=78, type='context', text='Wilhelm Conrad Röntgen', normalized_text='wilhelm conrad röntgen')], nq_answers=[[Entity(start_offset=56, end_offset=91, type='context', text='Wilhelm Conrad Röntgen , of Germany', normalized_text='wilhelm conrad röntgen of germany')], [Entity(start_offset=56, end_offset=78, type='context', text='Wilhelm Conrad Röntgen', normalized_text='wilhelm conrad röntgen')]], aligned_nps=[(Entity(start_offset=8, end_offset=40, type='question', text='the first nobel prize in physics', normalized_text='first nobel prize in physics'), Entity(start_offset=0, end_offset=32, type='context', text='The first Nobel Prize in Physics', normalized_text='first nobel prize in physics'))], explanation_type='single_sentence'),\n",
       " -7660771254611710392: QEDExample(example_id=-7660771254611710392, title='Fortnite', question='where did the idea of fortnite come from', passage=\"Fortnite is set in contemporary Earth , where the sudden appearance of a worldwide storm causes 98 % of the world 's population to disappear , and zombie - like creatures rise to attack the remainder . Considered by Epic as a cross between Minecraft and Left 4 Dead , Fortnite has up to four players cooperating on various missions on randomly - generated maps to collect resources , build fortifications around defensive objectives that are meant to help fight the storm and protect survivors , and construct weapons and traps to engage in combat with waves of these creatures that attempt to destroy the objectives . Players gain rewards through these missions to improve their hero characters , support teams , and arsenal of weapon and trap schematics to be able to take on more difficult missions . The game is supported through microtransactions to purchase in - game currency that can be used towards these upgrades .\", sentence_starts=[0, 202, 619, 804], selected_sent={'start': 202, 'end': 619, 'string': 'Considered by Epic as a cross between Minecraft and Left 4 Dead , Fortnite has up to four players cooperating on various missions on randomly - generated maps to collect resources , build fortifications around defensive objectives that are meant to help fight the storm and protect survivors , and construct weapons and traps to engage in combat with waves of these creatures that attempt to destroy the objectives . '}, answer=[Entity(start_offset=224, end_offset=265, type='context', text='a cross between Minecraft and Left 4 Dead', normalized_text='cross between minecraft and left 4 dead')], nq_answers=[[Entity(start_offset=221, end_offset=265, type='context', text='as a cross between Minecraft and Left 4 Dead', normalized_text='as cross between minecraft and left 4 dead')]], aligned_nps=[(Entity(start_offset=22, end_offset=30, type='question', text='fortnite', normalized_text='fortnite'), Entity(start_offset=268, end_offset=276, type='context', text='Fortnite', normalized_text='fortnite'))], explanation_type='single_sentence'),\n",
       " -4340755100872459608: QEDExample(example_id=-4340755100872459608, title='Health (gaming)', question='what does hp mean in war and order', passage='Health or vitality is an attribute assigned to entities , such as the player character , enemies and objects within a role - playing or video game , that indicates its state in combat . Health is usually measured in hit points or health points , shortened to HP . When the HP of a player character reaches zero , the player may lose a life or their character might become incapacitated or die . When the HP of an enemy reaches zero , it may be defeated or die and the player is usually rewarded in some way .', sentence_starts=[0, 186, 264, 395], selected_sent={'start': 186, 'end': 264, 'string': 'Health is usually measured in hit points or health points , shortened to HP . '}, answer=[Entity(start_offset=216, end_offset=243, type='context', text='hit points or health points', normalized_text='hit points or health points')], nq_answers=[[Entity(start_offset=216, end_offset=243, type='context', text='hit points or health points', normalized_text='hit points or health points')]], aligned_nps=[(Entity(start_offset=10, end_offset=12, type='question', text='hp', normalized_text='hp'), Entity(start_offset=259, end_offset=261, type='context', text='HP', normalized_text='hp'))], explanation_type='single_sentence'),\n",
       " 3221262508309669486: QEDExample(example_id=3221262508309669486, title='Governor-General of India', question='who was the governor general of india when country became independent', passage='India and Pakistan acquired independence in 1947 , but Governors - General continued to be appointed over each nation until republican constitutions were written . Louis Mountbatten , 1st Earl Mountbatten of Burma remained Governor - General of India for some time after independence , but the two nations were otherwise headed by native Governors - General . India became a secular republic in 1950 ; Pakistan became an Islamic one in 1956 .', sentence_starts=[0, 164, 360], selected_sent={'start': 164, 'end': 360, 'string': 'Louis Mountbatten , 1st Earl Mountbatten of Burma remained Governor - General of India for some time after independence , but the two nations were otherwise headed by native Governors - General . '}, answer=[Entity(start_offset=164, end_offset=213, type='context', text='Louis Mountbatten , 1st Earl Mountbatten of Burma', normalized_text='louis mountbatten 1st earl mountbatten of burma')], nq_answers=[[Entity(start_offset=164, end_offset=213, type='context', text='Louis Mountbatten , 1st Earl Mountbatten of Burma', normalized_text='louis mountbatten 1st earl mountbatten of burma')]], aligned_nps=[(Entity(start_offset=8, end_offset=37, type='question', text='the governor general of india', normalized_text='governor general of india'), Entity(start_offset=223, end_offset=250, type='context', text='Governor - General of India', normalized_text='governor general of india'))], explanation_type='single_sentence'),\n",
       " 6117400998512150504: QEDExample(example_id=6117400998512150504, title='Acute hemolytic transfusion reaction', question='what happens to the rbc in acute hemolytic reaction', passage=\"It is also known as an `` immediate hemolytic transfusion reaction '' . This is a medical emergency as it results from rapid destruction of the donor red blood cells by host antibodies ( IgG , IgM ) . It is usually related to ABO blood group incompatibility - the most severe of which often involves group A red cells being given to a patient with group O type blood . Properdin then binds to complement C3 in the donor blood , facilitating the reaction through the alternate pathway cascade . The donor cells also become coated with IgG and are subsequently removed by macrophages in the reticuloendothelial system ( RES ) . Jaundice and disseminated intravascular coagulation ( DIC ) may also occur . The most common cause is clerical error ( i.e. the wrong unit of blood being given to the patient ) .\", sentence_starts=[0, 72, 201, 369, 494, 626, 703], selected_sent={'start': 72, 'end': 201, 'string': 'This is a medical emergency as it results from rapid destruction of the donor red blood cells by host antibodies ( IgG , IgM ) . '}, answer=[Entity(start_offset=119, end_offset=198, type='context', text='rapid destruction of the donor red blood cells by host antibodies ( IgG , IgM )', normalized_text='rapid destruction of donor red blood cells by host antibodies igg igm')], nq_answers=[[Entity(start_offset=119, end_offset=184, type='context', text='rapid destruction of the donor red blood cells by host antibodies', normalized_text='rapid destruction of donor red blood cells by host antibodies')]], aligned_nps=[(Entity(start_offset=27, end_offset=51, type='question', text='acute hemolytic reaction', normalized_text='acute hemolytic reaction'), Entity(start_offset=72, end_offset=76, type='context', text='This', normalized_text='this')), (Entity(start_offset=16, end_offset=23, type='question', text='the rbc', normalized_text='rbc'), Entity(start_offset=140, end_offset=165, type='context', text='the donor red blood cells', normalized_text='donor red blood cells'))], explanation_type='single_sentence'),\n",
       " -1640714294501064196: QEDExample(example_id=-1640714294501064196, title='List of Dragon Ball Z episodes', question='how many episodes are there in dragon ball z', passage=\"Dragon Ball Z ( ドラゴンボール ゼット , Doragon Bōru Zetto , commonly abbreviated as DBZ ) is the long - running anime sequel to the Dragon Ball TV series , adapted from the final twenty - six volumes of the Dragon Ball manga written by Akira Toriyama . The manga portion of the series debuted in Weekly Shōnen Jump in October 4 , 1988 and lasted until 1995 ; the anime adaptation premiered in Japan on Fuji Television on April 26 , 1989 , taking over its predecessor 's time slot , and ran until its end on January 31 , 1996 , lasting 291 episodes in Japan , and 276 episodes in the United States originally , although all 291 episodes were later broadcast when content from the first 67 episodes was restored .\", sentence_starts=[0, 244], selected_sent={'start': 244, 'end': 702, 'string': \"The manga portion of the series debuted in Weekly Shōnen Jump in October 4 , 1988 and lasted until 1995 ; the anime adaptation premiered in Japan on Fuji Television on April 26 , 1989 , taking over its predecessor 's time slot , and ran until its end on January 31 , 1996 , lasting 291 episodes in Japan , and 276 episodes in the United States originally , although all 291 episodes were later broadcast when content from the first 67 episodes was restored .\"}, answer=[Entity(start_offset=526, end_offset=700, type='context', text='291 episodes in Japan , and 276 episodes in the United States originally , although all 291 episodes were later broadcast when content from the first 67 episodes was restored', normalized_text='291 episodes in japan and 276 episodes in united states originally although all 291 episodes were later broadcast when content from first 67 episodes was restored')], nq_answers=[[Entity(start_offset=526, end_offset=529, type='context', text='291', normalized_text='291')], [Entity(start_offset=526, end_offset=538, type='context', text='291 episodes', normalized_text='291 episodes')], [Entity(start_offset=614, end_offset=617, type='context', text='291', normalized_text='291')]], aligned_nps=[(Entity(start_offset=31, end_offset=44, type='question', text='dragon ball z', normalized_text='dragon ball z'), Entity(start_offset=350, end_offset=370, type='context', text='the anime adaptation', normalized_text='anime adaptation'))], explanation_type='single_sentence'),\n",
       " -3672139806378353884: QEDExample(example_id=-3672139806378353884, title='New Earswick', question='who designed the garden city of new earswick', passage=\"As a result of the report , Joseph Rowntree 's conviction that it must be possible to provide better housing for people on low incomes led him to acquire 150 acres of land near the village of Earswick , two and a half miles to the north of the centre of York . The planner Raymond Unwin and the architect Barry Parker were commissioned to produce an overall plan for a new ' garden ' village and the detailed designs for its first houses . They also designed the garden cities of Letchworth and Welwyn Garden City .\", sentence_starts=[0, 261, 440], selected_sent={'start': 261, 'end': 440, 'string': \"The planner Raymond Unwin and the architect Barry Parker were commissioned to produce an overall plan for a new ' garden ' village and the detailed designs for its first houses . \"}, answer=[Entity(start_offset=261, end_offset=317, type='context', text='The planner Raymond Unwin and the architect Barry Parker', normalized_text='planner raymond unwin and architect barry parker')], nq_answers=[[Entity(start_offset=261, end_offset=317, type='context', text='The planner Raymond Unwin and the architect Barry Parker', normalized_text='planner raymond unwin and architect barry parker')], [Entity(start_offset=265, end_offset=317, type='context', text='planner Raymond Unwin and the architect Barry Parker', normalized_text='planner raymond unwin and architect barry parker')], [Entity(start_offset=265, end_offset=286, type='context', text='planner Raymond Unwin', normalized_text='planner raymond unwin'), Entity(start_offset=295, end_offset=317, type='context', text='architect Barry Parker', normalized_text='architect barry parker')], [Entity(start_offset=273, end_offset=286, type='context', text='Raymond Unwin', normalized_text='raymond unwin')]], aligned_nps=[(Entity(start_offset=13, end_offset=44, type='question', text='the garden city of new earswick', normalized_text='garden city of new earswick'), Entity(start_offset=367, end_offset=391, type='context', text=\"a new ' garden ' village\", normalized_text='new garden village'))], explanation_type='single_sentence'),\n",
       " 6556718257422998662: QEDExample(example_id=6556718257422998662, title='Evolution of the eye', question='what is the first step in the evolution of the eye', passage=\"The earliest predecessors of the eye were photoreceptor proteins that sense light , found even in unicellular organisms , called `` eyespots '' . Eyespots can only sense ambient brightness : they can distinguish light from dark , sufficient for photoperiodism and daily synchronization of circadian rhythms . They are insufficient for vision , as they can not distinguish shapes or determine the direction light is coming from . Eyespots are found in nearly all major animal groups , and are common among unicellular organisms , including euglena . The euglena 's eyespot , called a stigma , is located at its anterior end . It is a small splotch of red pigment which shades a collection of light sensitive crystals . Together with the leading flagellum , the eyespot allows the organism to move in response to light , often toward the light to assist in photosynthesis , and to predict day and night , the primary function of circadian rhythms . Visual pigments are located in the brains of more complex organisms , and are thought to have a role in synchronising spawning with lunar cycles . By detecting the subtle changes in night - time illumination , organisms could synchronise the release of sperm and eggs to maximise the probability of fertilisation .\", sentence_starts=[0, 146, 309, 429, 549, 625, 718, 947, 1094], selected_sent={'start': 0, 'end': 146, 'string': \"The earliest predecessors of the eye were photoreceptor proteins that sense light , found even in unicellular organisms , called `` eyespots '' . \"}, answer=[Entity(start_offset=42, end_offset=81, type='context', text='photoreceptor proteins that sense light', normalized_text='photoreceptor proteins that sense light')], nq_answers=[[Entity(start_offset=42, end_offset=81, type='context', text='photoreceptor proteins that sense light', normalized_text='photoreceptor proteins that sense light')], [Entity(start_offset=132, end_offset=140, type='context', text='eyespots', normalized_text='eyespots')], [Entity(start_offset=42, end_offset=143, type='context', text=\"photoreceptor proteins that sense light , found even in unicellular organisms , called `` eyespots ''\", normalized_text='photoreceptor proteins that sense light found even in unicellular organisms called eyespots')]], aligned_nps=[(Entity(start_offset=43, end_offset=50, type='question', text='the eye', normalized_text='eye'), Entity(start_offset=29, end_offset=36, type='context', text='the eye', normalized_text='eye'))], explanation_type='single_sentence'),\n",
       " 3062778689902618642: QEDExample(example_id=3062778689902618642, title='The Curse of Oak Island', question='where is the tv show the curse of oak island filmed', passage=\"The Curse of Oak Island follows brothers Marty and Rick Lagina , originally from Kingsford , Michigan , through their efforts to find the speculated treasure or historical artifacts believed to be on Oak Island . The series discusses the history of the island , recent discoveries , theories , and prior attempts to investigate the site . Areas of interest include the `` Money Pit '' , Borehole 10 - x , Smith 's Cove , `` Nolan 's Cross '' , the `` Hatch '' , the `` Watchtower '' and the `` Swamp '' .\", sentence_starts=[0, 213, 339], selected_sent={'start': 0, 'end': 213, 'string': 'The Curse of Oak Island follows brothers Marty and Rick Lagina , originally from Kingsford , Michigan , through their efforts to find the speculated treasure or historical artifacts believed to be on Oak Island . '}, answer=[Entity(start_offset=200, end_offset=210, type='context', text='Oak Island', normalized_text='oak island')], nq_answers=[[Entity(start_offset=200, end_offset=210, type='context', text='Oak Island', normalized_text='oak island')]], aligned_nps=[(Entity(start_offset=9, end_offset=51, type='question', text='the tv show the curse of oak island filmed', normalized_text='tv show curse of oak island filmed'), Entity(start_offset=0, end_offset=23, type='context', text='The Curse of Oak Island', normalized_text='curse of oak island'))], explanation_type='single_sentence'),\n",
       " 2673329117028914160: QEDExample(example_id=2673329117028914160, title='Gallbladder', question='where is gall bladder situated in human body', passage='In vertebrates , the gallbladder is a small hollow organ where bile is stored and concentrated before it is released into the small intestine . In humans , the pear - shaped gallbladder lies beneath the liver , although the structure and position of the gallbladder can vary significantly among animal species . It receives and stores bile , produced by the liver , via the common hepatic duct , and releases it via the common bile duct into the duodenum , where the bile helps in the digestion of fats .', sentence_starts=[0, 144, 312], selected_sent={'start': 144, 'end': 312, 'string': 'In humans , the pear - shaped gallbladder lies beneath the liver , although the structure and position of the gallbladder can vary significantly among animal species . '}, answer=[Entity(start_offset=191, end_offset=208, type='context', text='beneath the liver', normalized_text='beneath liver')], nq_answers=[[Entity(start_offset=191, end_offset=208, type='context', text='beneath the liver', normalized_text='beneath liver')]], aligned_nps=[(Entity(start_offset=9, end_offset=21, type='question', text='gall bladder', normalized_text='gall bladder'), Entity(start_offset=156, end_offset=185, type='context', text='the pear - shaped gallbladder', normalized_text='pear shaped gallbladder'))], explanation_type='single_sentence'),\n",
       " -2162391145049066060: QEDExample(example_id=-2162391145049066060, title='Director of the United States Mint', question='who is the current director of the us mint', passage='The Director of the United States Mint is the head of the United States Mint . The position is currently vacant . Since January 20 , 2017 , the senior career official at the Mint has been Acting Principal Deputy Director David Motl .', sentence_starts=[0, 79, 114], selected_sent={'start': 79, 'end': 114, 'string': 'The position is currently vacant . '}, answer=[Entity(start_offset=105, end_offset=111, type='context', text='vacant', normalized_text='vacant')], nq_answers=[[Entity(start_offset=221, end_offset=231, type='context', text='David Motl', normalized_text='david motl')]], aligned_nps=[(Entity(start_offset=7, end_offset=42, type='question', text='the current director of the us mint', normalized_text='current director of us mint'), Entity(start_offset=79, end_offset=91, type='context', text='The position', normalized_text='position'))], explanation_type='single_sentence'),\n",
       " -7855437198803764135: QEDExample(example_id=-7855437198803764135, title='Lithium', question='what is the main mineral in lithium batteries', passage='Lithium and its compounds have several industrial applications , including heat - resistant glass and ceramics , lithium grease lubricants , flux additives for iron , steel and aluminium production , lithium batteries , and lithium - ion batteries . These uses consume more than three quarters of lithium production .', sentence_starts=[0, 250], selected_sent={'start': 0, 'end': 250, 'string': 'Lithium and its compounds have several industrial applications , including heat - resistant glass and ceramics , lithium grease lubricants , flux additives for iron , steel and aluminium production , lithium batteries , and lithium - ion batteries . '}, answer=[Entity(start_offset=0, end_offset=7, type='context', text='Lithium', normalized_text='lithium')], nq_answers=[[Entity(start_offset=0, end_offset=7, type='context', text='Lithium', normalized_text='lithium')]], aligned_nps=[(Entity(start_offset=28, end_offset=45, type='question', text='lithium batteries', normalized_text='lithium batteries'), Entity(start_offset=200, end_offset=217, type='context', text='lithium batteries', normalized_text='lithium batteries'))], explanation_type='single_sentence'),\n",
       " -8381009484419676852: QEDExample(example_id=-8381009484419676852, title='Adobe Flash', question='what is the use of adobe flash cs3 professional', passage=\"In 2007 , Adobe 's first version release was Adobe Flash CS3 Professional , the ninth major version of Flash . It introduced the ActionScript 3.0 programming language , which supported modern programming practices and enabled business applications to be developed with Flash . Adobe Flex Builder ( built on Eclipse ) targeted the enterprise application development market , and was also released the same year . Flex Builder included the Flex SDK , a set of components that included charting , advanced UI , and data services ( Flex Data Services ) .\", sentence_starts=[0, 111, 277, 412], selected_sent={'start': 111, 'end': 277, 'string': 'It introduced the ActionScript 3.0 programming language , which supported modern programming practices and enabled business applications to be developed with Flash . '}, answer=[Entity(start_offset=114, end_offset=274, type='context', text='introduced the ActionScript 3.0 programming language , which supported modern programming practices and enabled business applications to be developed with Flash', normalized_text='introduced actionscript 30 programming language which supported modern programming practices and enabled business applications to be developed with flash')], nq_answers=[[Entity(start_offset=175, end_offset=274, type='context', text='supported modern programming practices and enabled business applications to be developed with Flash', normalized_text='supported modern programming practices and enabled business applications to be developed with flash')]], aligned_nps=[(Entity(start_offset=19, end_offset=47, type='question', text='adobe flash cs3 professional', normalized_text='adobe flash cs3 professional'), Entity(start_offset=111, end_offset=113, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -523751984486228566: QEDExample(example_id=-523751984486228566, title='Middle cranial fossa', question='what part of the brain is in the middle cranial fossa', passage='It houses the temporal lobes of the brain and the pituitary gland . A middle fossa craniotomy is one means to surgically remove acoustic neuromas ( vestibular schwannoma ) growing within the internal auditory canal of the temporal bone .', sentence_starts=[0, 68], selected_sent={'start': 0, 'end': 68, 'string': 'It houses the temporal lobes of the brain and the pituitary gland . '}, answer=[Entity(start_offset=10, end_offset=28, type='context', text='the temporal lobes', normalized_text='temporal lobes')], nq_answers=[[Entity(start_offset=10, end_offset=28, type='context', text='the temporal lobes', normalized_text='temporal lobes')], [Entity(start_offset=14, end_offset=28, type='context', text='temporal lobes', normalized_text='temporal lobes'), Entity(start_offset=50, end_offset=65, type='context', text='pituitary gland', normalized_text='pituitary gland')], [Entity(start_offset=10, end_offset=28, type='context', text='the temporal lobes', normalized_text='temporal lobes'), Entity(start_offset=46, end_offset=65, type='context', text='the pituitary gland', normalized_text='pituitary gland')]], aligned_nps=[(Entity(start_offset=29, end_offset=53, type='question', text='the middle cranial fossa', normalized_text='middle cranial fossa'), Entity(start_offset=0, end_offset=2, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -1573340396671826912: QEDExample(example_id=-1573340396671826912, title='The Outsiders (novel)', question='where do the greasers live in the outsiders', passage='The story in the book takes place in Tulsa , Oklahoma , in 1965 , but this is never explicitly stated in the book .', sentence_starts=[0], selected_sent={'start': 0, 'end': 115, 'string': 'The story in the book takes place in Tulsa , Oklahoma , in 1965 , but this is never explicitly stated in the book .'}, answer=[Entity(start_offset=37, end_offset=53, type='context', text='Tulsa , Oklahoma', normalized_text='tulsa oklahoma')], nq_answers=[[Entity(start_offset=37, end_offset=53, type='context', text='Tulsa , Oklahoma', normalized_text='tulsa oklahoma')]], aligned_nps=[(Entity(start_offset=30, end_offset=43, type='question', text='the outsiders', normalized_text='outsiders'), Entity(start_offset=13, end_offset=21, type='context', text='the book', normalized_text='book'))], explanation_type='single_sentence'),\n",
       " -6560319052930436991: QEDExample(example_id=-6560319052930436991, title=\"Flight (Grey's Anatomy)\", question='who died in the plane crash greys anatomy', passage=\"`` Flight '' is the twenty - fourth and final episode of the eighth season of the American television medical drama Grey 's Anatomy , and the show 's 172nd episode overall . It was written by series creator Shonda Rhimes , and directed by Rob Corn . The episode was originally broadcast on the American Broadcasting Company ( ABC ) in the United States on May 17 , 2012 . In the episode , six doctors from Seattle Grace Mercy West Hospital who are victims of an aviation accident fight to stay alive , but Dr. Lexie Grey ( Chyler Leigh ) ultimately dies . Other storylines occur in Seattle where Dr. Richard Webber ( James Pickens , Jr . ) plans his annual dinner for the departing residents , Dr. Owen Hunt ( Kevin McKidd ) fires Dr. Teddy Altman ( Kim Raver ) , and Dr. Miranda Bailey ( Chandra Wilson ) gets engaged .\", sentence_starts=[0, 174, 250, 372, 556], selected_sent={'start': 372, 'end': 556, 'string': 'In the episode , six doctors from Seattle Grace Mercy West Hospital who are victims of an aviation accident fight to stay alive , but Dr. Lexie Grey ( Chyler Leigh ) ultimately dies . '}, answer=[Entity(start_offset=506, end_offset=520, type='context', text='Dr. Lexie Grey', normalized_text='dr lexie grey')], nq_answers=[[Entity(start_offset=506, end_offset=520, type='context', text='Dr. Lexie Grey', normalized_text='dr lexie grey')], [Entity(start_offset=506, end_offset=537, type='context', text='Dr. Lexie Grey ( Chyler Leigh )', normalized_text='dr lexie grey chyler leigh')]], aligned_nps=[(Entity(start_offset=12, end_offset=27, type='question', text='the plane crash', normalized_text='plane crash'), Entity(start_offset=459, end_offset=479, type='context', text='an aviation accident', normalized_text='aviation accident')), (Entity(start_offset=28, end_offset=41, type='question', text='greys anatomy', normalized_text='greys anatomy'), Entity(start_offset=375, end_offset=386, type='context', text='the episode', normalized_text='episode'))], explanation_type='single_sentence'),\n",
       " 1658149178541467525: QEDExample(example_id=1658149178541467525, title='Hops', question='where do they grow hops in the us', passage=\"Hops production is concentrated in moist temperate climates , with much of the world 's production occurring near the 48th parallel north . Hop plants prefer the same soils as potatoes and the leading potato - growing states in the United States are also major hops - producing areas ; however , not all potato - growing areas can produce good hops naturally : soils in the Maritime Provinces of Canada , for example , lack the boron that hops prefer . Historically , hops were not grown in Ireland , but were imported from England . In 1752 more than 500 tons of English hops were imported through Dublin alone .\", sentence_starts=[0, 140, 453, 534], selected_sent={'start': 140, 'end': 453, 'string': 'Hop plants prefer the same soils as potatoes and the leading potato - growing states in the United States are also major hops - producing areas ; however , not all potato - growing areas can produce good hops naturally : soils in the Maritime Provinces of Canada , for example , lack the boron that hops prefer . '}, answer=[Entity(start_offset=189, end_offset=224, type='context', text='the leading potato - growing states', normalized_text='leading potato growing states')], nq_answers=[[Entity(start_offset=189, end_offset=245, type='context', text='the leading potato - growing states in the United States', normalized_text='leading potato growing states in united states')]], aligned_nps=[(Entity(start_offset=19, end_offset=23, type='question', text='hops', normalized_text='hops'), Entity(start_offset=140, end_offset=150, type='context', text='Hop plants', normalized_text='hop plants')), (Entity(start_offset=27, end_offset=33, type='question', text='the us', normalized_text='us'), Entity(start_offset=228, end_offset=245, type='context', text='the United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " -8463303168185775472: QEDExample(example_id=-8463303168185775472, title='List of Tom and Jerry characters', question=\"what's the dog's name on tom and jerry\", passage=\"Spike , occasionally referred to as Butch or Killer , is a stern but occasionally dumb American bulldog who is particularly disapproving of cats , but a softie when it comes to mice ( though in his debut appearance , Dog Trouble , Spike goes after both Tom and Jerry ) , and later , his son Tyke . In the shorts Jerry would often try to get Tom in trouble with Spike making him a shoo - in for a beating from the bulldog . Spike has a few weaknesses that Tom tries to capitalize upon : his possessiveness about his bone and his ticklishness . He made his first appearance in the 1942 Tom and Jerry cartoon Dog Trouble , and his first speaking role was in 1944 's The Bodyguard , where he was voiced by Billy Bletcher up until 1949 , from which point he was voiced by Daws Butler . Unlike his father Spike , Tyke does not speak . He only communicates by yapping , whimpering , growling , facial expressions and wagging his tail . In Tom and Jerry Kids , Tyke does have a speaking role in the program and is the first time that viewers were able to hear Tyke speak . Spike is very protective towards his son and gets very angry at Tom if Tyke is bothered or harmed . Although Tyke has spoken in Tom and Jerry Kids , he has laughed in one Tom and Jerry short . After Daws Butler , Maurice LaMarche , Frank Welker , John DiMaggio , Michael Donovan , Phil LaMarr and currently Rick Zieff would all perform Spike 's voice . Tyke 's vocal effects are provided by Frank Welker and speaking roles by Patric Zimmerman .\", sentence_starts=[0, 298, 423, 543, 781, 829, 929, 1065, 1165, 1258, 1418], selected_sent={'start': 0, 'end': 298, 'string': 'Spike , occasionally referred to as Butch or Killer , is a stern but occasionally dumb American bulldog who is particularly disapproving of cats , but a softie when it comes to mice ( though in his debut appearance , Dog Trouble , Spike goes after both Tom and Jerry ) , and later , his son Tyke . '}, answer=[Entity(start_offset=0, end_offset=5, type='context', text='Spike', normalized_text='spike')], nq_answers=[[Entity(start_offset=0, end_offset=5, type='context', text='Spike', normalized_text='spike')], [Entity(start_offset=0, end_offset=51, type='context', text='Spike , occasionally referred to as Butch or Killer', normalized_text='spike occasionally referred to as butch or killer')]], aligned_nps=[(Entity(start_offset=7, end_offset=14, type='question', text='the dog', normalized_text='dog'), Entity(start_offset=57, end_offset=103, type='context', text='a stern but occasionally dumb American bulldog', normalized_text='stern but occasionally dumb american bulldog')), (Entity(start_offset=25, end_offset=38, type='question', text='tom and jerry', normalized_text='tom and jerry'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 6558406970363500511: QEDExample(example_id=6558406970363500511, title='What Ifs', question='where was the music video what ifs filmed', passage='The official music video for the song was directed by P.R. Brown and produced by Steve Lamar . The video was filmed along the Californian coast at The Inn at Newport Ranch , a resort and cattle ranch to the north of San Francisco . It features Brown and his duet partner Lauren Alaina singing along the coast . It was released on May 14 , 2017 . An earlier lyric video was first released on May 4 , 2017 , and shows Brown and Alaina cruising down a road .', sentence_starts=[0, 59, 95, 232, 311, 346], selected_sent={'start': 95, 'end': 232, 'string': 'The video was filmed along the Californian coast at The Inn at Newport Ranch , a resort and cattle ranch to the north of San Francisco . '}, answer=[Entity(start_offset=116, end_offset=229, type='context', text='along the Californian coast at The Inn at Newport Ranch , a resort and cattle ranch to the north of San Francisco', normalized_text='along californian coast at inn at newport ranch resort and cattle ranch to north of san francisco')], nq_answers=[[Entity(start_offset=116, end_offset=229, type='context', text='along the Californian coast at The Inn at Newport Ranch , a resort and cattle ranch to the north of San Francisco', normalized_text='along californian coast at inn at newport ranch resort and cattle ranch to north of san francisco')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text='the music video what ifs', normalized_text='music video what ifs'), Entity(start_offset=95, end_offset=104, type='context', text='The video', normalized_text='video'))], explanation_type='single_sentence'),\n",
       " -461258131989129967: QEDExample(example_id=-461258131989129967, title='Petroleum industry in Nigeria', question='in which regions are most of africa petroleum and natural gas found', passage='Nigeria is the largest oil and gas producer in Africa . Crude oil from the delta basin comes in two types : light , and comparatively heavy -- the lighter around 36 gravity and the heavier , 20 -- 25 gravity . Both types are paraffinic and low in sulfur .', sentence_starts=[0, 56, 210], selected_sent={'start': 0, 'end': 56, 'string': 'Nigeria is the largest oil and gas producer in Africa . '}, answer=[Entity(start_offset=0, end_offset=7, type='context', text='Nigeria', normalized_text='nigeria')], nq_answers=[[Entity(start_offset=0, end_offset=7, type='context', text='Nigeria', normalized_text='nigeria')]], aligned_nps=[(Entity(start_offset=29, end_offset=35, type='question', text='africa', normalized_text='africa'), Entity(start_offset=47, end_offset=53, type='context', text='Africa', normalized_text='africa'))], explanation_type='single_sentence'),\n",
       " -4876736938910486341: QEDExample(example_id=-4876736938910486341, title='Pearl', question='in which sea pearl is found in india', passage=\"For thousands of years , seawater pearls were retrieved by divers in the Indian Ocean in areas such as the Persian Gulf , the Red Sea and the Gulf of Mannar . Evidence also suggest a prehistoric origin to pearl diving in these regions . Starting in the Han Dynasty ( 206 BC -- 220 AD ) , the Chinese hunted extensively for seawater pearls in the South China Sea . In the 14th - century Arabian Sea , the traveller Ibn Battuta provided the earliest known description of pearl diving by means of attaching a cord to the diver 's waist .\", sentence_starts=[0, 159, 237, 364], selected_sent={'start': 0, 'end': 159, 'string': 'For thousands of years , seawater pearls were retrieved by divers in the Indian Ocean in areas such as the Persian Gulf , the Red Sea and the Gulf of Mannar . '}, answer=[Entity(start_offset=73, end_offset=85, type='context', text='Indian Ocean', normalized_text='indian ocean')], nq_answers=[[Entity(start_offset=69, end_offset=85, type='context', text='the Indian Ocean', normalized_text='indian ocean')]], aligned_nps=[(Entity(start_offset=13, end_offset=18, type='question', text='pearl', normalized_text='pearl'), Entity(start_offset=25, end_offset=40, type='context', text='seawater pearls', normalized_text='seawater pearls'))], explanation_type='single_sentence'),\n",
       " -3617870338472078590: QEDExample(example_id=-3617870338472078590, title='Kylo Ren', question=\"where does kylo ren's name come from\", passage=\"Abrams told Empire in August 2015 , `` Kylo Ren is not a Sith . He works under Supreme Leader Snoke , who is a powerful figure on the Dark Side of the Force . '' Abrams had previously told Entertainment Weekly that the character , `` came to the name Kylo Ren when he joined a group called the Knights of Ren . '' Robbie Collin of The Telegraph described Ren as `` a hot - headed , radicalised Dark Side jihadi , whose red lightsaber splutters and crackles as violently as his temper '' . Abrams noted , `` The lightsaber is something that he built himself , and is as dangerous and as fierce and as ragged as the character . '' The Telegraph also explains that Ren 's wild and erratic temper and `` angsty '' instability make him dangerous . Melissa Leon of The Daily Beast describes Ren 's use of the Force as `` formidable '' , citing his ability to stop a blaster shot mid-air , immobilize victims and probe their minds against their will .\", sentence_starts=[0, 64, 162, 314, 489, 629, 743], selected_sent={'start': 162, 'end': 314, 'string': \"Abrams had previously told Entertainment Weekly that the character , `` came to the name Kylo Ren when he joined a group called the Knights of Ren . '' \"}, answer=[Entity(start_offset=260, end_offset=308, type='context', text='when he joined a group called the Knights of Ren', normalized_text='when he joined group called knights of ren')], nq_answers=[[Entity(start_offset=215, end_offset=313, type='context', text=\"the character , `` came to the name Kylo Ren when he joined a group called the Knights of Ren . ''\", normalized_text='character came to name kylo ren when he joined group called knights of ren')]], aligned_nps=[(Entity(start_offset=11, end_offset=26, type='question', text=\"kylo ren's name\", normalized_text='kylo rens name'), Entity(start_offset=242, end_offset=259, type='context', text='the name Kylo Ren', normalized_text='name kylo ren'))], explanation_type='single_sentence'),\n",
       " -5202826780373179694: QEDExample(example_id=-5202826780373179694, title='Jeep', question='what type of car is a jeep considered', passage=\"Jeep 's current product range consists solely of sport utility vehicles and off - road vehicles , but has also included pickup trucks in the past . Some of Jeep 's vehicles , such as the Grand Cherokee and the Wagoneer , reach into the luxury segment . Jeep sold 1.4 million SUVs globally in 2016 , up from 500,000 in 2008 , two - thirds of which in North America , and was Fiat - Chrysler 's best selling brand in the U.S. during the first half of 2017 . In the U.S. alone , over 2400 dealerships hold franchise rights to sell Jeep - branded vehicles , and if Jeep were spun off into a separate company , it is estimated to be worth between $22 and $33.5 billion -- slightly more than all of FCA ( US ) .\", sentence_starts=[0, 148, 253, 456], selected_sent={'start': 0, 'end': 148, 'string': \"Jeep 's current product range consists solely of sport utility vehicles and off - road vehicles , but has also included pickup trucks in the past . \"}, answer=[Entity(start_offset=49, end_offset=95, type='context', text='sport utility vehicles and off - road vehicles', normalized_text='sport utility vehicles and off road vehicles')], nq_answers=[[Entity(start_offset=49, end_offset=71, type='context', text='sport utility vehicles', normalized_text='sport utility vehicles'), Entity(start_offset=76, end_offset=95, type='context', text='off - road vehicles', normalized_text='off road vehicles')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2324745743680584211: QEDExample(example_id=2324745743680584211, title='Eastern coastal plains', question='where are the coastal plains of india situated', passage='The Eastern Coastal Plains refers to a wide stretch of landmass of India , lying between the Eastern Ghats and the Bay of Bengal . It is wider and leveled than the western coastal plains and stretches from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha . Chilka Lake is a brackish water lake along the eastern coastal plain . It lies in the state of Odisha and stretches to the south of the Mahanadi Delta .', sentence_starts=[0, 131, 294, 365], selected_sent={'start': 0, 'end': 131, 'string': 'The Eastern Coastal Plains refers to a wide stretch of landmass of India , lying between the Eastern Ghats and the Bay of Bengal . '}, answer=[Entity(start_offset=81, end_offset=128, type='context', text='between the Eastern Ghats and the Bay of Bengal', normalized_text='between eastern ghats and bay of bengal')], nq_answers=[[Entity(start_offset=81, end_offset=128, type='context', text='between the Eastern Ghats and the Bay of Bengal', normalized_text='between eastern ghats and bay of bengal')], [Entity(start_offset=201, end_offset=291, type='context', text='from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha', normalized_text='from tamil nadu in south to west bengal in north through andhra pradesh and odisha')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text='the coastal plains of india', normalized_text='coastal plains of india'), Entity(start_offset=0, end_offset=26, type='context', text='The Eastern Coastal Plains', normalized_text='eastern coastal plains'))], explanation_type='single_sentence'),\n",
       " -8650104853556692961: QEDExample(example_id=-8650104853556692961, title='Manchester United F.C.', question='what is the name of manchester united stadium', passage=\"Manchester United Football Club is a professional football club based in Old Trafford , Greater Manchester , England , that competes in the Premier League , the top flight of English football . Nicknamed `` the Red Devils '' , the club was founded as Newton Heath LYR Football Club in 1878 , changed its name to Manchester United in 1902 and moved to its current stadium , Old Trafford , in 1910 .\", sentence_starts=[0, 194], selected_sent={'start': 194, 'end': 397, 'string': \"Nicknamed `` the Red Devils '' , the club was founded as Newton Heath LYR Football Club in 1878 , changed its name to Manchester United in 1902 and moved to its current stadium , Old Trafford , in 1910 .\"}, answer=[Entity(start_offset=373, end_offset=385, type='context', text='Old Trafford', normalized_text='old trafford')], nq_answers=[[Entity(start_offset=73, end_offset=85, type='context', text='Old Trafford', normalized_text='old trafford')], [Entity(start_offset=373, end_offset=385, type='context', text='Old Trafford', normalized_text='old trafford')]], aligned_nps=[(Entity(start_offset=20, end_offset=45, type='question', text='manchester united stadium', normalized_text='manchester united stadium'), Entity(start_offset=351, end_offset=370, type='context', text='its current stadium', normalized_text='its current stadium'))], explanation_type='single_sentence'),\n",
       " -5670674709553776773: QEDExample(example_id=-5670674709553776773, title='The Proud Family (soundtrack)', question='who sings the theme song for the proud family', passage=\"The Proud Family is a soundtrack album for the show of the same name . A combination of both original tunes by the characters in the show , popular hits by popular music artists such as Alicia Keys , Jhené Aiko , India Arie , and Solange Knowles & Destiny 's Child ( who perform the theme song ) , and classic soul music from artists such as Aretha Franklin and The O'Jays .\", sentence_starts=[0, 71], selected_sent={'start': 71, 'end': 374, 'string': \"A combination of both original tunes by the characters in the show , popular hits by popular music artists such as Alicia Keys , Jhené Aiko , India Arie , and Solange Knowles & Destiny 's Child ( who perform the theme song ) , and classic soul music from artists such as Aretha Franklin and The O'Jays .\"}, answer=[Entity(start_offset=248, end_offset=264, type='context', text=\"Destiny 's Child\", normalized_text='destiny s child')], nq_answers=[[Entity(start_offset=248, end_offset=264, type='context', text=\"Destiny 's Child\", normalized_text='destiny s child')], [Entity(start_offset=230, end_offset=245, type='context', text='Solange Knowles', normalized_text='solange knowles'), Entity(start_offset=248, end_offset=264, type='context', text=\"Destiny 's Child\", normalized_text='destiny s child')], [Entity(start_offset=230, end_offset=245, type='context', text='Solange Knowles', normalized_text='solange knowles'), Entity(start_offset=230, end_offset=245, type='context', text='Solange Knowles', normalized_text='solange knowles')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='the theme song for the proud family', normalized_text='theme song for proud family'), Entity(start_offset=279, end_offset=293, type='context', text='the theme song', normalized_text='theme song'))], explanation_type='single_sentence'),\n",
       " 3723628014502752965: QEDExample(example_id=3723628014502752965, title=\"Can't Get You Out of My Head\", question='who wrote cant get you out of my head lyrics', passage=\"`` Ca n't Get You Out of My Head '' is a song recorded by Australian singer Kylie Minogue for her eighth studio album , titled Fever , which she released in 2001 . The song was released in Australia by Parlophone as the lead single from the album on 8 September 2001 . It was released on 17 September 2001 in the United Kingdom . In the United States , the single was released on 18 February 2002 . Jointly written , composed , and produced by Cathy Dennis and Rob Davis , `` Ca n't Get You Out of My Head '' is a midtempo dance - pop song which lyrically details its narrator 's obsession towards her lover . The song is famous for its `` la la la '' hook .\", sentence_starts=[0, 164, 269, 330, 399, 610], selected_sent={'start': 399, 'end': 610, 'string': \"Jointly written , composed , and produced by Cathy Dennis and Rob Davis , `` Ca n't Get You Out of My Head '' is a midtempo dance - pop song which lyrically details its narrator 's obsession towards her lover . \"}, answer=[Entity(start_offset=444, end_offset=470, type='context', text='Cathy Dennis and Rob Davis', normalized_text='cathy dennis and rob davis')], nq_answers=[[Entity(start_offset=444, end_offset=470, type='context', text='Cathy Dennis and Rob Davis', normalized_text='cathy dennis and rob davis')], [Entity(start_offset=444, end_offset=456, type='context', text='Cathy Dennis', normalized_text='cathy dennis'), Entity(start_offset=461, end_offset=470, type='context', text='Rob Davis', normalized_text='rob davis')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text='cant get you out of my head', normalized_text='cant get you out of my head'), Entity(start_offset=476, end_offset=505, type='context', text=\"Ca n't Get You Out of My Head\", normalized_text='ca nt get you out of my head'))], explanation_type='single_sentence'),\n",
       " -5944168583179757903: QEDExample(example_id=-5944168583179757903, title='Hamlet', question='who did shakespeare write his play hamlet for', passage=\"The story of Shakespeare 's Hamlet was derived from the legend of Amleth , preserved by 13th - century chronicler Saxo Grammaticus in his Gesta Danorum , as subsequently retold by the 16th - century scholar François de Belleforest . Shakespeare may also have drawn on an earlier Elizabethan play known today as the Ur - Hamlet , though some scholars believe he himself wrote the Ur - Hamlet , later revising it to create the version of Hamlet we now have . He almost certainly wrote his version of the title role for his fellow actor , Richard Burbage , the leading tragedian of Shakespeare 's time . In the 400 years since its inception , the role has been performed by numerous highly acclaimed actors in each successive century .\", sentence_starts=[0, 233, 457, 601], selected_sent={'start': 457, 'end': 601, 'string': \"He almost certainly wrote his version of the title role for his fellow actor , Richard Burbage , the leading tragedian of Shakespeare 's time . \"}, answer=[Entity(start_offset=517, end_offset=598, type='context', text=\"his fellow actor , Richard Burbage , the leading tragedian of Shakespeare 's time\", normalized_text='his fellow actor richard burbage leading tragedian of shakespeare s time')], nq_answers=[[Entity(start_offset=460, end_offset=551, type='context', text='almost certainly wrote his version of the title role for his fellow actor , Richard Burbage', normalized_text='almost certainly wrote his version of title role for his fellow actor richard burbage')], [Entity(start_offset=517, end_offset=551, type='context', text='his fellow actor , Richard Burbage', normalized_text='his fellow actor richard burbage')], [Entity(start_offset=513, end_offset=598, type='context', text=\"for his fellow actor , Richard Burbage , the leading tragedian of Shakespeare 's time\", normalized_text='for his fellow actor richard burbage leading tragedian of shakespeare s time')]], aligned_nps=[(Entity(start_offset=8, end_offset=19, type='question', text='shakespeare', normalized_text='shakespeare'), Entity(start_offset=457, end_offset=459, type='context', text='He', normalized_text='he')), (Entity(start_offset=26, end_offset=41, type='question', text='his play hamlet', normalized_text='his play hamlet'), Entity(start_offset=483, end_offset=512, type='context', text='his version of the title role', normalized_text='his version of title role'))], explanation_type='single_sentence'),\n",
       " -4825429046585874047: QEDExample(example_id=-4825429046585874047, title='The Great Gatsby', question='where does the story the great gatsby take place', passage=\"The Great Gatsby is a 1925 novel written by American author F. Scott Fitzgerald that follows a cast of characters living in the fictional town of West Egg on prosperous Long Island in the summer of 1922 . The story primarily concerns the young and mysterious millionaire Jay Gatsby and his quixotic passion and obsession for the beautiful former debutante Daisy Buchanan . Considered to be Fitzgerald 's magnum opus , The Great Gatsby explores themes of decadence , idealism , resistance to change , social upheaval , and excess , creating a portrait of the Jazz Age or the Roaring Twenties that has been described as a cautionary tale regarding the American Dream .\", sentence_starts=[0, 205, 373], selected_sent={'start': 0, 'end': 205, 'string': 'The Great Gatsby is a 1925 novel written by American author F. Scott Fitzgerald that follows a cast of characters living in the fictional town of West Egg on prosperous Long Island in the summer of 1922 . '}, answer=[Entity(start_offset=124, end_offset=180, type='context', text='the fictional town of West Egg on prosperous Long Island', normalized_text='fictional town of west egg on prosperous long island')], nq_answers=[[Entity(start_offset=124, end_offset=180, type='context', text='the fictional town of West Egg on prosperous Long Island', normalized_text='fictional town of west egg on prosperous long island')]], aligned_nps=[(Entity(start_offset=11, end_offset=37, type='question', text='the story the great gatsby', normalized_text='story great gatsby'), Entity(start_offset=0, end_offset=16, type='context', text='The Great Gatsby', normalized_text='great gatsby'))], explanation_type='single_sentence'),\n",
       " -4316845615436935736: QEDExample(example_id=-4316845615436935736, title='The Mother (How I Met Your Mother)', question='who turned out to be the mother on how i met your mother', passage=\"Tracy McConnell , better known as `` The Mother '' , is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to a main character in season 9 . The Mother is played by Cristin Milioti .\", sentence_starts=[0, 131, 217, 430], selected_sent={'start': 0, 'end': 131, 'string': \"Tracy McConnell , better known as `` The Mother '' , is the title character from the CBS television sitcom How I Met Your Mother . \"}, answer=[Entity(start_offset=0, end_offset=15, type='context', text='Tracy McConnell', normalized_text='tracy mcconnell')], nq_answers=[[Entity(start_offset=0, end_offset=15, type='context', text='Tracy McConnell', normalized_text='tracy mcconnell')], [Entity(start_offset=217, end_offset=232, type='context', text='Tracy McConnell', normalized_text='tracy mcconnell')]], aligned_nps=[(Entity(start_offset=21, end_offset=31, type='question', text='the mother', normalized_text='mother'), Entity(start_offset=37, end_offset=47, type='context', text='The Mother', normalized_text='mother')), (Entity(start_offset=35, end_offset=56, type='question', text='how i met your mother', normalized_text='how i met your mother'), Entity(start_offset=81, end_offset=128, type='context', text='the CBS television sitcom How I Met Your Mother', normalized_text='cbs television sitcom how i met your mother'))], explanation_type='single_sentence'),\n",
       " 4627523927977896713: QEDExample(example_id=4627523927977896713, title='United Kingdom corporation tax', question='what is the corporate tax rate in great britain', passage=\"Originally introduced as a classical tax system , in which companies were subject to tax on their profits and companies ' shareholders were also liable to income tax on the dividends that they received , the first major amendment to corporation tax saw it move to a dividend imputation system in 1973 , under which an individual receiving a dividend became entitled to an income tax credit representing the corporation tax already paid by the company paying the dividend . The classical system was reintroduced in 1999 , with the abolition of advance corporation tax and of repayable dividend tax credits . Another change saw the single main rate of tax split into three . Tax competition between jurisdictions reduced the main corporate tax rate from 28 % in 2008 - 2010 to a flat rate of 20 % as of April 2015 .\", sentence_starts=[0, 473, 607, 673], selected_sent={'start': 673, 'end': 813, 'string': 'Tax competition between jurisdictions reduced the main corporate tax rate from 28 % in 2008 - 2010 to a flat rate of 20 % as of April 2015 .'}, answer=[Entity(start_offset=790, end_offset=794, type='context', text='20 %', normalized_text='20')], nq_answers=[[Entity(start_offset=775, end_offset=794, type='context', text='a flat rate of 20 %', normalized_text='flat rate of 20')], [Entity(start_offset=790, end_offset=794, type='context', text='20 %', normalized_text='20')]], aligned_nps=[(Entity(start_offset=8, end_offset=47, type='question', text='the corporate tax rate in great britain', normalized_text='corporate tax rate in great britain'), Entity(start_offset=719, end_offset=746, type='context', text='the main corporate tax rate', normalized_text='main corporate tax rate'))], explanation_type='single_sentence'),\n",
       " -1832461906521344120: QEDExample(example_id=-1832461906521344120, title='Sinéad', question='what is the meaning of the name sinead', passage=\"Sinéad ( / ʃɪˈneɪd / shi - NADE ; Irish pronunciation : ( ˈʃɪnjeːd̪ɣ ) or ( ʃɪˈnjeːd̪ɣ ) ) , is an Irish feminine name . It is derived from the French Jeanette , which is cognate to the English Janet , itself a feminine form of the Hebrew Yohannan , `` God forgave / God gratified '' . In English , Sinéad is also commonly spelled Sinead . The name is generally translated into English as either Jane or Jennifer , or as the female version of the Scottish name Jean .\", sentence_starts=[0, 121, 286, 340], selected_sent={'start': 121, 'end': 286, 'string': \"It is derived from the French Jeanette , which is cognate to the English Janet , itself a feminine form of the Hebrew Yohannan , `` God forgave / God gratified '' . \"}, answer=[Entity(start_offset=253, end_offset=280, type='context', text='God forgave / God gratified', normalized_text='god forgave god gratified')], nq_answers=[[Entity(start_offset=253, end_offset=280, type='context', text='God forgave / God gratified', normalized_text='god forgave god gratified')]], aligned_nps=[(Entity(start_offset=23, end_offset=38, type='question', text='the name sinead', normalized_text='name sinead'), Entity(start_offset=121, end_offset=123, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 595996307760943345: QEDExample(example_id=595996307760943345, title='Beijing', question='what was the city of beijing previously known as', passage=\"Beijing ( / beɪˈdʒɪŋ / ; Mandarin : ( pèi. tɕíŋ ) ( listen ) ) , formerly romanized as Peking , is the capital of the People 's Republic of China , the world 's second most populous city proper , and most populous capital city . The city , located in northern China , is governed as a direct - controlled municipality under the national government with 16 urban , suburban , and rural districts . Beijing Municipality is surrounded by Hebei Province with the exception of neighboring Tianjin Municipality to the southeast ; together the three divisions form the Jingjinji metropolitan region and the national capital region of China .\", sentence_starts=[0, 229, 397], selected_sent={'start': 0, 'end': 229, 'string': \"Beijing ( / beɪˈdʒɪŋ / ; Mandarin : ( pèi. tɕíŋ ) ( listen ) ) , formerly romanized as Peking , is the capital of the People 's Republic of China , the world 's second most populous city proper , and most populous capital city . \"}, answer=[Entity(start_offset=87, end_offset=93, type='context', text='Peking', normalized_text='peking')], nq_answers=[[Entity(start_offset=87, end_offset=93, type='context', text='Peking', normalized_text='peking')]], aligned_nps=[(Entity(start_offset=9, end_offset=28, type='question', text='the city of beijing', normalized_text='city of beijing'), Entity(start_offset=0, end_offset=7, type='context', text='Beijing', normalized_text='beijing'))], explanation_type='single_sentence'),\n",
       " 7152569300818483186: QEDExample(example_id=7152569300818483186, title='The Divergent Series', question='when is the fourth movie of the divergent series coming out', passage=\"The first installment , Divergent ( 2014 ) , grossed over $288 million worldwide , while the second installment , The Divergent Series : Insurgent ( 2015 ) , grossed over $297 million worldwide . Insurgent was also the first Divergent film to be released in IMAX 3D . The third installment , The Divergent Series : Allegiant ( 2016 ) , grossed $179 million . Thus , the first three films of the series have grossed over $765 million worldwide . A fourth film , The Divergent Series : Ascendant was never made , due to Allegiant 's poor showing at the box office .\", sentence_starts=[0, 196, 268, 359, 445], selected_sent={'start': 445, 'end': 563, 'string': \"A fourth film , The Divergent Series : Ascendant was never made , due to Allegiant 's poor showing at the box office .\"}, answer=[Entity(start_offset=498, end_offset=508, type='context', text='never made', normalized_text='never made')], nq_answers=[[Entity(start_offset=498, end_offset=508, type='context', text='never made', normalized_text='never made')]], aligned_nps=[(Entity(start_offset=8, end_offset=48, type='question', text='the fourth movie of the divergent series', normalized_text='fourth movie of divergent series'), Entity(start_offset=461, end_offset=493, type='context', text='The Divergent Series : Ascendant', normalized_text='divergent series ascendant'))], explanation_type='single_sentence'),\n",
       " -7115492812897878586: QEDExample(example_id=-7115492812897878586, title='Republic of Doyle', question='where is republic of doyle supposed to take place', passage=\"Republic of Doyle is a Canadian comedy - drama television series set in St. John 's , Newfoundland and Labrador which aired on CBC Television from January 6 , 2010 to December 10 , 2014 .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 187, 'string': \"Republic of Doyle is a Canadian comedy - drama television series set in St. John 's , Newfoundland and Labrador which aired on CBC Television from January 6 , 2010 to December 10 , 2014 .\"}, answer=[Entity(start_offset=72, end_offset=111, type='context', text=\"St. John 's , Newfoundland and Labrador\", normalized_text='st john s newfoundland and labrador')], nq_answers=[[Entity(start_offset=72, end_offset=111, type='context', text=\"St. John 's , Newfoundland and Labrador\", normalized_text='st john s newfoundland and labrador')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='republic of doyle', normalized_text='republic of doyle'), Entity(start_offset=0, end_offset=17, type='context', text='Republic of Doyle', normalized_text='republic of doyle'))], explanation_type='single_sentence'),\n",
       " -7299076255108845857: QEDExample(example_id=-7299076255108845857, title='Sentencing Reform Act', question='what is the sentencing reform act of 1984', passage=\"The Sentencing Reform Act , part of the Comprehensive Crime Control Act of 1984 , was a U.S. federal statute intended to increase consistency in United States federal sentencing . It established the United States Sentencing Commission . It also abolished federal parole , except for persons convicted under federal law before November 1 , 1987 , persons convicted under District of Columbia law , `` transfer treaty '' inmates , persons who violated military law who are in federal civilian prisons , and persons who are defendants in state cases and who are under the U.S. Marshals Service Witness Protection Program .\", sentence_starts=[0, 180, 237], selected_sent={'start': 0, 'end': 180, 'string': 'The Sentencing Reform Act , part of the Comprehensive Crime Control Act of 1984 , was a U.S. federal statute intended to increase consistency in United States federal sentencing . '}, answer=[Entity(start_offset=86, end_offset=177, type='context', text='a U.S. federal statute intended to increase consistency in United States federal sentencing', normalized_text='us federal statute intended to increase consistency in united states federal sentencing')], nq_answers=[[Entity(start_offset=88, end_offset=177, type='context', text='U.S. federal statute intended to increase consistency in United States federal sentencing', normalized_text='us federal statute intended to increase consistency in united states federal sentencing')], [Entity(start_offset=86, end_offset=177, type='context', text='a U.S. federal statute intended to increase consistency in United States federal sentencing', normalized_text='us federal statute intended to increase consistency in united states federal sentencing')]], aligned_nps=[(Entity(start_offset=8, end_offset=41, type='question', text='the sentencing reform act of 1984', normalized_text='sentencing reform act of 1984'), Entity(start_offset=0, end_offset=25, type='context', text='The Sentencing Reform Act', normalized_text='sentencing reform act'))], explanation_type='single_sentence'),\n",
       " 7983190845818424390: QEDExample(example_id=7983190845818424390, title='Succession to the British throne', question='who will take the throne after the queen dies', passage=\"Queen Elizabeth II is the sovereign , and her heir apparent is her eldest son , Charles , Prince of Wales . Next in line after him is Prince William , Duke of Cambridge , the Prince of Wales 's elder son . Third in line is Prince George , the eldest child of the Duke of Cambridge , followed by his sister , Princess Charlotte and younger brother , Prince Louis . Sixth in line is Prince Henry of Wales , the younger son of the Prince of Wales . Any of the first six in line marrying without the sovereign 's consent would be disqualified from succession .\", sentence_starts=[0, 108, 206, 364, 446], selected_sent={'start': 0, 'end': 108, 'string': 'Queen Elizabeth II is the sovereign , and her heir apparent is her eldest son , Charles , Prince of Wales . '}, answer=[Entity(start_offset=80, end_offset=105, type='context', text='Charles , Prince of Wales', normalized_text='charles prince of wales')], nq_answers=[[Entity(start_offset=80, end_offset=105, type='context', text='Charles , Prince of Wales', normalized_text='charles prince of wales')], [Entity(start_offset=63, end_offset=105, type='context', text='her eldest son , Charles , Prince of Wales', normalized_text='her eldest son charles prince of wales')]], aligned_nps=[(Entity(start_offset=31, end_offset=40, type='question', text='the queen', normalized_text='queen'), Entity(start_offset=0, end_offset=18, type='context', text='Queen Elizabeth II', normalized_text='queen elizabeth ii'))], explanation_type='single_sentence'),\n",
       " 3349644992728619890: QEDExample(example_id=3349644992728619890, title='21 Guns (song)', question='who is the girl in green day 21 guns', passage=\"The video takes place with the band and the album 's two protagonists Christian ( Josh Boswell ) and Gloria ( Lisa Stelly ) taking refuge in a white room after robbing a bank . The police arrive outside the room and open fire through the window , to the couple 's terror . As bullets rain through the room , the band continues playing . Gloria picks up the phone and throws it into a fish tank . As the bullets continue to fly and tear apart the room , Christian and Gloria become calm and walk toward each other , unharmed by the bullets . They embrace and kiss as the room goes dark , recreating the 21st Century Breakdown cover art . As the song ends , the room lights up again , and they are still uninjured . After the room lights up , there are various shots of destruction in the room , including a shot of some of the writing on the walls . The writing includes an excerpt of the lyrics to `` 21 Guns '' , as well as those of the song `` See The Light '' which also appears on `` 21st Century Breakdown '' . The video may represent the meaning of the song in the 21st Century Breakdown story .\", sentence_starts=[0, 177, 273, 337, 396, 541, 637, 714, 849, 1016], selected_sent={'start': 0, 'end': 177, 'string': \"The video takes place with the band and the album 's two protagonists Christian ( Josh Boswell ) and Gloria ( Lisa Stelly ) taking refuge in a white room after robbing a bank . \"}, answer=[Entity(start_offset=110, end_offset=121, type='context', text='Lisa Stelly', normalized_text='lisa stelly')], nq_answers=[[Entity(start_offset=110, end_offset=121, type='context', text='Lisa Stelly', normalized_text='lisa stelly')]], aligned_nps=[(Entity(start_offset=7, end_offset=36, type='question', text='the girl in green day 21 guns', normalized_text='girl in green day 21 guns'), Entity(start_offset=101, end_offset=107, type='context', text='Gloria', normalized_text='gloria'))], explanation_type='single_sentence'),\n",
       " 3421591493369976475: QEDExample(example_id=3421591493369976475, title='Five-Year Plans of India', question='which five year plan was affected by indo pak indo china war', passage='The Third Five - year Plan , stressed agriculture and improvement in the production of wheat , but the brief Sino - Indian War of 1962 exposed weaknesses in the economy and shifted the focus towards the defence industry and the Indian Army . In 1965 -- 1966 , India fought a War with Pakistan . There was also a severe drought in 1965 . The war led to inflation and the priority was shifted to price stabilisation . The construction of dams continued . Many cement and fertilizer plants were also built . Punjab began producing an abundance of wheat .', sentence_starts=[0, 242, 295, 337, 416, 453, 505], selected_sent={'start': 0, 'end': 242, 'string': 'The Third Five - year Plan , stressed agriculture and improvement in the production of wheat , but the brief Sino - Indian War of 1962 exposed weaknesses in the economy and shifted the focus towards the defence industry and the Indian Army . '}, answer=[Entity(start_offset=0, end_offset=26, type='context', text='The Third Five - year Plan', normalized_text='third five year plan')], nq_answers=[[Entity(start_offset=0, end_offset=26, type='context', text='The Third Five - year Plan', normalized_text='third five year plan')]], aligned_nps=[(Entity(start_offset=37, end_offset=60, type='question', text='indo pak indo china war', normalized_text='indo pak indo china war'), Entity(start_offset=99, end_offset=134, type='context', text='the brief Sino - Indian War of 1962', normalized_text='brief sino indian war of 1962'))], explanation_type='single_sentence'),\n",
       " 8697610951293426933: QEDExample(example_id=8697610951293426933, title='Human fertilization', question='name the process of fusion of an egg with a sperm', passage='Human fertilization is the union of a human egg and sperm , usually occurring in the ampulla of the fallopian tube . The result of this union is the production of a zygote cell , or fertilized egg , initiating prenatal development . Scientists discovered the dynamics of human fertilization in the nineteenth century .', sentence_starts=[0, 117, 233], selected_sent={'start': 0, 'end': 117, 'string': 'Human fertilization is the union of a human egg and sperm , usually occurring in the ampulla of the fallopian tube . '}, answer=[Entity(start_offset=6, end_offset=19, type='context', text='fertilization', normalized_text='fertilization')], nq_answers=[[Entity(start_offset=6, end_offset=19, type='context', text='fertilization', normalized_text='fertilization')], [Entity(start_offset=0, end_offset=19, type='context', text='Human fertilization', normalized_text='human fertilization')]], aligned_nps=[(Entity(start_offset=5, end_offset=49, type='question', text='the process of fusion of an egg with a sperm', normalized_text='process of fusion of egg with sperm'), Entity(start_offset=23, end_offset=57, type='context', text='the union of a human egg and sperm', normalized_text='union of human egg and sperm'))], explanation_type='single_sentence'),\n",
       " 3587867296617760276: QEDExample(example_id=3587867296617760276, title='Uvea', question='the vascular layer of the eye is the', passage='The uvea is the vascular middle layer of the eye . It is traditionally divided into three areas , from front to back , the :', sentence_starts=[0, 51], selected_sent={'start': 0, 'end': 51, 'string': 'The uvea is the vascular middle layer of the eye . '}, answer=[Entity(start_offset=4, end_offset=8, type='context', text='uvea', normalized_text='uvea')], nq_answers=[[Entity(start_offset=0, end_offset=8, type='context', text='The uvea', normalized_text='uvea')], [Entity(start_offset=25, end_offset=37, type='context', text='middle layer', normalized_text='middle layer')], [Entity(start_offset=4, end_offset=8, type='context', text='uvea', normalized_text='uvea')]], aligned_nps=[(Entity(start_offset=0, end_offset=29, type='question', text='the vascular layer of the eye', normalized_text='vascular layer of eye'), Entity(start_offset=12, end_offset=48, type='context', text='the vascular middle layer of the eye', normalized_text='vascular middle layer of eye'))], explanation_type='single_sentence'),\n",
       " 9206636474403612005: QEDExample(example_id=9206636474403612005, title='The Glory of Love (song)', question='who wrote the song the glory of love', passage=\"`` The Glory of Love '' is a song written by Billy Hill , recorded by Benny Goodman in 1936 , whose version was a number one pop hit . In 1951 , R&B vocal group , The Five Keys , had their biggest R&B hit with their version of the song , hitting number one on the R&B chart for four non-consecutive weeks . Although The Five Keys recording sold a reported million copies pressed recordings are very rare .\", sentence_starts=[0, 135, 307], selected_sent={'start': 0, 'end': 135, 'string': \"`` The Glory of Love '' is a song written by Billy Hill , recorded by Benny Goodman in 1936 , whose version was a number one pop hit . \"}, answer=[Entity(start_offset=45, end_offset=55, type='context', text='Billy Hill', normalized_text='billy hill')], nq_answers=[[Entity(start_offset=45, end_offset=55, type='context', text='Billy Hill', normalized_text='billy hill')]], aligned_nps=[(Entity(start_offset=10, end_offset=36, type='question', text='the song the glory of love', normalized_text='song glory of love'), Entity(start_offset=3, end_offset=20, type='context', text='The Glory of Love', normalized_text='glory of love'))], explanation_type='single_sentence'),\n",
       " 2352051038192309240: QEDExample(example_id=2352051038192309240, title='Brain', question='where does the brain get its energy from', passage=\"Brain tissue consumes a large amount of energy in proportion to its volume , so large brains place severe metabolic demands on animals . The need to limit body weight in order , for example , to fly , has apparently led to selection for a reduction of brain size in some species , such as bats . Most of the brain 's energy consumption goes into sustaining the electric charge ( membrane potential ) of neurons . Most vertebrate species devote between 2 % and 8 % of basal metabolism to the brain . In primates , however , the percentage is much higher -- in humans it rises to 20 -- 25 % . The energy consumption of the brain does not vary greatly over time , but active regions of the cerebral cortex consume somewhat more energy than inactive regions ; this forms the basis for the functional brain imaging methods PET , fMRI , and NIRS . The brain typically gets most of its energy from oxygen - dependent metabolism of glucose ( i.e. , blood sugar ) , but ketones provide a major alternative source , together with contributions from medium chain fatty acids ( caprylic and heptanoic acids ) , lactate , acetate , and possibly amino acids .\", sentence_starts=[0, 137, 296, 413, 499, 591, 842], selected_sent={'start': 842, 'end': 1145, 'string': 'The brain typically gets most of its energy from oxygen - dependent metabolism of glucose ( i.e. , blood sugar ) , but ketones provide a major alternative source , together with contributions from medium chain fatty acids ( caprylic and heptanoic acids ) , lactate , acetate , and possibly amino acids .'}, answer=[Entity(start_offset=891, end_offset=1143, type='context', text='oxygen - dependent metabolism of glucose ( i.e. , blood sugar ) , but ketones provide a major alternative source , together with contributions from medium chain fatty acids ( caprylic and heptanoic acids ) , lactate , acetate , and possibly amino acids', normalized_text='oxygen dependent metabolism of glucose ie blood sugar but ketones provide major alternative source together with contributions from medium chain fatty acids caprylic and heptanoic acids lactate acetate and possibly amino acids')], nq_answers=[[Entity(start_offset=867, end_offset=1143, type='context', text='most of its energy from oxygen - dependent metabolism of glucose ( i.e. , blood sugar ) , but ketones provide a major alternative source , together with contributions from medium chain fatty acids ( caprylic and heptanoic acids ) , lactate , acetate , and possibly amino acids', normalized_text='most of its energy from oxygen dependent metabolism of glucose ie blood sugar but ketones provide major alternative source together with contributions from medium chain fatty acids caprylic and heptanoic acids lactate acetate and possibly amino acids')], [Entity(start_offset=867, end_offset=954, type='context', text='most of its energy from oxygen - dependent metabolism of glucose ( i.e. , blood sugar )', normalized_text='most of its energy from oxygen dependent metabolism of glucose ie blood sugar')]], aligned_nps=[(Entity(start_offset=11, end_offset=20, type='question', text='the brain', normalized_text='brain'), Entity(start_offset=842, end_offset=851, type='context', text='The brain', normalized_text='brain')), (Entity(start_offset=25, end_offset=35, type='question', text='its energy', normalized_text='its energy'), Entity(start_offset=875, end_offset=885, type='context', text='its energy', normalized_text='its energy'))], explanation_type='single_sentence'),\n",
       " -7350738264545175214: QEDExample(example_id=-7350738264545175214, title='Maryse Ouellet', question='when does the miz and maryse show start', passage='In late - 2011 , she announced plans for a clothing and jewelry line called House of Maryse , and later began working as a realtor . In November 2016 , she began starring in the reality television series Total Divas on E ! as part of the main cast . She and her husband The Miz will also star in their own reality show titled Miz & Mrs. that will premiere in 2018 .', sentence_starts=[0, 133, 250], selected_sent={'start': 250, 'end': 365, 'string': 'She and her husband The Miz will also star in their own reality show titled Miz & Mrs. that will premiere in 2018 .'}, answer=[Entity(start_offset=359, end_offset=363, type='context', text='2018', normalized_text='2018')], nq_answers=[[Entity(start_offset=359, end_offset=363, type='context', text='2018', normalized_text='2018')]], aligned_nps=[(Entity(start_offset=10, end_offset=33, type='question', text='the miz and maryse show', normalized_text='miz and maryse show'), Entity(start_offset=296, end_offset=336, type='context', text='their own reality show titled Miz & Mrs.', normalized_text='their own reality show titled miz mrs'))], explanation_type='single_sentence'),\n",
       " 7306427910586845578: QEDExample(example_id=7306427910586845578, title='Slasher (TV series)', question='where was the first season of slasher filmed', passage=\"The first season , retroactively subtitled The Executioner , was produced in association with the Canadian network Super Channel , Slasher was the first original series by U.S. TV channel Chiller , which premiered the series on Friday , March 4 , 2016 , at 9 : 00 pm EST . Super Channel aired the show 's Canadian premiere on April 1 , 2016 . The series first season , which centered on a mysterious figure billed as `` The Executioner '' terrorizing the fictional town of Waterbury , Canada , was filmed between July and October 2015 in Sudbury , Parry Sound , and Sault Ste . Marie , Ontario .\", sentence_starts=[0, 273, 343, 578], selected_sent={'start': 343, 'end': 595, 'string': \"The series first season , which centered on a mysterious figure billed as `` The Executioner '' terrorizing the fictional town of Waterbury , Canada , was filmed between July and October 2015 in Sudbury , Parry Sound , and Sault Ste . Marie , Ontario .\"}, answer=[Entity(start_offset=538, end_offset=593, type='context', text='Sudbury , Parry Sound , and Sault Ste . Marie , Ontario', normalized_text='sudbury parry sound and sault ste marie ontario')], nq_answers=[[Entity(start_offset=538, end_offset=559, type='context', text='Sudbury , Parry Sound', normalized_text='sudbury parry sound'), Entity(start_offset=566, end_offset=593, type='context', text='Sault Ste . Marie , Ontario', normalized_text='sault ste marie ontario')], [Entity(start_offset=538, end_offset=593, type='context', text='Sudbury , Parry Sound , and Sault Ste . Marie , Ontario', normalized_text='sudbury parry sound and sault ste marie ontario')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text='the first season of slasher', normalized_text='first season of slasher'), Entity(start_offset=343, end_offset=366, type='context', text='The series first season', normalized_text='series first season'))], explanation_type='single_sentence'),\n",
       " 1404052427196543739: QEDExample(example_id=1404052427196543739, title='If a tree falls in a forest', question='who said if a tree falls in the woods and nobody hears it', passage=\"Philosopher George Berkeley , in his work , A Treatise Concerning the Principles of Human Knowledge ( 1710 ) , proposes , `` But , say you , surely there is nothing easier than for me to imagine trees , for instance , in a park ( ... ) and nobody by to perceive them . ( ... ) The objects of sense exist only when they are perceived ; the trees therefore are in the garden ( ... ) no longer than while there is somebody by to perceive them . '' ( It is worth noting that the quote from section 45 is arguably a statement of an objection to Berkeley 's view , and not a proclamation of it . ) Nevertheless , Berkeley never actually wrote about the question .\", sentence_starts=[0, 269, 277, 445, 592], selected_sent={'start': 0, 'end': 269, 'string': 'Philosopher George Berkeley , in his work , A Treatise Concerning the Principles of Human Knowledge ( 1710 ) , proposes , `` But , say you , surely there is nothing easier than for me to imagine trees , for instance , in a park ( ... ) and nobody by to perceive them . '}, answer=[Entity(start_offset=12, end_offset=27, type='context', text='George Berkeley', normalized_text='george berkeley')], nq_answers=[[Entity(start_offset=0, end_offset=27, type='context', text='Philosopher George Berkeley', normalized_text='philosopher george berkeley')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3307908231607643449: QEDExample(example_id=-3307908231607643449, title='American entry into World War I', question='when did united states enter world war i', passage='The American entry into World War I came in April 1917 , after more than two and a half years of efforts by President Woodrow Wilson to keep the United States out of the war . Apart from an Anglophile element urging early support for the British , American public opinion reflected that of the president : the sentiment for neutrality was particularly strong among Irish Americans , German Americans and Scandinavian Americans , as well as among church leaders and among women in general . On the other hand , even before World War I had broken out , American opinion had been more negative toward Germany than towards any other country in Europe . Over time , especially after reports of atrocities in Belgium in 1914 and following the sinking of the passenger liner RMS Lusitania in 1915 , the American people increasingly came to see Germany as the aggressor in Europe .', sentence_starts=[0, 176, 490, 649], selected_sent={'start': 0, 'end': 176, 'string': 'The American entry into World War I came in April 1917 , after more than two and a half years of efforts by President Woodrow Wilson to keep the United States out of the war . '}, answer=[Entity(start_offset=44, end_offset=54, type='context', text='April 1917', normalized_text='april 1917')], nq_answers=[[Entity(start_offset=44, end_offset=54, type='context', text='April 1917', normalized_text='april 1917')]], aligned_nps=[(Entity(start_offset=29, end_offset=40, type='question', text='world war i', normalized_text='world war i'), Entity(start_offset=24, end_offset=35, type='context', text='World War I', normalized_text='world war i'))], explanation_type='single_sentence'),\n",
       " 761079737280110147: QEDExample(example_id=761079737280110147, title='Strategy of unbalanced growth', question='who has given the theory of unbalanced economic growth', passage='The theory is generally associated with Hirschman . He presented a complete theoretical formulation of the strategy . Underdeveloped countries display common characteristics : low levels of GNI per capita and slow GNI per capita growth , large income inequalities and widespread poverty , low levels of productivity , great dependence on agriculture , a backward industrial structure , a high proportion of consumption and low savings , high rates of population growth and dependency burdens , high unemployment and underemployment , technological backwardness and dualism ( existence of both traditional and modern sectors ) . In a less - developed country , these characteristics lead to scarce resources or inadequate infrastructure to exploit these resources . With a lack of investors and entrepreneurs , cash flows can not be directed into various sectors that influence balanced economic growth .', sentence_starts=[0, 52, 118, 628, 765], selected_sent={'start': 0, 'end': 52, 'string': 'The theory is generally associated with Hirschman . '}, answer=[Entity(start_offset=40, end_offset=49, type='context', text='Hirschman', normalized_text='hirschman')], nq_answers=[[Entity(start_offset=40, end_offset=49, type='context', text='Hirschman', normalized_text='hirschman')]], aligned_nps=[(Entity(start_offset=14, end_offset=54, type='question', text='the theory of unbalanced economic growth', normalized_text='theory of unbalanced economic growth'), Entity(start_offset=0, end_offset=10, type='context', text='The theory', normalized_text='theory'))], explanation_type='single_sentence'),\n",
       " 3630714342371225513: QEDExample(example_id=3630714342371225513, title='Distilled beverage', question='where did the term spirits for alcohol come from', passage=\"The term `` spirit '' in reference to alcohol stems from Middle Eastern alchemy . These alchemists were more concerned with medical elixirs than with transmuting lead into gold . The vapor given off and collected during an alchemical process ( as with distillation of alcohol ) was called a spirit of the original material .\", sentence_starts=[0, 82, 179], selected_sent={'start': 0, 'end': 82, 'string': \"The term `` spirit '' in reference to alcohol stems from Middle Eastern alchemy . \"}, answer=[Entity(start_offset=57, end_offset=79, type='context', text='Middle Eastern alchemy', normalized_text='middle eastern alchemy')], nq_answers=[[Entity(start_offset=57, end_offset=79, type='context', text='Middle Eastern alchemy', normalized_text='middle eastern alchemy')]], aligned_nps=[(Entity(start_offset=10, end_offset=38, type='question', text='the term spirits for alcohol', normalized_text='term spirits for alcohol'), Entity(start_offset=0, end_offset=45, type='context', text=\"The term `` spirit '' in reference to alcohol\", normalized_text='term spirit in reference to alcohol'))], explanation_type='single_sentence'),\n",
       " -6591614197125818072: QEDExample(example_id=-6591614197125818072, title=\"John Brown's raid on Harpers Ferry\", question=\"who led the soldiers in ending the raid on the harper's ferry arsenal\", passage=\"John Brown 's raid on Harper 's Ferry ( also known as John Brown 's raid or The raid on Harper 's Ferry ) was an effort by armed abolitionist John Brown to initiate an armed slave revolt in 1859 by taking over a United States arsenal at Harpers Ferry , Virginia . Brown 's party of 22 was defeated by a company of U.S. Marines , led by First Lieutenant Israel Greene . Colonel Robert E. Lee was in overall command of the operation to retake the arsenal . John Brown had originally asked Harriet Tubman and Frederick Douglass , both of whom he had met in his transformative years as an abolitionist in Springfield , Massachusetts , to join him in his raid , but Tubman was prevented by illness and Douglass declined , as he believed Brown 's plan would fail .\", sentence_starts=[0, 264, 369, 455], selected_sent={'start': 264, 'end': 369, 'string': \"Brown 's party of 22 was defeated by a company of U.S. Marines , led by First Lieutenant Israel Greene . \"}, answer=[Entity(start_offset=336, end_offset=366, type='context', text='First Lieutenant Israel Greene', normalized_text='first lieutenant israel greene')], nq_answers=[[Entity(start_offset=336, end_offset=366, type='context', text='First Lieutenant Israel Greene', normalized_text='first lieutenant israel greene')], [Entity(start_offset=369, end_offset=390, type='context', text='Colonel Robert E. Lee', normalized_text='colonel robert e lee')]], aligned_nps=[(Entity(start_offset=31, end_offset=69, type='question', text=\"the raid on the harper's ferry arsenal\", normalized_text='raid on harpers ferry arsenal'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 4480034477137973992: QEDExample(example_id=4480034477137973992, title='Gymnosperm', question='the seed of a gymnosperm seed is made in the', passage=\"The gymnosperms are a group of seed - producing plants that includes conifers , cycads , Ginkgo , and gnetophytes . The term `` gymnosperm '' comes from the Greek composite word γυμνόσπερμος ( γυμνός gymnos , `` naked '' and σπέρμα sperma , `` seed '' ) , meaning `` naked seeds '' . The name is based on the unenclosed condition of their seeds ( called ovules in their unfertilized state ) . The non-encased condition of their seeds stands in contrast to the seeds and ovules of flowering plants ( angiosperms ) , which are enclosed within an ovary . Gymnosperm seeds develop either on the surface of scales or leaves , which are often modified to form cones , or solitary as in Yew , Torreya , Ginkgo .\", sentence_starts=[0, 116, 284, 393, 552], selected_sent={'start': 552, 'end': 704, 'string': 'Gymnosperm seeds develop either on the surface of scales or leaves , which are often modified to form cones , or solitary as in Yew , Torreya , Ginkgo .'}, answer=[Entity(start_offset=584, end_offset=618, type='context', text='on the surface of scales or leaves', normalized_text='on surface of scales or leaves')], nq_answers=[[Entity(start_offset=577, end_offset=618, type='context', text='either on the surface of scales or leaves', normalized_text='either on surface of scales or leaves')], [Entity(start_offset=577, end_offset=673, type='context', text='either on the surface of scales or leaves , which are often modified to form cones , or solitary', normalized_text='either on surface of scales or leaves which are often modified to form cones or solitary')], [Entity(start_offset=587, end_offset=618, type='context', text='the surface of scales or leaves', normalized_text='surface of scales or leaves')]], aligned_nps=[(Entity(start_offset=0, end_offset=24, type='question', text='the seed of a gymnosperm', normalized_text='seed of gymnosperm'), Entity(start_offset=552, end_offset=568, type='context', text='Gymnosperm seeds', normalized_text='gymnosperm seeds'))], explanation_type='single_sentence'),\n",
       " -7900537827363346667: QEDExample(example_id=-7900537827363346667, title='Subcutaneous injection', question='where would a subcutaneous injection be made in the skin', passage=\"A subcutaneous injection is administered as a bolus into the subcutis , the layer of skin directly below the dermis and epidermis , collectively referred to as the cutis . Subcutaneous injections are highly effective in administering vaccines and medications such as insulin , morphine , diacetylmorphine and goserelin . Subcutaneous , as opposed to intravenous , injection of recreational drugs is referred to as `` skin popping '' . Subcutaneous administration may be abbreviated as SC , SQ , sub-cu , sub-Q , SubQ , or subcut . Subcut is the preferred abbreviation for patient safety .\", sentence_starts=[0, 172, 321, 435, 531], selected_sent={'start': 0, 'end': 172, 'string': 'A subcutaneous injection is administered as a bolus into the subcutis , the layer of skin directly below the dermis and epidermis , collectively referred to as the cutis . '}, answer=[Entity(start_offset=52, end_offset=129, type='context', text='into the subcutis , the layer of skin directly below the dermis and epidermis', normalized_text='into subcutis layer of skin directly below dermis and epidermis')], nq_answers=[[Entity(start_offset=52, end_offset=129, type='context', text='into the subcutis , the layer of skin directly below the dermis and epidermis', normalized_text='into subcutis layer of skin directly below dermis and epidermis')], [Entity(start_offset=57, end_offset=169, type='context', text='the subcutis , the layer of skin directly below the dermis and epidermis , collectively referred to as the cutis', normalized_text='subcutis layer of skin directly below dermis and epidermis collectively referred to as cutis')], [Entity(start_offset=57, end_offset=69, type='context', text='the subcutis', normalized_text='subcutis')], [Entity(start_offset=72, end_offset=169, type='context', text='the layer of skin directly below the dermis and epidermis , collectively referred to as the cutis', normalized_text='layer of skin directly below dermis and epidermis collectively referred to as cutis')]], aligned_nps=[(Entity(start_offset=12, end_offset=36, type='question', text='a subcutaneous injection', normalized_text='subcutaneous injection'), Entity(start_offset=0, end_offset=24, type='context', text='A subcutaneous injection', normalized_text='subcutaneous injection')), (Entity(start_offset=48, end_offset=56, type='question', text='the skin', normalized_text='skin'), Entity(start_offset=85, end_offset=89, type='context', text='skin', normalized_text='skin'))], explanation_type='single_sentence'),\n",
       " 5704535453361095916: QEDExample(example_id=5704535453361095916, title='Small intestine', question='where are most nutrients absorbed in the human digestive tract', passage='The small intestine or small bowel is the part of the gastrointestinal tract between the stomach and the large intestine , and is where most of the end absorption of food takes place . The small intestine has three distinct regions -- the duodenum , jejunum , and ileum . The duodenum is the shortest part of the small intestine and is where preparation for absorption begins . It also receives bile and pancreatic juice through the pancreatic duct , controlled by the sphincter of Oddi . The primary function of the small intestine is the absorption of nutrients and minerals from food , using small finger - like protrusions called villi .', sentence_starts=[0, 185, 272, 378, 489], selected_sent={'start': 489, 'end': 641, 'string': 'The primary function of the small intestine is the absorption of nutrients and minerals from food , using small finger - like protrusions called villi .'}, answer=[Entity(start_offset=513, end_offset=532, type='context', text='the small intestine', normalized_text='small intestine')], nq_answers=[[Entity(start_offset=0, end_offset=34, type='context', text='The small intestine or small bowel', normalized_text='small intestine or small bowel')], [Entity(start_offset=4, end_offset=19, type='context', text='small intestine', normalized_text='small intestine')], [Entity(start_offset=0, end_offset=19, type='context', text='The small intestine', normalized_text='small intestine')]], aligned_nps=[(Entity(start_offset=37, end_offset=62, type='question', text='the human digestive tract', normalized_text='human digestive tract'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -510179348025098787: QEDExample(example_id=-510179348025098787, title='Board of directors', question='what does the board of directors consist of', passage=\"A board of directors is a recognized group of people who jointly oversee the activities of an organization , which can be either a for - profit business , nonprofit organization , or a government agency . Such a board 's powers , duties , and responsibilities are determined by government regulations ( including the jurisdiction 's corporations law ) and the organization 's own constitution and bylaws . These authorities may specify the number of members of the board , how they are to be chosen , and how often they are to meet .\", sentence_starts=[0, 205, 406], selected_sent={'start': 0, 'end': 205, 'string': 'A board of directors is a recognized group of people who jointly oversee the activities of an organization , which can be either a for - profit business , nonprofit organization , or a government agency . '}, answer=[Entity(start_offset=46, end_offset=106, type='context', text='people who jointly oversee the activities of an organization', normalized_text='people who jointly oversee activities of organization')], nq_answers=[[Entity(start_offset=24, end_offset=106, type='context', text='a recognized group of people who jointly oversee the activities of an organization', normalized_text='recognized group of people who jointly oversee activities of organization')]], aligned_nps=[(Entity(start_offset=10, end_offset=32, type='question', text='the board of directors', normalized_text='board of directors'), Entity(start_offset=0, end_offset=20, type='context', text='A board of directors', normalized_text='board of directors'))], explanation_type='single_sentence'),\n",
       " 3262882280361419647: QEDExample(example_id=3262882280361419647, title='Ossification center', question='when do primary ossification centers appear in an embryo', passage='A primary ossification center is the first area of a bone to start ossifying . It usually appears during prenatal development in the central part of each developing bone . In long bones the primary centers occur in the diaphysis / shaft and in irregular bones the primary centers occur usually in the body of the bone . Most bones have only one primary center ( e.g. all long bones ) but some irregular bones such as the os coxa ( hip ) and vertebrae have multiple primary centers .', sentence_starts=[0, 79, 172, 320], selected_sent={'start': 79, 'end': 172, 'string': 'It usually appears during prenatal development in the central part of each developing bone . '}, answer=[Entity(start_offset=105, end_offset=125, type='context', text='prenatal development', normalized_text='prenatal development')], nq_answers=[[Entity(start_offset=105, end_offset=125, type='context', text='prenatal development', normalized_text='prenatal development')]], aligned_nps=[(Entity(start_offset=8, end_offset=36, type='question', text='primary ossification centers', normalized_text='primary ossification centers'), Entity(start_offset=79, end_offset=81, type='context', text='It', normalized_text='it')), (Entity(start_offset=47, end_offset=56, type='question', text='an embryo', normalized_text='embryo'), Entity(start_offset=149, end_offset=171, type='context', text='each developing bone .', normalized_text='each developing bone'))], explanation_type='single_sentence'),\n",
       " -5765931546365345480: QEDExample(example_id=-5765931546365345480, title='Home Alone 2: Lost in New York', question='where does kevins family go in home alone 2', passage=\"The plot is as follows : Kevin and his family decide to take a trip to Florida , but Kevin takes the wrong plane and ends up in New York City . He tries to make do with what he has , such as using his father 's credit card to stay at the Plaza Hotel , but is soon confronted by the Wet Bandits and must outrun and out - prank them again .\", sentence_starts=[0, 144], selected_sent={'start': 0, 'end': 144, 'string': 'The plot is as follows : Kevin and his family decide to take a trip to Florida , but Kevin takes the wrong plane and ends up in New York City . '}, answer=[Entity(start_offset=71, end_offset=78, type='context', text='Florida', normalized_text='florida')], nq_answers=[[Entity(start_offset=71, end_offset=78, type='context', text='Florida', normalized_text='florida')]], aligned_nps=[(Entity(start_offset=11, end_offset=24, type='question', text='kevins family', normalized_text='kevins family'), Entity(start_offset=35, end_offset=45, type='context', text='his family', normalized_text='his family')), (Entity(start_offset=31, end_offset=43, type='question', text='home alone 2', normalized_text='home alone 2'), Entity(start_offset=0, end_offset=8, type='context', text='The plot', normalized_text='plot'))], explanation_type='single_sentence'),\n",
       " 5098377822521811712: QEDExample(example_id=5098377822521811712, title='Jessica Jones (season 2)', question='when is season 2 of jessica jones being released', passage='The season is scheduled to be released on March 8 , 2018 .', sentence_starts=[0], selected_sent={'start': 0, 'end': 58, 'string': 'The season is scheduled to be released on March 8 , 2018 .'}, answer=[Entity(start_offset=42, end_offset=56, type='context', text='March 8 , 2018', normalized_text='march 8 2018')], nq_answers=[[Entity(start_offset=42, end_offset=56, type='context', text='March 8 , 2018', normalized_text='march 8 2018')]], aligned_nps=[(Entity(start_offset=8, end_offset=33, type='question', text='season 2 of jessica jones', normalized_text='season 2 of jessica jones'), Entity(start_offset=0, end_offset=10, type='context', text='The season', normalized_text='season'))], explanation_type='single_sentence'),\n",
       " -3088831012491766629: QEDExample(example_id=-3088831012491766629, title='Game of Thrones (season 8)', question='what is final season of game of thrones', passage=\"The eighth and final season of the fantasy drama television series Game of Thrones was announced by HBO in July 2016 . Unlike the first six seasons that each had ten episodes and the seventh that had seven episodes , the eighth season will have only six episodes . Like the previous season , it will largely consist of original content not found currently in George R.R. Martin 's A Song of Ice and Fire series , and will instead adapt material Martin has revealed to showrunners about the upcoming novels in the series , The Winds of Winter and A Dream of Spring .\", sentence_starts=[0, 119, 265, 371], selected_sent={'start': 0, 'end': 119, 'string': 'The eighth and final season of the fantasy drama television series Game of Thrones was announced by HBO in July 2016 . '}, answer=[Entity(start_offset=4, end_offset=10, type='context', text='eighth', normalized_text='eighth')], nq_answers=[[Entity(start_offset=217, end_offset=234, type='context', text='the eighth season', normalized_text='eighth season')], [Entity(start_offset=4, end_offset=10, type='context', text='eighth', normalized_text='eighth')], [Entity(start_offset=0, end_offset=10, type='context', text='The eighth', normalized_text='eighth')]], aligned_nps=[(Entity(start_offset=8, end_offset=39, type='question', text='final season of game of thrones', normalized_text='final season of game of thrones'), Entity(start_offset=0, end_offset=82, type='context', text='The eighth and final season of the fantasy drama television series Game of Thrones', normalized_text='eighth and final season of fantasy drama television series game of thrones'))], explanation_type='single_sentence'),\n",
       " 8620612587997496991: QEDExample(example_id=8620612587997496991, title='Vikram Samvat', question='vikram samvat calender is official in which country', passage='The Rana rulers of Nepal made Vikram Samvat the official Hindu calendar in 1901 CE , which started as Samvat 1958 . In Nepal , the new year begins with the first day of the month of Baishakh , which usually falls within the months of April -- May in the Gregorian calendar . The first day of the new year is passionately celebrated in a historical carnival that takes place every year in Bhaktapur , called Bisket Jatra.As before , from 2007 AD Nepal Sambat is recognized as the national calender .', sentence_starts=[0, 116, 275], selected_sent={'start': 0, 'end': 116, 'string': 'The Rana rulers of Nepal made Vikram Samvat the official Hindu calendar in 1901 CE , which started as Samvat 1958 . '}, answer=[Entity(start_offset=19, end_offset=24, type='context', text='Nepal', normalized_text='nepal')], nq_answers=[[Entity(start_offset=19, end_offset=24, type='context', text='Nepal', normalized_text='nepal')]], aligned_nps=[(Entity(start_offset=0, end_offset=22, type='question', text='vikram samvat calender', normalized_text='vikram samvat calender'), Entity(start_offset=30, end_offset=43, type='context', text='Vikram Samvat', normalized_text='vikram samvat'))], explanation_type='single_sentence'),\n",
       " 4142183495658071394: QEDExample(example_id=4142183495658071394, title='Loop (graph theory)', question='an edge that is between a vertex and itself is a', passage=\"In graph theory , a loop ( also called a self - loop or a `` buckle '' ) is an edge that connects a vertex to itself . A simple graph contains no loops .\", sentence_starts=[0, 119], selected_sent={'start': 0, 'end': 119, 'string': \"In graph theory , a loop ( also called a self - loop or a `` buckle '' ) is an edge that connects a vertex to itself . \"}, answer=[Entity(start_offset=18, end_offset=72, type='context', text=\"a loop ( also called a self - loop or a `` buckle '' )\", normalized_text='loop also called self loop or buckle')], nq_answers=[[Entity(start_offset=20, end_offset=72, type='context', text=\"loop ( also called a self - loop or a `` buckle '' )\", normalized_text='loop also called self loop or buckle')], [Entity(start_offset=20, end_offset=24, type='context', text='loop', normalized_text='loop')]], aligned_nps=[(Entity(start_offset=0, end_offset=43, type='question', text='an edge that is between a vertex and itself', normalized_text='edge that is between vertex and itself'), Entity(start_offset=76, end_offset=116, type='context', text='an edge that connects a vertex to itself', normalized_text='edge that connects vertex to itself'))], explanation_type='single_sentence'),\n",
       " 5926634737519636306: QEDExample(example_id=5926634737519636306, title='The Little Couple', question='when does the little couples new season start', passage='The new season of The Little Couple premiered on September 19 , 2017 .', sentence_starts=[0], selected_sent={'start': 0, 'end': 70, 'string': 'The new season of The Little Couple premiered on September 19 , 2017 .'}, answer=[Entity(start_offset=49, end_offset=68, type='context', text='September 19 , 2017', normalized_text='september 19 2017')], nq_answers=[[Entity(start_offset=49, end_offset=68, type='context', text='September 19 , 2017', normalized_text='september 19 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text='the little couples new season', normalized_text='little couples new season'), Entity(start_offset=0, end_offset=35, type='context', text='The new season of The Little Couple', normalized_text='new season of little couple'))], explanation_type='single_sentence'),\n",
       " 1311019403755331535: QEDExample(example_id=1311019403755331535, title='Robbie Coltrane', question='how tall is the actor who plays hagrid in harry potter', passage=\"His roles continued in the 1990s with the TV series Cracker ( 1993 -- 1996 , returning in 2006 for a one - off special ) , in which he starred as forensic psychologist Dr. Edward `` Fitz '' Fitzgerald . The role won him three BAFTA awards . Roles in bigger films followed ; the James Bond films GoldenEye ( 1995 ) and The World Is Not Enough ( 1999 ) , a supporting role in From Hell ( 2001 ) , as well as half - giant Rubeus Hagrid in the Harry Potter films ( 2001 -- 2011 ) . J.K. Rowling , author of the Harry Potter series , had Coltrane at the top of her list to play Hagrid and , when asked whom she would like to see in the role , responded `` Robbie Coltrane for Hagrid '' in one quick breath . There is also an unnamed 8ft actor who stands in for the 6ft 1in Coltrane in some scenes .\", sentence_starts=[0, 203, 241, 478, 483, 703], selected_sent={'start': 703, 'end': 793, 'string': 'There is also an unnamed 8ft actor who stands in for the 6ft 1in Coltrane in some scenes .'}, answer=[Entity(start_offset=760, end_offset=767, type='context', text='6ft 1in', normalized_text='6ft 1in')], nq_answers=[[Entity(start_offset=760, end_offset=767, type='context', text='6ft 1in', normalized_text='6ft 1in')]], aligned_nps=[(Entity(start_offset=12, end_offset=54, type='question', text='the actor who plays hagrid in harry potter', normalized_text='actor who plays hagrid in harry potter'), Entity(start_offset=756, end_offset=776, type='context', text='the 6ft 1in Coltrane', normalized_text='6ft 1in coltrane'))], explanation_type='single_sentence'),\n",
       " 9111835660082410727: QEDExample(example_id=9111835660082410727, title='Justice of the peace', question='what is the job of justice of the peace', passage='A justice of the peace ( JP ) is a judicial officer , of a lower or puisne court , elected or appointed by means of a commission ( letters patent ) to keep the peace . In past centuries the term commissioner of the peace was often used with the same meaning . Depending on the jurisdiction , such justices dispense summary justice or merely deal with local administrative applications in common law jurisdictions . Justices of the peace are appointed or elected from the citizens of the jurisdiction in which they serve , and are ( or were ) usually not required to have any formal legal education in order to qualify for the office . Some jurisdictions have varying forms of training for JPs .', sentence_starts=[0, 168, 260, 415, 635], selected_sent={'start': 0, 'end': 168, 'string': 'A justice of the peace ( JP ) is a judicial officer , of a lower or puisne court , elected or appointed by means of a commission ( letters patent ) to keep the peace . '}, answer=[Entity(start_offset=33, end_offset=165, type='context', text='a judicial officer , of a lower or puisne court , elected or appointed by means of a commission ( letters patent ) to keep the peace', normalized_text='judicial officer of lower or puisne court elected or appointed by means of commission letters patent to keep peace')], nq_answers=[[Entity(start_offset=33, end_offset=167, type='context', text='a judicial officer , of a lower or puisne court , elected or appointed by means of a commission ( letters patent ) to keep the peace .', normalized_text='judicial officer of lower or puisne court elected or appointed by means of commission letters patent to keep peace')], [Entity(start_offset=306, end_offset=330, type='context', text='dispense summary justice', normalized_text='dispense summary justice'), Entity(start_offset=341, end_offset=412, type='context', text='deal with local administrative applications in common law jurisdictions', normalized_text='deal with local administrative applications in common law jurisdictions')]], aligned_nps=[(Entity(start_offset=19, end_offset=39, type='question', text='justice of the peace', normalized_text='justice of peace'), Entity(start_offset=0, end_offset=22, type='context', text='A justice of the peace', normalized_text='justice of peace'))], explanation_type='single_sentence'),\n",
       " -6216202368088666946: QEDExample(example_id=-6216202368088666946, title='Melbourne Cup', question='who has trained the most melbourne cup winners', passage=\"1877 is also the year that the trainer Etienne de Mestre won his fourth Melbourne Cup with Chester owned by Hon . James White . In 1878 , as in previous years De Mestre fielded more than one horse . He entered the favourite Firebell ( owned by W.S. Cox ) who finished last , Chester ( owned by Hon . James White ) the previous year 's winner who fell , and Calamia ( owned by de Mestre ) who , though less fancied , won easily by two lengths . First prize was £ 1,790 , the crowd was 80,000 and there were 30 starters . De Mestre 's 1878 win with Calamia brought to 5 the number of Melbourne Cups he had won . This record was not to be matched for nearly 100 years when the trainer Bart Cummings won his fifth Melbourne Cup in 1975 . Bart Cummings , regarded as the best Australian horse trainer of all time , went on to win 12 Melbourne Cups to 2008 .\", sentence_starts=[0, 114, 128, 199, 249, 300, 444, 520, 610, 734], selected_sent={'start': 734, 'end': 852, 'string': 'Bart Cummings , regarded as the best Australian horse trainer of all time , went on to win 12 Melbourne Cups to 2008 .'}, answer=[Entity(start_offset=734, end_offset=747, type='context', text='Bart Cummings', normalized_text='bart cummings')], nq_answers=[[Entity(start_offset=734, end_offset=747, type='context', text='Bart Cummings', normalized_text='bart cummings')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 8268392025144002146: QEDExample(example_id=8268392025144002146, title='Lynne Hobbs', question=\"who was kat slater's sisters in eastenders\", passage=\"Lynne is the eldest of the Slater sisters and she arrives in Albert Square in 2000 with her family : father Charlie ( Derek Martin ) ; sisters Kat ( Jessie Wallace ) , Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ) , and grandmother Mo ( Laila Morse ) . Unlike Little Mo and Zoe , Lynne is aware that Zoe is in fact Kat 's daughter and helps keep the family secret until Kat reveals the truth to Zoe .\", sentence_starts=[0, 263], selected_sent={'start': 0, 'end': 263, 'string': 'Lynne is the eldest of the Slater sisters and she arrives in Albert Square in 2000 with her family : father Charlie ( Derek Martin ) ; sisters Kat ( Jessie Wallace ) , Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ) , and grandmother Mo ( Laila Morse ) . '}, answer=[Entity(start_offset=0, end_offset=5, type='context', text='Lynne', normalized_text='lynne'), Entity(start_offset=168, end_offset=177, type='context', text='Little Mo', normalized_text='little mo'), Entity(start_offset=202, end_offset=205, type='context', text='Zoe', normalized_text='zoe')], nq_answers=[[Entity(start_offset=0, end_offset=5, type='context', text='Lynne', normalized_text='lynne'), Entity(start_offset=168, end_offset=177, type='context', text='Little Mo', normalized_text='little mo')], [Entity(start_offset=0, end_offset=5, type='context', text='Lynne', normalized_text='lynne'), Entity(start_offset=168, end_offset=177, type='context', text='Little Mo', normalized_text='little mo'), Entity(start_offset=202, end_offset=205, type='context', text='Zoe', normalized_text='zoe')]], aligned_nps=[(Entity(start_offset=8, end_offset=18, type='question', text='kat slater', normalized_text='kat slater'), Entity(start_offset=143, end_offset=146, type='context', text='Kat', normalized_text='kat')), (Entity(start_offset=32, end_offset=42, type='question', text='eastenders', normalized_text='eastenders'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -5372667077951673175: QEDExample(example_id=-5372667077951673175, title='Typeface anatomy', question='what is the cross on a letter t called', passage='A main vertical stroke is called a stem . The letter m has three , the left , middle , and right stems . The central stroke of an s is called the spine . When the stroke is part of a lowercase and rises above the height of an x ( called the x height ) , it is called an ascender . Letters with ascenders are bdfhkl . A stroke which drops below the baseline is a descender . Letters with descenders are gjpqy . An arching stroke is called a shoulder as in the top of an R or sometimes just an arch , as in hnm . A closed curved stroke is called a bowl in bdopq DOPQ ; B has two bowls . A trailing outstroke , as in jy JQR is called a tail . The inferior diagonal stroke in K is called leg . A short horizontal stroke , as in the center of ef and the middle stroke of EF , is called a bar . When the strokes connect as in A and H or cross strokes as in t is also known as crossbar . A longer horizontal stroke at the top or bottom , as in ET , is called an arm . The bottom of the two - story g is called a loop ; the very short stroke at the top is called the ear . ij each have a dot , jot , or tittle . Angles of strokes are called apices if at the top and vertices if at the bottom . w has one apex and two vertices ; v has one vertex .', sentence_starts=[0, 42, 105, 154, 281, 317, 374, 410, 511, 585, 640, 690, 789, 881, 961, 1065, 1104, 1186], selected_sent={'start': 789, 'end': 881, 'string': 'When the strokes connect as in A and H or cross strokes as in t is also known as crossbar . '}, answer=[Entity(start_offset=870, end_offset=878, type='context', text='crossbar', normalized_text='crossbar')], nq_answers=[[Entity(start_offset=870, end_offset=878, type='context', text='crossbar', normalized_text='crossbar')], [Entity(start_offset=955, end_offset=958, type='context', text='arm', normalized_text='arm')]], aligned_nps=[(Entity(start_offset=21, end_offset=31, type='question', text='a letter t', normalized_text='letter t'), Entity(start_offset=851, end_offset=852, type='context', text='t', normalized_text='t'))], explanation_type='single_sentence'),\n",
       " -8462578313793667601: QEDExample(example_id=-8462578313793667601, title='Doctor Poison', question='who plays the evil doctor in wonder woman', passage='The original Princess Maru incarnation of the character made her cinematic debut in the 2017 film Wonder Woman , portrayed by Spanish actress Elena Anaya .', sentence_starts=[0], selected_sent={'start': 0, 'end': 155, 'string': 'The original Princess Maru incarnation of the character made her cinematic debut in the 2017 film Wonder Woman , portrayed by Spanish actress Elena Anaya .'}, answer=[Entity(start_offset=142, end_offset=153, type='context', text='Elena Anaya', normalized_text='elena anaya')], nq_answers=[[Entity(start_offset=142, end_offset=153, type='context', text='Elena Anaya', normalized_text='elena anaya')], [Entity(start_offset=126, end_offset=153, type='context', text='Spanish actress Elena Anaya', normalized_text='spanish actress elena anaya')]], aligned_nps=[(Entity(start_offset=10, end_offset=25, type='question', text='the evil doctor', normalized_text='evil doctor'), Entity(start_offset=42, end_offset=55, type='context', text='the character', normalized_text='character')), (Entity(start_offset=29, end_offset=41, type='question', text='wonder woman', normalized_text='wonder woman'), Entity(start_offset=84, end_offset=110, type='context', text='the 2017 film Wonder Woman', normalized_text='2017 film wonder woman'))], explanation_type='single_sentence'),\n",
       " -5345751650770708960: QEDExample(example_id=-5345751650770708960, title='Sacrifice (song)', question='what album is sacrifice by elton john on', passage=\"`` Sacrifice '' is a ballad performed by musician Elton John . The lyrics are by Bernie Taupin and the music by John . The song appears on the 1989 album Sleeping with the Past . It was first released in October 1989 , then in 1990 , and was the second single from the album . It achieved success , particularly in France and the UK , where it became his first solo chart - topper , spending five weeks at the top .\", sentence_starts=[0, 63, 119, 179, 277], selected_sent={'start': 119, 'end': 179, 'string': 'The song appears on the 1989 album Sleeping with the Past . '}, answer=[Entity(start_offset=154, end_offset=176, type='context', text='Sleeping with the Past', normalized_text='sleeping with past')], nq_answers=[[Entity(start_offset=154, end_offset=176, type='context', text='Sleeping with the Past', normalized_text='sleeping with past')], [Entity(start_offset=154, end_offset=178, type='context', text='Sleeping with the Past .', normalized_text='sleeping with past')], [Entity(start_offset=139, end_offset=176, type='context', text='the 1989 album Sleeping with the Past', normalized_text='1989 album sleeping with past')]], aligned_nps=[(Entity(start_offset=14, end_offset=37, type='question', text='sacrifice by elton john', normalized_text='sacrifice by elton john'), Entity(start_offset=119, end_offset=127, type='context', text='The song', normalized_text='song'))], explanation_type='single_sentence'),\n",
       " 587999005951345244: QEDExample(example_id=587999005951345244, title='Pencil', question='when did they replace lead with graphite in pencils', passage=\"As a technique for drawing , the closest predecesor to the pencil was Silverpoint until in 1565 ( some sources say as early as 1500 ) , a large deposit of graphite was discovered on the approach to Grey Knotts from the hamlet of Seathwaite in Borrowdale parish , Cumbria , England . This particular deposit of graphite was extremely pure and solid , and it could easily be sawn into sticks . It remains the only large - scale deposit of graphite ever found in this solid form . Chemistry was in its infancy and the substance was thought to be a form of lead . Consequently , it was called plumbago ( Latin for `` lead ore '' ) . Because the pencil core is still referred to as `` lead '' , or a `` lead '' , many people have the misconception that the graphite in the pencil is lead , and the black core of pencils is still referred to as lead , even though it never contained the element lead . The words for pencil in German ( bleistift ) , Irish ( peann luaidhe ) , Arabic ( قلم رصاص qalam raṣāṣ ) , and some other languages literally mean lead pen .\", sentence_starts=[0, 283, 392, 478, 560, 629, 896], selected_sent={'start': 629, 'end': 896, 'string': \"Because the pencil core is still referred to as `` lead '' , or a `` lead '' , many people have the misconception that the graphite in the pencil is lead , and the black core of pencils is still referred to as lead , even though it never contained the element lead . \"}, answer=[Entity(start_offset=858, end_offset=893, type='context', text='it never contained the element lead', normalized_text='it never contained element lead')], nq_answers=[[Entity(start_offset=861, end_offset=893, type='context', text='never contained the element lead', normalized_text='never contained element lead')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 8426342968417319670: QEDExample(example_id=8426342968417319670, title='1924 Winter Olympics medal table', question='who won the most medals in the 1924 winter olympics', passage=\"The 1924 Winter Olympics , officially known as the I Olympic Winter Games , and known at the time as Semaine Internationale des Sports d'Hiver ( `` International Winter Sports Week '' ) , was a winter multi-sport event held in Chamonix , France , from 25 January to 5 February 1924 . Norway topped the table , collecting seventeen medals in total , including four gold , three of which were won by Thorleif Haug in the nordic combined and cross-country skiing events . Norway also achieved two podium sweeps , winning all three medals in both the 50 km cross-country skiing and the nordic combined . This remained a record at the Winter Olympics until 2014 .\", sentence_starts=[0, 284, 469, 600], selected_sent={'start': 284, 'end': 469, 'string': 'Norway topped the table , collecting seventeen medals in total , including four gold , three of which were won by Thorleif Haug in the nordic combined and cross-country skiing events . '}, answer=[Entity(start_offset=284, end_offset=290, type='context', text='Norway', normalized_text='norway')], nq_answers=[[Entity(start_offset=284, end_offset=290, type='context', text='Norway', normalized_text='norway')]], aligned_nps=[(Entity(start_offset=27, end_offset=51, type='question', text='the 1924 winter olympics', normalized_text='1924 winter olympics'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 397204824317594616: QEDExample(example_id=397204824317594616, title='List of Downton Abbey episodes', question='what is the final season of downton abbey', passage='Downton Abbey is a British period drama television series created by Julian Fellowes and co-produced by Carnival Films and Masterpiece . It first aired on ITV in the United Kingdom on 26 September 2010 , and on PBS in the United States on 9 January 2011 , as part of the Masterpiece Classic anthology . Six series have been made , the sixth airing in the autumn of 2015 in the UK and Ireland , and in January 2016 in the United States . On 26 March 2015 , the sixth series was confirmed to be the final series , with the final episode airing in the UK on 25 December 2015 on ITV . During the course of the programme , 52 episodes of Downton Abbey aired over six series .', sentence_starts=[0, 137, 303, 437, 581], selected_sent={'start': 437, 'end': 581, 'string': 'On 26 March 2015 , the sixth series was confirmed to be the final series , with the final episode airing in the UK on 25 December 2015 on ITV . '}, answer=[Entity(start_offset=460, end_offset=465, type='context', text='sixth', normalized_text='sixth')], nq_answers=[[Entity(start_offset=658, end_offset=661, type='context', text='six', normalized_text='six')], [Entity(start_offset=456, end_offset=465, type='context', text='the sixth', normalized_text='sixth')], [Entity(start_offset=456, end_offset=472, type='context', text='the sixth series', normalized_text='sixth series')], [Entity(start_offset=460, end_offset=465, type='context', text='sixth', normalized_text='sixth')], [Entity(start_offset=303, end_offset=306, type='context', text='Six', normalized_text='six')]], aligned_nps=[(Entity(start_offset=8, end_offset=41, type='question', text='the final season of downton abbey', normalized_text='final season of downton abbey'), Entity(start_offset=493, end_offset=509, type='context', text='the final series', normalized_text='final series'))], explanation_type='single_sentence'),\n",
       " -1268179953831754266: QEDExample(example_id=-1268179953831754266, title='Regulatory site', question='which site of an enzyme is called allosteric site', passage=\"A regulatory site ( also known as an `` allosteric site '' ) is a site on an allosteric protein to which a modulator molecule ( or allosteric regulator ) binds . This ligand - binding site on a receptor or enzyme is distinct from the active site . Allosteric modulators alter enzyme activity by binding to the regulatory site . Some allosteric regulators activate enzymes , while others inhibit them . The working hypothesis is that when allosteric regulators bind to the regulatory site , the protein undergoes conformational changes which changes the enzyme 's activity .\", sentence_starts=[0, 162, 248, 328, 402], selected_sent={'start': 0, 'end': 162, 'string': \"A regulatory site ( also known as an `` allosteric site '' ) is a site on an allosteric protein to which a modulator molecule ( or allosteric regulator ) binds . \"}, answer=[Entity(start_offset=0, end_offset=17, type='context', text='A regulatory site', normalized_text='regulatory site')], nq_answers=[[Entity(start_offset=2, end_offset=17, type='context', text='regulatory site', normalized_text='regulatory site')]], aligned_nps=[(Entity(start_offset=34, end_offset=49, type='question', text='allosteric site', normalized_text='allosteric site'), Entity(start_offset=40, end_offset=55, type='context', text='allosteric site', normalized_text='allosteric site'))], explanation_type='single_sentence'),\n",
       " 4980328185343503580: QEDExample(example_id=4980328185343503580, title=\"You'll Never Find Another Love Like Mine\", question=\"who sings the song you'll never find another love like mine\", passage=\"`` You 'll Never Find Another Love Like Mine '' ( written by Kenny Gamble & Leon Huff ) is a song performed by R&B singer Lou Rawls on his 1976 album All Things in Time . The song proved to be Rawls ' breakthrough hit , reaching number one on both the R&B and Easy Listening charts as well as number four on the dance chart and number two on the US Billboard Hot 100 , where it was kept from the top spot for two weeks by `` You Should Be Dancing '' by The Bee Gees and `` ( Shake , Shake , Shake ) Shake Your Booty '' by KC and the Sunshine Band , respectively . This was the first and only time that one of Rawls ' records managed to reach Billboard 's pop top ten . It was the first big hit for Philadelphia International to feature the reformulated MFSB , after many of the original members left Gamble and Huff for better opportunities . The song started Rawls ' live shows from 1977 on .\", sentence_starts=[0, 171, 564, 669, 843], selected_sent={'start': 0, 'end': 171, 'string': \"`` You 'll Never Find Another Love Like Mine '' ( written by Kenny Gamble & Leon Huff ) is a song performed by R&B singer Lou Rawls on his 1976 album All Things in Time . \"}, answer=[Entity(start_offset=122, end_offset=131, type='context', text='Lou Rawls', normalized_text='lou rawls')], nq_answers=[[Entity(start_offset=122, end_offset=131, type='context', text='Lou Rawls', normalized_text='lou rawls')]], aligned_nps=[(Entity(start_offset=10, end_offset=59, type='question', text=\"the song you'll never find another love like mine\", normalized_text='song youll never find another love like mine'), Entity(start_offset=3, end_offset=44, type='context', text=\"You 'll Never Find Another Love Like Mine\", normalized_text='you ll never find another love like mine'))], explanation_type='single_sentence'),\n",
       " 4259863793651737582: QEDExample(example_id=4259863793651737582, title=\"Earth's magnetic field\", question=\"what is earth's magnetic field responsible for\", passage=\"The Earth 's magnetic field serves to deflect most of the solar wind , whose charged particles would otherwise strip away the ozone layer that protects the Earth from harmful ultraviolet radiation . One stripping mechanism is for gas to be caught in bubbles of magnetic field , which are ripped off by solar winds . Calculations of the loss of carbon dioxide from the atmosphere of Mars , resulting from scavenging of ions by the solar wind , indicate that the dissipation of the magnetic field of Mars caused a near total loss of its atmosphere .\", sentence_starts=[0, 199, 316], selected_sent={'start': 0, 'end': 199, 'string': \"The Earth 's magnetic field serves to deflect most of the solar wind , whose charged particles would otherwise strip away the ozone layer that protects the Earth from harmful ultraviolet radiation . \"}, answer=[Entity(start_offset=38, end_offset=196, type='context', text='deflect most of the solar wind , whose charged particles would otherwise strip away the ozone layer that protects the Earth from harmful ultraviolet radiation', normalized_text='deflect most of solar wind whose charged particles would otherwise strip away ozone layer that protects earth from harmful ultraviolet radiation')], nq_answers=[[Entity(start_offset=38, end_offset=196, type='context', text='deflect most of the solar wind , whose charged particles would otherwise strip away the ozone layer that protects the Earth from harmful ultraviolet radiation', normalized_text='deflect most of solar wind whose charged particles would otherwise strip away ozone layer that protects earth from harmful ultraviolet radiation')]], aligned_nps=[(Entity(start_offset=8, end_offset=30, type='question', text=\"earth's magnetic field\", normalized_text='earths magnetic field'), Entity(start_offset=0, end_offset=27, type='context', text=\"The Earth 's magnetic field\", normalized_text='earth s magnetic field'))], explanation_type='single_sentence'),\n",
       " 4053461415821443645: QEDExample(example_id=4053461415821443645, title='What a Friend We Have in Jesus', question='who wrote song what a friend we have in jesus', passage=\"`` What a Friend We Have in Jesus '' is a Christian hymn originally written by Joseph M. Scriven as a poem in 1855 to comfort his mother who was living in Ireland while he was in Canada . Scriven originally published the poem anonymously , and only received full credit for it in the 1880s . The tune to the hymn was composed by Charles Crozat Converse in 1868 . William Bolcom composed a setting of the hymn .\", sentence_starts=[0, 188, 292, 363], selected_sent={'start': 0, 'end': 188, 'string': \"`` What a Friend We Have in Jesus '' is a Christian hymn originally written by Joseph M. Scriven as a poem in 1855 to comfort his mother who was living in Ireland while he was in Canada . \"}, answer=[Entity(start_offset=79, end_offset=96, type='context', text='Joseph M. Scriven', normalized_text='joseph m scriven')], nq_answers=[[Entity(start_offset=79, end_offset=96, type='context', text='Joseph M. Scriven', normalized_text='joseph m scriven')], [Entity(start_offset=79, end_offset=96, type='context', text='Joseph M. Scriven', normalized_text='joseph m scriven'), Entity(start_offset=329, end_offset=352, type='context', text='Charles Crozat Converse', normalized_text='charles crozat converse'), Entity(start_offset=363, end_offset=377, type='context', text='William Bolcom', normalized_text='william bolcom')], [Entity(start_offset=79, end_offset=96, type='context', text='Joseph M. Scriven', normalized_text='joseph m scriven'), Entity(start_offset=329, end_offset=352, type='context', text='Charles Crozat Converse', normalized_text='charles crozat converse')]], aligned_nps=[(Entity(start_offset=15, end_offset=45, type='question', text='what a friend we have in jesus', normalized_text='what friend we have in jesus'), Entity(start_offset=3, end_offset=33, type='context', text='What a Friend We Have in Jesus', normalized_text='what friend we have in jesus'))], explanation_type='single_sentence'),\n",
       " -5775387077145633620: QEDExample(example_id=-5775387077145633620, title='Philippe Petit', question='who is the guy who walked across the twin towers', passage=\"Philippe Petit ( French pronunciation : \\u200b ( filip pəti ) ; born 13 August 1949 ) is a French high - wire artist who gained fame for his high - wire walk between the Twin Towers of the World Trade Center in New York City , on the morning of August 7 , 1974 as well as his high wire walk between the Notre Dame cathedral in Paris , 1971 . For his unauthorized feat 400 metres ( 1,000 feet ) above the ground -- which he referred to as `` le coup '' -- he rigged a 200 - kilogram ( 440 - pound ) cable and used a custom - made 8 - metre ( 30 - foot ) long , 25 - kilogram ( 55 - pound ) balancing pole . He performed for 45 minutes , making eight passes along the wire . The following week , he celebrated his 25th birthday . All charges were dismissed in exchange for him doing a performance in Central Park for children .\", sentence_starts=[0, 337, 601, 668, 723], selected_sent={'start': 0, 'end': 337, 'string': 'Philippe Petit ( French pronunciation : \\u200b ( filip pəti ) ; born 13 August 1949 ) is a French high - wire artist who gained fame for his high - wire walk between the Twin Towers of the World Trade Center in New York City , on the morning of August 7 , 1974 as well as his high wire walk between the Notre Dame cathedral in Paris , 1971 . '}, answer=[Entity(start_offset=0, end_offset=14, type='context', text='Philippe Petit', normalized_text='philippe petit')], nq_answers=[[Entity(start_offset=0, end_offset=14, type='context', text='Philippe Petit', normalized_text='philippe petit')]], aligned_nps=[(Entity(start_offset=33, end_offset=48, type='question', text='the twin towers', normalized_text='twin towers'), Entity(start_offset=161, end_offset=219, type='context', text='the Twin Towers of the World Trade Center in New York City', normalized_text='twin towers of world trade center in new york city'))], explanation_type='single_sentence'),\n",
       " 224088321079691518: QEDExample(example_id=224088321079691518, title='Motor neuron', question='all the motor neurons that control the skeletal muscles are', passage=\"The term ' motor neuron ' is usually restricted to the lower motor neurons , the efferent nerves that directly innervate muscles .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 130, 'string': \"The term ' motor neuron ' is usually restricted to the lower motor neurons , the efferent nerves that directly innervate muscles .\"}, answer=[Entity(start_offset=81, end_offset=96, type='context', text='efferent nerves', normalized_text='efferent nerves')], nq_answers=[[Entity(start_offset=81, end_offset=96, type='context', text='efferent nerves', normalized_text='efferent nerves')]], aligned_nps=[(Entity(start_offset=4, end_offset=55, type='question', text='the motor neurons that control the skeletal muscles', normalized_text='motor neurons that control skeletal muscles'), Entity(start_offset=51, end_offset=74, type='context', text='the lower motor neurons', normalized_text='lower motor neurons'))], explanation_type='single_sentence'),\n",
       " -51011525148659082: QEDExample(example_id=-51011525148659082, title='Heart sounds', question='when do you hear the lub and dub sounds of the heart', passage='In healthy adults , there are two normal heart sounds , often described as a lub and a dub ( or dup ) , that occur in sequence with each heartbeat . These are the first heart sound ( S ) and second heart sound ( S ) , produced by the closing of the atrioventricular valves and semilunar valves , respectively . In addition to these normal sounds , a variety of other sounds may be present including heart murmurs , adventitious sounds , and gallop rhythms S and S .', sentence_starts=[0, 149, 311], selected_sent={'start': 149, 'end': 311, 'string': 'These are the first heart sound ( S ) and second heart sound ( S ) , produced by the closing of the atrioventricular valves and semilunar valves , respectively . '}, answer=[Entity(start_offset=230, end_offset=308, type='context', text='the closing of the atrioventricular valves and semilunar valves , respectively', normalized_text='closing of atrioventricular valves and semilunar valves respectively')], nq_answers=[[Entity(start_offset=230, end_offset=308, type='context', text='the closing of the atrioventricular valves and semilunar valves , respectively', normalized_text='closing of atrioventricular valves and semilunar valves respectively')]], aligned_nps=[(Entity(start_offset=17, end_offset=52, type='question', text='the lub and dub sounds of the heart', normalized_text='lub and dub sounds of heart'), Entity(start_offset=149, end_offset=154, type='context', text='These', normalized_text='these'))], explanation_type='single_sentence'),\n",
       " -7442827774477803702: QEDExample(example_id=-7442827774477803702, title='List of Premier League players with 100 or more goals', question='who has scored more goals in the premier league', passage='During the 1995 -- 96 season , Alan Shearer became the first player to score 100 Premier League goals , and holds the record for the fewest games taken to reach 100 , doing so in 124 appearances . He also holds the record for most goals scored in the Premier League . After Shearer , Harry Kane is the second - fastest to 100 goals , doing so in 141 games .', sentence_starts=[0, 197, 268], selected_sent={'start': 197, 'end': 268, 'string': 'He also holds the record for most goals scored in the Premier League . '}, answer=[Entity(start_offset=31, end_offset=43, type='context', text='Alan Shearer', normalized_text='alan shearer')], nq_answers=[[Entity(start_offset=31, end_offset=43, type='context', text='Alan Shearer', normalized_text='alan shearer')]], aligned_nps=[(Entity(start_offset=29, end_offset=47, type='question', text='the premier league', normalized_text='premier league'), Entity(start_offset=247, end_offset=265, type='context', text='the Premier League', normalized_text='premier league'))], explanation_type='single_sentence'),\n",
       " -4222512069603517522: QEDExample(example_id=-4222512069603517522, title='National Assembly of Pakistan', question='total number of mna in pakistan national assembly', passage=\"The Pakistani National Assembly ( Urdu : قومی اسمبلئ پاکستان \\u202c \\u200e -- Qaumī Asimbli'e Pākistān ) ; is the lower house of the bicameral Majlis - e-Shura , which also comprises the President of Pakistan and Senate ( upper house ) . The National Assembly and the Senate both convene at Parliament House in Islamabad . The National Assembly is a democratically elected body consisting of a total of 332 members who are referred to as Members of the National Assembly ( MNAs ) , of which 272 are directly elected members and 70 reserved seats for women and religious minorities . A political party must secure 172 seats to obtain and preserve a majority .\", sentence_starts=[0, 228, 313, 573], selected_sent={'start': 313, 'end': 573, 'string': 'The National Assembly is a democratically elected body consisting of a total of 332 members who are referred to as Members of the National Assembly ( MNAs ) , of which 272 are directly elected members and 70 reserved seats for women and religious minorities . '}, answer=[Entity(start_offset=393, end_offset=396, type='context', text='332', normalized_text='332')], nq_answers=[[Entity(start_offset=393, end_offset=396, type='context', text='332', normalized_text='332')], [Entity(start_offset=393, end_offset=404, type='context', text='332 members', normalized_text='332 members')]], aligned_nps=[(Entity(start_offset=23, end_offset=49, type='question', text='pakistan national assembly', normalized_text='pakistan national assembly'), Entity(start_offset=313, end_offset=334, type='context', text='The National Assembly', normalized_text='national assembly'))], explanation_type='single_sentence'),\n",
       " 4839853516523677080: QEDExample(example_id=4839853516523677080, title='Muscle relaxant', question='when are centrally acting skeletal muscle relaxants used', passage=\"A muscle relaxant is a drug that affects skeletal muscle function and decreases the muscle tone . It may be used to alleviate symptoms such as muscle spasms , pain , and hyperreflexia . The term `` muscle relaxant '' is used to refer to two major therapeutic groups : neuromuscular blockers and spasmolytics . Neuromuscular blockers act by interfering with transmission at the neuromuscular end plate and have no central nervous system ( CNS ) activity . They are often used during surgical procedures and in intensive care and emergency medicine to cause temporary paralysis . Spasmolytics , also known as `` centrally acting '' muscle relaxants , are used to alleviate musculoskeletal pain and spasms and to reduce spasticity in a variety of neurological conditions . While both neuromuscular blockers and spasmolytics are often grouped together as muscle relaxants , the term is commonly used to refer to spasmolytics only .\", sentence_starts=[0, 98, 186, 310, 455, 578, 770], selected_sent={'start': 578, 'end': 770, 'string': \"Spasmolytics , also known as `` centrally acting '' muscle relaxants , are used to alleviate musculoskeletal pain and spasms and to reduce spasticity in a variety of neurological conditions . \"}, answer=[Entity(start_offset=658, end_offset=767, type='context', text='to alleviate musculoskeletal pain and spasms and to reduce spasticity in a variety of neurological conditions', normalized_text='to alleviate musculoskeletal pain and spasms and to reduce spasticity in variety of neurological conditions')], nq_answers=[[Entity(start_offset=658, end_offset=767, type='context', text='to alleviate musculoskeletal pain and spasms and to reduce spasticity in a variety of neurological conditions', normalized_text='to alleviate musculoskeletal pain and spasms and to reduce spasticity in variety of neurological conditions')], [Entity(start_offset=658, end_offset=702, type='context', text='to alleviate musculoskeletal pain and spasms', normalized_text='to alleviate musculoskeletal pain and spasms'), Entity(start_offset=707, end_offset=767, type='context', text='to reduce spasticity in a variety of neurological conditions', normalized_text='to reduce spasticity in variety of neurological conditions')]], aligned_nps=[(Entity(start_offset=9, end_offset=51, type='question', text='centrally acting skeletal muscle relaxants', normalized_text='centrally acting skeletal muscle relaxants'), Entity(start_offset=607, end_offset=646, type='context', text=\"`` centrally acting '' muscle relaxants\", normalized_text='centrally acting muscle relaxants'))], explanation_type='single_sentence'),\n",
       " 2879480778972019439: QEDExample(example_id=2879480778972019439, title='Rio Bravo (film)', question='who played stumpy in the movie rio bravo', passage=\"Chance 's friend Pat Wheeler ( Ward Bond ) and his wagon train of supplies stop in town , with a young gunslinger , Colorado Ryan ( Ricky Nelson ) , riding guard . Inside the jail , Stumpy ( Walter Brennan ) , Chance 's game - legged deputy , keeps watch over the jail and Joe , who knows that Stumpy holds an old grudge against Joe 's wealthy and powerful brother . Joe warns his jailers that Nathan Burdette will not like how his brother is being treated .\", sentence_starts=[0, 164, 367], selected_sent={'start': 164, 'end': 367, 'string': \"Inside the jail , Stumpy ( Walter Brennan ) , Chance 's game - legged deputy , keeps watch over the jail and Joe , who knows that Stumpy holds an old grudge against Joe 's wealthy and powerful brother . \"}, answer=[Entity(start_offset=191, end_offset=205, type='context', text='Walter Brennan', normalized_text='walter brennan')], nq_answers=[[Entity(start_offset=191, end_offset=205, type='context', text='Walter Brennan', normalized_text='walter brennan')]], aligned_nps=[(Entity(start_offset=11, end_offset=17, type='question', text='stumpy', normalized_text='stumpy'), Entity(start_offset=182, end_offset=188, type='context', text='Stumpy', normalized_text='stumpy')), (Entity(start_offset=21, end_offset=40, type='question', text='the movie rio bravo', normalized_text='movie rio bravo'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -8899928590244132355: QEDExample(example_id=-8899928590244132355, title='Second Great Awakening', question='what was the purpose of a revival meeting during the second great awakening', passage='The Second Great Awakening occurred in several episodes and over different denominations ; however , the revivals were very similar . As the most effective form of evangelizing during this period , revival meetings cut across geographical boundaries , and the movement quickly spread throughout Kentucky , Tennessee and southern Ohio . Each denomination had assets that allowed it to thrive on the frontier . The Methodists had an efficient organization that depended on itinerant ministers , known as circuit riders , who sought out people in remote frontier locations . The circuit riders came from among the common people , which helped them establish rapport with the frontier families they hoped to convert .', sentence_starts=[0, 134, 336, 409, 572], selected_sent={'start': 134, 'end': 336, 'string': 'As the most effective form of evangelizing during this period , revival meetings cut across geographical boundaries , and the movement quickly spread throughout Kentucky , Tennessee and southern Ohio . '}, answer=[Entity(start_offset=164, end_offset=176, type='context', text='evangelizing', normalized_text='evangelizing')], nq_answers=[[Entity(start_offset=164, end_offset=176, type='context', text='evangelizing', normalized_text='evangelizing')]], aligned_nps=[(Entity(start_offset=49, end_offset=75, type='question', text='the second great awakening', normalized_text='second great awakening'), Entity(start_offset=184, end_offset=195, type='context', text='this period', normalized_text='this period')), (Entity(start_offset=24, end_offset=41, type='question', text='a revival meeting', normalized_text='revival meeting'), Entity(start_offset=198, end_offset=214, type='context', text='revival meetings', normalized_text='revival meetings'))], explanation_type='single_sentence'),\n",
       " -413717867881585106: QEDExample(example_id=-413717867881585106, title='Catch Me If You Can', question='when was catch me if you can made', passage='Catch Me If You Can is a 2002 American biographical crime film directed and co-produced by Steven Spielberg from a screenplay by Jeff Nathanson . The film is based on the life of Frank Abagnale , who , before his 19th birthday , successfully performed cons worth millions of dollars by posing as a Pan American World Airways pilot , a Georgia doctor and a Louisiana parish prosecutor . His primary crime was check fraud ; he became so experienced that the FBI eventually turned to him for help in catching other checking forgers . The film stars Leonardo DiCaprio and Tom Hanks , with Christopher Walken , Martin Sheen , and Nathalie Baye in supporting roles .', sentence_starts=[0, 146, 386, 531], selected_sent={'start': 0, 'end': 146, 'string': 'Catch Me If You Can is a 2002 American biographical crime film directed and co-produced by Steven Spielberg from a screenplay by Jeff Nathanson . '}, answer=[Entity(start_offset=25, end_offset=29, type='context', text='2002', normalized_text='2002')], nq_answers=[[Entity(start_offset=25, end_offset=29, type='context', text='2002', normalized_text='2002')]], aligned_nps=[(Entity(start_offset=9, end_offset=28, type='question', text='catch me if you can', normalized_text='catch me if you can'), Entity(start_offset=0, end_offset=19, type='context', text='Catch Me If You Can', normalized_text='catch me if you can'))], explanation_type='single_sentence'),\n",
       " -4553359052770918451: QEDExample(example_id=-4553359052770918451, title='Eastern coastal plains', question='where are the coastal plains located in india', passage='The Eastern Coastal Plains refers to a wide stretch of landmass of India , lying between the Eastern Ghats and the Bay of Bengal . It is wider and leveled than the western coastal plains and stretches from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha . Chilka Lake is a brackish water lake along the eastern coastal plain . It lies in the state of Odisha and stretches to the south of the Mahanadi Delta .', sentence_starts=[0, 131, 294, 365], selected_sent={'start': 0, 'end': 131, 'string': 'The Eastern Coastal Plains refers to a wide stretch of landmass of India , lying between the Eastern Ghats and the Bay of Bengal . '}, answer=[Entity(start_offset=81, end_offset=128, type='context', text='between the Eastern Ghats and the Bay of Bengal', normalized_text='between eastern ghats and bay of bengal')], nq_answers=[[Entity(start_offset=81, end_offset=128, type='context', text='between the Eastern Ghats and the Bay of Bengal', normalized_text='between eastern ghats and bay of bengal')]], aligned_nps=[(Entity(start_offset=10, end_offset=28, type='question', text='the coastal plains', normalized_text='coastal plains'), Entity(start_offset=0, end_offset=26, type='context', text='The Eastern Coastal Plains', normalized_text='eastern coastal plains')), (Entity(start_offset=40, end_offset=45, type='question', text='india', normalized_text='india'), Entity(start_offset=67, end_offset=72, type='context', text='India', normalized_text='india'))], explanation_type='single_sentence'),\n",
       " 1002962494655967639: QEDExample(example_id=1002962494655967639, title='Toyota', question='when did toyota first come to the united states', passage=\"From September 1947 , Toyota 's small - sized vehicles were sold under the name `` Toyopet '' ( トヨペット ) . The first vehicle sold under this name was the Toyopet SA , but it also included vehicles such as the Toyopet SB light truck , Toyopet Stout light truck , Toyopet Crown , Toyopet Master , and the Toyopet Corona . The word `` Toyopet ( Japanese article ) '' was a nickname given to the Toyota SA due to its small size , as the result of a naming contest the Toyota Company organized in 1947 . However , when Toyota eventually entered the American market in 1957 with the Crown , the name was not well received due to connotations of toys and pets . The name was soon dropped for the American market , but continued in other markets until the mid-1960s .\", sentence_starts=[0, 106, 319, 498, 654], selected_sent={'start': 498, 'end': 654, 'string': 'However , when Toyota eventually entered the American market in 1957 with the Crown , the name was not well received due to connotations of toys and pets . '}, answer=[Entity(start_offset=562, end_offset=566, type='context', text='1957', normalized_text='1957')], nq_answers=[[Entity(start_offset=562, end_offset=566, type='context', text='1957', normalized_text='1957')]], aligned_nps=[(Entity(start_offset=9, end_offset=15, type='question', text='toyota', normalized_text='toyota'), Entity(start_offset=513, end_offset=519, type='context', text='Toyota', normalized_text='toyota'))], explanation_type='single_sentence'),\n",
       " -4141063008045921128: QEDExample(example_id=-4141063008045921128, title='Council of Jerusalem', question='which apostle spoke at the council of jerusalem', passage=\"At the Council , following advice offered by Simon Peter ( Acts 15 : 7 -- 11 and Acts 15 : 14 ) , Barnabas and Paul gave an account of their ministry among the gentiles ( Acts 15 : 12 ) , and the apostle James quoted from the words of the prophet Amos ( Acts 15 : 16 -- 17 , quoting Amos 9 : 11 -- 12 ) . James added his own words to the quotation : `` Known to God from eternity are all His works '' and then submitted a proposal , which was accepted by the Church and became known as the Apostolic Decree :\", sentence_starts=[0, 305], selected_sent={'start': 0, 'end': 305, 'string': 'At the Council , following advice offered by Simon Peter ( Acts 15 : 7 -- 11 and Acts 15 : 14 ) , Barnabas and Paul gave an account of their ministry among the gentiles ( Acts 15 : 12 ) , and the apostle James quoted from the words of the prophet Amos ( Acts 15 : 16 -- 17 , quoting Amos 9 : 11 -- 12 ) . '}, answer=[Entity(start_offset=204, end_offset=209, type='context', text='James', normalized_text='james')], nq_answers=[[Entity(start_offset=204, end_offset=209, type='context', text='James', normalized_text='james')], [Entity(start_offset=45, end_offset=56, type='context', text='Simon Peter', normalized_text='simon peter'), Entity(start_offset=98, end_offset=106, type='context', text='Barnabas', normalized_text='barnabas'), Entity(start_offset=111, end_offset=115, type='context', text='Paul', normalized_text='paul'), Entity(start_offset=204, end_offset=209, type='context', text='James', normalized_text='james')]], aligned_nps=[(Entity(start_offset=23, end_offset=47, type='question', text='the council of jerusalem', normalized_text='council of jerusalem'), Entity(start_offset=3, end_offset=14, type='context', text='the Council', normalized_text='council'))], explanation_type='single_sentence'),\n",
       " -5670136654288025028: QEDExample(example_id=-5670136654288025028, title='Crown-of-thorns starfish', question='where is the crown of thorns starfish located', passage='A. planci has a very wide Indo - Pacific distribution . It is perhaps most common in Australia , but can occur at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean , and across the Pacific Ocean to the west coast of Central America . It occurs where coral reefs or hard coral communities occur in this region .', sentence_starts=[0, 56, 287], selected_sent={'start': 56, 'end': 287, 'string': 'It is perhaps most common in Australia , but can occur at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean , and across the Pacific Ocean to the west coast of Central America . '}, answer=[Entity(start_offset=70, end_offset=284, type='context', text='most common in Australia , but can occur at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean , and across the Pacific Ocean to the west coast of Central America', normalized_text='most common in australia but can occur at tropical and subtropical latitudes from red sea and east african coast across indian ocean and across pacific ocean to west coast of central america')], nq_answers=[[Entity(start_offset=62, end_offset=284, type='context', text='perhaps most common in Australia , but can occur at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean , and across the Pacific Ocean to the west coast of Central America', normalized_text='perhaps most common in australia but can occur at tropical and subtropical latitudes from red sea and east african coast across indian ocean and across pacific ocean to west coast of central america')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the crown of thorns starfish', normalized_text='crown of thorns starfish'), Entity(start_offset=56, end_offset=58, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 7775645844703785477: QEDExample(example_id=7775645844703785477, title='Will Friedle', question='actor who plays eric on boy meets world', passage=\"William Alan `` Will '' Friedle ( born August 11 , 1976 ) is an American actor and voice actor . He is best known for his comedic roles , most notably the underachieving elder brother Eric Matthews on the long - running TV sitcom Boy Meets World from 1993 to 2000 . More recently , he has voiced a number of animated characters such as Terry McGinnis / Batman , the title character of Batman Beyond , and Ron Stoppable of Kim Possible . He voices Deadpool in Ultimate Spider - Man and Star - Lord in the animated version of Guardians of the Galaxy , replacing Chris Cox . He also performed the voices of Doyle in The Secret Saturdays , Lion - O in the rebooted ThunderCats series , and Blue Beetle on Batman : The Brave and the Bold . One of his most recent roles has been the speaking voice of Bumblebee in the final episode of Transformers : Prime and the movie Transformers Prime Beast Hunters : Predacons Rising and in the sequel series Transformers : Robots in Disguise , as well as in Transformers : Rescue Bots .\", sentence_starts=[0, 97, 266, 437, 572, 735], selected_sent={'start': 97, 'end': 266, 'string': 'He is best known for his comedic roles , most notably the underachieving elder brother Eric Matthews on the long - running TV sitcom Boy Meets World from 1993 to 2000 . '}, answer=[Entity(start_offset=0, end_offset=31, type='context', text=\"William Alan `` Will '' Friedle\", normalized_text='william alan will friedle')], nq_answers=[[Entity(start_offset=0, end_offset=31, type='context', text=\"William Alan `` Will '' Friedle\", normalized_text='william alan will friedle')]], aligned_nps=[(Entity(start_offset=16, end_offset=20, type='question', text='eric', normalized_text='eric'), Entity(start_offset=151, end_offset=197, type='context', text='the underachieving elder brother Eric Matthews', normalized_text='underachieving elder brother eric matthews')), (Entity(start_offset=24, end_offset=39, type='question', text='boy meets world', normalized_text='boy meets world'), Entity(start_offset=201, end_offset=245, type='context', text='the long - running TV sitcom Boy Meets World', normalized_text='long running tv sitcom boy meets world'))], explanation_type='single_sentence'),\n",
       " 5350383719875421584: QEDExample(example_id=5350383719875421584, title='The Dukes of Hazzard (film)', question='who played daisy duke in the new dukes of hazzard', passage=\"Cousins Bo ( Seann William Scott ) , Luke ( Johnny Knoxville ) , and Daisy Duke ( Jessica Simpson ) run a moonshine business for their Uncle Jesse ( Willie Nelson ) in Hazzard County , Georgia . The cousins ' primary mode of transportation is an orange 1969 Dodge Charger that the boys affectionately refer to as the `` General Lee '' . Along the way , the family is tormented by corrupt Hazzard County Commissioner Jefferson Davis Hogg , widely known as `` Boss Hogg '' ( Burt Reynolds ) , and his willing but dimwitted henchman , Sheriff Rosco P. Coltrane ( M.C. Gainey ) .\", sentence_starts=[0, 195, 337, 565], selected_sent={'start': 0, 'end': 195, 'string': 'Cousins Bo ( Seann William Scott ) , Luke ( Johnny Knoxville ) , and Daisy Duke ( Jessica Simpson ) run a moonshine business for their Uncle Jesse ( Willie Nelson ) in Hazzard County , Georgia . '}, answer=[Entity(start_offset=82, end_offset=97, type='context', text='Jessica Simpson', normalized_text='jessica simpson')], nq_answers=[[Entity(start_offset=82, end_offset=97, type='context', text='Jessica Simpson', normalized_text='jessica simpson')]], aligned_nps=[(Entity(start_offset=11, end_offset=21, type='question', text='daisy duke', normalized_text='daisy duke'), Entity(start_offset=69, end_offset=79, type='context', text='Daisy Duke', normalized_text='daisy duke')), (Entity(start_offset=25, end_offset=49, type='question', text='the new dukes of hazzard', normalized_text='new dukes of hazzard'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -7008368888638493698: QEDExample(example_id=-7008368888638493698, title='Country Music Hall of Fame and Museum', question='where is the country music hall of fame located', passage=\"The Country Music Hall of Fame and Museum in Nashville , Tennessee , is one of the world 's largest museums and research centers dedicated to the preservation and interpretation of American vernacular music . Chartered in 1964 , the museum has amassed one of the world 's most extensive musical collections .\", sentence_starts=[0, 209], selected_sent={'start': 0, 'end': 209, 'string': \"The Country Music Hall of Fame and Museum in Nashville , Tennessee , is one of the world 's largest museums and research centers dedicated to the preservation and interpretation of American vernacular music . \"}, answer=[Entity(start_offset=45, end_offset=66, type='context', text='Nashville , Tennessee', normalized_text='nashville tennessee')], nq_answers=[[Entity(start_offset=45, end_offset=66, type='context', text='Nashville , Tennessee', normalized_text='nashville tennessee')]], aligned_nps=[(Entity(start_offset=9, end_offset=39, type='question', text='the country music hall of fame', normalized_text='country music hall of fame'), Entity(start_offset=0, end_offset=41, type='context', text='The Country Music Hall of Fame and Museum', normalized_text='country music hall of fame and museum'))], explanation_type='single_sentence'),\n",
       " -3001662032923593229: QEDExample(example_id=-3001662032923593229, title=\"India's Next Superstars\", question=\"who has won india's next super star\", passage=\"India 's Next Superstars is a talent - searcher Indian reality show , which premiered on Star Plus and is streamed on Hotstar . Karan Johar and Rohit Shetty are the judges for the show . Aman Gandotra and Natasha Bharadwaj are declared winners of 2018 season , alongside Shruti Sharma who won a ' Special Mention ' award . Runners up in the male category were Aashish Mehrotra and Harshvardhan Deo and in the female category were Naina Singh and Shruti Sharma .\", sentence_starts=[0, 128, 187, 323], selected_sent={'start': 187, 'end': 323, 'string': \"Aman Gandotra and Natasha Bharadwaj are declared winners of 2018 season , alongside Shruti Sharma who won a ' Special Mention ' award . \"}, answer=[Entity(start_offset=187, end_offset=222, type='context', text='Aman Gandotra and Natasha Bharadwaj', normalized_text='aman gandotra and natasha bharadwaj')], nq_answers=[[Entity(start_offset=187, end_offset=200, type='context', text='Aman Gandotra', normalized_text='aman gandotra'), Entity(start_offset=205, end_offset=222, type='context', text='Natasha Bharadwaj', normalized_text='natasha bharadwaj')]], aligned_nps=[(Entity(start_offset=12, end_offset=35, type='question', text=\"india's next super star\", normalized_text='indias next super star'), Entity(start_offset=247, end_offset=258, type='context', text='2018 season', normalized_text='2018 season'))], explanation_type='single_sentence'),\n",
       " 7735703748660141931: QEDExample(example_id=7735703748660141931, title='Bad Boys (Inner Circle song)', question='who sings the theme song for the tv show cops', passage=\"`` Bad Boys '' is a 1987 song by the Jamaican reggae band Inner Circle , which obtained high popularity in the United States after its re-release in 1993 , peaking at number 8 on the Billboard Hot 100 and number 7 on the Top 40 Mainstream . It is well known as the opening theme to the U.S. TV show Cops .\", sentence_starts=[0, 241], selected_sent={'start': 0, 'end': 241, 'string': \"`` Bad Boys '' is a 1987 song by the Jamaican reggae band Inner Circle , which obtained high popularity in the United States after its re-release in 1993 , peaking at number 8 on the Billboard Hot 100 and number 7 on the Top 40 Mainstream . \"}, answer=[Entity(start_offset=58, end_offset=70, type='context', text='Inner Circle', normalized_text='inner circle')], nq_answers=[[Entity(start_offset=58, end_offset=70, type='context', text='Inner Circle', normalized_text='inner circle')], [Entity(start_offset=33, end_offset=70, type='context', text='the Jamaican reggae band Inner Circle', normalized_text='jamaican reggae band inner circle')], [Entity(start_offset=37, end_offset=70, type='context', text='Jamaican reggae band Inner Circle', normalized_text='jamaican reggae band inner circle')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='the theme song for the tv show cops', normalized_text='theme song for tv show cops'), Entity(start_offset=3, end_offset=11, type='context', text='Bad Boys', normalized_text='bad boys'))], explanation_type='single_sentence'),\n",
       " 908345273639329593: QEDExample(example_id=908345273639329593, title='Minimum wage in the United States', question='when was the minimum wage established in the united states', passage=\"In 1910 , in conjunction with advocacy work led by Florence Kelley of the National Consumer League , the Women 's Trade Union League ( WTLU ) of Massachusetts under the leadership of Elizabeth Evans took up the cause of minimum wage legislation in Massachusetts . Over the next two years , a coalition of social reform groups and labor advocates in Boston pushed for minimum wage legislation in the state . In 1912 , Massachusetts passed the first American minimum wage legislation , which established a state commission for recommending non-compulsory minimum wages for women and children . Within eight years , at least thirteen U.S. states and the District of Columbia would pass minimum wage laws , with pressure being placed on state legislatures by the National Consumers League in a coalition with other women 's voluntary associations and organized labor . The United States Supreme Court of the Lochner era consistently invalidated compulsory minimum wage laws . Advocates for these minimum wage laws hoped that they would be upheld under the precedent of Muller v. Oregon , which upheld maximum working hours laws for women on the grounds that women required special protection that men did not . However , the Court did not extend this principle to minimum wage laws , considering the latter as interfering with the ability of employers to freely negotiate wage contracts with employees .\", sentence_starts=[0, 264, 407, 592, 865, 972, 1207], selected_sent={'start': 407, 'end': 592, 'string': 'In 1912 , Massachusetts passed the first American minimum wage legislation , which established a state commission for recommending non-compulsory minimum wages for women and children . '}, answer=[Entity(start_offset=410, end_offset=414, type='context', text='1912', normalized_text='1912')], nq_answers=[[Entity(start_offset=410, end_offset=414, type='context', text='1912', normalized_text='1912')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -4234103220698127642: QEDExample(example_id=-4234103220698127642, title='Regulatory Reform (Fire Safety) Order 2005', question='when did the the regulatory reform (fire safety) order 2005 first come into effect', passage='The Regulatory Reform ( Fire Safety ) Order 2005 ( officially listed as The Regulatory Reform ( Fire Safety ) Order 2005 S.I. 2005 No. 1541 ) is a statutory instrument , applicable only in England and Wales . The Order places the responsibility on individuals within an organisation to carry out risk assessments to identify , manage and reduce the risk of fire . The Order was made into law on 7 June 2005 and came into force on 1 October 2006 .', sentence_starts=[0, 209, 364], selected_sent={'start': 364, 'end': 446, 'string': 'The Order was made into law on 7 June 2005 and came into force on 1 October 2006 .'}, answer=[Entity(start_offset=430, end_offset=444, type='context', text='1 October 2006', normalized_text='1 october 2006')], nq_answers=[[Entity(start_offset=430, end_offset=444, type='context', text='1 October 2006', normalized_text='1 october 2006')]], aligned_nps=[(Entity(start_offset=9, end_offset=59, type='question', text='the the regulatory reform (fire safety) order 2005', normalized_text='regulatory reform fire safety order 2005'), Entity(start_offset=364, end_offset=373, type='context', text='The Order', normalized_text='order'))], explanation_type='single_sentence'),\n",
       " 1033762063117474533: QEDExample(example_id=1033762063117474533, title='Diary of a Wimpy Kid (book series)', question='how many books are in the diary of a whimpy kid series', passage=\"The book became an instant hit , and the online version received about 20 million views as of 2009 ; many online readers requested a printed version . Kinney had agreed , and in April 2007 , Diary of a Wimpy Kid was published . To date , twelve Wimpy Kid books have been released , plus one do - it - yourself book and two movie diaries . In April 2009 , TIME named Kinney one of The World 's Most Influential People .\", sentence_starts=[0, 151, 228, 339], selected_sent={'start': 228, 'end': 339, 'string': 'To date , twelve Wimpy Kid books have been released , plus one do - it - yourself book and two movie diaries . '}, answer=[Entity(start_offset=238, end_offset=244, type='context', text='twelve', normalized_text='twelve')], nq_answers=[[Entity(start_offset=238, end_offset=336, type='context', text='twelve Wimpy Kid books have been released , plus one do - it - yourself book and two movie diaries', normalized_text='twelve wimpy kid books have been released plus one do it yourself book and two movie diaries')]], aligned_nps=[(Entity(start_offset=22, end_offset=54, type='question', text='the diary of a whimpy kid series', normalized_text='diary of whimpy kid series'), Entity(start_offset=245, end_offset=254, type='context', text='Wimpy Kid', normalized_text='wimpy kid'))], explanation_type='single_sentence'),\n",
       " -4206190509773458361: QEDExample(example_id=-4206190509773458361, title='Large denominations of United States currency', question='what is the largest bill in american money', passage='Large denominations of United States currency greater than $100 were circulated by the United States Treasury until 1969 . Since then , U.S. dollar banknotes have only been issued in seven denominations : $1 , $2 , $5 , $10 , $20 , $50 , and $100 .', sentence_starts=[0, 123], selected_sent={'start': 123, 'end': 248, 'string': 'Since then , U.S. dollar banknotes have only been issued in seven denominations : $1 , $2 , $5 , $10 , $20 , $50 , and $100 .'}, answer=[Entity(start_offset=242, end_offset=246, type='context', text='$100', normalized_text='100')], nq_answers=[[Entity(start_offset=242, end_offset=246, type='context', text='$100', normalized_text='100')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -7394149107458430124: QEDExample(example_id=-7394149107458430124, title='Villanova Wildcats', question='when was the last time villanova won the ncaa basketball championship', passage=\"The Villanova Wildcats compete in the Big East Conference and are coached by Jay Wright . The team has traditionally divides its home schedule between its on - campus arena , the William B. Finneran Pavilion , and the Wells Fargo Center in South Philadelphia , for larger draws . During the 2017 - 18 season , the team played its entire home schedule that season at the Wells Fargo Center following the reconstruction of the Pavilion scheduled to be completed in time for the 2018 - 19 school year . Wright has taken the Wildcats to 12 postseason appearances including 7 consecutive trips ( 2005 -- 2011 ) and 5 consecutive trips ( 2013 - 2017 ) to the NCAA Tournament . The 2011 - 12 team struggled and missed postseason but Coach Wright brought a surprising young team back to the 2013 NCAA Tournament . Villanova has appeared in the NIT 17 times , winning in 1994 , and won the Big East Tournament in 1995 , 2015 and 2017 . The Wildcats have appeared in the NCAA Men 's Tournament 37 times , the 8th highest total in NCAA history have reached the Elite Eight 13 times . They have been to the Final Four of the NCAA Division I Men 's Basketball Tournament on five occasions . The 1939 team coached by Al Severance reached the inaugural NCAA Final Four played at the Palestra for the 1939 NCAA Basketball Tournament . All - American Howard Porter led a Wildcat team coached by Jack Kraft to Final Four of the 1971 NCAA University Division Basketball Tournament . Coach Rollie Massimino took Villanova to a surprising 1985 National Championship . Current Coach Jay Wright reached the Final Four at the 2009 NCAA Division I Men 's Basketball Tournament behind Dante Cunningham and Scottie Reynolds . The team most recently won the 2018 NCAA Division I Men 's Basketball Tournament for their third National Championship .\", sentence_starts=[0, 90, 280, 500, 671, 806, 927, 1073, 1178, 1319, 1464, 1547, 1699], selected_sent={'start': 1699, 'end': 1819, 'string': \"The team most recently won the 2018 NCAA Division I Men 's Basketball Tournament for their third National Championship .\"}, answer=[Entity(start_offset=1730, end_offset=1734, type='context', text='2018', normalized_text='2018')], nq_answers=[[Entity(start_offset=1730, end_offset=1734, type='context', text='2018', normalized_text='2018')]], aligned_nps=[(Entity(start_offset=23, end_offset=32, type='question', text='villanova', normalized_text='villanova'), Entity(start_offset=1699, end_offset=1707, type='context', text='The team', normalized_text='team')), (Entity(start_offset=37, end_offset=69, type='question', text='the ncaa basketball championship', normalized_text='ncaa basketball championship'), Entity(start_offset=1726, end_offset=1779, type='context', text=\"the 2018 NCAA Division I Men 's Basketball Tournament\", normalized_text='2018 ncaa division i men s basketball tournament'))], explanation_type='single_sentence'),\n",
       " 647659679149316553: QEDExample(example_id=647659679149316553, title='Sahara', question='what is the significance of the sahara desert', passage=\"The Sahara ( Arabic : الصحراء الكبرى \\u200e , aṣ - ṣaḥrāʼ al - kubrá , ' the Great Desert ' ) is the largest hot desert and the third largest desert in the world after Antarctica and the Arctic . Its area of 9,200,000 square kilometres ( 3,600,000 sq mi ) is comparable to the area of China or the United States . The name ' Sahara ' is derived from dialectal Arabic word for `` desert '' , ṣaḥra ( صحرا / ˈsʕaħra / ) .\", sentence_starts=[0, 191, 309], selected_sent={'start': 0, 'end': 191, 'string': \"The Sahara ( Arabic : الصحراء الكبرى \\u200e , aṣ - ṣaḥrāʼ al - kubrá , ' the Great Desert ' ) is the largest hot desert and the third largest desert in the world after Antarctica and the Arctic . \"}, answer=[Entity(start_offset=92, end_offset=188, type='context', text='the largest hot desert and the third largest desert in the world after Antarctica and the Arctic', normalized_text='largest hot desert and third largest desert in world after antarctica and arctic')], nq_answers=[[Entity(start_offset=92, end_offset=188, type='context', text='the largest hot desert and the third largest desert in the world after Antarctica and the Arctic', normalized_text='largest hot desert and third largest desert in world after antarctica and arctic')], [Entity(start_offset=92, end_offset=114, type='context', text='the largest hot desert', normalized_text='largest hot desert'), Entity(start_offset=119, end_offset=188, type='context', text='the third largest desert in the world after Antarctica and the Arctic', normalized_text='third largest desert in world after antarctica and arctic')]], aligned_nps=[(Entity(start_offset=28, end_offset=45, type='question', text='the sahara desert', normalized_text='sahara desert'), Entity(start_offset=0, end_offset=10, type='context', text='The Sahara', normalized_text='sahara'))], explanation_type='single_sentence'),\n",
       " 1550607712450089106: QEDExample(example_id=1550607712450089106, title='Cape of Good Hope', question='who captained the first european ship to sail around the tip of africa', passage=\"When following the western side of the African coastline from the equator , however , the Cape of Good Hope marks the point where a ship begins to travel more eastward than southward . Thus , the first modern rounding of the cape in 1488 by Portuguese explorer Bartolomeu Dias was a milestone in the attempts by the Portuguese to establish direct trade relations with the Far East ( although Herodotus mentioned a claim that the Phoenicians had done so far earlier ) . Dias called the cape Cabo das Tormentas ( `` Cape of Storms '' ; Dutch : Stormkaap ) , which was the original name of the `` Cape of Good Hope '' .\", sentence_starts=[0, 185, 469], selected_sent={'start': 185, 'end': 469, 'string': 'Thus , the first modern rounding of the cape in 1488 by Portuguese explorer Bartolomeu Dias was a milestone in the attempts by the Portuguese to establish direct trade relations with the Far East ( although Herodotus mentioned a claim that the Phoenicians had done so far earlier ) . '}, answer=[Entity(start_offset=261, end_offset=276, type='context', text='Bartolomeu Dias', normalized_text='bartolomeu dias')], nq_answers=[[Entity(start_offset=261, end_offset=276, type='context', text='Bartolomeu Dias', normalized_text='bartolomeu dias')]], aligned_nps=[(Entity(start_offset=53, end_offset=70, type='question', text='the tip of africa', normalized_text='tip of africa'), Entity(start_offset=221, end_offset=229, type='context', text='the cape', normalized_text='cape'))], explanation_type='single_sentence'),\n",
       " 2588583207329611463: QEDExample(example_id=2588583207329611463, title='A Whiter Shade of Pale', question='who sang a whiter shade of pale first', passage=\"`` A Whiter Shade of Pale '' is the debut single by the British rock band Procol Harum , released 12 May 1967 . The single reached number one in the UK Singles Chart on 8 June 1967 and stayed there for six weeks . Without much promotion , it reached number 5 on the Bilboard pop chart in the United States . One of the anthems of the 1967 Summer of Love , it is one of fewer than 30 singles to have sold over 10 million copies worldwide .\", sentence_starts=[0, 112, 214, 308], selected_sent={'start': 0, 'end': 112, 'string': \"`` A Whiter Shade of Pale '' is the debut single by the British rock band Procol Harum , released 12 May 1967 . \"}, answer=[Entity(start_offset=74, end_offset=86, type='context', text='Procol Harum', normalized_text='procol harum')], nq_answers=[[Entity(start_offset=74, end_offset=86, type='context', text='Procol Harum', normalized_text='procol harum')], [Entity(start_offset=56, end_offset=86, type='context', text='British rock band Procol Harum', normalized_text='british rock band procol harum')]], aligned_nps=[(Entity(start_offset=9, end_offset=31, type='question', text='a whiter shade of pale', normalized_text='whiter shade of pale'), Entity(start_offset=3, end_offset=25, type='context', text='A Whiter Shade of Pale', normalized_text='whiter shade of pale'))], explanation_type='single_sentence'),\n",
       " -7930247987013374697: QEDExample(example_id=-7930247987013374697, title='Burzahom archaeological site', question='what material was used to build the roofs of houses in burzahom', passage=\"The Burzahom site is a prehistoric settlement in the village of the same name in the Srinagar District . It is 16 kilometres ( 9.9 mi ) to the northeast of Srinagar on the Naseem - Shalimar road . The elevation of the site is 1,800 metres ( 5,900 ft ) above sea - level . It is the northernmost excavated Neolithic site of India . The site is on an ancient Pleistocene lake bed . The location is in a high terrace which is part of the floodplain of the Jhelum river and has Karewa soil ( clay ) formation . The site has a commanding view of the Dal lake which is about 2 kilometres ( 1.2 mi ) away . In the Kashmiri language ' Burzahom ' means `` birch '' , a tree species ( that generally grows in the elevation range of 3,000 to 4,200 metres ( 9,800 to 13,800 ft ) in the Himalayas ) , which is found in the excavated housing area in the form of roofing material , and thus confirming the existence of the tree even in the pre-historic Neolithic times .\", sentence_starts=[0, 105, 197, 272, 331, 380, 507, 600], selected_sent={'start': 600, 'end': 955, 'string': \"In the Kashmiri language ' Burzahom ' means `` birch '' , a tree species ( that generally grows in the elevation range of 3,000 to 4,200 metres ( 9,800 to 13,800 ft ) in the Himalayas ) , which is found in the excavated housing area in the form of roofing material , and thus confirming the existence of the tree even in the pre-historic Neolithic times .\"}, answer=[Entity(start_offset=647, end_offset=652, type='context', text='birch', normalized_text='birch')], nq_answers=[[Entity(start_offset=647, end_offset=652, type='context', text='birch', normalized_text='birch')]], aligned_nps=[(Entity(start_offset=55, end_offset=63, type='question', text='burzahom', normalized_text='burzahom'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -7326729858763272108: QEDExample(example_id=-7326729858763272108, title='Law & Order: Special Victims Unit (season 19)', question='when does the new season of law and order svu come on', passage='The nineteenth season of Law & Order : Special Victims Unit premiered on September 27 , 2017 .', sentence_starts=[0], selected_sent={'start': 0, 'end': 94, 'string': 'The nineteenth season of Law & Order : Special Victims Unit premiered on September 27 , 2017 .'}, answer=[Entity(start_offset=73, end_offset=92, type='context', text='September 27 , 2017', normalized_text='september 27 2017')], nq_answers=[[Entity(start_offset=73, end_offset=92, type='context', text='September 27 , 2017', normalized_text='september 27 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='the new season of law and order svu', normalized_text='new season of law and order svu'), Entity(start_offset=0, end_offset=59, type='context', text='The nineteenth season of Law & Order : Special Victims Unit', normalized_text='nineteenth season of law order special victims unit'))], explanation_type='single_sentence'),\n",
       " -2898557982435101429: QEDExample(example_id=-2898557982435101429, title='Human digestive system', question='in what part of the digestive tube do you expect the initial digestion of starch', passage=\"Within the oral mucosa ( a mucous membrane ) lining the mouth and also on the tongue and palates and mouth floor , are the minor salivary glands ; their secretions are mainly mucous and are innervated by the facial nerve ( the seventh cranial nerve ) . The glands also secrete amylase a first stage in the breakdown of food acting on the carbohydrate in the food to transform the starch content into maltose . There are other glands on the surface of the tongue that encircle taste buds on the back part of the tongue and these also produce lingual lipase . Lipase is a digestive enzyme that catalyses the hydrolysis of lipids ( fats ) . These glands are termed Von Ebner 's glands which have also been shown to have another function in the secretion of histatins which offer an early defense ( outside of the immune system ) against microbes in food , when it makes contact with these glands on the tongue tissue . Sensory information can stimulate the secretion of saliva providing the necessary fluid for the tongue to work with and also to ease swallowing of the food .\", sentence_starts=[0, 253, 410, 558, 638, 916], selected_sent={'start': 253, 'end': 410, 'string': 'The glands also secrete amylase a first stage in the breakdown of food acting on the carbohydrate in the food to transform the starch content into maltose . '}, answer=[Entity(start_offset=52, end_offset=61, type='context', text='the mouth', normalized_text='mouth')], nq_answers=[[Entity(start_offset=52, end_offset=61, type='context', text='the mouth', normalized_text='mouth')], [Entity(start_offset=119, end_offset=144, type='context', text='the minor salivary glands', normalized_text='minor salivary glands')]], aligned_nps=[(Entity(start_offset=74, end_offset=80, type='question', text='starch', normalized_text='starch'), Entity(start_offset=376, end_offset=394, type='context', text='the starch content', normalized_text='starch content'))], explanation_type='single_sentence'),\n",
       " -12824711872448438: QEDExample(example_id=-12824711872448438, title='Brigade de cuisine', question='who was the french chef given credit for developing the classic kitchen\\u200b brigade', passage='The concept was developed by Georges Auguste Escoffier . This structured team system delegates responsibilities to different individuals who specialize in certain tasks in the kitchen .', sentence_starts=[0, 57], selected_sent={'start': 0, 'end': 57, 'string': 'The concept was developed by Georges Auguste Escoffier . '}, answer=[Entity(start_offset=29, end_offset=54, type='context', text='Georges Auguste Escoffier', normalized_text='georges auguste escoffier')], nq_answers=[[Entity(start_offset=29, end_offset=54, type='context', text='Georges Auguste Escoffier', normalized_text='georges auguste escoffier')]], aligned_nps=[(Entity(start_offset=52, end_offset=80, type='question', text='the classic kitchen\\u200b brigade', normalized_text='classic kitchen\\u200b brigade'), Entity(start_offset=0, end_offset=11, type='context', text='The concept', normalized_text='concept'))], explanation_type='single_sentence'),\n",
       " 2374750245195224966: QEDExample(example_id=2374750245195224966, title=\"For What It's Worth\", question=\"who sings stop listen what's that sound\", passage=\"`` For What It 's Worth ( Stop , Hey What 's That Sound ) '' ( often referred to as simply `` For What It 's Worth '' ) is a song written by Stephen Stills . It was performed by Buffalo Springfield , recorded on December 5 , 1966 , and released as a single on Atco Records in January 1967 . The single peaked at number seven on the Billboard Hot 100 chart . This song is currently ranked number 63 on Rolling Stone 's list of The 500 Greatest Songs of All Time as well as the eighth best song of 1967 by Acclaimed Music .\", sentence_starts=[0, 158, 291, 358], selected_sent={'start': 0, 'end': 158, 'string': \"`` For What It 's Worth ( Stop , Hey What 's That Sound ) '' ( often referred to as simply `` For What It 's Worth '' ) is a song written by Stephen Stills . \"}, answer=[Entity(start_offset=141, end_offset=155, type='context', text='Stephen Stills', normalized_text='stephen stills')], nq_answers=[[Entity(start_offset=178, end_offset=197, type='context', text='Buffalo Springfield', normalized_text='buffalo springfield')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text=\"stop listen what's that sound\", normalized_text='stop listen whats that sound'), Entity(start_offset=3, end_offset=57, type='context', text=\"For What It 's Worth ( Stop , Hey What 's That Sound )\", normalized_text='for what it s worth stop hey what s that sound'))], explanation_type='single_sentence'),\n",
       " 5758694170037504500: QEDExample(example_id=5758694170037504500, title='The Gift of the Magi', question='what is the short story the gift of the magi about', passage=\"`` The Gift of the Magi '' is a short story , written by O. Henry ( a pen name for William Sydney Porter ) , about a young husband and wife and how they deal with the challenge of buying secret Christmas gifts for each other with very little money . As a sentimental story with a moral lesson about gift - giving , it has been a popular one for adaptation , especially for presentation at Christmas time . The plot and its twist ending are well - known , and the ending is generally considered an example of comic irony . It was allegedly written at Pete 's Tavern on Irving Place in New York City .\", sentence_starts=[0, 250, 406, 522], selected_sent={'start': 0, 'end': 250, 'string': \"`` The Gift of the Magi '' is a short story , written by O. Henry ( a pen name for William Sydney Porter ) , about a young husband and wife and how they deal with the challenge of buying secret Christmas gifts for each other with very little money . \"}, answer=[Entity(start_offset=115, end_offset=247, type='context', text='a young husband and wife and how they deal with the challenge of buying secret Christmas gifts for each other with very little money', normalized_text='young husband and wife and how they deal with challenge of buying secret christmas gifts for each other with very little money')], nq_answers=[[Entity(start_offset=115, end_offset=247, type='context', text='a young husband and wife and how they deal with the challenge of buying secret Christmas gifts for each other with very little money', normalized_text='young husband and wife and how they deal with challenge of buying secret christmas gifts for each other with very little money')]], aligned_nps=[(Entity(start_offset=8, end_offset=44, type='question', text='the short story the gift of the magi', normalized_text='short story gift of magi'), Entity(start_offset=3, end_offset=23, type='context', text='The Gift of the Magi', normalized_text='gift of magi'))], explanation_type='single_sentence'),\n",
       " 6572568689091749101: QEDExample(example_id=6572568689091749101, title='Johnny Crawford', question='who played mark on the show the rifleman', passage='John Ernest Crawford ( born March 26 , 1946 ) is an American character actor , singer , and musician . At age 12 , Crawford rose to fame for playing Mark McCain , the son of Lucas McCain ( played by Chuck Connors ) , in the popular ABC Western series , The Rifleman , which originally aired from 1958 to 1963 . Crawford first performed before a national audience as a Mouseketeer .', sentence_starts=[0, 103, 311], selected_sent={'start': 103, 'end': 311, 'string': 'At age 12 , Crawford rose to fame for playing Mark McCain , the son of Lucas McCain ( played by Chuck Connors ) , in the popular ABC Western series , The Rifleman , which originally aired from 1958 to 1963 . '}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='John Ernest Crawford', normalized_text='john ernest crawford')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='John Ernest Crawford', normalized_text='john ernest crawford')]], aligned_nps=[(Entity(start_offset=11, end_offset=15, type='question', text='mark', normalized_text='mark'), Entity(start_offset=149, end_offset=160, type='context', text='Mark McCain', normalized_text='mark mccain')), (Entity(start_offset=28, end_offset=40, type='question', text='the rifleman', normalized_text='rifleman'), Entity(start_offset=220, end_offset=265, type='context', text='the popular ABC Western series , The Rifleman', normalized_text='popular abc western series rifleman'))], explanation_type='single_sentence'),\n",
       " 802677011826729357: QEDExample(example_id=802677011826729357, title='Daren Kagasoff', question='who played ricky in secret life of the american teenager', passage='Daren Maxwell Kagasoff ( KA - guh - sawf ) ( born September 16 , 1987 ) is an American actor . He is known for starring as Ricky Underwood on the ABC Family teen drama series The Secret Life of the American Teenager from 2008 to 2013 .', sentence_starts=[0, 95], selected_sent={'start': 95, 'end': 235, 'string': 'He is known for starring as Ricky Underwood on the ABC Family teen drama series The Secret Life of the American Teenager from 2008 to 2013 .'}, answer=[Entity(start_offset=0, end_offset=22, type='context', text='Daren Maxwell Kagasoff', normalized_text='daren maxwell kagasoff')], nq_answers=[[Entity(start_offset=0, end_offset=22, type='context', text='Daren Maxwell Kagasoff', normalized_text='daren maxwell kagasoff')]], aligned_nps=[(Entity(start_offset=11, end_offset=16, type='question', text='ricky', normalized_text='ricky'), Entity(start_offset=123, end_offset=138, type='context', text='Ricky Underwood', normalized_text='ricky underwood')), (Entity(start_offset=20, end_offset=56, type='question', text='secret life of the american teenager', normalized_text='secret life of american teenager'), Entity(start_offset=142, end_offset=215, type='context', text='the ABC Family teen drama series The Secret Life of the American Teenager', normalized_text='abc family teen drama series secret life of american teenager'))], explanation_type='single_sentence'),\n",
       " 3028343500075334931: QEDExample(example_id=3028343500075334931, title='Meet the Press', question='who had the longest tenure as moderator on meet the press', passage=\"Network officials , concerned for the show 's future , turned to Tim Russert , the network 's Washington , D.C. , bureau chief . He took over as moderator of Meet the Press on December 8 , 1991 , and remained with the program until his death on June 13 , 2008 , becoming the longest serving moderator in the program 's history .\", sentence_starts=[0, 129], selected_sent={'start': 129, 'end': 328, 'string': \"He took over as moderator of Meet the Press on December 8 , 1991 , and remained with the program until his death on June 13 , 2008 , becoming the longest serving moderator in the program 's history .\"}, answer=[Entity(start_offset=65, end_offset=76, type='context', text='Tim Russert', normalized_text='tim russert')], nq_answers=[[Entity(start_offset=65, end_offset=76, type='context', text='Tim Russert', normalized_text='tim russert')]], aligned_nps=[(Entity(start_offset=30, end_offset=57, type='question', text='moderator on meet the press', normalized_text='moderator on meet press'), Entity(start_offset=145, end_offset=172, type='context', text='moderator of Meet the Press', normalized_text='moderator of meet press'))], explanation_type='single_sentence'),\n",
       " -701619113953256261: QEDExample(example_id=-701619113953256261, title='Atwood machine', question='what is a real world application of an atwood machine', passage='An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses . The same principle is used for funicular railways with two connected railway cars on inclined tracks , and for the elevators on the Eiffel Tower which counterbalance each other . Ski lifts are another example , where the gondolas move on a closed ( continuous ) pulley system up and down the mountain . The ski lift is similar to the counter-weighted elevator , but with a constraining force provided by the cable in the vertical dimension thereby achieving work in both the horizontal and vertical dimensions . Boat lifts are another type of counter-weighted elevator system approximating an Atwood machine .', sentence_starts=[0, 229, 408, 532, 741], selected_sent={'start': 0, 'end': 229, 'string': 'An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses . '}, answer=[Entity(start_offset=0, end_offset=33, type='context', text='An elevator with a counterbalance', normalized_text='elevator with counterbalance')], nq_answers=[[Entity(start_offset=0, end_offset=33, type='context', text='An elevator with a counterbalance', normalized_text='elevator with counterbalance')]], aligned_nps=[(Entity(start_offset=36, end_offset=53, type='question', text='an atwood machine', normalized_text='atwood machine'), Entity(start_offset=47, end_offset=70, type='context', text='an ideal Atwood machine', normalized_text='ideal atwood machine'))], explanation_type='single_sentence'),\n",
       " 6766518966445775953: QEDExample(example_id=6766518966445775953, title='Tin Woodman', question='who wants a heart in the wizard of oz', passage=\"Originally an ordinary man by the name of Nick Chopper ( the name first appearing in The Marvelous Land of Oz ) , the Tin Woodman used to make his living chopping down trees in the forests of Oz , as his father had before him . The Wicked Witch of the East enchanted his axe to prevent him from marrying his sweetheart , after being bribed by the lazy old woman who kept the Munchkin maiden as a servant , and did not wish to lose her . ( In a later book of the series , The Tin Woodman of Oz , the woman is said to be the Witch 's servant , and it is the Witch herself who decides to enchant Nick 's axe . ) The enchanted axe chopped off his limbs , one by one . Each time he lost a limb , Ku - Klip the tinsmith replaced it with a prosthetic limb made of tin . Finally , nothing was left of him but tin . However , Ku - Klip neglected to replace his heart . Once Nick Chopper was made entirely of tin , he was no longer able to love the lady he had fallen for .\", sentence_starts=[0, 228, 437, 609, 664, 763, 807, 860], selected_sent={'start': 807, 'end': 860, 'string': 'However , Ku - Klip neglected to replace his heart . '}, answer=[Entity(start_offset=114, end_offset=129, type='context', text='the Tin Woodman', normalized_text='tin woodman')], nq_answers=[[Entity(start_offset=114, end_offset=129, type='context', text='the Tin Woodman', normalized_text='tin woodman')]], aligned_nps=[(Entity(start_offset=21, end_offset=37, type='question', text='the wizard of oz', normalized_text='wizard of oz'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 4399912168528695468: QEDExample(example_id=4399912168528695468, title='Rigor mortis', question='what are the importance of rigor mortis in meat processing', passage='Rigor mortis is very important in meat technology . The onset of rigor mortis and its resolution partially determine the tenderness of meat . If the post-slaughter meat is immediately chilled to 15 ° C ( 59 ° F ) , a phenomenon known as cold shortening occurs , whereby the muscle sarcomeres shrink to a third of their original length .', sentence_starts=[0, 52, 142], selected_sent={'start': 52, 'end': 142, 'string': 'The onset of rigor mortis and its resolution partially determine the tenderness of meat . '}, answer=[Entity(start_offset=52, end_offset=139, type='context', text='The onset of rigor mortis and its resolution partially determine the tenderness of meat', normalized_text='onset of rigor mortis and its resolution partially determine tenderness of meat')], nq_answers=[[Entity(start_offset=65, end_offset=139, type='context', text='rigor mortis and its resolution partially determine the tenderness of meat', normalized_text='rigor mortis and its resolution partially determine tenderness of meat')], [Entity(start_offset=121, end_offset=139, type='context', text='tenderness of meat', normalized_text='tenderness of meat')]], aligned_nps=[(Entity(start_offset=27, end_offset=39, type='question', text='rigor mortis', normalized_text='rigor mortis'), Entity(start_offset=65, end_offset=77, type='context', text='rigor mortis', normalized_text='rigor mortis'))], explanation_type='single_sentence'),\n",
       " 6091079313707220510: QEDExample(example_id=6091079313707220510, title='Life of Pi', question='what is the tigers name in life of pi', passage=\"Life of Pi is a Canadian fantasy adventure novel by Yann Martel published in 2001 . The protagonist is Piscine Molitor `` Pi '' Patel , an Indian boy from Pondicherry who explores issues of spirituality and practicality from an early age . He survives 227 days after a shipwreck while stranded on a lifeboat in the Pacific Ocean with a Bengal tiger named Richard Parker .\", sentence_starts=[0, 84, 240], selected_sent={'start': 240, 'end': 371, 'string': 'He survives 227 days after a shipwreck while stranded on a lifeboat in the Pacific Ocean with a Bengal tiger named Richard Parker .'}, answer=[Entity(start_offset=355, end_offset=369, type='context', text='Richard Parker', normalized_text='richard parker')], nq_answers=[[Entity(start_offset=355, end_offset=369, type='context', text='Richard Parker', normalized_text='richard parker')]], aligned_nps=[(Entity(start_offset=8, end_offset=17, type='question', text='the tiger', normalized_text='tiger'), Entity(start_offset=334, end_offset=348, type='context', text='a Bengal tiger', normalized_text='bengal tiger')), (Entity(start_offset=27, end_offset=37, type='question', text='life of pi', normalized_text='life of pi'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -7275272659885289884: QEDExample(example_id=-7275272659885289884, title='Workweek and weekend', question='when did the 5 day work week begin', passage='In 1908 , the first five - day workweek in the United States was instituted by a New England cotton mill so that Jewish workers would not have to work on the Sabbath from sundown Friday to sundown Saturday . In 1926 , Henry Ford began shutting down his automotive factories for all of Saturday and Sunday . In 1929 , the Amalgamated Clothing Workers of America Union was the first union to demand a five - day workweek and receive it . After that , the rest of the United States slowly followed , but it was not until 1940 , when a provision of the 1938 Fair Labor Standards Act mandating a maximum 40 - hour workweek went into effect , that the two - day weekend was adopted nationwide .', sentence_starts=[0, 208, 307, 436], selected_sent={'start': 436, 'end': 688, 'string': 'After that , the rest of the United States slowly followed , but it was not until 1940 , when a provision of the 1938 Fair Labor Standards Act mandating a maximum 40 - hour workweek went into effect , that the two - day weekend was adopted nationwide .'}, answer=[Entity(start_offset=518, end_offset=522, type='context', text='1940', normalized_text='1940')], nq_answers=[[Entity(start_offset=3, end_offset=7, type='context', text='1908', normalized_text='1908')], [Entity(start_offset=518, end_offset=522, type='context', text='1940', normalized_text='1940')], [Entity(start_offset=0, end_offset=7, type='context', text='In 1908', normalized_text='in 1908')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6959456828837530300: QEDExample(example_id=-6959456828837530300, title='North Pole', question='where is the north pole on the world map', passage='Coordinates : 90 ° N 0 ° W \\ufeff / \\ufeff 90 ° N - 0 ° E \\ufeff / 90 ; - 0', sentence_starts=[0], selected_sent={'start': 0, 'end': 60, 'string': 'Coordinates : 90 ° N 0 ° W \\ufeff / \\ufeff 90 ° N - 0 ° E \\ufeff / 90 ; - 0'}, answer=[Entity(start_offset=14, end_offset=60, type='context', text='90 ° N 0 ° W \\ufeff / \\ufeff 90 ° N - 0 ° E \\ufeff / 90 ; - 0', normalized_text='90 ° n 0 ° w \\ufeff \\ufeff 90 ° n 0 ° e \\ufeff 90 0')], nq_answers=[[Entity(start_offset=14, end_offset=47, type='context', text='90 ° N 0 ° W \\ufeff / \\ufeff 90 ° N - 0 ° E', normalized_text='90 ° n 0 ° w \\ufeff \\ufeff 90 ° n 0 ° e')]], aligned_nps=[(Entity(start_offset=9, end_offset=23, type='question', text='the north pole', normalized_text='north pole'), Entity(start_offset=0, end_offset=11, type='context', text='Coordinates', normalized_text='coordinates'))], explanation_type='single_sentence'),\n",
       " 2339339749699668536: QEDExample(example_id=2339339749699668536, title='Super Bowl LI halftime show', question='who performed the halftime show at super bowl 51', passage='The Super Bowl LI Halftime show took place on February 5 , 2017 , at NRG Stadium in Houston , Texas as part of Super Bowl LI . The show was headlined by Lady Gaga , who performed a medley of her songs , including newer material from her most recent studio album Joanne .', sentence_starts=[0, 127], selected_sent={'start': 127, 'end': 270, 'string': 'The show was headlined by Lady Gaga , who performed a medley of her songs , including newer material from her most recent studio album Joanne .'}, answer=[Entity(start_offset=153, end_offset=162, type='context', text='Lady Gaga', normalized_text='lady gaga')], nq_answers=[[Entity(start_offset=153, end_offset=162, type='context', text='Lady Gaga', normalized_text='lady gaga')]], aligned_nps=[(Entity(start_offset=14, end_offset=48, type='question', text='the halftime show at super bowl 51', normalized_text='halftime show at super bowl 51'), Entity(start_offset=127, end_offset=135, type='context', text='The show', normalized_text='show'))], explanation_type='single_sentence'),\n",
       " -4482484688035625980: QEDExample(example_id=-4482484688035625980, title='The Man in the High Castle', question='what do the films mean in high castle', passage=\"There are several major additional characters introduced by the television series and numerous narrative details and the plotline differ radically from the source novel . For example , the planned Nazi pre-emptive nuclear strike on Japan , `` Operation Dandelion , '' is apparently being prevented only by Hitler 's personal refusal to authorise it , leading Heydrich and the faction demanding pre-emptive war to plot the Führer 's assassination . In addition , Hawthorne Abendsen does not appear in the first season of the television version and The Grasshopper Lies Heavy is a series of newsreel films depicting multiple alternative realities rather than a novel ( although this idea may actually be borrowed from Dick 's later novel Valis which features a mysterious film depicting yet another dystopian alternative history of the USA ) . As of the Season 1 finale , these films are being tracked down by SS agents like Blake for dispatch to Hitler for an as - yet - unknown purpose .\", sentence_starts=[0, 171, 448, 842], selected_sent={'start': 448, 'end': 842, 'string': \"In addition , Hawthorne Abendsen does not appear in the first season of the television version and The Grasshopper Lies Heavy is a series of newsreel films depicting multiple alternative realities rather than a novel ( although this idea may actually be borrowed from Dick 's later novel Valis which features a mysterious film depicting yet another dystopian alternative history of the USA ) . \"}, answer=[Entity(start_offset=577, end_offset=644, type='context', text='a series of newsreel films depicting multiple alternative realities', normalized_text='series of newsreel films depicting multiple alternative realities')], nq_answers=[[Entity(start_offset=547, end_offset=644, type='context', text='The Grasshopper Lies Heavy is a series of newsreel films depicting multiple alternative realities', normalized_text='grasshopper lies heavy is series of newsreel films depicting multiple alternative realities')], [Entity(start_offset=959, end_offset=985, type='context', text='as - yet - unknown purpose', normalized_text='as yet unknown purpose')]], aligned_nps=[(Entity(start_offset=8, end_offset=17, type='question', text='the films', normalized_text='films'), Entity(start_offset=547, end_offset=573, type='context', text='The Grasshopper Lies Heavy', normalized_text='grasshopper lies heavy')), (Entity(start_offset=26, end_offset=37, type='question', text='high castle', normalized_text='high castle'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -3310154792386934413: QEDExample(example_id=-3310154792386934413, title='Houston Astros', question='when is last time the astros won the world series', passage='The Astros played in the NL from 1962 to 2012 . They played in the West Division from 1969 to 1993 , and the Central Division from 1994 to 2012 . While a member of the NL , the Astros played in one World Series , in 2005 , against the Chicago White Sox , in which they were swept in four games . In 2017 , they became the first franchise in MLB history to have won a pennant in both the NL and the AL , when they defeated the New York Yankees in the ALCS . They subsequently won the 2017 World Series against the Los Angeles Dodgers , winning four games to three , earning the team , and Texas , its first World Series title .', sentence_starts=[0, 48, 146, 296, 457], selected_sent={'start': 457, 'end': 626, 'string': 'They subsequently won the 2017 World Series against the Los Angeles Dodgers , winning four games to three , earning the team , and Texas , its first World Series title .'}, answer=[Entity(start_offset=483, end_offset=487, type='context', text='2017', normalized_text='2017')], nq_answers=[[Entity(start_offset=483, end_offset=487, type='context', text='2017', normalized_text='2017')]], aligned_nps=[(Entity(start_offset=18, end_offset=28, type='question', text='the astros', normalized_text='astros'), Entity(start_offset=479, end_offset=500, type='context', text='the 2017 World Series', normalized_text='2017 world series'))], explanation_type='single_sentence'),\n",
       " -7876533033876892996: QEDExample(example_id=-7876533033876892996, title='Shooting an Elephant', question='who is the speaker in shooting an elephant', passage=\"The essay describes the experience of the English narrator , possibly Orwell himself , called upon to shoot an aggressive elephant while working as a police officer in Burma . Because the locals expect him to do the job , he does so against his better judgment , his anguish increased by the elephant 's slow and painful death . The story is regarded as a metaphor for British imperialism , and for Orwell 's view that `` when the white man turns tyrant it is his own freedom that he destroys . ''\", sentence_starts=[0, 176, 329], selected_sent={'start': 0, 'end': 176, 'string': 'The essay describes the experience of the English narrator , possibly Orwell himself , called upon to shoot an aggressive elephant while working as a police officer in Burma . '}, answer=[Entity(start_offset=61, end_offset=84, type='context', text='possibly Orwell himself', normalized_text='possibly orwell himself')], nq_answers=[[Entity(start_offset=61, end_offset=173, type='context', text='possibly Orwell himself , called upon to shoot an aggressive elephant while working as a police officer in Burma', normalized_text='possibly orwell himself called upon to shoot aggressive elephant while working as police officer in burma')], [Entity(start_offset=38, end_offset=84, type='context', text='the English narrator , possibly Orwell himself', normalized_text='english narrator possibly orwell himself')]], aligned_nps=[(Entity(start_offset=22, end_offset=42, type='question', text='shooting an elephant', normalized_text='shooting elephant'), Entity(start_offset=0, end_offset=9, type='context', text='The essay', normalized_text='essay'))], explanation_type='single_sentence'),\n",
       " 2876182999155230775: QEDExample(example_id=2876182999155230775, title='United States two-dollar bill', question='when were 2 dollar bills stopped being made', passage=\"The United States two - dollar bill ( $2 ) is a current denomination of U.S. currency . The third U.S. President ( 1801 -- 09 ) , Thomas Jefferson , is featured on the obverse of the note . The reverse features an engraving of the painting The Declaration of Independence by John Trumbull . Throughout the $2 bill 's pre-1929 life as a large - sized note , it was issued as a United States Note , National Bank Note , silver certificate , Treasury or `` Coin '' Note and Federal Reserve Bank Note . When U.S. currency was changed to its current size , the $2 bill was issued only as a United States Note . Production went on until 1966 , when the series was discontinued . Ten years passed before the $2 bill was reissued as a Federal Reserve Note with a new reverse design . Two - dollar bills are seldom seen in circulation as a result of banking policies with businesses which has resulted in low production numbers due to lack of demand . This comparative scarcity in circulation , coupled with a lack of public knowledge that the bill is still in production and circulation , has also inspired urban legends and occasionally has created problems for people trying to use the bill to make purchases .\", sentence_starts=[0, 88, 190, 291, 499, 606, 673, 776, 943], selected_sent={'start': 943, 'end': 1204, 'string': 'This comparative scarcity in circulation , coupled with a lack of public knowledge that the bill is still in production and circulation , has also inspired urban legends and occasionally has created problems for people trying to use the bill to make purchases .'}, answer=[Entity(start_offset=1031, end_offset=1078, type='context', text='the bill is still in production and circulation', normalized_text='bill is still in production and circulation')], nq_answers=[[Entity(start_offset=48, end_offset=85, type='context', text='current denomination of U.S. currency', normalized_text='current denomination of us currency')]], aligned_nps=[(Entity(start_offset=10, end_offset=24, type='question', text='2 dollar bills', normalized_text='2 dollar bills'), Entity(start_offset=1031, end_offset=1039, type='context', text='the bill', normalized_text='bill'))], explanation_type='single_sentence'),\n",
       " 7005697705009934957: QEDExample(example_id=7005697705009934957, title=\"It Ain't Me\", question=\"who sings the song it ain't me\", passage=\"`` It Ai n't Me '' is a song by Norwegian DJ Kygo and American singer Selena Gomez . It was released by Interscope Records , Sony and Ultra on 17 February 2017 as the lead single from Kygo 's first EP , Stargazing . The song was written by Kygo , Gomez , Andrew Watt , Brian Lee and Ali Tamposi . It was produced by Kygo , Watt , Ben Rice and Louis Bell . A dance - pop , electropop and tropical house song , `` It Ai n't Me '' comprises an acoustic guitar line , and a build - drop arrangement in its chorus featuring pulsing piano notes , bass , synthesizers , finger - snap claps and pan flute melodies . Gomez sings the track in a husky tone , while in the chorus her vocals are reduced to recurring syllables . The lyrics are nostalgic and narrate a past relationship ruined by alcoholism and partying too often .\", sentence_starts=[0, 85, 216, 297, 356, 608, 716], selected_sent={'start': 0, 'end': 85, 'string': \"`` It Ai n't Me '' is a song by Norwegian DJ Kygo and American singer Selena Gomez . \"}, answer=[Entity(start_offset=70, end_offset=82, type='context', text='Selena Gomez', normalized_text='selena gomez')], nq_answers=[[Entity(start_offset=70, end_offset=82, type='context', text='Selena Gomez', normalized_text='selena gomez')], [Entity(start_offset=54, end_offset=82, type='context', text='American singer Selena Gomez', normalized_text='american singer selena gomez')]], aligned_nps=[(Entity(start_offset=10, end_offset=30, type='question', text=\"the song it ain't me\", normalized_text='song it aint me'), Entity(start_offset=3, end_offset=15, type='context', text=\"It Ai n't Me\", normalized_text='it ai nt me'))], explanation_type='single_sentence'),\n",
       " -3975410771448678514: QEDExample(example_id=-3975410771448678514, title='Gerald Ford', question='what us president is the only president to become an eagle scout', passage=\"Ford was involved in the Boy Scouts of America , and earned that program 's highest rank , Eagle Scout . He is the only Eagle Scout to have ascended to the U.S. Presidency .\", sentence_starts=[0, 105], selected_sent={'start': 105, 'end': 173, 'string': 'He is the only Eagle Scout to have ascended to the U.S. Presidency .'}, answer=[Entity(start_offset=0, end_offset=4, type='context', text='Ford', normalized_text='ford')], nq_answers=[[Entity(start_offset=0, end_offset=4, type='context', text='Ford', normalized_text='ford')]], aligned_nps=[(Entity(start_offset=5, end_offset=7, type='question', text='us', normalized_text='us'), Entity(start_offset=156, end_offset=160, type='context', text='U.S.', normalized_text='us'))], explanation_type='single_sentence'),\n",
       " -752870544387680116: QEDExample(example_id=-752870544387680116, title='U.S. history of alcohol minimum purchase age by state', question='when was the drinking age set to 21', passage='From 1976 to 1983 , several states voluntarily raised their purchase ages to 19 ( or , less commonly , 20 or 21 ) , in part to combat drunk driving fatalities . In 1984 , Congress passed the National Minimum Drinking Age Act , which required states to raise their ages for purchase and public possession to 21 by October 1986 or lose 10 % of their federal highway funds . By mid-1988 , all 50 states and the District of Columbia had raised their purchase ages to 21 ( but not Puerto Rico , Guam , or the Virgin Islands , see Additional Notes below ) . South Dakota and Wyoming were the final two states to comply with the age 21 mandate . The current drinking age of 21 remains a point of contention among many Americans , because of it being higher than the age of majority ( 18 in most states ) and higher than the drinking ages of most other countries . The National Minimum Drinking Age Act is also seen as a congressional sidestep of the tenth amendment . Although debates have not been highly publicized , a few states have proposed legislation to lower their drinking age , while Guam has raised its drinking age to 21 in July 2010 .', sentence_starts=[0, 161, 372, 552, 639, 857, 961], selected_sent={'start': 372, 'end': 552, 'string': 'By mid-1988 , all 50 states and the District of Columbia had raised their purchase ages to 21 ( but not Puerto Rico , Guam , or the Virgin Islands , see Additional Notes below ) . '}, answer=[Entity(start_offset=375, end_offset=383, type='context', text='mid-1988', normalized_text='mid1988')], nq_answers=[[Entity(start_offset=372, end_offset=383, type='context', text='By mid-1988', normalized_text='by mid1988')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 7903911150166287814: QEDExample(example_id=7903911150166287814, title='Doug Pederson', question='what position did doug peterson play in the nfl', passage='Douglas Irving Pederson ( born January 31 , 1968 ) is an American football coach who is currently the head coach of the Philadelphia Eagles of the National Football League ( NFL ) . He served as the offensive coordinator of the Kansas City Chiefs from 2013 -- 2015 . He spent most of his playing career as a member of the Green Bay Packers , serving as a backup quarterback to Brett Favre and holder on placekicks , and winning Super Bowl XXXI with the team over the New England Patriots . He was also a backup to Dan Marino as a member of the Miami Dolphins , and a starting quarterback for the Eagles and Cleveland Browns .', sentence_starts=[0, 182, 267, 490], selected_sent={'start': 267, 'end': 490, 'string': 'He spent most of his playing career as a member of the Green Bay Packers , serving as a backup quarterback to Brett Favre and holder on placekicks , and winning Super Bowl XXXI with the team over the New England Patriots . '}, answer=[Entity(start_offset=355, end_offset=373, type='context', text='backup quarterback', normalized_text='backup quarterback')], nq_answers=[[Entity(start_offset=306, end_offset=413, type='context', text='a member of the Green Bay Packers , serving as a backup quarterback to Brett Favre and holder on placekicks', normalized_text='member of green bay packers serving as backup quarterback to brett favre and holder on placekicks'), Entity(start_offset=504, end_offset=558, type='context', text='backup to Dan Marino as a member of the Miami Dolphins', normalized_text='backup to dan marino as member of miami dolphins'), Entity(start_offset=567, end_offset=623, type='context', text='starting quarterback for the Eagles and Cleveland Browns', normalized_text='starting quarterback for eagles and cleveland browns')], [Entity(start_offset=362, end_offset=373, type='context', text='quarterback', normalized_text='quarterback')], [Entity(start_offset=362, end_offset=373, type='context', text='quarterback', normalized_text='quarterback'), Entity(start_offset=393, end_offset=413, type='context', text='holder on placekicks', normalized_text='holder on placekicks')]], aligned_nps=[(Entity(start_offset=18, end_offset=31, type='question', text='doug peterson', normalized_text='doug peterson'), Entity(start_offset=267, end_offset=269, type='context', text='He', normalized_text='he')), (Entity(start_offset=40, end_offset=47, type='question', text='the nfl', normalized_text='nfl'), Entity(start_offset=284, end_offset=302, type='context', text='his playing career', normalized_text='his playing career'))], explanation_type='single_sentence'),\n",
       " -3553072210127301492: QEDExample(example_id=-3553072210127301492, title='Geoffrey Palmer (actor)', question='who played lionel in as time goes by', passage='Geoffrey Dyson Palmer , OBE ( born 4 June 1927 ) is an English actor known for his roles in British television sitcoms playing Jimmy Anderson in The Fall and Rise of Reginald Perrin ( 1976 -- 79 ) , Ben Parkinson in Butterflies ( 1978 -- 83 ) and Lionel Hardcastle in As Time Goes By ( 1992 -- 2005 ) . His film appearances include A Fish Called Wanda ( 1988 ) , The Madness of King George ( 1994 ) , Mrs. Brown ( 1997 ) , and Tomorrow Never Dies ( 1997 ) .', sentence_starts=[0, 303], selected_sent={'start': 0, 'end': 303, 'string': 'Geoffrey Dyson Palmer , OBE ( born 4 June 1927 ) is an English actor known for his roles in British television sitcoms playing Jimmy Anderson in The Fall and Rise of Reginald Perrin ( 1976 -- 79 ) , Ben Parkinson in Butterflies ( 1978 -- 83 ) and Lionel Hardcastle in As Time Goes By ( 1992 -- 2005 ) . '}, answer=[Entity(start_offset=0, end_offset=27, type='context', text='Geoffrey Dyson Palmer , OBE', normalized_text='geoffrey dyson palmer obe')], nq_answers=[[Entity(start_offset=0, end_offset=27, type='context', text='Geoffrey Dyson Palmer , OBE', normalized_text='geoffrey dyson palmer obe')], [Entity(start_offset=0, end_offset=21, type='context', text='Geoffrey Dyson Palmer', normalized_text='geoffrey dyson palmer')]], aligned_nps=[(Entity(start_offset=11, end_offset=17, type='question', text='lionel', normalized_text='lionel'), Entity(start_offset=247, end_offset=264, type='context', text='Lionel Hardcastle', normalized_text='lionel hardcastle')), (Entity(start_offset=21, end_offset=36, type='question', text='as time goes by', normalized_text='as time goes by'), Entity(start_offset=268, end_offset=283, type='context', text='As Time Goes By', normalized_text='as time goes by'))], explanation_type='single_sentence'),\n",
       " -6800766892221135307: QEDExample(example_id=-6800766892221135307, title='Optic chiasm', question='where does the optic nerve cross the midline \\u200b', passage=\"The optic chiasm or optic chiasma ( / ɒptɪk kaɪæzəm / ; Greek χίασμα , `` crossing '' , from the Greek χιάζω ' to mark with an X ' , after the Greek letter ' Χ ' , chi ) is the part of the brain where the optic nerves partially cross . The optic chiasm is located at the bottom of the brain immediately below the hypothalamus . The optic chiasm is found in all vertebrates , although in cyclostomes ( lampreys and hagfishes ) it is located within the brain .\", sentence_starts=[0, 236, 328], selected_sent={'start': 0, 'end': 236, 'string': \"The optic chiasm or optic chiasma ( / ɒptɪk kaɪæzəm / ; Greek χίασμα , `` crossing '' , from the Greek χιάζω ' to mark with an X ' , after the Greek letter ' Χ ' , chi ) is the part of the brain where the optic nerves partially cross . \"}, answer=[Entity(start_offset=0, end_offset=16, type='context', text='The optic chiasm', normalized_text='optic chiasm')], nq_answers=[[Entity(start_offset=4, end_offset=16, type='context', text='optic chiasm', normalized_text='optic chiasm')], [Entity(start_offset=0, end_offset=33, type='context', text='The optic chiasm or optic chiasma', normalized_text='optic chiasm or optic chiasma')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -9199561147097898525: QEDExample(example_id=-9199561147097898525, title='Where the Red Fern Grows', question='what is billy last name in where the red fern grows', passage=\"When leaving work in Idaho 's Snake River Valley , Billy Colman sees a pack of dogs attacking a stray coonhound . He takes the stray home to feed it . Once it has rested , Billy sets it free , knowing that it will return home .\", sentence_starts=[0, 114, 151], selected_sent={'start': 0, 'end': 114, 'string': \"When leaving work in Idaho 's Snake River Valley , Billy Colman sees a pack of dogs attacking a stray coonhound . \"}, answer=[Entity(start_offset=57, end_offset=63, type='context', text='Colman', normalized_text='colman')], nq_answers=[[Entity(start_offset=57, end_offset=63, type='context', text='Colman', normalized_text='colman')], [Entity(start_offset=51, end_offset=63, type='context', text='Billy Colman', normalized_text='billy colman')]], aligned_nps=[(Entity(start_offset=8, end_offset=23, type='question', text='billy last name', normalized_text='billy last name'), Entity(start_offset=57, end_offset=63, type='context', text='Colman', normalized_text='colman')), (Entity(start_offset=27, end_offset=51, type='question', text='where the red fern grows', normalized_text='where red fern grows'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 7526277995958905171: QEDExample(example_id=7526277995958905171, title='Too Much Time on My Hands', question='who sings too much time on my hands lyrics', passage=\"`` Too Much Time on My Hands '' is the second single released from Styx 's 1981 triple - platinum album Paradise Theatre . It was written and sung by Tommy Shaw , who also plays the lead guitar solo during the break in the song .\", sentence_starts=[0, 123], selected_sent={'start': 123, 'end': 229, 'string': 'It was written and sung by Tommy Shaw , who also plays the lead guitar solo during the break in the song .'}, answer=[Entity(start_offset=150, end_offset=160, type='context', text='Tommy Shaw', normalized_text='tommy shaw')], nq_answers=[[Entity(start_offset=150, end_offset=160, type='context', text='Tommy Shaw', normalized_text='tommy shaw')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='too much time on my hands', normalized_text='too much time on my hands'), Entity(start_offset=123, end_offset=125, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 3274948378518710725: QEDExample(example_id=3274948378518710725, title='FIFA World Cup hosts', question='who has hosted the most fifa world cups', passage=\"Only Mexico , Italy , France , Germany ( West Germany until shortly after the 1990 World Cup ) and Brazil have hosted the event on two occasions . Mexico City 's Estadio Azteca and Rio de Janeiro 's Maracanã are the only venues ever to have hosted two FIFA World Cup finals . Only the 2002 FIFA World Cup had more than one host , being split between Japan and South Korea .\", sentence_starts=[0, 147, 276], selected_sent={'start': 0, 'end': 147, 'string': 'Only Mexico , Italy , France , Germany ( West Germany until shortly after the 1990 World Cup ) and Brazil have hosted the event on two occasions . '}, answer=[Entity(start_offset=5, end_offset=105, type='context', text='Mexico , Italy , France , Germany ( West Germany until shortly after the 1990 World Cup ) and Brazil', normalized_text='mexico italy france germany west germany until shortly after 1990 world cup and brazil')], nq_answers=[[Entity(start_offset=5, end_offset=144, type='context', text='Mexico , Italy , France , Germany ( West Germany until shortly after the 1990 World Cup ) and Brazil have hosted the event on two occasions', normalized_text='mexico italy france germany west germany until shortly after 1990 world cup and brazil have hosted event on two occasions')], [Entity(start_offset=5, end_offset=11, type='context', text='Mexico', normalized_text='mexico'), Entity(start_offset=14, end_offset=19, type='context', text='Italy', normalized_text='italy'), Entity(start_offset=22, end_offset=28, type='context', text='France', normalized_text='france'), Entity(start_offset=31, end_offset=38, type='context', text='Germany', normalized_text='germany'), Entity(start_offset=99, end_offset=105, type='context', text='Brazil', normalized_text='brazil')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -125564053796187750: QEDExample(example_id=-125564053796187750, title='Geography of Prince Edward Island', question='why does prince edward island have red sand', passage='The coastline of the island consists of a combination of long beaches , dunes , red sandstone cliffs , salt water marshes and numerous bays and harbours . The beaches , dunes and sandstone cliffs consist of sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air . The geological properties of a white silica sand found at Basin Head are unique in the province ; the sand grains cause a scrubbing noise as they rub against each other when walked on . Large dune fields on the north shore can be found on barrier islands at the entrances to various bays and harbours . The magnificent sand dunes at Greenwich are of particular significance . The shifting , parabolic dune system is home to a variety of birds and rare plants and is also a site of significant archeological interest .', sentence_starts=[0, 155, 316, 502, 619, 692], selected_sent={'start': 155, 'end': 316, 'string': 'The beaches , dunes and sandstone cliffs consist of sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air . '}, answer=[Entity(start_offset=155, end_offset=313, type='context', text='The beaches , dunes and sandstone cliffs consist of sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air', normalized_text='beaches dunes and sandstone cliffs consist of sedimentary rock and other material with high iron concentration which oxidizes upon exposure to air')], nq_answers=[[Entity(start_offset=207, end_offset=313, type='context', text='sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air', normalized_text='sedimentary rock and other material with high iron concentration which oxidizes upon exposure to air')]], aligned_nps=[(Entity(start_offset=9, end_offset=29, type='question', text='prince edward island', normalized_text='prince edward island'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -1014091045618911654: QEDExample(example_id=-1014091045618911654, title='Independence (probability theory)', question='when are two events said to be independent', passage='In probability theory , two events are independent , statistically independent , or stochastically independent if the occurrence of one does not affect the probability of occurrence of the other . Similarly , two random variables are independent if the realization of one does not affect the probability distribution of the other .', sentence_starts=[0, 197], selected_sent={'start': 0, 'end': 197, 'string': 'In probability theory , two events are independent , statistically independent , or stochastically independent if the occurrence of one does not affect the probability of occurrence of the other . '}, answer=[Entity(start_offset=111, end_offset=194, type='context', text='if the occurrence of one does not affect the probability of occurrence of the other', normalized_text='if occurrence of one does not affect probability of occurrence of other')], nq_answers=[[Entity(start_offset=111, end_offset=194, type='context', text='if the occurrence of one does not affect the probability of occurrence of the other', normalized_text='if occurrence of one does not affect probability of occurrence of other')], [Entity(start_offset=111, end_offset=196, type='context', text='if the occurrence of one does not affect the probability of occurrence of the other .', normalized_text='if occurrence of one does not affect probability of occurrence of other')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 8881606849310681343: QEDExample(example_id=8881606849310681343, title='Salton Sea', question='what kind of fish live in the salton sea', passage='Due to the high salinity , very few fish species can tolerate living in the Salton Sea . Introduced tilapia are the main fish that can tolerate the high salinity levels and pollution . Other freshwater fish species live in the rivers and canals that feed the Salton Sea , including threadfin shad , carp , red shiner , channel catfish , white catfish , largemouth bass , mosquitofish , sailfin molly , and the vulnerable desert pupfish .', sentence_starts=[0, 89, 185], selected_sent={'start': 89, 'end': 185, 'string': 'Introduced tilapia are the main fish that can tolerate the high salinity levels and pollution . '}, answer=[Entity(start_offset=89, end_offset=107, type='context', text='Introduced tilapia', normalized_text='introduced tilapia')], nq_answers=[[Entity(start_offset=100, end_offset=107, type='context', text='tilapia', normalized_text='tilapia')]], aligned_nps=[(Entity(start_offset=26, end_offset=40, type='question', text='the salton sea', normalized_text='salton sea'), Entity(start_offset=144, end_offset=184, type='context', text='the high salinity levels and pollution .', normalized_text='high salinity levels and pollution'))], explanation_type='single_sentence'),\n",
       " 1213934315672255524: QEDExample(example_id=1213934315672255524, title='Defensive three-second violation', question='when was the defensive 3 second rule implemented', passage=\"A defensive three - second violation , also known as illegal defense , is a basketball rules infraction in the National Basketball Association ( NBA ) introduced in the 2001 -- 2002 season . It is assessed when a member of the defending team spends more than three seconds in the free throw lane ( also known as the 16 - foot lane , or colloquially as `` in the paint '' ) while not actively guarding an opponent . To be considered actively guarding , a defender must be within arm 's length of an opponent and in a guarding position . A three - second count is suspended if :\", sentence_starts=[0, 191, 415, 536], selected_sent={'start': 0, 'end': 191, 'string': 'A defensive three - second violation , also known as illegal defense , is a basketball rules infraction in the National Basketball Association ( NBA ) introduced in the 2001 -- 2002 season . '}, answer=[Entity(start_offset=165, end_offset=188, type='context', text='the 2001 -- 2002 season', normalized_text='2001 2002 season')], nq_answers=[[Entity(start_offset=162, end_offset=188, type='context', text='in the 2001 -- 2002 season', normalized_text='in 2001 2002 season')], [Entity(start_offset=169, end_offset=188, type='context', text='2001 -- 2002 season', normalized_text='2001 2002 season')], [Entity(start_offset=165, end_offset=188, type='context', text='the 2001 -- 2002 season', normalized_text='2001 2002 season')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -8488338195071516656: QEDExample(example_id=-8488338195071516656, title='Jack McCoy', question='when did jack mccoy join law and order', passage='John James McCoy is a fictional character in the television drama Law & Order . He was created by Michael S. Chernuchin and portrayed by Sam Waterston from 1994 until the end of the series in 2010 . He is the second - longest tenured character on the show ( 16 seasons ) , after Lt. Anita Van Buren ( 17 seasons ; portrayed by S. Epatha Merkerson ) . He appeared in 368 episodes of Law & Order , four episodes of Law & Order : Special Victims Unit , two episodes of Law & Order : Trial by Jury , two episodes of Homicide : Life on the Street , and the made - for - TV movie Exiled .', sentence_starts=[0, 80, 199, 351], selected_sent={'start': 80, 'end': 199, 'string': 'He was created by Michael S. Chernuchin and portrayed by Sam Waterston from 1994 until the end of the series in 2010 . '}, answer=[Entity(start_offset=156, end_offset=160, type='context', text='1994', normalized_text='1994')], nq_answers=[[Entity(start_offset=156, end_offset=160, type='context', text='1994', normalized_text='1994')]], aligned_nps=[(Entity(start_offset=9, end_offset=19, type='question', text='jack mccoy', normalized_text='jack mccoy'), Entity(start_offset=80, end_offset=82, type='context', text='He', normalized_text='he')), (Entity(start_offset=25, end_offset=38, type='question', text='law and order', normalized_text='law and order'), Entity(start_offset=178, end_offset=188, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " 5855711681130036664: QEDExample(example_id=5855711681130036664, title='Yo Gabba Gabba!', question='who are the characters in yo gabba gabba', passage='Hosted by a character named DJ Lance Rock , the series featured a mix of live - action segments featuring cartoonish costumed characters -- Muno ( the red cyclops ) , Foofa ( the pink flower bubble ) , Brobee ( a little hairy green monster ) , Toodee ( the blue cat - dragon ) and Plex ( the magic yellow robot ) -- and many short animated sketches and musical numbers .', sentence_starts=[0], selected_sent={'start': 0, 'end': 370, 'string': 'Hosted by a character named DJ Lance Rock , the series featured a mix of live - action segments featuring cartoonish costumed characters -- Muno ( the red cyclops ) , Foofa ( the pink flower bubble ) , Brobee ( a little hairy green monster ) , Toodee ( the blue cat - dragon ) and Plex ( the magic yellow robot ) -- and many short animated sketches and musical numbers .'}, answer=[Entity(start_offset=28, end_offset=41, type='context', text='DJ Lance Rock', normalized_text='dj lance rock'), Entity(start_offset=140, end_offset=312, type='context', text='Muno ( the red cyclops ) , Foofa ( the pink flower bubble ) , Brobee ( a little hairy green monster ) , Toodee ( the blue cat - dragon ) and Plex ( the magic yellow robot )', normalized_text='muno red cyclops foofa pink flower bubble brobee little hairy green monster toodee blue cat dragon and plex magic yellow robot')], nq_answers=[[Entity(start_offset=28, end_offset=41, type='context', text='DJ Lance Rock', normalized_text='dj lance rock'), Entity(start_offset=140, end_offset=164, type='context', text='Muno ( the red cyclops )', normalized_text='muno red cyclops'), Entity(start_offset=167, end_offset=199, type='context', text='Foofa ( the pink flower bubble )', normalized_text='foofa pink flower bubble'), Entity(start_offset=202, end_offset=241, type='context', text='Brobee ( a little hairy green monster )', normalized_text='brobee little hairy green monster'), Entity(start_offset=244, end_offset=276, type='context', text='Toodee ( the blue cat - dragon )', normalized_text='toodee blue cat dragon'), Entity(start_offset=281, end_offset=312, type='context', text='Plex ( the magic yellow robot )', normalized_text='plex magic yellow robot')], [Entity(start_offset=140, end_offset=164, type='context', text='Muno ( the red cyclops )', normalized_text='muno red cyclops'), Entity(start_offset=167, end_offset=199, type='context', text='Foofa ( the pink flower bubble )', normalized_text='foofa pink flower bubble'), Entity(start_offset=202, end_offset=241, type='context', text='Brobee ( a little hairy green monster )', normalized_text='brobee little hairy green monster'), Entity(start_offset=244, end_offset=276, type='context', text='Toodee ( the blue cat - dragon )', normalized_text='toodee blue cat dragon'), Entity(start_offset=281, end_offset=312, type='context', text='Plex ( the magic yellow robot )', normalized_text='plex magic yellow robot')]], aligned_nps=[(Entity(start_offset=8, end_offset=40, type='question', text='the characters in yo gabba gabba', normalized_text='characters in yo gabba gabba'), Entity(start_offset=44, end_offset=54, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " 775172980988648781: QEDExample(example_id=775172980988648781, title='Thanksgiving dinner', question='name a food you might eat on thanksgiving', passage='The centerpiece of contemporary Thanksgiving in the United States and Canada is a large meal , generally centered on a large roasted turkey . It is served with a variety of side dishes which vary from traditional dishes such as mashed potatoes , stuffing , and cranberry sauce , to ones that reflect regional or cultural heritage . The majority of the dishes in the traditional American version of Thanksgiving dinner are made from foods native to the New World , as according to tradition the Pilgrims received these foods , or learned how to grow them , from the Native Americans . Thanksgiving dinner is the largest eating event in the United States ; people eat more on Thanksgiving than on any other day of the year .', sentence_starts=[0, 142, 332, 584], selected_sent={'start': 0, 'end': 142, 'string': 'The centerpiece of contemporary Thanksgiving in the United States and Canada is a large meal , generally centered on a large roasted turkey . '}, answer=[Entity(start_offset=117, end_offset=139, type='context', text='a large roasted turkey', normalized_text='large roasted turkey')], nq_answers=[[Entity(start_offset=133, end_offset=139, type='context', text='turkey', normalized_text='turkey')], [Entity(start_offset=117, end_offset=139, type='context', text='a large roasted turkey', normalized_text='large roasted turkey')]], aligned_nps=[(Entity(start_offset=29, end_offset=41, type='question', text='thanksgiving', normalized_text='thanksgiving'), Entity(start_offset=19, end_offset=44, type='context', text='contemporary Thanksgiving', normalized_text='contemporary thanksgiving'))], explanation_type='single_sentence'),\n",
       " -2419576910417046724: QEDExample(example_id=-2419576910417046724, title='Southend Pier', question='what is the longest pier in the uk', passage=\"Southend Pier is a major landmark in Southend - on - Sea . Extending 1.34 miles ( 2.16 km ) into the Thames Estuary , it is the longest pleasure pier in the world . Sir John Betjeman once said that `` the Pier is Southend , Southend is the Pier '' . The pier is a Grade II listed building .\", sentence_starts=[0, 59, 165, 250], selected_sent={'start': 59, 'end': 165, 'string': 'Extending 1.34 miles ( 2.16 km ) into the Thames Estuary , it is the longest pleasure pier in the world . '}, answer=[Entity(start_offset=0, end_offset=13, type='context', text='Southend Pier', normalized_text='southend pier')], nq_answers=[[Entity(start_offset=0, end_offset=13, type='context', text='Southend Pier', normalized_text='southend pier')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 6087243958702853181: QEDExample(example_id=6087243958702853181, title=\"The Miller's Daughter (Once Upon a Time)\", question='who did cora marry in once upon a time', passage=\"The day before her wedding , Cora questions her plans ; she is unlikely to become queen as Henry is fifth in line to the throne , while Rumplestiltskin , with whom she has been having an affair , offers her love . They agree to amend the contract so Cora owes Rumplestiltskin his child . He also agrees to teach her how to take a heart , so that she can kill King Xavier . That night , she confronts the king . He reveals that he knows of her relationship with Rumplestiltskin ; telling her that `` love is weakness , '' he lays out her choice between love and power . Cora returns to her room carrying a heart in a box . Later , she meets Rumplestilskin and informs him that she did not take the king 's heart , and that she is going to marry the prince instead of running away with Rumplestiltskin . The heart she removed was her own , to prevent it from being an obstacle . Rumplestiltskin tries to invoke their contract , but she points out that he only has a claim on his own child , which she will never bear .\", sentence_starts=[0, 214, 288, 373, 411, 569, 622, 802, 877], selected_sent={'start': 0, 'end': 214, 'string': 'The day before her wedding , Cora questions her plans ; she is unlikely to become queen as Henry is fifth in line to the throne , while Rumplestiltskin , with whom she has been having an affair , offers her love . '}, answer=[Entity(start_offset=91, end_offset=96, type='context', text='Henry', normalized_text='henry')], nq_answers=[[Entity(start_offset=91, end_offset=96, type='context', text='Henry', normalized_text='henry')]], aligned_nps=[(Entity(start_offset=8, end_offset=12, type='question', text='cora', normalized_text='cora'), Entity(start_offset=29, end_offset=33, type='context', text='Cora', normalized_text='cora')), (Entity(start_offset=22, end_offset=38, type='question', text='once upon a time', normalized_text='once upon time'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -5073140698639294679: QEDExample(example_id=-5073140698639294679, title='Robert Griffin III', question='what nfl team is robert griffin the third playing for', passage='Robert Lee Griffin III ( born February 12 , 1990 ) , nicknamed RG3 or RGIII , is an American football quarterback who is currently a free agent . He played college football at Baylor , where he won the 2011 Heisman Trophy . He was drafted by the Washington Redskins second overall in the first round of the 2012 NFL Draft .', sentence_starts=[0, 146, 224], selected_sent={'start': 0, 'end': 146, 'string': 'Robert Lee Griffin III ( born February 12 , 1990 ) , nicknamed RG3 or RGIII , is an American football quarterback who is currently a free agent . '}, answer=[Entity(start_offset=121, end_offset=143, type='context', text='currently a free agent', normalized_text='currently free agent')], nq_answers=[[Entity(start_offset=121, end_offset=143, type='context', text='currently a free agent', normalized_text='currently free agent')]], aligned_nps=[(Entity(start_offset=17, end_offset=41, type='question', text='robert griffin the third', normalized_text='robert griffin third'), Entity(start_offset=0, end_offset=22, type='context', text='Robert Lee Griffin III', normalized_text='robert lee griffin iii'))], explanation_type='single_sentence'),\n",
       " -764171144565980759: QEDExample(example_id=-764171144565980759, title=\"All the world's a stage\", question='where does the seven ages of man come from', passage=\"`` All the world 's a stage '' is the phrase that begins a monologue from William Shakespeare 's As You Like It , spoken by the melancholy Jaques in Act II Scene VII . The speech compares the world to a stage and life to a play , and catalogues the seven stages of a man 's life , sometimes referred to as the seven ages of man : infant , schoolboy , lover , soldier , justice , Pantalone and old age , facing imminent death . It is one of Shakespeare 's most frequently quoted passages .\", sentence_starts=[0, 168, 427], selected_sent={'start': 168, 'end': 427, 'string': \"The speech compares the world to a stage and life to a play , and catalogues the seven stages of a man 's life , sometimes referred to as the seven ages of man : infant , schoolboy , lover , soldier , justice , Pantalone and old age , facing imminent death . \"}, answer=[Entity(start_offset=69, end_offset=111, type='context', text=\"from William Shakespeare 's As You Like It\", normalized_text='from william shakespeare s as you like it')], nq_answers=[[Entity(start_offset=69, end_offset=111, type='context', text=\"from William Shakespeare 's As You Like It\", normalized_text='from william shakespeare s as you like it')], [Entity(start_offset=57, end_offset=111, type='context', text=\"a monologue from William Shakespeare 's As You Like It\", normalized_text='monologue from william shakespeare s as you like it')], [Entity(start_offset=74, end_offset=111, type='context', text=\"William Shakespeare 's As You Like It\", normalized_text='william shakespeare s as you like it')]], aligned_nps=[(Entity(start_offset=11, end_offset=32, type='question', text='the seven ages of man', normalized_text='seven ages of man'), Entity(start_offset=306, end_offset=327, type='context', text='the seven ages of man', normalized_text='seven ages of man'))], explanation_type='single_sentence'),\n",
       " -5762375008462850995: QEDExample(example_id=-5762375008462850995, title='State of the Union', question='when is the state of the union televised', passage='What began as a communication between president and Congress has become a communication between the president and the people of the United States . Since the advent of radio , and then television , the speech has been broadcast live on most networks , preempting scheduled programming . To reach the largest audience , the speech , once given during the day , is now typically given in the evening , after 9pm ET ( UTC - 5 ) .', sentence_starts=[0, 148, 287], selected_sent={'start': 287, 'end': 426, 'string': 'To reach the largest audience , the speech , once given during the day , is now typically given in the evening , after 9pm ET ( UTC - 5 ) .'}, answer=[Entity(start_offset=367, end_offset=424, type='context', text='typically given in the evening , after 9pm ET ( UTC - 5 )', normalized_text='typically given in evening after 9pm et utc 5')], nq_answers=[[Entity(start_offset=383, end_offset=424, type='context', text='in the evening , after 9pm ET ( UTC - 5 )', normalized_text='in evening after 9pm et utc 5')]], aligned_nps=[(Entity(start_offset=8, end_offset=30, type='question', text='the state of the union', normalized_text='state of union'), Entity(start_offset=319, end_offset=329, type='context', text='the speech', normalized_text='speech'))], explanation_type='single_sentence'),\n",
       " 6255051608078138794: QEDExample(example_id=6255051608078138794, title=\"Joe's Garage (song)\", question='who sings why does it hurt when i pee', passage=\"`` Joe 's Garage '' is a single on Frank Zappa 's 1979 album Joe 's Garage Act I. After the introductory track , `` The Central Scrutinizer '' , this song begins the story of Joe 's Garage . Although it only charted in Norway and Sweden ( where it was a top 20 hit in both countries ) , it was one of Zappa 's songs which had the most airplay on American FM radio , at the time still album - centered . The song was played in concert from 1980 to 1988 along with the song `` Why Does it Hurt When I Pee ? '' in all tours of Zappa 's after the single 's release . The single version of the song lacks many of the special effects that the album version contains . The single version of `` Joe 's Garage '' was put onto Zappa 's best - of Strictly Commercial .\", sentence_starts=[0, 191, 403, 508, 563, 662], selected_sent={'start': 403, 'end': 563, 'string': \"The song was played in concert from 1980 to 1988 along with the song `` Why Does it Hurt When I Pee ? '' in all tours of Zappa 's after the single 's release . \"}, answer=[Entity(start_offset=35, end_offset=46, type='context', text='Frank Zappa', normalized_text='frank zappa')], nq_answers=[[Entity(start_offset=35, end_offset=46, type='context', text='Frank Zappa', normalized_text='frank zappa')], [Entity(start_offset=35, end_offset=49, type='context', text=\"Frank Zappa 's\", normalized_text='frank zappa s')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text='why does it hurt when i pee', normalized_text='why does it hurt when i pee'), Entity(start_offset=403, end_offset=411, type='context', text='The song', normalized_text='song'))], explanation_type='single_sentence'),\n",
       " -1609362606908546787: QEDExample(example_id=-1609362606908546787, title='Cannes Film Festival', question='when does the cannes film festival take place', passage='The Cannes Festival ( / kæn / ; French : Festival de Cannes ) , named until 2002 as the International Film Festival ( Festival international du film ) and known in English as the Cannes Film Festival , is an annual film festival held in Cannes , France , which previews new films of all genres , including documentaries , from all around the world . Founded in 1946 , the invitation - only festival is held annually ( usually in May ) at the Palais des Festivals et des Congrès .', sentence_starts=[0, 350], selected_sent={'start': 350, 'end': 479, 'string': 'Founded in 1946 , the invitation - only festival is held annually ( usually in May ) at the Palais des Festivals et des Congrès .'}, answer=[Entity(start_offset=418, end_offset=432, type='context', text='usually in May', normalized_text='usually in may')], nq_answers=[[Entity(start_offset=418, end_offset=432, type='context', text='usually in May', normalized_text='usually in may')], [Entity(start_offset=237, end_offset=252, type='context', text='Cannes , France', normalized_text='cannes france')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text='the cannes film festival', normalized_text='cannes film festival'), Entity(start_offset=368, end_offset=398, type='context', text='the invitation - only festival', normalized_text='invitation only festival'))], explanation_type='single_sentence'),\n",
       " -2402537297213964031: QEDExample(example_id=-2402537297213964031, title='I Write Sins Not Tragedies', question='panic at the disco song about a wedding', passage=\"`` I Write Sins Not Tragedies '' is Panic ! at the Disco 's first single to have a music video . ( `` The Only Difference Between Martyrdom and Suicide Is Press Coverage '' was the first single , but no video was filmed . ) The video for the song takes place at a strange , circus - themed wedding played by the Lucent Dossier Vaudeville Cirque .\", sentence_starts=[0, 44, 97, 224], selected_sent={'start': 224, 'end': 346, 'string': 'The video for the song takes place at a strange , circus - themed wedding played by the Lucent Dossier Vaudeville Cirque .'}, answer=[Entity(start_offset=0, end_offset=32, type='context', text=\"`` I Write Sins Not Tragedies ''\", normalized_text='i write sins not tragedies')], nq_answers=[[Entity(start_offset=0, end_offset=32, type='context', text=\"`` I Write Sins Not Tragedies ''\", normalized_text='i write sins not tragedies')], [Entity(start_offset=3, end_offset=29, type='context', text='I Write Sins Not Tragedies', normalized_text='i write sins not tragedies')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 3641020426740791843: QEDExample(example_id=3641020426740791843, title=\"Destiny's Child\", question='what happened to the fourth member of destinys child', passage=\"In early 2000 , both Roberson and Luckett were replaced with Williams and Farrah Franklin ; however , Franklin quit after five months , leaving the group as a trio . Their third album , Survivor ( 2001 ) , which contains themes the public interpreted as a channel to the group 's experience , contains the worldwide hits `` Independent Women '' , `` Survivor '' and `` Bootylicious '' . In 2002 , they announced a hiatus and re-united two years later for the release of their fourth and final studio album , Destiny Fulfilled ( 2004 ) . Destiny 's Child has sold more than sixty million records worldwide to date . Billboard magazine ranks the group as one of the greatest musical trios of all time , the ninth most successful artist / band of the 2000s , placed the group 68th in its All - Time Hot 100 Artists list in 2008 and in December 2016 , the magazine ranked them as the 90th most successful dance club artist of all - time . The group was nominated for 14 Grammy Awards , winning twice for Best R&B Performance by a Duo or Group with Vocals and once for Best R&B Song .\", sentence_starts=[0, 166, 387, 537, 615, 935], selected_sent={'start': 0, 'end': 166, 'string': 'In early 2000 , both Roberson and Luckett were replaced with Williams and Farrah Franklin ; however , Franklin quit after five months , leaving the group as a trio . '}, answer=[Entity(start_offset=111, end_offset=133, type='context', text='quit after five months', normalized_text='quit after five months')], nq_answers=[[Entity(start_offset=102, end_offset=163, type='context', text='Franklin quit after five months , leaving the group as a trio', normalized_text='franklin quit after five months leaving group as trio')]], aligned_nps=[(Entity(start_offset=17, end_offset=52, type='question', text='the fourth member of destinys child', normalized_text='fourth member of destinys child'), Entity(start_offset=102, end_offset=110, type='context', text='Franklin', normalized_text='franklin'))], explanation_type='single_sentence'),\n",
       " 8288075782992894495: QEDExample(example_id=8288075782992894495, title='Tie a Yellow Ribbon Round the Ole Oak Tree', question='who sings tie a yellow ribbon around the old oak tree', passage=\"`` Tie a Yellow Ribbon Round the Ole Oak Tree '' is a song by Tony Orlando and Dawn . It was written by Irwin Levine and L. Russell Brown and produced by Hank Medress and Dave Appell , with Motown / Stax backing vocalist Telma Hopkins , Joyce Vincent Wilson and her sister Pamela Vincent on backing vocals . It was a worldwide hit for the group in 1973 .\", sentence_starts=[0, 86, 308], selected_sent={'start': 0, 'end': 86, 'string': \"`` Tie a Yellow Ribbon Round the Ole Oak Tree '' is a song by Tony Orlando and Dawn . \"}, answer=[Entity(start_offset=62, end_offset=83, type='context', text='Tony Orlando and Dawn', normalized_text='tony orlando and dawn')], nq_answers=[[Entity(start_offset=62, end_offset=83, type='context', text='Tony Orlando and Dawn', normalized_text='tony orlando and dawn'), Entity(start_offset=190, end_offset=234, type='context', text='Motown / Stax backing vocalist Telma Hopkins', normalized_text='motown stax backing vocalist telma hopkins'), Entity(start_offset=237, end_offset=257, type='context', text='Joyce Vincent Wilson', normalized_text='joyce vincent wilson'), Entity(start_offset=273, end_offset=287, type='context', text='Pamela Vincent', normalized_text='pamela vincent')]], aligned_nps=[(Entity(start_offset=10, end_offset=53, type='question', text='tie a yellow ribbon around the old oak tree', normalized_text='tie yellow ribbon around old oak tree'), Entity(start_offset=3, end_offset=45, type='context', text='Tie a Yellow Ribbon Round the Ole Oak Tree', normalized_text='tie yellow ribbon round ole oak tree'))], explanation_type='single_sentence'),\n",
       " -6632801910088531808: QEDExample(example_id=-6632801910088531808, title='Patience is a virtue', question='where does patience is a virtue come from', passage=\"Patience is a virtue is a proverbial phrase referring to one of the seven heavenly virtues typically said to date back to `` Psychomachia , '' an epic poem written in the fifth century .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 186, 'string': \"Patience is a virtue is a proverbial phrase referring to one of the seven heavenly virtues typically said to date back to `` Psychomachia , '' an epic poem written in the fifth century .\"}, answer=[Entity(start_offset=57, end_offset=184, type='context', text=\"one of the seven heavenly virtues typically said to date back to `` Psychomachia , '' an epic poem written in the fifth century\", normalized_text='one of seven heavenly virtues typically said to date back to psychomachia epic poem written in fifth century')], nq_answers=[[Entity(start_offset=122, end_offset=186, type='context', text=\"`` Psychomachia , '' an epic poem written in the fifth century .\", normalized_text='psychomachia epic poem written in fifth century')], [Entity(start_offset=122, end_offset=142, type='context', text=\"`` Psychomachia , ''\", normalized_text='psychomachia')], [Entity(start_offset=122, end_offset=184, type='context', text=\"`` Psychomachia , '' an epic poem written in the fifth century\", normalized_text='psychomachia epic poem written in fifth century')]], aligned_nps=[(Entity(start_offset=11, end_offset=31, type='question', text='patience is a virtue', normalized_text='patience is virtue'), Entity(start_offset=0, end_offset=20, type='context', text='Patience is a virtue', normalized_text='patience is virtue'))], explanation_type='single_sentence'),\n",
       " -3527567175577846943: QEDExample(example_id=-3527567175577846943, title='Attack on Pearl Harbor', question='why did the attack on pearl harbor take place', passage='Japan intended the attack as a preventive action to keep the U.S. Pacific Fleet from interfering with military actions that were planned in Southeast Asia against overseas territories of the United Kingdom , the Netherlands , and the United States . Over the next seven hours there were coordinated Japanese attacks on the U.S. - held Philippines , Guam and Wake Island and on the British Empire in Malaya , Singapore , and Hong Kong .', sentence_starts=[0, 250], selected_sent={'start': 0, 'end': 250, 'string': 'Japan intended the attack as a preventive action to keep the U.S. Pacific Fleet from interfering with military actions that were planned in Southeast Asia against overseas territories of the United Kingdom , the Netherlands , and the United States . '}, answer=[Entity(start_offset=26, end_offset=247, type='context', text='as a preventive action to keep the U.S. Pacific Fleet from interfering with military actions that were planned in Southeast Asia against overseas territories of the United Kingdom , the Netherlands , and the United States', normalized_text='as preventive action to keep us pacific fleet from interfering with military actions that were planned in southeast asia against overseas territories of united kingdom netherlands and united states')], nq_answers=[[Entity(start_offset=26, end_offset=247, type='context', text='as a preventive action to keep the U.S. Pacific Fleet from interfering with military actions that were planned in Southeast Asia against overseas territories of the United Kingdom , the Netherlands , and the United States', normalized_text='as preventive action to keep us pacific fleet from interfering with military actions that were planned in southeast asia against overseas territories of united kingdom netherlands and united states')], [Entity(start_offset=26, end_offset=154, type='context', text='as a preventive action to keep the U.S. Pacific Fleet from interfering with military actions that were planned in Southeast Asia', normalized_text='as preventive action to keep us pacific fleet from interfering with military actions that were planned in southeast asia')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text='the attack on pearl harbor', normalized_text='attack on pearl harbor'), Entity(start_offset=15, end_offset=25, type='context', text='the attack', normalized_text='attack'))], explanation_type='single_sentence'),\n",
       " -1728802954650926880: QEDExample(example_id=-1728802954650926880, title='Eragon', question='what is the name of the dragon in eragon', passage=\"The book tells the story of a farm boy named Eragon , who finds a mysterious stone in the mountains . Not knowing the stone 's origin or worth , he attempts to use it as payment to a butcher . A dragon he later names Saphira hatches from the stone , which was really an egg . When the evil King Galbatorix finds out the general location of the egg he sends the Ra'zac to acquire it . By that time Saphira had been growing for a while and takes Eragon to the Spine after Ra'zac appear in their village Carvahall . Eragon and Saphira are forced to flee from their hometown , with a storyteller called Brom , and decide to search for the Varden , a group of rebels who want the downfall of Galbatorix .\", sentence_starts=[0, 102, 193, 276, 384, 513], selected_sent={'start': 193, 'end': 276, 'string': 'A dragon he later names Saphira hatches from the stone , which was really an egg . '}, answer=[Entity(start_offset=217, end_offset=224, type='context', text='Saphira', normalized_text='saphira')], nq_answers=[[Entity(start_offset=217, end_offset=224, type='context', text='Saphira', normalized_text='saphira')]], aligned_nps=[(Entity(start_offset=20, end_offset=40, type='question', text='the dragon in eragon', normalized_text='dragon in eragon'), Entity(start_offset=193, end_offset=201, type='context', text='A dragon', normalized_text='dragon'))], explanation_type='single_sentence'),\n",
       " -3828702383571778476: QEDExample(example_id=-3828702383571778476, title='von', question='what is the meaning of the name von', passage='Von ( fɔn ) is a term used in German language surnames either as a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners .', sentence_starts=[0], selected_sent={'start': 0, 'end': 209, 'string': 'Von ( fɔn ) is a term used in German language surnames either as a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners .'}, answer=[Entity(start_offset=65, end_offset=207, type='context', text='a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners', normalized_text='nobiliary particle indicating noble patrilineality or as simple preposition that approximately means of or from in case of commoners')], nq_answers=[[Entity(start_offset=62, end_offset=207, type='context', text='as a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners', normalized_text='as nobiliary particle indicating noble patrilineality or as simple preposition that approximately means of or from in case of commoners')], [Entity(start_offset=55, end_offset=207, type='context', text='either as a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners', normalized_text='either as nobiliary particle indicating noble patrilineality or as simple preposition that approximately means of or from in case of commoners')], [Entity(start_offset=62, end_offset=119, type='context', text='as a nobiliary particle indicating a noble patrilineality', normalized_text='as nobiliary particle indicating noble patrilineality'), Entity(start_offset=123, end_offset=207, type='context', text='as a simple preposition that approximately means of or from in the case of commoners', normalized_text='as simple preposition that approximately means of or from in case of commoners')]], aligned_nps=[(Entity(start_offset=23, end_offset=35, type='question', text='the name von', normalized_text='name von'), Entity(start_offset=0, end_offset=3, type='context', text='Von', normalized_text='von'))], explanation_type='single_sentence'),\n",
       " 7775092479081500347: QEDExample(example_id=7775092479081500347, title='Coal power in the United States', question='how much energy does coal produce in the us', passage=\"Coal power in the United States accounted for 39 % of the country 's electricity production at utility - scale facilities in 2014 , 33 % in 2015 , and 30.4 % in 2016 Coal supplied 16.5 quadrillion BTUs of primary energy to electric power plants in 2013 , which made up nearly 92 % of coal 's contribution to energy supply . Utilities buy more than 90 percent of the coal consumed in the United States .\", sentence_starts=[0, 324], selected_sent={'start': 0, 'end': 324, 'string': \"Coal power in the United States accounted for 39 % of the country 's electricity production at utility - scale facilities in 2014 , 33 % in 2015 , and 30.4 % in 2016 Coal supplied 16.5 quadrillion BTUs of primary energy to electric power plants in 2013 , which made up nearly 92 % of coal 's contribution to energy supply . \"}, answer=[Entity(start_offset=180, end_offset=321, type='context', text=\"16.5 quadrillion BTUs of primary energy to electric power plants in 2013 , which made up nearly 92 % of coal 's contribution to energy supply\", normalized_text='165 quadrillion btus of primary energy to electric power plants in 2013 which made up nearly 92 of coal s contribution to energy supply')], nq_answers=[[Entity(start_offset=180, end_offset=201, type='context', text='16.5 quadrillion BTUs', normalized_text='165 quadrillion btus')], [Entity(start_offset=151, end_offset=157, type='context', text='30.4 %', normalized_text='304')]], aligned_nps=[(Entity(start_offset=21, end_offset=25, type='question', text='coal', normalized_text='coal'), Entity(start_offset=166, end_offset=170, type='context', text='Coal', normalized_text='coal')), (Entity(start_offset=37, end_offset=43, type='question', text='the us', normalized_text='us'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -86170850928243739: QEDExample(example_id=-86170850928243739, title='The Fate of the Furious', question='fast & furious 8 release date in india', passage='The Fate of the Furious had its world premiere in Berlin on April 4 , 2017 . The film was theatrically released in the United States on April 14 , 2017 , playing in 3D , IMAX 3D , and 4DX internationally , and received a day - and - date release across major markets such as Australia , the United Kingdom , China , and India , beginning on April 12 , 2017 . The film was released day - and - date in 1,074 IMAX screens around the world , making it the widest day - and - date opening in IMAX history .', sentence_starts=[0, 77, 359], selected_sent={'start': 77, 'end': 359, 'string': 'The film was theatrically released in the United States on April 14 , 2017 , playing in 3D , IMAX 3D , and 4DX internationally , and received a day - and - date release across major markets such as Australia , the United Kingdom , China , and India , beginning on April 12 , 2017 . '}, answer=[Entity(start_offset=341, end_offset=356, type='context', text='April 12 , 2017', normalized_text='april 12 2017')], nq_answers=[[Entity(start_offset=341, end_offset=356, type='context', text='April 12 , 2017', normalized_text='april 12 2017')]], aligned_nps=[(Entity(start_offset=0, end_offset=24, type='question', text='fast & furious 8 release', normalized_text='fast furious 8 release'), Entity(start_offset=77, end_offset=85, type='context', text='The film', normalized_text='film')), (Entity(start_offset=33, end_offset=38, type='question', text='india', normalized_text='india'), Entity(start_offset=320, end_offset=325, type='context', text='India', normalized_text='india'))], explanation_type='single_sentence'),\n",
       " -927966355158112429: QEDExample(example_id=-927966355158112429, title='United States presidential election', question='the group that officially elects the president of the united states is called', passage='The election of President and Vice President of the United States is an indirect election in which citizens of the United States who are registered to vote in one of the 50 U.S. states or in Washington , D.C. cast ballots not directly for those offices , but instead for members of the U.S. Electoral College , known as electors . These electors then in turn cast direct votes , known as electoral votes , for President , and for Vice President . The candidate who receives an absolute majority of electoral votes ( at least 270 out of a total of 538 , since the Twenty - Third Amendment granting voting rights to citizens of Washington , D.C. ) is then elected to that office . If no candidate receives an absolute majority of the votes for President , the House of Representatives chooses the winner ; if no one receives an absolute majority of the votes for Vice President , then the Senate chooses the winner .', sentence_starts=[0, 331, 447, 679], selected_sent={'start': 331, 'end': 447, 'string': 'These electors then in turn cast direct votes , known as electoral votes , for President , and for Vice President . '}, answer=[Entity(start_offset=286, end_offset=308, type='context', text='U.S. Electoral College', normalized_text='us electoral college')], nq_answers=[[Entity(start_offset=286, end_offset=308, type='context', text='U.S. Electoral College', normalized_text='us electoral college')], [Entity(start_offset=282, end_offset=308, type='context', text='the U.S. Electoral College', normalized_text='us electoral college')]], aligned_nps=[(Entity(start_offset=33, end_offset=67, type='question', text='the president of the united states', normalized_text='president of united states'), Entity(start_offset=410, end_offset=419, type='context', text='President', normalized_text='president'))], explanation_type='single_sentence'),\n",
       " 3043899135697147040: QEDExample(example_id=3043899135697147040, title='Tessa Peake-Jones', question='who played raquel in only fools and horses', passage='Tessa Peake - Jones ( born 9 May 1957 ) is an English actress . She is known for her role as Raquel in the BBC sitcom Only Fools and Horses , whom she played from December 1988 until it ended in 2003 .', sentence_starts=[0, 64], selected_sent={'start': 64, 'end': 201, 'string': 'She is known for her role as Raquel in the BBC sitcom Only Fools and Horses , whom she played from December 1988 until it ended in 2003 .'}, answer=[Entity(start_offset=0, end_offset=19, type='context', text='Tessa Peake - Jones', normalized_text='tessa peake jones')], nq_answers=[[Entity(start_offset=0, end_offset=19, type='context', text='Tessa Peake - Jones', normalized_text='tessa peake jones')]], aligned_nps=[(Entity(start_offset=11, end_offset=17, type='question', text='raquel', normalized_text='raquel'), Entity(start_offset=93, end_offset=99, type='context', text='Raquel', normalized_text='raquel')), (Entity(start_offset=21, end_offset=42, type='question', text='only fools and horses', normalized_text='only fools and horses'), Entity(start_offset=103, end_offset=139, type='context', text='the BBC sitcom Only Fools and Horses', normalized_text='bbc sitcom only fools and horses'))], explanation_type='single_sentence'),\n",
       " -8390473838502496745: QEDExample(example_id=-8390473838502496745, title='Politics of El Salvador', question='what type of political system does el salvador have', passage='Politics of El Salvador takes place in land a framework of a presidential representative democratic republic , whereby the President of El Salvador is both head of state and head of government , and of an Executive power is exercised by the government .', sentence_starts=[0], selected_sent={'start': 0, 'end': 253, 'string': 'Politics of El Salvador takes place in land a framework of a presidential representative democratic republic , whereby the President of El Salvador is both head of state and head of government , and of an Executive power is exercised by the government .'}, answer=[Entity(start_offset=59, end_offset=108, type='context', text='a presidential representative democratic republic', normalized_text='presidential representative democratic republic')], nq_answers=[[Entity(start_offset=61, end_offset=108, type='context', text='presidential representative democratic republic', normalized_text='presidential representative democratic republic')], [Entity(start_offset=61, end_offset=251, type='context', text='presidential representative democratic republic , whereby the President of El Salvador is both head of state and head of government , and of an Executive power is exercised by the government', normalized_text='presidential representative democratic republic whereby president of el salvador is both head of state and head of government and of executive power is exercised by government')], [Entity(start_offset=59, end_offset=108, type='context', text='a presidential representative democratic republic', normalized_text='presidential representative democratic republic')]], aligned_nps=[(Entity(start_offset=35, end_offset=46, type='question', text='el salvador', normalized_text='el salvador'), Entity(start_offset=12, end_offset=23, type='context', text='El Salvador', normalized_text='el salvador'))], explanation_type='single_sentence'),\n",
       " 5046330903295447703: QEDExample(example_id=5046330903295447703, title='Beverage can', question='when did they stop making pull tabs on beer cans', passage=\"The safety and litter problems were both eventually solved later in the 1970s with Daniel F. Cudzik 's invention of the non-removing `` Stay - Tab '' . The pull - ring was replaced with a stiff aluminium lever , and the removable tab was replaced with a pre-scored round tab that functioned similarly to the push - tab , but the raised blister was no longer needed , as the riveted lever would now do the job of pushing the tab open and into the interior of the can .\", sentence_starts=[0, 152], selected_sent={'start': 152, 'end': 467, 'string': 'The pull - ring was replaced with a stiff aluminium lever , and the removable tab was replaced with a pre-scored round tab that functioned similarly to the push - tab , but the raised blister was no longer needed , as the riveted lever would now do the job of pushing the tab open and into the interior of the can .'}, answer=[Entity(start_offset=72, end_offset=77, type='context', text='1970s', normalized_text='1970s')], nq_answers=[[Entity(start_offset=72, end_offset=77, type='context', text='1970s', normalized_text='1970s')]], aligned_nps=[(Entity(start_offset=26, end_offset=48, type='question', text='pull tabs on beer cans', normalized_text='pull tabs on beer cans'), Entity(start_offset=152, end_offset=167, type='context', text='The pull - ring', normalized_text='pull ring'))], explanation_type='single_sentence'),\n",
       " -7371190246861514246: QEDExample(example_id=-7371190246861514246, title='Plain English', question='explain what is meant by plain english and why is it used', passage=\"Plain English ( or layman 's terms ) is a style of communication that uses easy to understand , plain language with an emphasis on clarity , brevity , and avoidance of overly complex vocabulary . It is commonly used in relation to official government or business communication . The goal is to write or speak in a way that is easily understood by the target audience . It is clear and straightforward , concise , free of clichés and needless technical jargon , and appropriate to the audience 's developmental or educational level and their familiarity with the topic .\", sentence_starts=[0, 196, 279, 369], selected_sent={'start': 0, 'end': 196, 'string': \"Plain English ( or layman 's terms ) is a style of communication that uses easy to understand , plain language with an emphasis on clarity , brevity , and avoidance of overly complex vocabulary . \"}, answer=[Entity(start_offset=40, end_offset=193, type='context', text='a style of communication that uses easy to understand , plain language with an emphasis on clarity , brevity , and avoidance of overly complex vocabulary', normalized_text='style of communication that uses easy to understand plain language with emphasis on clarity brevity and avoidance of overly complex vocabulary')], nq_answers=[[Entity(start_offset=40, end_offset=195, type='context', text='a style of communication that uses easy to understand , plain language with an emphasis on clarity , brevity , and avoidance of overly complex vocabulary .', normalized_text='style of communication that uses easy to understand plain language with emphasis on clarity brevity and avoidance of overly complex vocabulary'), Entity(start_offset=291, end_offset=366, type='context', text='to write or speak in a way that is easily understood by the target audience', normalized_text='to write or speak in way that is easily understood by target audience')]], aligned_nps=[(Entity(start_offset=25, end_offset=38, type='question', text='plain english', normalized_text='plain english'), Entity(start_offset=0, end_offset=13, type='context', text='Plain English', normalized_text='plain english'))], explanation_type='single_sentence'),\n",
       " -5984668857988357373: QEDExample(example_id=-5984668857988357373, title='Sacroiliac joint', question='the joint between a coxal bone of the pelvis and the sacrum', passage='The sacroiliac joint or SI joint ( SIJ ) is the joint between the sacrum and the ilium bones of the pelvis , which are connected by strong ligaments . In humans , the sacrum supports the spine and is supported in turn by an ilium on each side . The joint is a strong , weight transferral synovial plane joint with irregular elevations and depressions that produce interlocking of the two bones . The human body has two sacroiliac joints , one on the left and one on the right , that often match each other but are highly variable from person to person .', sentence_starts=[0, 151, 245, 396], selected_sent={'start': 0, 'end': 151, 'string': 'The sacroiliac joint or SI joint ( SIJ ) is the joint between the sacrum and the ilium bones of the pelvis , which are connected by strong ligaments . '}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='The sacroiliac joint', normalized_text='sacroiliac joint')], nq_answers=[[Entity(start_offset=4, end_offset=20, type='context', text='sacroiliac joint', normalized_text='sacroiliac joint')], [Entity(start_offset=0, end_offset=40, type='context', text='The sacroiliac joint or SI joint ( SIJ )', normalized_text='sacroiliac joint or si joint sij')]], aligned_nps=[(Entity(start_offset=49, end_offset=59, type='question', text='the sacrum', normalized_text='sacrum'), Entity(start_offset=62, end_offset=72, type='context', text='the sacrum', normalized_text='sacrum')), (Entity(start_offset=34, end_offset=44, type='question', text='the pelvis', normalized_text='pelvis'), Entity(start_offset=96, end_offset=106, type='context', text='the pelvis', normalized_text='pelvis'))], explanation_type='single_sentence'),\n",
       " -8837653404749291736: QEDExample(example_id=-8837653404749291736, title='Music of Red Dead Redemption', question='what is the song in red dead redemption', passage=\"Red Dead Redemption won the award for Best Original Music from GameSpot , and Best Original Score at the Spike Video Game Awards ; the latter also awarded `` Far Away '' by José González with Best Song in a Game . Gonzalez performed the song on Zane Lowe 's show on BBC Radio 1 in June 2010 , at the Rockstar offices in New York in July 2010 , and at the Spike Video Game Awards in December 2010 . The performance at the Spike Video Game Awards was accompanied by a music video for the song , which Rockstar published a few weeks later . Ashtar Command also performed a live version of the song `` Deadman 's Gun '' in August 2010 . The popularity of the game has led to numerous cover versions of the music being released by various artists , such as musician Ben `` Squid Physics '' Morfitt , and artist María Katt .\", sentence_starts=[0, 214, 398, 538, 633], selected_sent={'start': 0, 'end': 214, 'string': \"Red Dead Redemption won the award for Best Original Music from GameSpot , and Best Original Score at the Spike Video Game Awards ; the latter also awarded `` Far Away '' by José González with Best Song in a Game . \"}, answer=[Entity(start_offset=155, end_offset=186, type='context', text=\"`` Far Away '' by José González\", normalized_text='far away by josé gonzález')], nq_answers=[[Entity(start_offset=158, end_offset=166, type='context', text='Far Away', normalized_text='far away')]], aligned_nps=[(Entity(start_offset=20, end_offset=39, type='question', text='red dead redemption', normalized_text='red dead redemption'), Entity(start_offset=0, end_offset=19, type='context', text='Red Dead Redemption', normalized_text='red dead redemption'))], explanation_type='single_sentence'),\n",
       " -785011001543926485: QEDExample(example_id=-785011001543926485, title='Lagaan', question='once upon time in india kis film ka tag line hai', passage='Lagaan ( English : Taxation ; also called Lagaan : Once Upon a Time in India ) is a 2001 Indian epic sports - drama film , directed by Ashutosh Gowariker , produced by Aamir Khan and Mansoor Khan , and written by Gowariker and Abbas Tyrewala . Aamir Khan stars along with Gracy Singh , with British actors Rachel Shelley and Paul Blackthorne playing supporting roles . Made on a then - unprecedented budget of ₹ 250 million ( equivalent to ₹ 700 million or US $11 million in 2016 ) , the film was shot in an ancient village near Bhuj , India .', sentence_starts=[0, 244, 369], selected_sent={'start': 0, 'end': 244, 'string': 'Lagaan ( English : Taxation ; also called Lagaan : Once Upon a Time in India ) is a 2001 Indian epic sports - drama film , directed by Ashutosh Gowariker , produced by Aamir Khan and Mansoor Khan , and written by Gowariker and Abbas Tyrewala . '}, answer=[Entity(start_offset=0, end_offset=6, type='context', text='Lagaan', normalized_text='lagaan')], nq_answers=[[Entity(start_offset=0, end_offset=78, type='context', text='Lagaan ( English : Taxation ; also called Lagaan : Once Upon a Time in India )', normalized_text='lagaan english taxation also called lagaan once upon time in india')]], aligned_nps=[(Entity(start_offset=0, end_offset=23, type='question', text='once upon time in india', normalized_text='once upon time in india'), Entity(start_offset=51, end_offset=76, type='context', text='Once Upon a Time in India', normalized_text='once upon time in india'))], explanation_type='single_sentence'),\n",
       " -6731660837492850061: QEDExample(example_id=-6731660837492850061, title='Tomato purée', question='whats the difference between tomato paste and tomato puree', passage='Tomato purée is a thick liquid made by cooking and straining tomatoes . The difference between tomato paste , tomato purée , and tomato sauce is consistency ; tomato puree has a thicker consistency and a deeper flavour than sauce .', sentence_starts=[0, 72], selected_sent={'start': 72, 'end': 231, 'string': 'The difference between tomato paste , tomato purée , and tomato sauce is consistency ; tomato puree has a thicker consistency and a deeper flavour than sauce .'}, answer=[Entity(start_offset=145, end_offset=156, type='context', text='consistency', normalized_text='consistency')], nq_answers=[[Entity(start_offset=145, end_offset=156, type='context', text='consistency', normalized_text='consistency')]], aligned_nps=[(Entity(start_offset=29, end_offset=41, type='question', text='tomato paste', normalized_text='tomato paste'), Entity(start_offset=95, end_offset=107, type='context', text='tomato paste', normalized_text='tomato paste')), (Entity(start_offset=46, end_offset=58, type='question', text='tomato puree', normalized_text='tomato puree'), Entity(start_offset=110, end_offset=122, type='context', text='tomato purée', normalized_text='tomato purée'))], explanation_type='single_sentence'),\n",
       " -8188778280161966817: QEDExample(example_id=-8188778280161966817, title='Volcanology of Iceland', question='what type of plate boundary is associated with iceland and its volcanic eruptions', passage=\"Volcanology of Iceland includes a high concentration of active volcanoes due to Iceland 's location on the mid-Atlantic Ridge , a divergent tectonic plate boundary , and also due to its location over a hot spot . The island has 30 active volcanic systems , of which 13 have erupted since the settlement of Iceland in AD 874 .\", sentence_starts=[0, 213], selected_sent={'start': 0, 'end': 213, 'string': \"Volcanology of Iceland includes a high concentration of active volcanoes due to Iceland 's location on the mid-Atlantic Ridge , a divergent tectonic plate boundary , and also due to its location over a hot spot . \"}, answer=[Entity(start_offset=128, end_offset=163, type='context', text='a divergent tectonic plate boundary', normalized_text='divergent tectonic plate boundary')], nq_answers=[[Entity(start_offset=103, end_offset=125, type='context', text='the mid-Atlantic Ridge', normalized_text='midatlantic ridge')], [Entity(start_offset=128, end_offset=163, type='context', text='a divergent tectonic plate boundary', normalized_text='divergent tectonic plate boundary')], [Entity(start_offset=130, end_offset=163, type='context', text='divergent tectonic plate boundary', normalized_text='divergent tectonic plate boundary')]], aligned_nps=[(Entity(start_offset=47, end_offset=54, type='question', text='iceland', normalized_text='iceland'), Entity(start_offset=15, end_offset=22, type='context', text='Iceland', normalized_text='iceland'))], explanation_type='single_sentence'),\n",
       " -5064749377166389418: QEDExample(example_id=-5064749377166389418, title='British Empire in World War II', question='when did the united kingdom entered world war 2', passage=\"On 1 September 1939 , Germany invaded Poland . Two days later , on 3 September , after a British ultimatum to Germany to cease military operations was ignored , Britain and France declared war on Germany . Britain 's declaration of war automatically committed India , the Crown colonies , and the protectorates , but the 1931 Statute of Westminster had granted autonomy to the Dominions so each decided their course separately .\", sentence_starts=[0, 47, 206], selected_sent={'start': 47, 'end': 206, 'string': 'Two days later , on 3 September , after a British ultimatum to Germany to cease military operations was ignored , Britain and France declared war on Germany . '}, answer=[Entity(start_offset=15, end_offset=19, type='context', text='1939', normalized_text='1939')], nq_answers=[[Entity(start_offset=15, end_offset=19, type='context', text='1939', normalized_text='1939')]], aligned_nps=[(Entity(start_offset=13, end_offset=27, type='question', text='united kingdom', normalized_text='united kingdom'), Entity(start_offset=161, end_offset=168, type='context', text='Britain', normalized_text='britain')), (Entity(start_offset=36, end_offset=47, type='question', text='world war 2', normalized_text='world war 2'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 7691004684523216707: QEDExample(example_id=7691004684523216707, title='Precipitation (chemistry)', question='when does precipitate form in a chemical reaction', passage=\"Precipitation is the creation of a solid from a solution . When the reaction occurs in a liquid solution , the solid formed is called the ' precipitate ' . The chemical that causes the solid to form is called the ' precipitant ' . Without sufficient force of gravity ( settling ) to bring the solid particles together , the precipitate remains in suspension . After sedimentation , especially when using a centrifuge to press it into a compact mass , the precipitate may be referred to as a ' pellet ' . Precipitation can be used as a medium . The precipitate - free liquid remaining above the solid is called the ' supernate ' or ' supernatant ' . Powders derived from precipitation have also historically been known as ' flowers ' . When the solid appears in the form of cellulose fibers which have been through chemical processing , the process is often referred to as regeneration .\", sentence_starts=[0, 59, 156, 231, 360, 504, 544, 649, 735], selected_sent={'start': 59, 'end': 156, 'string': \"When the reaction occurs in a liquid solution , the solid formed is called the ' precipitate ' . \"}, answer=[Entity(start_offset=59, end_offset=104, type='context', text='When the reaction occurs in a liquid solution', normalized_text='when reaction occurs in liquid solution')], nq_answers=[[Entity(start_offset=59, end_offset=104, type='context', text='When the reaction occurs in a liquid solution', normalized_text='when reaction occurs in liquid solution')]], aligned_nps=[(Entity(start_offset=10, end_offset=21, type='question', text='precipitate', normalized_text='precipitate'), Entity(start_offset=134, end_offset=153, type='context', text=\"the ' precipitate '\", normalized_text='precipitate'))], explanation_type='single_sentence'),\n",
       " 2943048018320429657: QEDExample(example_id=2943048018320429657, title='First Family of the United States', question='where does the president and his family live', passage='The First Family of the United States ( FFOTUS ) is the official title for the family of the President of the United States , who is both head of state and head of government of the United States . Members of the First Family consist of the President , the First Lady of the United States , and any of their children . However , other close relatives of the President and First Lady , such as parents , grandchildren , stepchildren , and in - laws , may be classified as members of the First Family if they reside in the Executive Residence of the White House Complex .', sentence_starts=[0, 198, 319], selected_sent={'start': 319, 'end': 569, 'string': 'However , other close relatives of the President and First Lady , such as parents , grandchildren , stepchildren , and in - laws , may be classified as members of the First Family if they reside in the Executive Residence of the White House Complex .'}, answer=[Entity(start_offset=517, end_offset=567, type='context', text='the Executive Residence of the White House Complex', normalized_text='executive residence of white house complex')], nq_answers=[[Entity(start_offset=517, end_offset=567, type='context', text='the Executive Residence of the White House Complex', normalized_text='executive residence of white house complex')], [Entity(start_offset=514, end_offset=567, type='context', text='in the Executive Residence of the White House Complex', normalized_text='in executive residence of white house complex')]], aligned_nps=[(Entity(start_offset=11, end_offset=24, type='question', text='the president', normalized_text='president'), Entity(start_offset=354, end_offset=367, type='context', text='the President', normalized_text='president'))], explanation_type='single_sentence'),\n",
       " -5682352906951331542: QEDExample(example_id=-5682352906951331542, title='Cornell Notes', question='who invented the cornell method of note taking', passage='The Cornell Notes system ( also Cornell note - taking system , Cornell method , or Cornell way ) is a note - taking system devised in the 1940s by Walter Pauk , an education professor at Cornell University . Pauk advocated its use in his best - selling book How to Study in College .', sentence_starts=[0, 208], selected_sent={'start': 0, 'end': 208, 'string': 'The Cornell Notes system ( also Cornell note - taking system , Cornell method , or Cornell way ) is a note - taking system devised in the 1940s by Walter Pauk , an education professor at Cornell University . '}, answer=[Entity(start_offset=147, end_offset=158, type='context', text='Walter Pauk', normalized_text='walter pauk')], nq_answers=[[Entity(start_offset=147, end_offset=158, type='context', text='Walter Pauk', normalized_text='walter pauk')], [Entity(start_offset=147, end_offset=205, type='context', text='Walter Pauk , an education professor at Cornell University', normalized_text='walter pauk education professor at cornell university')]], aligned_nps=[(Entity(start_offset=13, end_offset=46, type='question', text='the cornell method of note taking', normalized_text='cornell method of note taking'), Entity(start_offset=63, end_offset=77, type='context', text='Cornell method', normalized_text='cornell method'))], explanation_type='single_sentence'),\n",
       " -1738218384036165752: QEDExample(example_id=-1738218384036165752, title='Young and Beautiful (Lana Del Rey song)', question=\"who sings will you still love me when i'm not young and beautiful\", passage=\"`` Young and Beautiful '' is a song by American singer and songwriter Lana Del Rey used for the soundtrack to the drama film The Great Gatsby ( 2013 ) . It was released on April 23 , 2013 through Interscope Records as the lead single from the soundtrack . `` Young and Beautiful '' was written by Del Rey and Rick Nowels , who also produced the song . The music video features an orchestral version of the song , produced by Dan Heath , which is included on the deluxe edition of the soundtrack .\", sentence_starts=[0, 153, 256, 352], selected_sent={'start': 0, 'end': 153, 'string': \"`` Young and Beautiful '' is a song by American singer and songwriter Lana Del Rey used for the soundtrack to the drama film The Great Gatsby ( 2013 ) . \"}, answer=[Entity(start_offset=70, end_offset=82, type='context', text='Lana Del Rey', normalized_text='lana del rey')], nq_answers=[[Entity(start_offset=70, end_offset=82, type='context', text='Lana Del Rey', normalized_text='lana del rey')]], aligned_nps=[(Entity(start_offset=10, end_offset=65, type='question', text=\"will you still love me when i'm not young and beautiful\", normalized_text='will you still love me when im not young and beautiful'), Entity(start_offset=3, end_offset=22, type='context', text='Young and Beautiful', normalized_text='young and beautiful'))], explanation_type='single_sentence'),\n",
       " -5942357491167725852: QEDExample(example_id=-5942357491167725852, title='Gun laws in Switzerland', question='what kind of guns are allowed in switzerland', passage='The legislation is considered liberal and allows the free purchase of semi-automatic , but not fully automatic , firearms by Swiss citizens and foreigners with permanent residence .', sentence_starts=[0], selected_sent={'start': 0, 'end': 181, 'string': 'The legislation is considered liberal and allows the free purchase of semi-automatic , but not fully automatic , firearms by Swiss citizens and foreigners with permanent residence .'}, answer=[Entity(start_offset=70, end_offset=121, type='context', text='semi-automatic , but not fully automatic , firearms', normalized_text='semiautomatic but not fully automatic firearms')], nq_answers=[[Entity(start_offset=70, end_offset=121, type='context', text='semi-automatic , but not fully automatic , firearms', normalized_text='semiautomatic but not fully automatic firearms')]], aligned_nps=[(Entity(start_offset=33, end_offset=44, type='question', text='switzerland', normalized_text='switzerland'), Entity(start_offset=0, end_offset=15, type='context', text='The legislation', normalized_text='legislation'))], explanation_type='single_sentence'),\n",
       " 1340598526765817964: QEDExample(example_id=1340598526765817964, title='Supreme Court of the United States', question=\"what is the supreme court's major power\", passage='The Supreme Court of the United States ( sometimes colloquially referred to by the acronym SCOTUS ) is the highest federal court of the United States . Established pursuant to Article Three of the United States Constitution in 1789 , it has ultimate ( and largely discretionary ) appellate jurisdiction over all federal courts and state court cases involving issues of federal law plus original jurisdiction over a small range of cases . In the legal system of the United States , the Supreme Court is generally the final interpreter of federal law including the United States Constitution , but it may act only within the context of a case in which it has jurisdiction . The Court may decide cases having political overtones but does not have power to decide nonjusticiable political questions , and its enforcement arm is in the executive rather than judicial branch of government .', sentence_starts=[0, 152, 438, 672], selected_sent={'start': 152, 'end': 438, 'string': 'Established pursuant to Article Three of the United States Constitution in 1789 , it has ultimate ( and largely discretionary ) appellate jurisdiction over all federal courts and state court cases involving issues of federal law plus original jurisdiction over a small range of cases . '}, answer=[Entity(start_offset=241, end_offset=435, type='context', text='ultimate ( and largely discretionary ) appellate jurisdiction over all federal courts and state court cases involving issues of federal law plus original jurisdiction over a small range of cases', normalized_text='ultimate and largely discretionary appellate jurisdiction over all federal courts and state court cases involving issues of federal law plus original jurisdiction over small range of cases')], nq_answers=[[Entity(start_offset=241, end_offset=435, type='context', text='ultimate ( and largely discretionary ) appellate jurisdiction over all federal courts and state court cases involving issues of federal law plus original jurisdiction over a small range of cases', normalized_text='ultimate and largely discretionary appellate jurisdiction over all federal courts and state court cases involving issues of federal law plus original jurisdiction over small range of cases')], [Entity(start_offset=234, end_offset=380, type='context', text='it has ultimate ( and largely discretionary ) appellate jurisdiction over all federal courts and state court cases involving issues of federal law', normalized_text='it has ultimate and largely discretionary appellate jurisdiction over all federal courts and state court cases involving issues of federal law')]], aligned_nps=[(Entity(start_offset=8, end_offset=25, type='question', text='the supreme court', normalized_text='supreme court'), Entity(start_offset=234, end_offset=236, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 2985591975335305853: QEDExample(example_id=2985591975335305853, title='Maquiladora', question='factories that assemble parts made in other countries', passage=\"In Mexico , a maquiladora ( Spanish pronunciation : ( makilaˈðoɾa ) ) or maquila ( IPA : ( maˈkila ) ) is a manufacturing operation , where factories import certain material and equipment on a duty - free and tariff - free basis for assembly , processing , or manufacturing and then export the assembled , processed and / or manufactured products , sometimes back to the raw materials ' country of origin . They are an example of special economic zones as seen in many countries .\", sentence_starts=[0, 407], selected_sent={'start': 0, 'end': 407, 'string': \"In Mexico , a maquiladora ( Spanish pronunciation : ( makilaˈðoɾa ) ) or maquila ( IPA : ( maˈkila ) ) is a manufacturing operation , where factories import certain material and equipment on a duty - free and tariff - free basis for assembly , processing , or manufacturing and then export the assembled , processed and / or manufactured products , sometimes back to the raw materials ' country of origin . \"}, answer=[Entity(start_offset=12, end_offset=25, type='context', text='a maquiladora', normalized_text='maquiladora')], nq_answers=[[Entity(start_offset=430, end_offset=452, type='context', text='special economic zones', normalized_text='special economic zones')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6050703859996827650: QEDExample(example_id=-6050703859996827650, title='Epistle to the Galatians', question='who is the book of galatians written to', passage='The Epistle to the Galatians , often shortened to Galatians , is the ninth book of the New Testament . It is a letter from Paul the Apostle to a number of Early Christian communities in Galatia . Scholars have suggested that this is either the Roman province of Galatia in southern Anatolia , or a large region defined by an ethnic group of Celtic people in central Anatolia .', sentence_starts=[0, 103, 196], selected_sent={'start': 103, 'end': 196, 'string': 'It is a letter from Paul the Apostle to a number of Early Christian communities in Galatia . '}, answer=[Entity(start_offset=143, end_offset=193, type='context', text='a number of Early Christian communities in Galatia', normalized_text='number of early christian communities in galatia')], nq_answers=[[Entity(start_offset=143, end_offset=193, type='context', text='a number of Early Christian communities in Galatia', normalized_text='number of early christian communities in galatia')]], aligned_nps=[(Entity(start_offset=7, end_offset=28, type='question', text='the book of galatians', normalized_text='book of galatians'), Entity(start_offset=103, end_offset=105, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -7812103900635685817: QEDExample(example_id=-7812103900635685817, title='Dilwale Dulhania Le Jayenge', question='tujhe dekha toh yeh jana sanam movie name', passage=\"Dilwale Dulhania Le Jayenge was filmed in several 5 - , 10 - and 20 - day schedules between September 1994 and August 1995 . The first sequence filmed was for the song `` Ho Gaya Hai Tujhko '' with Kajol and Shah Rukh in Switzerland . The European journey scenes and songs were mainly filmed in Saanen , Montbovon and Gstaad , Switzerland . Other scenes were shot in England , at locations including Trafalgar Square , King 's Cross railway station and Angel Underground station . Film 's cinematographer Manmohan Singh , a regular collaborator with Chopra , shot the song `` Tujhe Dekha To '' , including the iconic mustard fields scenes with Shah Rukh and Kajol in the mustard fields in Gurgaon on the outskirts of the National Capital Region Delhi .\", sentence_starts=[0, 125, 235, 341, 481], selected_sent={'start': 481, 'end': 752, 'string': \"Film 's cinematographer Manmohan Singh , a regular collaborator with Chopra , shot the song `` Tujhe Dekha To '' , including the iconic mustard fields scenes with Shah Rukh and Kajol in the mustard fields in Gurgaon on the outskirts of the National Capital Region Delhi .\"}, answer=[Entity(start_offset=0, end_offset=27, type='context', text='Dilwale Dulhania Le Jayenge', normalized_text='dilwale dulhania le jayenge')], nq_answers=[[Entity(start_offset=0, end_offset=27, type='context', text='Dilwale Dulhania Le Jayenge', normalized_text='dilwale dulhania le jayenge')]], aligned_nps=[(Entity(start_offset=0, end_offset=30, type='question', text='tujhe dekha toh yeh jana sanam', normalized_text='tujhe dekha toh yeh jana sanam'), Entity(start_offset=564, end_offset=593, type='context', text=\"the song `` Tujhe Dekha To ''\", normalized_text='song tujhe dekha to'))], explanation_type='single_sentence'),\n",
       " 1668669287255788257: QEDExample(example_id=1668669287255788257, title='Sophocles', question='who wrote antigone and what are the dates of his birth and death', passage='Sophocles ( / ˈsɒfəkliːz / ; Greek : Σοφοκλῆς , Sophoklēs , Ancient Greek : ( so. pho. klɛ̂ːs ) ; c. 497 / 6 -- winter 406 / 5 BC ) is one of three ancient Greek tragedians whose plays have survived . His first plays were written later than those of Aeschylus , and earlier than or contemporary with those of Euripides . Sophocles wrote over 120 plays during the course of his life , but only seven have survived in a complete form : Ajax , Antigone , The Women of Trachis , Oedipus Rex , Electra , Philoctetes and Oedipus at Colonus . For almost 50 years , Sophocles was the most celebrated playwright in the dramatic competitions of the city - state of Athens that took place during the religious festivals of the Lenaea and the Dionysia . He competed in 30 competitions , won 24 , and was never judged lower than second place . Aeschylus won 13 competitions , and was sometimes defeated by Sophocles , while Euripides won 4 competitions .', sentence_starts=[0, 201, 321, 536, 742, 831], selected_sent={'start': 321, 'end': 536, 'string': 'Sophocles wrote over 120 plays during the course of his life , but only seven have survived in a complete form : Ajax , Antigone , The Women of Trachis , Oedipus Rex , Electra , Philoctetes and Oedipus at Colonus . '}, answer=[Entity(start_offset=0, end_offset=129, type='context', text='Sophocles ( / ˈsɒfəkliːz / ; Greek : Σοφοκλῆς , Sophoklēs , Ancient Greek : ( so. pho. klɛ̂ːs ) ; c. 497 / 6 -- winter 406 / 5 BC', normalized_text='sophocles ˈsɒfəkliːz greek σοφοκλῆς sophoklēs ancient greek so pho klɛ̂ːs c 497 6 winter 406 5 bc')], nq_answers=[[Entity(start_offset=0, end_offset=9, type='context', text='Sophocles', normalized_text='sophocles'), Entity(start_offset=98, end_offset=129, type='context', text='c. 497 / 6 -- winter 406 / 5 BC', normalized_text='c 497 6 winter 406 5 bc')], [Entity(start_offset=0, end_offset=9, type='context', text='Sophocles', normalized_text='sophocles')], [Entity(start_offset=0, end_offset=9, type='context', text='Sophocles', normalized_text='sophocles'), Entity(start_offset=98, end_offset=108, type='context', text='c. 497 / 6', normalized_text='c 497 6'), Entity(start_offset=112, end_offset=129, type='context', text='winter 406 / 5 BC', normalized_text='winter 406 5 bc')]], aligned_nps=[(Entity(start_offset=10, end_offset=18, type='question', text='antigone', normalized_text='antigone'), Entity(start_offset=441, end_offset=449, type='context', text='Antigone', normalized_text='antigone'))], explanation_type='single_sentence'),\n",
       " -4153891120088105846: QEDExample(example_id=-4153891120088105846, title='List of The Lion King characters', question='what is the name of the hyena in lion king', passage=\"Shenzi ( voiced by Whoopi Goldberg in the films and Tress MacNeille in Timon & Pumbaa and Kingdom Hearts II ) , Banzai ( voiced by Cheech Marin in the films and Kingdom Hearts II and Rob Paulsen in Timon & Pumbaa ) and Ed ( voiced by Jim Cummings ) are the three spotted hyenas who make up Scar 's henchmen . After Scar promises them that they will have food , the hyenas trigger the wildebeest stampede and chase Simba out of Pride Rock . When Simba returns to Pride Rock , Shenzi and Banzai are defeated by Pumbaa . The three turn on Scar when the latter tries to blame them for Mufasa 's death and the ruin of the Pride Lands , and eat him alive during a thunderstorm .\", sentence_starts=[0, 309, 440, 518], selected_sent={'start': 0, 'end': 309, 'string': \"Shenzi ( voiced by Whoopi Goldberg in the films and Tress MacNeille in Timon & Pumbaa and Kingdom Hearts II ) , Banzai ( voiced by Cheech Marin in the films and Kingdom Hearts II and Rob Paulsen in Timon & Pumbaa ) and Ed ( voiced by Jim Cummings ) are the three spotted hyenas who make up Scar 's henchmen . \"}, answer=[Entity(start_offset=0, end_offset=248, type='context', text='Shenzi ( voiced by Whoopi Goldberg in the films and Tress MacNeille in Timon & Pumbaa and Kingdom Hearts II ) , Banzai ( voiced by Cheech Marin in the films and Kingdom Hearts II and Rob Paulsen in Timon & Pumbaa ) and Ed ( voiced by Jim Cummings )', normalized_text='shenzi voiced by whoopi goldberg in films and tress macneille in timon pumbaa and kingdom hearts ii banzai voiced by cheech marin in films and kingdom hearts ii and rob paulsen in timon pumbaa and ed voiced by jim cummings')], nq_answers=[[Entity(start_offset=0, end_offset=6, type='context', text='Shenzi', normalized_text='shenzi'), Entity(start_offset=112, end_offset=118, type='context', text='Banzai', normalized_text='banzai'), Entity(start_offset=219, end_offset=221, type='context', text='Ed', normalized_text='ed')], [Entity(start_offset=112, end_offset=118, type='context', text='Banzai', normalized_text='banzai'), Entity(start_offset=219, end_offset=221, type='context', text='Ed', normalized_text='ed'), Entity(start_offset=0, end_offset=6, type='context', text='Shenzi', normalized_text='shenzi')]], aligned_nps=[(Entity(start_offset=33, end_offset=42, type='question', text='lion king', normalized_text='lion king'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -6868606462984512329: QEDExample(example_id=-6868606462984512329, title='White Witch', question='where does the white witch live in narnia', passage=\"But with the approach of Aslan , her magical winter thaws , and Edmund is rescued after his treason . He had been greeted with a hostile reception from the White Witch after arriving at her castle alone , and even more so after informing her that Aslan had come to Narnia . The harshness of the Witch 's winter had made Edmund realise that he had been wrong in thinking that her side was the right side to be on , and he realised the full extent of her evil when he witnessed her turning a party of creatures into stone after their revelation that Father Christmas had been in Narnia - much to the Witch 's horror after she had banished him .\", sentence_starts=[0, 102, 274], selected_sent={'start': 102, 'end': 274, 'string': 'He had been greeted with a hostile reception from the White Witch after arriving at her castle alone , and even more so after informing her that Aslan had come to Narnia . '}, answer=[Entity(start_offset=186, end_offset=196, type='context', text='her castle', normalized_text='her castle')], nq_answers=[[Entity(start_offset=186, end_offset=196, type='context', text='her castle', normalized_text='her castle')]], aligned_nps=[(Entity(start_offset=11, end_offset=26, type='question', text='the white witch', normalized_text='white witch'), Entity(start_offset=152, end_offset=167, type='context', text='the White Witch', normalized_text='white witch')), (Entity(start_offset=35, end_offset=41, type='question', text='narnia', normalized_text='narnia'), Entity(start_offset=265, end_offset=271, type='context', text='Narnia', normalized_text='narnia'))], explanation_type='single_sentence'),\n",
       " -8588049058110544544: QEDExample(example_id=-8588049058110544544, title='Eobard Thawne', question=\"who kills barry's mom in the flash\", passage=\"When Thawne reappears , he murders the revived Johnny Quick , before proceeding to trap Barry and the revived Max Mercury inside the negative Speed Force . Thawne then attempts to kill Wally West 's children through their connection to the Speed Force in front of Linda Park - West , only to be stopped by Jay Garrick and Bart Allen . Thawne defeats Jay and prepares to kill Bart , but Barry , Max , Wally , Jesse Quick , and Impulse arrive to prevent the villain from doing so . In the ensuing fight , Thawne reveals that he is responsible for every tragedy that has occurred in Barry 's life , including the death of his mother . Thawne then decides to destroy everything the Flash holds dear by killing Barry 's wife , Iris , before they even met .\", sentence_starts=[0, 156, 335, 480, 632], selected_sent={'start': 480, 'end': 632, 'string': \"In the ensuing fight , Thawne reveals that he is responsible for every tragedy that has occurred in Barry 's life , including the death of his mother . \"}, answer=[Entity(start_offset=503, end_offset=509, type='context', text='Thawne', normalized_text='thawne')], nq_answers=[[Entity(start_offset=503, end_offset=509, type='context', text='Thawne', normalized_text='thawne')]], aligned_nps=[(Entity(start_offset=10, end_offset=21, type='question', text=\"barry's mom\", normalized_text='barrys mom'), Entity(start_offset=619, end_offset=629, type='context', text='his mother', normalized_text='his mother')), (Entity(start_offset=25, end_offset=34, type='question', text='the flash', normalized_text='flash'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3491840972245765831: QEDExample(example_id=3491840972245765831, title='Acts of the Apostles', question='who is the book of acts written to', passage=\"Luke -- Acts is an attempt to answer a theological problem , namely how the Messiah of the Jews came to have an overwhelmingly non-Jewish church ; the answer it provides , and its central theme , is that the message of Christ was sent to the Gentiles because the Jews rejected it . Luke -- Acts can be also seen as a defense of ( or `` apology '' for ) the Jesus movement addressed to the Jews : the bulk of the speeches and sermons in Acts are addressed to Jewish audiences , with the Romans serving as external arbiters on disputes concerning Jewish customs and law . On the one hand Luke portrays the Christians as a sect of the Jews , and therefore entitled to legal protection as a recognised religion ; on the other , Luke seems unclear as to the future God intends for Jews and Christians , celebrating the Jewishness of Jesus and his immediate followers while also stressing how the Jews had rejected God 's promised Messiah .\", sentence_starts=[0, 282, 570], selected_sent={'start': 282, 'end': 570, 'string': \"Luke -- Acts can be also seen as a defense of ( or `` apology '' for ) the Jesus movement addressed to the Jews : the bulk of the speeches and sermons in Acts are addressed to Jewish audiences , with the Romans serving as external arbiters on disputes concerning Jewish customs and law . \"}, answer=[Entity(start_offset=385, end_offset=393, type='context', text='the Jews', normalized_text='jews')], nq_answers=[[Entity(start_offset=455, end_offset=474, type='context', text='to Jewish audiences', normalized_text='to jewish audiences')], [Entity(start_offset=458, end_offset=474, type='context', text='Jewish audiences', normalized_text='jewish audiences')]], aligned_nps=[(Entity(start_offset=7, end_offset=23, type='question', text='the book of acts', normalized_text='book of acts'), Entity(start_offset=282, end_offset=294, type='context', text='Luke -- Acts', normalized_text='luke acts'))], explanation_type='single_sentence'),\n",
       " -7520682400646360503: QEDExample(example_id=-7520682400646360503, title='Gómez', question='what is the meaning of the name gomez', passage=\"It is derived from the given name Gomes which is a loanword of the Visigothic word guma `` man '' . It is itself related to the Common Germanic word guma ( Old English guma `` man '' , Middle English gome ) / gomo ( High Old German gomo `` man '' , Middle High German gome ) related to Latin homo `` man '' .\", sentence_starts=[0, 100], selected_sent={'start': 0, 'end': 100, 'string': \"It is derived from the given name Gomes which is a loanword of the Visigothic word guma `` man '' . \"}, answer=[Entity(start_offset=91, end_offset=94, type='context', text='man', normalized_text='man')], nq_answers=[[Entity(start_offset=300, end_offset=303, type='context', text='man', normalized_text='man')], [Entity(start_offset=91, end_offset=94, type='context', text='man', normalized_text='man')], [Entity(start_offset=6, end_offset=97, type='context', text=\"derived from the given name Gomes which is a loanword of the Visigothic word guma `` man ''\", normalized_text='derived from given name gomes which is loanword of visigothic word guma man')]], aligned_nps=[(Entity(start_offset=23, end_offset=37, type='question', text='the name gomez', normalized_text='name gomez'), Entity(start_offset=0, end_offset=2, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 7107516997642411919: QEDExample(example_id=7107516997642411919, title='Pi Day', question='how long have we been celebrating pi day', passage='Pi Day is an annual celebration of the mathematical constant π ( pi ) . Pi Day is observed on March 14 ( 3 / 14 in the month / day format ) since 3 , 1 , and 4 are the first three significant digits of π . In 2009 , the United States House of Representatives supported the designation of Pi Day .', sentence_starts=[0, 72, 206], selected_sent={'start': 206, 'end': 296, 'string': 'In 2009 , the United States House of Representatives supported the designation of Pi Day .'}, answer=[Entity(start_offset=209, end_offset=213, type='context', text='2009', normalized_text='2009')], nq_answers=[[Entity(start_offset=209, end_offset=213, type='context', text='2009', normalized_text='2009')]], aligned_nps=[(Entity(start_offset=34, end_offset=40, type='question', text='pi day', normalized_text='pi day'), Entity(start_offset=288, end_offset=294, type='context', text='Pi Day', normalized_text='pi day'))], explanation_type='single_sentence'),\n",
       " -6729136649709789995: QEDExample(example_id=-6729136649709789995, title='Holy See–European Union relations', question='who is allowed to be apart of the european union', passage=\"According to the EU 's Copenhagen criteria which define what states are eligible to join the EU , a candidate state must be a free market democracy . Given that the Holy See is a theocracy it does not meet the criteria . However , as it is so small , and surrounded by an EU state ( Italy ) , it is intrinsically linked to the EU . Vatican City has an open border with the EU and intends to join the Schengen Information System . It also uses the euro as its sole currency and has an agreement with the EU allowing them to mint their own coins . The EU gave Italy authority to negotiate a deal with the Holy See in 2000 which allowed the Holy See to mint a maximum of € 670,000 . After a review of the arrangements , a new agreement came into force in 2010 which allowed the Holy See to mint € 1 million a year ( plus up to an additional € 300,000 on special occasions ) .\", sentence_starts=[0, 150, 221, 332, 430, 546, 680], selected_sent={'start': 0, 'end': 150, 'string': \"According to the EU 's Copenhagen criteria which define what states are eligible to join the EU , a candidate state must be a free market democracy . \"}, answer=[Entity(start_offset=98, end_offset=147, type='context', text='a candidate state must be a free market democracy', normalized_text='candidate state must be free market democracy')], nq_answers=[[Entity(start_offset=98, end_offset=147, type='context', text='a candidate state must be a free market democracy', normalized_text='candidate state must be free market democracy')]], aligned_nps=[(Entity(start_offset=30, end_offset=48, type='question', text='the european union', normalized_text='european union'), Entity(start_offset=13, end_offset=19, type='context', text='the EU', normalized_text='eu'))], explanation_type='single_sentence'),\n",
       " 551385218565928061: QEDExample(example_id=551385218565928061, title='The Death of Superman', question='when does the new death of superman come out', passage='The story has been repeatedly adapted into various forms of media , including the novelization Superman : Doomsday & Beyond ( 1993 ) and the video game The Death and Return of Superman ( 1994 ) . An loose animated adaptation of the film , Superman : Doomsday , was released in 2007 and launched the DC Universe Animated Original Movies line . A second animated adaptation will be released as a two - part film in 2018 and 2019 and will be more faithful to the original story .', sentence_starts=[0, 196, 343], selected_sent={'start': 343, 'end': 476, 'string': 'A second animated adaptation will be released as a two - part film in 2018 and 2019 and will be more faithful to the original story .'}, answer=[Entity(start_offset=413, end_offset=426, type='context', text='2018 and 2019', normalized_text='2018 and 2019')], nq_answers=[[Entity(start_offset=413, end_offset=417, type='context', text='2018', normalized_text='2018'), Entity(start_offset=422, end_offset=426, type='context', text='2019', normalized_text='2019')], [Entity(start_offset=410, end_offset=426, type='context', text='in 2018 and 2019', normalized_text='in 2018 and 2019')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='the new death of superman', normalized_text='new death of superman'), Entity(start_offset=343, end_offset=371, type='context', text='A second animated adaptation', normalized_text='second animated adaptation'))], explanation_type='single_sentence'),\n",
       " 3929376598998928646: QEDExample(example_id=3929376598998928646, title='Kaiser Permanente', question='where did the name kaiser permanente come from', passage=\"In July , the Permanente Foundation formed to operate Northern California hospitals that would be linked to the outpatient health plans , followed shortly thereafter by the creation of Northern Permanente Foundation for Oregon and Washington and Southern Permanente Foundation for California . The name Permanente came from Permanente Creek , which flowed past Henry Kaiser 's first cement plant on Black Mountain in Cupertino , California . Kaiser 's first wife , Bess Fosburgh , liked the name . An abandoned Oakland facility was modernized as the 170 - bed Permanente Hospital opened on August 1 , 1942 . Three weeks later , the 71 - bed Richmond Field Hospital opened . Six first aid stations were set up in the shipyards to treat industrial accidents and minor illness . Each first aid station had an ambulance ready to rush patients to the surgical field hospital if required . Stabilized patients could be moved to the larger hospital for recuperative care . The Northern Permanente Hospital opened two weeks later to serve workers at the Kaiser shipyard in Vancouver , Washington . Shipyard workers paid seven cents per day for comprehensive health care coverage ; and within a year the shipyard health plan employed sixty physicians with salaries between $450 and $1,000 per month . These physicians established California Physicians Service to offer similar health coverage to the families of shipyard workers . In 1944 , Kaiser decided to continue the program after the war and to open it up to the general public .\", sentence_starts=[0, 294, 442, 498, 608, 674, 776, 884, 966, 1090, 1292, 1422], selected_sent={'start': 294, 'end': 442, 'string': \"The name Permanente came from Permanente Creek , which flowed past Henry Kaiser 's first cement plant on Black Mountain in Cupertino , California . \"}, answer=[Entity(start_offset=324, end_offset=395, type='context', text=\"Permanente Creek , which flowed past Henry Kaiser 's first cement plant\", normalized_text='permanente creek which flowed past henry kaiser s first cement plant')], nq_answers=[[Entity(start_offset=324, end_offset=439, type='context', text=\"Permanente Creek , which flowed past Henry Kaiser 's first cement plant on Black Mountain in Cupertino , California\", normalized_text='permanente creek which flowed past henry kaiser s first cement plant on black mountain in cupertino california')]], aligned_nps=[(Entity(start_offset=19, end_offset=36, type='question', text='kaiser permanente', normalized_text='kaiser permanente'), Entity(start_offset=294, end_offset=313, type='context', text='The name Permanente', normalized_text='name permanente'))], explanation_type='single_sentence'),\n",
       " -7504769624068905017: QEDExample(example_id=-7504769624068905017, title=\"Knockin' on Heaven's Door\", question='who wrote knock knock knocking on heavens door', passage=\"`` Knockin ' on Heaven 's Door '' is a song written and sung by Bob Dylan , for the soundtrack of the 1973 film Pat Garrett and Billy the Kid . Released as a single , it reached No. 12 on the Billboard Hot 100 singles chart . Described by Dylan biographer Clinton Heylin as `` an exercise in splendid simplicity '' , the song , in terms of the number of other artists who have covered it , is one of Dylan 's most popular post-1960s compositions .\", sentence_starts=[0, 144, 226], selected_sent={'start': 0, 'end': 144, 'string': \"`` Knockin ' on Heaven 's Door '' is a song written and sung by Bob Dylan , for the soundtrack of the 1973 film Pat Garrett and Billy the Kid . \"}, answer=[Entity(start_offset=64, end_offset=73, type='context', text='Bob Dylan', normalized_text='bob dylan')], nq_answers=[[Entity(start_offset=64, end_offset=73, type='context', text='Bob Dylan', normalized_text='bob dylan')]], aligned_nps=[(Entity(start_offset=10, end_offset=46, type='question', text='knock knock knocking on heavens door', normalized_text='knock knock knocking on heavens door'), Entity(start_offset=3, end_offset=30, type='context', text=\"Knockin ' on Heaven 's Door\", normalized_text='knockin on heaven s door'))], explanation_type='single_sentence'),\n",
       " 3046222823254798993: QEDExample(example_id=3046222823254798993, title='List of Gavin & Stacey characters', question=\"who plays stacey's mum in gavin and stacey\", passage=\"Gavin & Stacey is an award winning British television comedy series , following the lives of the title characters Gavin ( Mathew Horne ) and Stacey ( Joanna Page ) , who , before marrying , live on opposite sides of the country , Gavin in Billericay , Essex , and Stacey in Barry , Vale of Glamorgan . During the first two series Gavin lives with his parents Mick ( Larry Lamb ) and Pam ( Alison Steadman ) but in the third series he has moved , with Stacey , to Barry and lives with Stacey 's mum . He has a best friend Neil `` Smithy '' Smith ( James Corden ) . For most of the episodes Stacey lives in Barry with her mum Gwen ( Melanie Walters ) , with an extended family of Uncle Bryn ( Rob Brydon ) across the street , and best friend Vanessa Shanessa `` Nessa '' Jenkins ( Ruth Jones ) , but for a short while during series two she lived with Gavin , Pam and Mick in Essex .\", sentence_starts=[0, 302, 500, 564], selected_sent={'start': 564, 'end': 880, 'string': \"For most of the episodes Stacey lives in Barry with her mum Gwen ( Melanie Walters ) , with an extended family of Uncle Bryn ( Rob Brydon ) across the street , and best friend Vanessa Shanessa `` Nessa '' Jenkins ( Ruth Jones ) , but for a short while during series two she lived with Gavin , Pam and Mick in Essex .\"}, answer=[Entity(start_offset=631, end_offset=646, type='context', text='Melanie Walters', normalized_text='melanie walters')], nq_answers=[[Entity(start_offset=631, end_offset=646, type='context', text='Melanie Walters', normalized_text='melanie walters')]], aligned_nps=[(Entity(start_offset=10, end_offset=22, type='question', text=\"stacey's mum\", normalized_text='staceys mum'), Entity(start_offset=616, end_offset=628, type='context', text='her mum Gwen', normalized_text='her mum gwen')), (Entity(start_offset=26, end_offset=42, type='question', text='gavin and stacey', normalized_text='gavin and stacey'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 1172277683662974732: QEDExample(example_id=1172277683662974732, title='Hasta la vista, baby', question='where did hasta la vista baby come from', passage=\"`` Hasta la vista , baby '' is a catchphrase associated with Arnold Schwarzenegger 's title character from the 1991 science fiction thriller film Terminator 2 : Judgment Day .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 175, 'string': \"`` Hasta la vista , baby '' is a catchphrase associated with Arnold Schwarzenegger 's title character from the 1991 science fiction thriller film Terminator 2 : Judgment Day .\"}, answer=[Entity(start_offset=61, end_offset=173, type='context', text=\"Arnold Schwarzenegger 's title character from the 1991 science fiction thriller film Terminator 2 : Judgment Day\", normalized_text='arnold schwarzenegger s title character from 1991 science fiction thriller film terminator 2 judgment day')], nq_answers=[[Entity(start_offset=61, end_offset=173, type='context', text=\"Arnold Schwarzenegger 's title character from the 1991 science fiction thriller film Terminator 2 : Judgment Day\", normalized_text='arnold schwarzenegger s title character from 1991 science fiction thriller film terminator 2 judgment day')]], aligned_nps=[(Entity(start_offset=10, end_offset=29, type='question', text='hasta la vista baby', normalized_text='hasta la vista baby'), Entity(start_offset=3, end_offset=24, type='context', text='Hasta la vista , baby', normalized_text='hasta la vista baby'))], explanation_type='single_sentence'),\n",
       " -7657379080399040683: QEDExample(example_id=-7657379080399040683, title='Army–Navy Game', question='where is this years army navy game played', passage='Currently the game is played primarily at Lincoln Financial Field in Philadelphia , the home of the Philadelphia Eagles . Since the 1980s , the game has been held roughly once every three or four years at a site other than Philadelphia . In addition to the Rose Bowl , these sites have included Giants Stadium in East Rutherford , New Jersey ( replaced in 2010 by MetLife Stadium , which is scheduled to host the game for the first time in 2021 ) , M&T Bank Stadium in Baltimore and FedExField in Landover , Maryland . These are still considered neutral - site games , but provide locations that are closer to one academy or the other .', sentence_starts=[0, 122, 238, 519], selected_sent={'start': 0, 'end': 122, 'string': 'Currently the game is played primarily at Lincoln Financial Field in Philadelphia , the home of the Philadelphia Eagles . '}, answer=[Entity(start_offset=42, end_offset=81, type='context', text='Lincoln Financial Field in Philadelphia', normalized_text='lincoln financial field in philadelphia')], nq_answers=[[Entity(start_offset=42, end_offset=81, type='context', text='Lincoln Financial Field in Philadelphia', normalized_text='lincoln financial field in philadelphia')]], aligned_nps=[(Entity(start_offset=20, end_offset=34, type='question', text='army navy game', normalized_text='army navy game'), Entity(start_offset=10, end_offset=18, type='context', text='the game', normalized_text='game'))], explanation_type='single_sentence'),\n",
       " 6914041288553081723: QEDExample(example_id=6914041288553081723, title='Cold turkey', question='what is the origin of the phrase going cold turkey', passage=\"`` Cold turkey '' refers to the abrupt cessation of a substance dependence and the resulting unpleasant experience , as opposed to gradually easing the process through reduction over time or by using replacement medication . The term comes from the piloerection or `` goose bumps '' that occurs with abrupt withdrawal from opioids , which resembles the skin of a plucked refrigerated turkey .\", sentence_starts=[0, 225], selected_sent={'start': 225, 'end': 392, 'string': \"The term comes from the piloerection or `` goose bumps '' that occurs with abrupt withdrawal from opioids , which resembles the skin of a plucked refrigerated turkey .\"}, answer=[Entity(start_offset=245, end_offset=390, type='context', text=\"the piloerection or `` goose bumps '' that occurs with abrupt withdrawal from opioids , which resembles the skin of a plucked refrigerated turkey\", normalized_text='piloerection or goose bumps that occurs with abrupt withdrawal from opioids which resembles skin of plucked refrigerated turkey')], nq_answers=[[Entity(start_offset=245, end_offset=390, type='context', text=\"the piloerection or `` goose bumps '' that occurs with abrupt withdrawal from opioids , which resembles the skin of a plucked refrigerated turkey\", normalized_text='piloerection or goose bumps that occurs with abrupt withdrawal from opioids which resembles skin of plucked refrigerated turkey')]], aligned_nps=[(Entity(start_offset=22, end_offset=50, type='question', text='the phrase going cold turkey', normalized_text='phrase going cold turkey'), Entity(start_offset=225, end_offset=233, type='context', text='The term', normalized_text='term'))], explanation_type='single_sentence'),\n",
       " 4086158102790148091: QEDExample(example_id=4086158102790148091, title='I Just Want to Dance with You', question='who sings i want to dance with you', passage=\"`` I Just Want to Dance with You '' is a song written by John Prine and Roger Cook , and performed by American country music singer George Strait . It was released in April 1998 as the first single to his album , One Step at a Time , it is his 34th Number One single on the Billboard Hot Country Singles & Tracks ( now Hot Country Songs ) chart , and his 42nd Number One single when all major trade charts are counted . Prine recorded it 12 years earlier , for his 1986 album `` German Afternoons . ''\", sentence_starts=[0, 148, 420], selected_sent={'start': 0, 'end': 148, 'string': \"`` I Just Want to Dance with You '' is a song written by John Prine and Roger Cook , and performed by American country music singer George Strait . \"}, answer=[Entity(start_offset=132, end_offset=145, type='context', text='George Strait', normalized_text='george strait')], nq_answers=[[Entity(start_offset=132, end_offset=145, type='context', text='George Strait', normalized_text='george strait')], [Entity(start_offset=102, end_offset=145, type='context', text='American country music singer George Strait', normalized_text='american country music singer george strait')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text='i want to dance with you', normalized_text='i want to dance with you'), Entity(start_offset=3, end_offset=32, type='context', text='I Just Want to Dance with You', normalized_text='i just want to dance with you'))], explanation_type='single_sentence'),\n",
       " -1545150092700302635: QEDExample(example_id=-1545150092700302635, title='Nginx', question='what is nginx and what is it used for', passage='Nginx ( / ˌɛndʒɪnˈɛks / EN - jin - EKS ) ( stylized as NGINX , NGiИX or nginx ) is a web server which can also be used as a reverse proxy , load balancer and HTTP cache . The software was created by Igor Sysoev and first publicly released in 2004 . A company of the same name was founded in 2011 to provide support .', sentence_starts=[0, 171, 249], selected_sent={'start': 0, 'end': 171, 'string': 'Nginx ( / ˌɛndʒɪnˈɛks / EN - jin - EKS ) ( stylized as NGINX , NGiИX or nginx ) is a web server which can also be used as a reverse proxy , load balancer and HTTP cache . '}, answer=[Entity(start_offset=83, end_offset=168, type='context', text='a web server which can also be used as a reverse proxy , load balancer and HTTP cache', normalized_text='web server which can also be used as reverse proxy load balancer and http cache')], nq_answers=[[Entity(start_offset=83, end_offset=168, type='context', text='a web server which can also be used as a reverse proxy , load balancer and HTTP cache', normalized_text='web server which can also be used as reverse proxy load balancer and http cache')]], aligned_nps=[(Entity(start_offset=8, end_offset=13, type='question', text='nginx', normalized_text='nginx'), Entity(start_offset=0, end_offset=5, type='context', text='Nginx', normalized_text='nginx'))], explanation_type='single_sentence'),\n",
       " -4874966898403317469: QEDExample(example_id=-4874966898403317469, title='The dose makes the poison', question='who said the poison is in the dose', passage=\"`` The dose makes the poison '' ( Latin : sola dosis facit venenum ) is an adage intended to indicate a basic principle of toxicology . It is credited to Paracelsus who expressed the classic toxicology maxim `` All things are poison and nothing is without poison ; only the dose makes a thing not a poison . '' This is often condensed to : `` The dose makes the poison '' or in Latin , `` Sola dosis facit venenum '' . It means that a substance can produce the harmful effect associated with its toxic properties only if it reaches a susceptible biological system within the body in a high enough concentration ( i.e. , dose ) .\", sentence_starts=[0, 136, 311, 419], selected_sent={'start': 136, 'end': 311, 'string': \"It is credited to Paracelsus who expressed the classic toxicology maxim `` All things are poison and nothing is without poison ; only the dose makes a thing not a poison . '' \"}, answer=[Entity(start_offset=154, end_offset=164, type='context', text='Paracelsus', normalized_text='paracelsus')], nq_answers=[[Entity(start_offset=154, end_offset=164, type='context', text='Paracelsus', normalized_text='paracelsus')], [Entity(start_offset=142, end_offset=164, type='context', text='credited to Paracelsus', normalized_text='credited to paracelsus')]], aligned_nps=[(Entity(start_offset=9, end_offset=34, type='question', text='the poison is in the dose', normalized_text='poison is in dose'), Entity(start_offset=136, end_offset=138, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 1389150369608771478: QEDExample(example_id=1389150369608771478, title='Human skin', question='the outer layer of the skin that contains no blood or nerve supply is the', passage=\"The epidermis contains no blood vessels , and cells in the deepest layers are nourished almost exclusively by diffused oxygen from the surrounding air and to a far lesser degree by blood capillaries extending to the outer layers of the dermis . The main type of cells which make up the epidermis are Merkel cells , keratinocytes , with melanocytes and Langerhans cells also present . The epidermis can be further subdivided into the following strata ( beginning with the outermost layer ) : corneum , lucidum ( only in palms of hands and bottoms of feet ) , granulosum , spinosum , basale . Cells are formed through mitosis at the basale layer . The daughter cells ( see cell division ) move up the strata changing shape and composition as they die due to isolation from their blood source . The cytoplasm is released and the protein keratin is inserted . They eventually reach the corneum and slough off ( desquamation ) . This process is called `` keratinization '' . This keratinized layer of skin is responsible for keeping water in the body and keeping other harmful chemicals and pathogens out , making skin a natural barrier to infection .\", sentence_starts=[0, 245, 384, 591, 646, 792, 856, 924, 970], selected_sent={'start': 0, 'end': 245, 'string': 'The epidermis contains no blood vessels , and cells in the deepest layers are nourished almost exclusively by diffused oxygen from the surrounding air and to a far lesser degree by blood capillaries extending to the outer layers of the dermis . '}, answer=[Entity(start_offset=0, end_offset=13, type='context', text='The epidermis', normalized_text='epidermis')], nq_answers=[[Entity(start_offset=4, end_offset=13, type='context', text='epidermis', normalized_text='epidermis')]], aligned_nps=[(Entity(start_offset=19, end_offset=27, type='question', text='the skin', normalized_text='skin'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3371658713053301705: QEDExample(example_id=3371658713053301705, title='Seven Nation Army', question='what year did seven nation army come out', passage=\"`` Seven Nation Army '' ( also stylized as `` 7 Nation Army '' ) is a song by American rock duo the White Stripes . It was released as the lead single from their fourth studio album , Elephant , in March 2003 , and reached number one on the Alternative Songs chart -- maintaining that position for three weeks . It also became the third best - performing song of the decade on the same chart . It was well received commercially as well , and won the Grammy Award for Best Rock Song .\", sentence_starts=[0, 116, 312, 394], selected_sent={'start': 116, 'end': 312, 'string': 'It was released as the lead single from their fourth studio album , Elephant , in March 2003 , and reached number one on the Alternative Songs chart -- maintaining that position for three weeks . '}, answer=[Entity(start_offset=198, end_offset=208, type='context', text='March 2003', normalized_text='march 2003')], nq_answers=[[Entity(start_offset=198, end_offset=208, type='context', text='March 2003', normalized_text='march 2003')], [Entity(start_offset=204, end_offset=208, type='context', text='2003', normalized_text='2003')]], aligned_nps=[(Entity(start_offset=14, end_offset=31, type='question', text='seven nation army', normalized_text='seven nation army'), Entity(start_offset=116, end_offset=118, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6454311031309410150: QEDExample(example_id=6454311031309410150, title='Capital punishment in Canada', question='when did canada get rid of the death penalty', passage=\"Capital punishment in Canada dates back to Canada 's earliest history , including its period as a French colony and , after 1763 , its time as a British colony . From 1867 to the elimination of the death penalty for murder on July 14 , 1976 , 1,481 people had been sentenced to death , and 710 had been executed . Of those executed , 697 were men and 13 were women . The only method used in Canada for capital punishment of civilians after the end of the French regime was hanging . The last execution in Canada was the double hanging of Arthur Lucas and Ronald Turpin on December 11 , 1962 , at Toronto 's Don Jail .\", sentence_starts=[0, 162, 314, 367, 483], selected_sent={'start': 162, 'end': 314, 'string': 'From 1867 to the elimination of the death penalty for murder on July 14 , 1976 , 1,481 people had been sentenced to death , and 710 had been executed . '}, answer=[Entity(start_offset=226, end_offset=240, type='context', text='July 14 , 1976', normalized_text='july 14 1976')], nq_answers=[[Entity(start_offset=226, end_offset=240, type='context', text='July 14 , 1976', normalized_text='july 14 1976')]], aligned_nps=[(Entity(start_offset=9, end_offset=15, type='question', text='canada', normalized_text='canada'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3248410603422198181: QEDExample(example_id=3248410603422198181, title='Carnegie Hall', question='who conducted the opening concert at carnegie hall', passage=\"Carnegie Hall is named after Andrew Carnegie , who funded its construction . It was intended as a venue for the Oratorio Society of New York and the New York Symphony Society , on whose boards Carnegie served . Construction began in 1890 , and was carried out by Isaac A. Hopper and Company . Although the building was in use from April 1891 , the official opening night was May 5 , with a concert conducted by maestro Walter Damrosch and great Russian composer Pyotr Ilyich Tchaikovsky . Originally known simply as `` Music Hall '' ( the words `` Music Hall founded by Andrew Carnegie '' still appear on the façade above the marquee ) , the hall was renamed Carnegie Hall in 1893 after board members of the Music Hall Company of New York ( the hall 's original governing body ) persuaded Carnegie to allow the use of his name . Several alterations were made to the building between 1893 and 1896 , including the addition of two towers of artists ' studios , and alterations to the smaller auditorium on the building 's lower level .\", sentence_starts=[0, 77, 211, 293, 489, 829], selected_sent={'start': 293, 'end': 489, 'string': 'Although the building was in use from April 1891 , the official opening night was May 5 , with a concert conducted by maestro Walter Damrosch and great Russian composer Pyotr Ilyich Tchaikovsky . '}, answer=[Entity(start_offset=411, end_offset=486, type='context', text='maestro Walter Damrosch and great Russian composer Pyotr Ilyich Tchaikovsky', normalized_text='maestro walter damrosch and great russian composer pyotr ilyich tchaikovsky')], nq_answers=[[Entity(start_offset=411, end_offset=486, type='context', text='maestro Walter Damrosch and great Russian composer Pyotr Ilyich Tchaikovsky', normalized_text='maestro walter damrosch and great russian composer pyotr ilyich tchaikovsky')], [Entity(start_offset=419, end_offset=434, type='context', text='Walter Damrosch', normalized_text='walter damrosch'), Entity(start_offset=462, end_offset=486, type='context', text='Pyotr Ilyich Tchaikovsky', normalized_text='pyotr ilyich tchaikovsky')], [Entity(start_offset=411, end_offset=434, type='context', text='maestro Walter Damrosch', normalized_text='maestro walter damrosch')]], aligned_nps=[(Entity(start_offset=14, end_offset=50, type='question', text='the opening concert at carnegie hall', normalized_text='opening concert at carnegie hall'), Entity(start_offset=388, end_offset=397, type='context', text='a concert', normalized_text='concert'))], explanation_type='single_sentence'),\n",
       " 1180829738254891996: QEDExample(example_id=1180829738254891996, title='Currency Act', question='who was involved in the currency act of 1764', passage='The Currency Act of 1764 ( 4 Geo . III c. 34 ) extended the 1751 Act to all of the British colonies of North America . Unlike the earlier Act , this statute did not prohibit the colonies from issuing paper money , but it did forbid them from designating future currency emissions as legal tender for public and private debts . This tight money policy created financial difficulties in the colonies , where gold and silver were in short supply . Benjamin Franklin , a colonial agent in London , lobbied for repeal of the Act over the next several years , as did other agents . The act arose when Virginia farmers continued to import during the French and Indian War . Virginia issued 250,000 pounds in bills of credit to finance both public and private debts . This legislation differed from the 1751 act in that it prohibited the colonists from designating paper currency for use as payment for any debts , public or private . Parliament did not , however , prohibit the colonists from issuing paper money . The Act was put into place as a hedge against risks associated with economic fluctuations and uncertainty .', sentence_starts=[0, 35, 119, 327, 445, 576, 667, 760, 927, 1008], selected_sent={'start': 0, 'end': 119, 'string': 'The Currency Act of 1764 ( 4 Geo . III c. 34 ) extended the 1751 Act to all of the British colonies of North America . '}, answer=[Entity(start_offset=72, end_offset=116, type='context', text='all of the British colonies of North America', normalized_text='all of british colonies of north america')], nq_answers=[[Entity(start_offset=72, end_offset=116, type='context', text='all of the British colonies of North America', normalized_text='all of british colonies of north america')]], aligned_nps=[(Entity(start_offset=20, end_offset=44, type='question', text='the currency act of 1764', normalized_text='currency act of 1764'), Entity(start_offset=0, end_offset=24, type='context', text='The Currency Act of 1764', normalized_text='currency act of 1764'))], explanation_type='single_sentence'),\n",
       " 1174522695577165411: QEDExample(example_id=1174522695577165411, title='The Fool on the Hill', question='what is the meaning of the song fool on the hill', passage=\"The song 's lyrics describe the titular `` fool '' , a solitary figure who is not understood by others , but is actually wise . McCartney said the song relates to someone like Maharishi Mahesh Yogi :\", sentence_starts=[0, 128], selected_sent={'start': 0, 'end': 128, 'string': \"The song 's lyrics describe the titular `` fool '' , a solitary figure who is not understood by others , but is actually wise . \"}, answer=[Entity(start_offset=53, end_offset=125, type='context', text='a solitary figure who is not understood by others , but is actually wise', normalized_text='solitary figure who is not understood by others but is actually wise')], nq_answers=[[Entity(start_offset=53, end_offset=125, type='context', text='a solitary figure who is not understood by others , but is actually wise', normalized_text='solitary figure who is not understood by others but is actually wise')]], aligned_nps=[(Entity(start_offset=23, end_offset=48, type='question', text='the song fool on the hill', normalized_text='song fool on hill'), Entity(start_offset=0, end_offset=8, type='context', text='The song', normalized_text='song'))], explanation_type='single_sentence'),\n",
       " 3374568953386327339: QEDExample(example_id=3374568953386327339, title='Islamia College University', question='who laid foundation stone of islamia college peshawar', passage=\"Haji Sahib of Turangzai , the most famous Pukhtun religious leader of the time was requested by Nawab Sir Sahibzada Abdul Qayyum to lay the foundation stone of Islamia College . Haji Sahib agreed to the request , however , he had been declared a proclaimed offender by the British for his anti-British activities and his entry was banned into British controlled territory . He was residing in tribal territory , which was outside British control , so Nawab Sahib prevailed upon Sir George Roos - Keppel and the British to permit Haji Sahib to enter British controlled territory for one day so he could lay the foundation stone of Islamia College . The British agreed to this request with the understanding that Haji Sahib would return to tribal territory once he had laid the foundation stone . Haji Sahib was permitted to enter British controlled territory for the ceremony and spent the night in the ' Pokh ' Mosque of Tehkal . At the foundation stone laying ceremony , Sir Roos Keppel and other British officials were present , so Haji Sahib hid his face in his sheet ( Chadar ) from them and was led by Sheikh Muhammad Ibrahim to the place where he was to lay the foundation stone . After laying the stone Haji Sahib went to Tehkal and then returned to the tribal territory .\", sentence_starts=[0, 178, 374, 648, 795, 930, 1187], selected_sent={'start': 930, 'end': 1187, 'string': 'At the foundation stone laying ceremony , Sir Roos Keppel and other British officials were present , so Haji Sahib hid his face in his sheet ( Chadar ) from them and was led by Sheikh Muhammad Ibrahim to the place where he was to lay the foundation stone . '}, answer=[Entity(start_offset=0, end_offset=78, type='context', text='Haji Sahib of Turangzai , the most famous Pukhtun religious leader of the time', normalized_text='haji sahib of turangzai most famous pukhtun religious leader of time')], nq_answers=[[Entity(start_offset=0, end_offset=78, type='context', text='Haji Sahib of Turangzai , the most famous Pukhtun religious leader of the time', normalized_text='haji sahib of turangzai most famous pukhtun religious leader of time')], [Entity(start_offset=0, end_offset=23, type='context', text='Haji Sahib of Turangzai', normalized_text='haji sahib of turangzai')], [Entity(start_offset=1210, end_offset=1220, type='context', text='Haji Sahib', normalized_text='haji sahib')]], aligned_nps=[(Entity(start_offset=9, end_offset=53, type='question', text='foundation stone of islamia college peshawar', normalized_text='foundation stone of islamia college peshawar'), Entity(start_offset=1164, end_offset=1184, type='context', text='the foundation stone', normalized_text='foundation stone'))], explanation_type='single_sentence'),\n",
       " -7761868052579751930: QEDExample(example_id=-7761868052579751930, title='Thorin Oakenshield', question='who became king of erebor after thorin dies', passage=\"When Thorin died , he was buried with the Arkenstone , and Orcrist was returned and laid upon his tomb . The blade would glow blue should Orcs approach , and they could thus not take the Mountain by surprise . Thorin was succeeded as leader of Durin 's Folk by his cousin Dáin .\", sentence_starts=[0, 105, 210], selected_sent={'start': 210, 'end': 278, 'string': \"Thorin was succeeded as leader of Durin 's Folk by his cousin Dáin .\"}, answer=[Entity(start_offset=261, end_offset=276, type='context', text='his cousin Dáin', normalized_text='his cousin dáin')], nq_answers=[[Entity(start_offset=272, end_offset=276, type='context', text='Dáin', normalized_text='dáin')], [Entity(start_offset=261, end_offset=276, type='context', text='his cousin Dáin', normalized_text='his cousin dáin')]], aligned_nps=[(Entity(start_offset=32, end_offset=38, type='question', text='thorin', normalized_text='thorin'), Entity(start_offset=210, end_offset=216, type='context', text='Thorin', normalized_text='thorin'))], explanation_type='single_sentence'),\n",
       " -8432751606955067146: QEDExample(example_id=-8432751606955067146, title='Acid rain', question='rain sleet or snow that contains a high concentration of acids is called', passage='Acid rain is a rain or any other form of precipitation that is unusually acidic , meaning that it has elevated levels of hydrogen ions ( low pH ) . It can have harmful effects on plants , aquatic animals and infrastructure . Acid rain is caused by emissions of sulfur dioxide and nitrogen oxide , which react with the water molecules in the atmosphere to produce acids . Some governments have made efforts since the 1970s to reduce the release of sulfur dioxide and nitrogen oxide into the atmosphere with positive results . Nitrogen oxides can also be produced naturally by lightning strikes , and sulfur dioxide is produced by volcanic eruptions . Acid rain has been shown to have adverse impacts on forests , freshwaters and soils , killing insect and aquatic life - forms , causing paint to peel , corrosion of steel structures such as bridges , and weathering of stone buildings and statues as well as having impacts on human health .', sentence_starts=[0, 148, 225, 371, 525, 650], selected_sent={'start': 0, 'end': 148, 'string': 'Acid rain is a rain or any other form of precipitation that is unusually acidic , meaning that it has elevated levels of hydrogen ions ( low pH ) . '}, answer=[Entity(start_offset=0, end_offset=9, type='context', text='Acid rain', normalized_text='acid rain')], nq_answers=[[Entity(start_offset=0, end_offset=9, type='context', text='Acid rain', normalized_text='acid rain')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 6911525668586993309: QEDExample(example_id=6911525668586993309, title='Jack Skellington', question='who plays jack skellington in nightmare before christmas', passage=\"Jack Skellington is a character and the main protagonist of the 1993 film The Nightmare Before Christmas . Jack is the `` Pumpkin King '' of Halloween Town , a fantasy world based solely on the Halloween holiday . Jack is voiced by Chris Sarandon . Danny Elfman provided Jack 's singing voice in the film , although Sarandon has sung as Jack in subsequent productions .\", sentence_starts=[0, 107, 214, 249], selected_sent={'start': 214, 'end': 249, 'string': 'Jack is voiced by Chris Sarandon . '}, answer=[Entity(start_offset=232, end_offset=246, type='context', text='Chris Sarandon', normalized_text='chris sarandon')], nq_answers=[[Entity(start_offset=232, end_offset=246, type='context', text='Chris Sarandon', normalized_text='chris sarandon')], [Entity(start_offset=232, end_offset=246, type='context', text='Chris Sarandon', normalized_text='chris sarandon'), Entity(start_offset=249, end_offset=261, type='context', text='Danny Elfman', normalized_text='danny elfman')]], aligned_nps=[(Entity(start_offset=10, end_offset=26, type='question', text='jack skellington', normalized_text='jack skellington'), Entity(start_offset=214, end_offset=218, type='context', text='Jack', normalized_text='jack')), (Entity(start_offset=30, end_offset=56, type='question', text='nightmare before christmas', normalized_text='nightmare before christmas'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3667525092654016134: QEDExample(example_id=3667525092654016134, title='StarLink corn recall', question='what is the main issue behind starlink corn', passage='The StarLink corn recalls occurred in the autumn of 2000 , when over 300 food products were found to contain a genetically modified corn that had not been approved for human consumption . It was the first - ever recall of a genetically modified food . The anti-GMO activist coalition Genetically Engineered Food Alert , which detected and first reported the contamination , was critical of the FDA for not doing its job . The recall of Taco Bell - branded taco shells , manufactured by Kraft Foods and sold in supermarkets , was the most publicized of the recalls . One settlement resulted in $60 million going to Taco Bell franchisees for lost sales due to the damage to the Taco Bell brand .', sentence_starts=[0, 188, 252, 422, 566], selected_sent={'start': 0, 'end': 188, 'string': 'The StarLink corn recalls occurred in the autumn of 2000 , when over 300 food products were found to contain a genetically modified corn that had not been approved for human consumption . '}, answer=[Entity(start_offset=64, end_offset=185, type='context', text='over 300 food products were found to contain a genetically modified corn that had not been approved for human consumption', normalized_text='over 300 food products were found to contain genetically modified corn that had not been approved for human consumption')], nq_answers=[[Entity(start_offset=64, end_offset=185, type='context', text='over 300 food products were found to contain a genetically modified corn that had not been approved for human consumption', normalized_text='over 300 food products were found to contain genetically modified corn that had not been approved for human consumption')]], aligned_nps=[(Entity(start_offset=30, end_offset=43, type='question', text='starlink corn', normalized_text='starlink corn'), Entity(start_offset=4, end_offset=17, type='context', text='StarLink corn', normalized_text='starlink corn'))], explanation_type='single_sentence'),\n",
       " -1732734622903151644: QEDExample(example_id=-1732734622903151644, title='The House of the Rising Sun', question='oldest recording of house of the rising sun', passage=\"The oldest known recording of the song , under the title `` Rising Sun Blues '' , is by Appalachian artists Clarence `` Tom '' Ashley and Gwen Foster , who recorded it for Vocalion Records on September 6 , 1933 . Ashley said he had learned it from his grandfather , Enoch Ashley . Roy Acuff , an `` early - day friend and apprentice '' of Ashley 's , learned it from him and recorded it as `` Rising Sun '' on November 3 , 1938 . Several older blues recordings of songs with similar titles are unrelated , for example , `` Rising Sun Blues '' by Ivy Smith ( 1927 ) and `` The Risin ' Sun '' by Texas Alexander ( 1928 ) .\", sentence_starts=[0, 213, 281, 430], selected_sent={'start': 0, 'end': 213, 'string': \"The oldest known recording of the song , under the title `` Rising Sun Blues '' , is by Appalachian artists Clarence `` Tom '' Ashley and Gwen Foster , who recorded it for Vocalion Records on September 6 , 1933 . \"}, answer=[Entity(start_offset=88, end_offset=149, type='context', text=\"Appalachian artists Clarence `` Tom '' Ashley and Gwen Foster\", normalized_text='appalachian artists clarence tom ashley and gwen foster')], nq_answers=[[Entity(start_offset=85, end_offset=210, type='context', text=\"by Appalachian artists Clarence `` Tom '' Ashley and Gwen Foster , who recorded it for Vocalion Records on September 6 , 1933\", normalized_text='by appalachian artists clarence tom ashley and gwen foster who recorded it for vocalion records on september 6 1933')], [Entity(start_offset=41, end_offset=210, type='context', text=\"under the title `` Rising Sun Blues '' , is by Appalachian artists Clarence `` Tom '' Ashley and Gwen Foster , who recorded it for Vocalion Records on September 6 , 1933\", normalized_text='under title rising sun blues is by appalachian artists clarence tom ashley and gwen foster who recorded it for vocalion records on september 6 1933')]], aligned_nps=[(Entity(start_offset=0, end_offset=43, type='question', text='oldest recording of house of the rising sun', normalized_text='oldest recording of house of rising sun'), Entity(start_offset=0, end_offset=38, type='context', text='The oldest known recording of the song', normalized_text='oldest known recording of song'))], explanation_type='single_sentence'),\n",
       " 246927435436425337: QEDExample(example_id=246927435436425337, title='Around the World in Eighty Days', question='what is the story of around the world in 80 days', passage=\"Around the World in Eighty Days ( French : Le tour du monde en quatre - vingts jours ) is a classic adventure novel by the French writer Jules Verne , published in 1873 . In the story , Phileas Fogg of London and his newly employed French valet Passepartout attempt to circumnavigate the world in 80 days on a £ 20,000 wager ( £ 2,075,400 in 2017 ) set by his friends at the Reform Club . It is one of Verne 's most acclaimed works .\", sentence_starts=[0, 171, 389], selected_sent={'start': 171, 'end': 389, 'string': 'In the story , Phileas Fogg of London and his newly employed French valet Passepartout attempt to circumnavigate the world in 80 days on a £ 20,000 wager ( £ 2,075,400 in 2017 ) set by his friends at the Reform Club . '}, answer=[Entity(start_offset=186, end_offset=386, type='context', text='Phileas Fogg of London and his newly employed French valet Passepartout attempt to circumnavigate the world in 80 days on a £ 20,000 wager ( £ 2,075,400 in 2017 ) set by his friends at the Reform Club', normalized_text='phileas fogg of london and his newly employed french valet passepartout attempt to circumnavigate world in 80 days on £ 20000 wager £ 2075400 in 2017 set by his friends at reform club')], nq_answers=[[Entity(start_offset=186, end_offset=386, type='context', text='Phileas Fogg of London and his newly employed French valet Passepartout attempt to circumnavigate the world in 80 days on a £ 20,000 wager ( £ 2,075,400 in 2017 ) set by his friends at the Reform Club', normalized_text='phileas fogg of london and his newly employed french valet passepartout attempt to circumnavigate world in 80 days on £ 20000 wager £ 2075400 in 2017 set by his friends at reform club')]], aligned_nps=[(Entity(start_offset=8, end_offset=48, type='question', text='the story of around the world in 80 days', normalized_text='story of around world in 80 days'), Entity(start_offset=174, end_offset=183, type='context', text='the story', normalized_text='story'))], explanation_type='single_sentence'),\n",
       " -1106714590515566575: QEDExample(example_id=-1106714590515566575, title='Grand Inquisitor', question='who was the head of the spanish inquisition', passage='Grand Inquisitor ( Latin : Inquisitor Generalis , literally Inquisitor General or General Inquisitor ) was the lead official of the Inquisition . The title usually refers to the chief inquisitor of the Spanish Inquisition , even after the reunification of the inquisitions . Secretaries - general of the Roman Inquisition were often styled as Grand Inquisitor but the role and functions were different .', sentence_starts=[0, 146, 275], selected_sent={'start': 0, 'end': 146, 'string': 'Grand Inquisitor ( Latin : Inquisitor Generalis , literally Inquisitor General or General Inquisitor ) was the lead official of the Inquisition . '}, answer=[Entity(start_offset=0, end_offset=16, type='context', text='Grand Inquisitor', normalized_text='grand inquisitor')], nq_answers=[[Entity(start_offset=0, end_offset=16, type='context', text='Grand Inquisitor', normalized_text='grand inquisitor')]], aligned_nps=[(Entity(start_offset=8, end_offset=43, type='question', text='the head of the spanish inquisition', normalized_text='head of spanish inquisition'), Entity(start_offset=107, end_offset=143, type='context', text='the lead official of the Inquisition', normalized_text='lead official of inquisition'))], explanation_type='single_sentence'),\n",
       " -529657106587628938: QEDExample(example_id=-529657106587628938, title='Work function', question='what is a work function of a metal', passage=\"In solid - state physics , the work function ( sometimes spelled workfunction ) is the minimum thermodynamic work ( i.e. energy ) needed to remove an electron from a solid to a point in the vacuum immediately outside the solid surface . Here `` immediately '' means that the final electron position is far from the surface on the atomic scale , but still too close to the solid to be influenced by ambient electric fields in the vacuum . The work function is not a characteristic of a bulk material , but rather a property of the surface of the material ( depending on crystal face and contamination ) .\", sentence_starts=[0, 237, 438], selected_sent={'start': 0, 'end': 237, 'string': 'In solid - state physics , the work function ( sometimes spelled workfunction ) is the minimum thermodynamic work ( i.e. energy ) needed to remove an electron from a solid to a point in the vacuum immediately outside the solid surface . '}, answer=[Entity(start_offset=83, end_offset=234, type='context', text='the minimum thermodynamic work ( i.e. energy ) needed to remove an electron from a solid to a point in the vacuum immediately outside the solid surface', normalized_text='minimum thermodynamic work ie energy needed to remove electron from solid to point in vacuum immediately outside solid surface')], nq_answers=[[Entity(start_offset=83, end_offset=234, type='context', text='the minimum thermodynamic work ( i.e. energy ) needed to remove an electron from a solid to a point in the vacuum immediately outside the solid surface', normalized_text='minimum thermodynamic work ie energy needed to remove electron from solid to point in vacuum immediately outside solid surface')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 7937545581647887851: QEDExample(example_id=7937545581647887851, title='Make It or Break It', question='make it or break it who goes to the olympics', passage=\"Season Three opens with Payson , Lauren , and Kaylie heading to the American Olympic Training Center as they prepare for the 2012 London Olympics . They deal with a new coach and teammates , including upcoming gymnasts . Max and Payson have a relationship through letters ; on the first day Payson receives a letter in which Max breaks up with her because he 's confused . Later Payson , Lauren , Kaylie , and Austin are having a conversation based around the breakup and Austin admits to the group that Max was bisexual and that they shared a kiss on the night of the party which leaves all three girls stunned . An uninvited gymnast , Jordan Randall , convinces Coach MacIntire to let her train with the group , causing tension . Coach Mac pairs up the girls , forcing Kaylie to live and work with Kelly Parker and Lauren to work with Payson . They eventually become close friends . Kelly is not good enough for the Olympics and leaves gymnastics . Payson has a new romance with Rigo ( Tom Maden ) . Payson finds out that Lauren has an irregular heart beat , but Lauren has heart surgery . Austin does not make the Olympic Team and blames Kaylie . Jordan reveals that a former coach , Coach Keagan , molested her when she was young . Desperate to ensure her spot on the team , Wendy drugs Kaylie with a cold medicine containing a banned substance . After Austin and Kaylie reunite , then Lauren , Payson , and Jordan tell the NGO that they are boycotting Olympic tryouts unless Kaylie is allowed to perform . Lauren discovers the secret Wendy has been hiding and exposes her , getting Wendy kicked out . The season three finale culminates with the five girls , Payson , Lauren , Kaylie , plus Jordan , and finally Colleen , being chosen to represent the U.S. in the Olympics .\", sentence_starts=[0, 148, 221, 373, 614, 732, 846, 885, 951, 1002, 1092, 1150, 1236, 1351, 1511, 1606], selected_sent={'start': 1606, 'end': 1778, 'string': 'The season three finale culminates with the five girls , Payson , Lauren , Kaylie , plus Jordan , and finally Colleen , being chosen to represent the U.S. in the Olympics .'}, answer=[Entity(start_offset=1646, end_offset=1723, type='context', text='the five girls , Payson , Lauren , Kaylie , plus Jordan , and finally Colleen', normalized_text='five girls payson lauren kaylie plus jordan and finally colleen')], nq_answers=[[Entity(start_offset=1663, end_offset=1669, type='context', text='Payson', normalized_text='payson'), Entity(start_offset=1672, end_offset=1678, type='context', text='Lauren', normalized_text='lauren'), Entity(start_offset=1681, end_offset=1687, type='context', text='Kaylie', normalized_text='kaylie'), Entity(start_offset=1695, end_offset=1701, type='context', text='Jordan', normalized_text='jordan'), Entity(start_offset=1716, end_offset=1723, type='context', text='Colleen', normalized_text='colleen')]], aligned_nps=[(Entity(start_offset=32, end_offset=44, type='question', text='the olympics', normalized_text='olympics'), Entity(start_offset=1764, end_offset=1776, type='context', text='the Olympics', normalized_text='olympics')), (Entity(start_offset=0, end_offset=19, type='question', text='make it or break it', normalized_text='make it or break it'), Entity(start_offset=1606, end_offset=1629, type='context', text='The season three finale', normalized_text='season three finale'))], explanation_type='single_sentence'),\n",
       " 4375682753291546963: QEDExample(example_id=4375682753291546963, title='Error (baseball)', question='does reaching base on an error count as an at bat', passage=\"An error does not count as a hit but still counts as an at bat for the batter unless , in the scorer 's judgment , the batter would have reached first base safely but one or more of the additional base ( s ) reached was the result of the fielder 's mistake . In that case , the play will be scored both as a hit ( for the number of bases the fielders should have limited the batter to ) and an error . However , if a batter is judged to have reached base solely because of a fielder 's mistake , it is scored as a `` hit on error , '' and treated the same as if the batter had been put out , hence lowering his batting average .\", sentence_starts=[0, 259, 402], selected_sent={'start': 0, 'end': 259, 'string': \"An error does not count as a hit but still counts as an at bat for the batter unless , in the scorer 's judgment , the batter would have reached first base safely but one or more of the additional base ( s ) reached was the result of the fielder 's mistake . \"}, answer=[Entity(start_offset=43, end_offset=256, type='context', text=\"counts as an at bat for the batter unless , in the scorer 's judgment , the batter would have reached first base safely but one or more of the additional base ( s ) reached was the result of the fielder 's mistake\", normalized_text='counts as at bat for batter unless in scorer s judgment batter would have reached first base safely but one or more of additional base s reached was result of fielder s mistake')], nq_answers=[[Entity(start_offset=43, end_offset=256, type='context', text=\"counts as an at bat for the batter unless , in the scorer 's judgment , the batter would have reached first base safely but one or more of the additional base ( s ) reached was the result of the fielder 's mistake\", normalized_text='counts as at bat for batter unless in scorer s judgment batter would have reached first base safely but one or more of additional base s reached was result of fielder s mistake')]], aligned_nps=[(Entity(start_offset=22, end_offset=30, type='question', text='an error', normalized_text='error'), Entity(start_offset=0, end_offset=8, type='context', text='An error', normalized_text='error'))], explanation_type='single_sentence'),\n",
       " 1491405245207392860: QEDExample(example_id=1491405245207392860, title='Green Revolution', question='what was the primary goal of the first green revolution', passage=\"It has been argued that `` during the twentieth century two ' revolutions ' transformed rural Mexico : the Mexican Revolution ( 1910 -- 1920 ) and the Green Revolution ( 1950 -- 1970 ) '' . With the support of the Mexican government , the U.S. government , the United Nations , the Food and Agriculture Organization ( FAO ) , and the Rockefeller Foundation , Mexico made a concerted effort to transform agricultural productivity , particularly with irrigated rather than dry - land cultivation in its northwest , to solve its problem of lack of food self - sufficiency . In the center and south of Mexico , where large - scale production faced challenges , agricultural production languished . Increased production meant food self - sufficiency in Mexico to feed its growing and urbanizing population , with the number of calories consumed per Mexican increasing . Technology was seen as a valuable way to feed the poor , and would relieve some pressure of the land redistribution process .\", sentence_starts=[0, 190, 571, 694, 865], selected_sent={'start': 190, 'end': 571, 'string': 'With the support of the Mexican government , the U.S. government , the United Nations , the Food and Agriculture Organization ( FAO ) , and the Rockefeller Foundation , Mexico made a concerted effort to transform agricultural productivity , particularly with irrigated rather than dry - land cultivation in its northwest , to solve its problem of lack of food self - sufficiency . '}, answer=[Entity(start_offset=359, end_offset=568, type='context', text='Mexico made a concerted effort to transform agricultural productivity , particularly with irrigated rather than dry - land cultivation in its northwest , to solve its problem of lack of food self - sufficiency', normalized_text='mexico made concerted effort to transform agricultural productivity particularly with irrigated rather than dry land cultivation in its northwest to solve its problem of lack of food self sufficiency')], nq_answers=[[Entity(start_offset=888, end_offset=988, type='context', text='a valuable way to feed the poor , and would relieve some pressure of the land redistribution process', normalized_text='valuable way to feed poor and would relieve some pressure of land redistribution process')]], aligned_nps=[(Entity(start_offset=29, end_offset=55, type='question', text='the first green revolution', normalized_text='first green revolution'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -704529031648349308: QEDExample(example_id=-704529031648349308, title='Kate Mulgrew', question='who plays red on orange is new black', passage=\"Katherine Kiernan Maria `` Kate '' Mulgrew ( born April 29 , 1955 ) is an American actress . She is known for the roles of Captain Kathryn Janeway on Star Trek : Voyager and Galina `` Red '' Reznikov on Orange Is the New Black . She first came to attention in the role of Mary Ryan on the daytime soap opera Ryan 's Hope . Mulgrew has won an Obie Award , and has received a Golden Globe Award and Primetime Emmy Award nomination . She is an active member of the Alzheimer 's Association National Advisory Council and the voice of Cleveland 's MetroHealth System .\", sentence_starts=[0, 93, 229, 323, 431], selected_sent={'start': 93, 'end': 229, 'string': \"She is known for the roles of Captain Kathryn Janeway on Star Trek : Voyager and Galina `` Red '' Reznikov on Orange Is the New Black . \"}, answer=[Entity(start_offset=0, end_offset=42, type='context', text=\"Katherine Kiernan Maria `` Kate '' Mulgrew\", normalized_text='katherine kiernan maria kate mulgrew')], nq_answers=[[Entity(start_offset=0, end_offset=42, type='context', text=\"Katherine Kiernan Maria `` Kate '' Mulgrew\", normalized_text='katherine kiernan maria kate mulgrew')], [Entity(start_offset=24, end_offset=42, type='context', text=\"`` Kate '' Mulgrew\", normalized_text='kate mulgrew')]], aligned_nps=[(Entity(start_offset=10, end_offset=13, type='question', text='red', normalized_text='red'), Entity(start_offset=174, end_offset=199, type='context', text=\"Galina `` Red '' Reznikov\", normalized_text='galina red reznikov')), (Entity(start_offset=17, end_offset=36, type='question', text='orange is new black', normalized_text='orange is new black'), Entity(start_offset=203, end_offset=226, type='context', text='Orange Is the New Black', normalized_text='orange is new black'))], explanation_type='single_sentence'),\n",
       " 7525433307945555136: QEDExample(example_id=7525433307945555136, title='I Am Number Four (film)', question='where was the movie i am number 4 filmed', passage=\"Principal photography began on May 17 , 2010 , using 20 locations all within the Pittsburgh metropolitan area . DreamWorks selected the area primarily due to tax incentives from the Pennsylvania Film Production Tax Credit . The film studio also had a positive experience shooting She 's Out of My League in Pittsburgh in 2008 . The production was scheduled to last 12 to 13 weeks .\", sentence_starts=[0, 112, 224, 328], selected_sent={'start': 0, 'end': 112, 'string': 'Principal photography began on May 17 , 2010 , using 20 locations all within the Pittsburgh metropolitan area . '}, answer=[Entity(start_offset=53, end_offset=109, type='context', text='20 locations all within the Pittsburgh metropolitan area', normalized_text='20 locations all within pittsburgh metropolitan area')], nq_answers=[[Entity(start_offset=53, end_offset=109, type='context', text='20 locations all within the Pittsburgh metropolitan area', normalized_text='20 locations all within pittsburgh metropolitan area')], [Entity(start_offset=77, end_offset=109, type='context', text='the Pittsburgh metropolitan area', normalized_text='pittsburgh metropolitan area')]], aligned_nps=[(Entity(start_offset=10, end_offset=33, type='question', text='the movie i am number 4', normalized_text='movie i am number 4'), Entity(start_offset=0, end_offset=21, type='context', text='Principal photography', normalized_text='principal photography'))], explanation_type='single_sentence'),\n",
       " 3337415792007864057: QEDExample(example_id=3337415792007864057, title='Pulmonary circulation', question='where does blood go when it leaves the pulmonary artery', passage='From the right ventricle , blood is pumped through the semilunar pulmonary valve into the left and right main pulmonary arteries ( one for each lung ) , which branch into smaller pulmonary arteries that spread throughout the lungs .', sentence_starts=[0], selected_sent={'start': 0, 'end': 232, 'string': 'From the right ventricle , blood is pumped through the semilunar pulmonary valve into the left and right main pulmonary arteries ( one for each lung ) , which branch into smaller pulmonary arteries that spread throughout the lungs .'}, answer=[Entity(start_offset=166, end_offset=230, type='context', text='into smaller pulmonary arteries that spread throughout the lungs', normalized_text='into smaller pulmonary arteries that spread throughout lungs')], nq_answers=[[Entity(start_offset=166, end_offset=230, type='context', text='into smaller pulmonary arteries that spread throughout the lungs', normalized_text='into smaller pulmonary arteries that spread throughout lungs')]], aligned_nps=[(Entity(start_offset=11, end_offset=16, type='question', text='blood', normalized_text='blood'), Entity(start_offset=27, end_offset=32, type='context', text='blood', normalized_text='blood'))], explanation_type='single_sentence'),\n",
       " -4622532030074150432: QEDExample(example_id=-4622532030074150432, title='United States House of Representatives', question='what is the title of the person who runs the house of representatives', passage='The presiding officer is the Speaker of the House , who is elected by the members thereof and is therefore traditionally the leader of the controlling party . He or she and other floor leaders are chosen by the Democratic Caucus or the Republican Conference , depending on whichever party has more voting members . The House meets in the south wing of the United States Capitol .', sentence_starts=[0, 159, 315], selected_sent={'start': 0, 'end': 159, 'string': 'The presiding officer is the Speaker of the House , who is elected by the members thereof and is therefore traditionally the leader of the controlling party . '}, answer=[Entity(start_offset=25, end_offset=49, type='context', text='the Speaker of the House', normalized_text='speaker of house')], nq_answers=[[Entity(start_offset=29, end_offset=49, type='context', text='Speaker of the House', normalized_text='speaker of house')], [Entity(start_offset=25, end_offset=49, type='context', text='the Speaker of the House', normalized_text='speaker of house')]], aligned_nps=[(Entity(start_offset=21, end_offset=69, type='question', text='the person who runs the house of representatives', normalized_text='person who runs house of representatives'), Entity(start_offset=0, end_offset=21, type='context', text='The presiding officer', normalized_text='presiding officer'))], explanation_type='single_sentence'),\n",
       " 275718753854271176: QEDExample(example_id=275718753854271176, title='Finance Secretary', question='who has been designed as the new finance secretary of india', passage='Hasmukh Adhia is the present finance secretary of India .', sentence_starts=[0], selected_sent={'start': 0, 'end': 57, 'string': 'Hasmukh Adhia is the present finance secretary of India .'}, answer=[Entity(start_offset=0, end_offset=13, type='context', text='Hasmukh Adhia', normalized_text='hasmukh adhia')], nq_answers=[[Entity(start_offset=0, end_offset=13, type='context', text='Hasmukh Adhia', normalized_text='hasmukh adhia')]], aligned_nps=[(Entity(start_offset=25, end_offset=59, type='question', text='the new finance secretary of india', normalized_text='new finance secretary of india'), Entity(start_offset=17, end_offset=55, type='context', text='the present finance secretary of India', normalized_text='present finance secretary of india'))], explanation_type='single_sentence'),\n",
       " -6966959898445658330: QEDExample(example_id=-6966959898445658330, title='NFL Kickoff Game', question='who plays the first nfl game of the season', passage='The National Football League Kickoff game , along with related festivities , marks the official start of the National Football League ( NFL ) regular season . A single game is held , preceded by a concert and other ceremonies . This first game of the season is usually scheduled for the Thursday following Labor Day and since 2004 , it was hosted by the most recent Super Bowl champions . However , in 2012 , the game was moved to Wednesday to prevent conflicts with the acceptance speech of the Democratic National Convention . The remainder of the league plays their opening weekend games the following Sunday and Monday .', sentence_starts=[0, 159, 228, 389, 529], selected_sent={'start': 228, 'end': 389, 'string': 'This first game of the season is usually scheduled for the Thursday following Labor Day and since 2004 , it was hosted by the most recent Super Bowl champions . '}, answer=[Entity(start_offset=350, end_offset=386, type='context', text='the most recent Super Bowl champions', normalized_text='most recent super bowl champions')], nq_answers=[[Entity(start_offset=350, end_offset=386, type='context', text='the most recent Super Bowl champions', normalized_text='most recent super bowl champions')]], aligned_nps=[(Entity(start_offset=10, end_offset=42, type='question', text='the first nfl game of the season', normalized_text='first nfl game of season'), Entity(start_offset=228, end_offset=257, type='context', text='This first game of the season', normalized_text='this first game of season'))], explanation_type='single_sentence'),\n",
       " -6112660378083609841: QEDExample(example_id=-6112660378083609841, title='List of French cheeses', question='how many types of cheese are produced in france', passage=\"This is a list of cheeses from France . Traditionally , there are from 350 to 450 distinct types of French cheese grouped into eight categories ' les huit familles de fromage ' . There can be many varieties within each type of cheese , leading some to claim closer to 1,000 different types of French cheese .\", sentence_starts=[0, 40, 179], selected_sent={'start': 40, 'end': 179, 'string': \"Traditionally , there are from 350 to 450 distinct types of French cheese grouped into eight categories ' les huit familles de fromage ' . \"}, answer=[Entity(start_offset=66, end_offset=96, type='context', text='from 350 to 450 distinct types', normalized_text='from 350 to 450 distinct types')], nq_answers=[[Entity(start_offset=66, end_offset=96, type='context', text='from 350 to 450 distinct types', normalized_text='from 350 to 450 distinct types')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -7226074159102484517: QEDExample(example_id=-7226074159102484517, title='The Goonies', question='where was the last scene of goonies filmed', passage=\"Some of the on - location filming was done in Astoria , Oregon . The interior and exterior of the old Clatsop County Jail features as the holding place of Jake Fratelli at the start of the film . ( The building was later converted into the Oregon Film Museum , which opened on the 25th anniversary of The Goonies with memorabilia from this and other local films . ) The museum where Mikey 's father works is , in reality , the Captain George Flavel House Museum . The Walsh family home is a real home on the eastern end of the town . The scenes along the coast were filmed in Oregon , but they were a considerable distance from Astoria . The Goonies bicycle to Ecola State Park ( in reality , over 26 miles south of Astoria ) and then find the starting location of the map using Haystack Rock as a guide . Underground scenes were filmed at Warner Bros. Studios in Burbank , California , including the cavernous set where the Goonies find One - Eyed Willy 's ship , which was in Stage 16 , one of the largest sound stages in America . The final scene was shot at Goat Rock State Beach in Sonoma County , California .\", sentence_starts=[0, 65, 196, 366, 464, 534, 638, 806, 1034], selected_sent={'start': 1034, 'end': 1115, 'string': 'The final scene was shot at Goat Rock State Beach in Sonoma County , California .'}, answer=[Entity(start_offset=1062, end_offset=1113, type='context', text='Goat Rock State Beach in Sonoma County , California', normalized_text='goat rock state beach in sonoma county california')], nq_answers=[[Entity(start_offset=1062, end_offset=1113, type='context', text='Goat Rock State Beach in Sonoma County , California', normalized_text='goat rock state beach in sonoma county california')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='the last scene of goonies', normalized_text='last scene of goonies'), Entity(start_offset=1034, end_offset=1049, type='context', text='The final scene', normalized_text='final scene'))], explanation_type='single_sentence'),\n",
       " 3555567859880958432: QEDExample(example_id=3555567859880958432, title='CLS Group', question='cls bank deals with transactions arising out of', passage='CLS ( originally Continuous Linked Settlement ) is a specialist US financial institution that provides settlement services to its members in the foreign exchange market ( FX ) . Although the forex market is decentralised and has no central exchange or clearing facility , firms that chose to use CLS to settle their FX transactions can mitigate the settlement risk associated with their trades .', sentence_starts=[0, 178], selected_sent={'start': 0, 'end': 178, 'string': 'CLS ( originally Continuous Linked Settlement ) is a specialist US financial institution that provides settlement services to its members in the foreign exchange market ( FX ) . '}, answer=[Entity(start_offset=141, end_offset=168, type='context', text='the foreign exchange market', normalized_text='foreign exchange market')], nq_answers=[[Entity(start_offset=141, end_offset=168, type='context', text='the foreign exchange market', normalized_text='foreign exchange market')], [Entity(start_offset=145, end_offset=168, type='context', text='foreign exchange market', normalized_text='foreign exchange market')], [Entity(start_offset=141, end_offset=175, type='context', text='the foreign exchange market ( FX )', normalized_text='foreign exchange market fx')]], aligned_nps=[(Entity(start_offset=0, end_offset=8, type='question', text='cls bank', normalized_text='cls bank'), Entity(start_offset=0, end_offset=3, type='context', text='CLS', normalized_text='cls'))], explanation_type='single_sentence'),\n",
       " -7416755475743802921: QEDExample(example_id=-7416755475743802921, title='Ratification', question='who is in charge of ratifying treaties in the us', passage=\"Treaty power is a co-ordinated effort between the Executive branch and the Senate . The President may form and negotiate , but the treaty must be advised and consented to by a two - thirds vote in the Senate . Only after the Senate approves the treaty can the President ratify it . Once it is ratified , it becomes binding on all the states under the Supremacy Clause . While the House of Representatives does not vote on it at all , the requirement for the Senate 's advice and consent to ratification makes it considerably more difficult to rally enough political support for international treaties . Also , if implementation of the treaty requires the expenditure of funds , the House of Representatives may be able to block or at least impede such implementation by refusing to vote for the appropriation of the necessary funds .\", sentence_starts=[0, 84, 210, 282, 370, 603], selected_sent={'start': 210, 'end': 282, 'string': 'Only after the Senate approves the treaty can the President ratify it . '}, answer=[Entity(start_offset=256, end_offset=269, type='context', text='the President', normalized_text='president')], nq_answers=[[Entity(start_offset=256, end_offset=269, type='context', text='the President', normalized_text='president')], [Entity(start_offset=46, end_offset=66, type='context', text='the Executive branch', normalized_text='executive branch'), Entity(start_offset=71, end_offset=81, type='context', text='the Senate', normalized_text='senate')], [Entity(start_offset=201, end_offset=207, type='context', text='Senate', normalized_text='senate')], [Entity(start_offset=197, end_offset=207, type='context', text='the Senate', normalized_text='senate'), Entity(start_offset=256, end_offset=269, type='context', text='the President', normalized_text='president')]], aligned_nps=[(Entity(start_offset=42, end_offset=48, type='question', text='the us', normalized_text='us'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -1582234629547061501: QEDExample(example_id=-1582234629547061501, title='Tami Lynn', question=\"who sang i'm gonna run away from you\", passage=\"Tami Lynn ( born 1942 , Gert Town , New Orleans , Louisiana , United States ) is an American soul singer . She scored a Top Ten hit on the UK Singles Chart in 1971 , with the song `` I 'm Gonna Run Away From You '' .\", sentence_starts=[0, 107], selected_sent={'start': 107, 'end': 216, 'string': \"She scored a Top Ten hit on the UK Singles Chart in 1971 , with the song `` I 'm Gonna Run Away From You '' .\"}, answer=[Entity(start_offset=0, end_offset=9, type='context', text='Tami Lynn', normalized_text='tami lynn')], nq_answers=[[Entity(start_offset=0, end_offset=9, type='context', text='Tami Lynn', normalized_text='tami lynn')]], aligned_nps=[(Entity(start_offset=9, end_offset=36, type='question', text=\"i'm gonna run away from you\", normalized_text='im gonna run away from you'), Entity(start_offset=183, end_offset=211, type='context', text=\"I 'm Gonna Run Away From You\", normalized_text='i m gonna run away from you'))], explanation_type='single_sentence'),\n",
       " 6507459087595991641: QEDExample(example_id=6507459087595991641, title='Black Mass (film)', question=\"who plays whitey bulger's girlfriend in black mass\", passage=\"On June 9 , Depp 's 51st birthday , he was filming scenes on location in Quincy , where actress Dakota Johnson was in Back Bay , playing Whitey Bulger 's longtime former girlfriend , Lindsey Cyr . On June 11 , shooting was underway in Lynn , where the crew was filming scenes in which Bulger and Stephen Flemmi pick up a prostitute named Deborah Hussey ( played by Juno Temple ) from the police station . Temple was seen on the set . On June 16 , Depp and Plemons were spotted on the set of the film in South Boston .\", sentence_starts=[0, 197, 405, 434], selected_sent={'start': 0, 'end': 197, 'string': \"On June 9 , Depp 's 51st birthday , he was filming scenes on location in Quincy , where actress Dakota Johnson was in Back Bay , playing Whitey Bulger 's longtime former girlfriend , Lindsey Cyr . \"}, answer=[Entity(start_offset=96, end_offset=110, type='context', text='Dakota Johnson', normalized_text='dakota johnson')], nq_answers=[[Entity(start_offset=88, end_offset=110, type='context', text='actress Dakota Johnson', normalized_text='actress dakota johnson')], [Entity(start_offset=96, end_offset=110, type='context', text='Dakota Johnson', normalized_text='dakota johnson')]], aligned_nps=[(Entity(start_offset=10, end_offset=36, type='question', text=\"whitey bulger's girlfriend\", normalized_text='whitey bulgers girlfriend'), Entity(start_offset=137, end_offset=194, type='context', text=\"Whitey Bulger 's longtime former girlfriend , Lindsey Cyr\", normalized_text='whitey bulger s longtime former girlfriend lindsey cyr')), (Entity(start_offset=40, end_offset=50, type='question', text='black mass', normalized_text='black mass'), Entity(start_offset=51, end_offset=57, type='context', text='scenes', normalized_text='scenes'))], explanation_type='single_sentence'),\n",
       " 7647339054759303922: QEDExample(example_id=7647339054759303922, title='ΔF508', question='what dna changes produce the delta f508 mutation', passage='ΔF508 ( Delta - F508 , full name CFTRΔF508 or F508del - CFTR ; rs113993960 ) is a specific mutation within the gene for a protein called the cystic fibrosis transmembrane conductance regulator ( CFTR ) . The mutation is a deletion of three nucleotides spanning positions 507 and 508 of the CFTR gene on chromosome 7 , which ultimately results in the loss of a single codon for the amino acid phenylalanine ( F ) . A person with the CFTRΔF508 mutation will produce an abnormal CFTR protein that lacks this phenylalanine residue and which can not fold properly . This protein does not escape the endoplasmic reticulum for further processing . Having two copies of this mutation ( one inherited from each parent ) is by far the most common cause of cystic fibrosis ( CF ) , responsible for nearly two - thirds of cases worldwide .', sentence_starts=[0, 204, 414, 561, 641], selected_sent={'start': 204, 'end': 414, 'string': 'The mutation is a deletion of three nucleotides spanning positions 507 and 508 of the CFTR gene on chromosome 7 , which ultimately results in the loss of a single codon for the amino acid phenylalanine ( F ) . '}, answer=[Entity(start_offset=220, end_offset=315, type='context', text='a deletion of three nucleotides spanning positions 507 and 508 of the CFTR gene on chromosome 7', normalized_text='deletion of three nucleotides spanning positions 507 and 508 of cftr gene on chromosome 7')], nq_answers=[[Entity(start_offset=222, end_offset=315, type='context', text='deletion of three nucleotides spanning positions 507 and 508 of the CFTR gene on chromosome 7', normalized_text='deletion of three nucleotides spanning positions 507 and 508 of cftr gene on chromosome 7')], [Entity(start_offset=222, end_offset=411, type='context', text='deletion of three nucleotides spanning positions 507 and 508 of the CFTR gene on chromosome 7 , which ultimately results in the loss of a single codon for the amino acid phenylalanine ( F )', normalized_text='deletion of three nucleotides spanning positions 507 and 508 of cftr gene on chromosome 7 which ultimately results in loss of single codon for amino acid phenylalanine f')]], aligned_nps=[(Entity(start_offset=25, end_offset=48, type='question', text='the delta f508 mutation', normalized_text='delta f508 mutation'), Entity(start_offset=204, end_offset=216, type='context', text='The mutation', normalized_text='mutation'))], explanation_type='single_sentence'),\n",
       " 848669583015546693: QEDExample(example_id=848669583015546693, title='Fluid compartments', question='what are the two extracellular fluid compartments in the body', passage=\"About two thirds of the total body water of humans is held in the cells , mostly in the cytosol , and the remainder is found in the extracellular compartment . The extracellular fluids may be divided into three types : interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals ) , blood plasma and lymph in the `` intravascular compartment '' ( inside the blood vessels and lymphatic vessels ) , and small amounts of transcellular fluid such as ocular and cerebrospinal fluids in the `` transcellular compartment '' . The interstitial and intravascular compartments readily exchange water and solutes but the third extracellular compartment , the transcellular , is thought of as separate from the other two and not in dynamic equilibrium with them .\", sentence_starts=[0, 160, 608], selected_sent={'start': 608, 'end': 840, 'string': 'The interstitial and intravascular compartments readily exchange water and solutes but the third extracellular compartment , the transcellular , is thought of as separate from the other two and not in dynamic equilibrium with them .'}, answer=[Entity(start_offset=608, end_offset=655, type='context', text='The interstitial and intravascular compartments', normalized_text='interstitial and intravascular compartments'), Entity(start_offset=733, end_offset=750, type='context', text='the transcellular', normalized_text='transcellular')], nq_answers=[[Entity(start_offset=219, end_offset=275, type='context', text=\"interstitial fluid in the `` interstitial compartment ''\", normalized_text='interstitial fluid in interstitial compartment'), Entity(start_offset=371, end_offset=432, type='context', text=\"blood plasma and lymph in the `` intravascular compartment ''\", normalized_text='blood plasma and lymph in intravascular compartment'), Entity(start_offset=490, end_offset=605, type='context', text=\"small amounts of transcellular fluid such as ocular and cerebrospinal fluids in the `` transcellular compartment ''\", normalized_text='small amounts of transcellular fluid such as ocular and cerebrospinal fluids in transcellular compartment')]], aligned_nps=[(Entity(start_offset=53, end_offset=61, type='question', text='the body', normalized_text='body'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -4461484002255201500: QEDExample(example_id=-4461484002255201500, title='A White Sport Coat', question='who sang the song a white sports coat and a pink carnation', passage=\"`` A White Sport Coat ( and a Pink Carnation ) '' is a 1957 country and western song with words and music both written by Marty Robbins . It was recorded on January 25 , 1957 , and released on the Columbia Records label , over a month later , on March 4 . The arranger and recording session conductor was Ray Conniff , an in - house conductor / arranger at Columbia . Robbins had demanded to have Conniff oversee the recording after his earlier hit , `` Singing the Blues '' , had been quickly eclipsed on the charts by Guy Mitchell 's cover version scored and conducted by Conniff in October , 1956 .\", sentence_starts=[0, 138, 256, 368], selected_sent={'start': 138, 'end': 256, 'string': 'It was recorded on January 25 , 1957 , and released on the Columbia Records label , over a month later , on March 4 . '}, answer=[Entity(start_offset=122, end_offset=135, type='context', text='Marty Robbins', normalized_text='marty robbins')], nq_answers=[[Entity(start_offset=122, end_offset=135, type='context', text='Marty Robbins', normalized_text='marty robbins')]], aligned_nps=[(Entity(start_offset=18, end_offset=58, type='question', text='a white sports coat and a pink carnation', normalized_text='white sports coat and pink carnation'), Entity(start_offset=138, end_offset=140, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -4966275942482530330: QEDExample(example_id=-4966275942482530330, title='Seafloor spreading', question='where does new crust come from in sea floor spreading', passage='Seafloor spreading is a process that occurs at mid-ocean ridges , where new oceanic crust is formed through volcanic activity and then gradually moves away from the ridge . Seafloor spreading helps explain continental drift in the theory of plate tectonics . When oceanic plates diverge , tensional stress causes fractures to occur in the lithosphere. The motivating force for seafloor spreading ridges is tectonic plate pull rather than magma pressure , although there is typically significant magma activity at spreading ridges . At a spreading center basaltic magma rises up the fractures and cools on the ocean floor to form new seabed . Hydrothermal vents are common at spreading centers . Older rocks will be found farther away from the spreading zone while younger rocks will be found nearer to the spreading zone . Additionally spreading rates determine if the ridge is a fast , intermediate , or slow . As a general rule , fast ridges see spreading rate of more than 9 cm / year . Intermediate ridges have a spreading rate of 4 -- 9 cm / year while slow spreading ridges have a rate less than 4 cm / year .', sentence_starts=[0, 173, 259, 532, 642, 695, 823, 912, 990], selected_sent={'start': 0, 'end': 173, 'string': 'Seafloor spreading is a process that occurs at mid-ocean ridges , where new oceanic crust is formed through volcanic activity and then gradually moves away from the ridge . '}, answer=[Entity(start_offset=108, end_offset=125, type='context', text='volcanic activity', normalized_text='volcanic activity')], nq_answers=[[Entity(start_offset=108, end_offset=125, type='context', text='volcanic activity', normalized_text='volcanic activity')], [Entity(start_offset=554, end_offset=568, type='context', text='basaltic magma', normalized_text='basaltic magma')]], aligned_nps=[(Entity(start_offset=34, end_offset=53, type='question', text='sea floor spreading', normalized_text='sea floor spreading'), Entity(start_offset=0, end_offset=18, type='context', text='Seafloor spreading', normalized_text='seafloor spreading')), (Entity(start_offset=11, end_offset=20, type='question', text='new crust', normalized_text='new crust'), Entity(start_offset=72, end_offset=89, type='context', text='new oceanic crust', normalized_text='new oceanic crust'))], explanation_type='single_sentence'),\n",
       " 7640959384571480586: QEDExample(example_id=7640959384571480586, title='Disneyland Paris', question='how much did disneyland paris cost to build', passage=\"Michael Eisner , Disney 's CEO at the time , signed the first letter of agreement with the French government for the 20 - square - kilometre ( 4,940 - acre ) site on 18 December 1985 , and the first financial contracts were drawn up during the following spring . The final contract was signed by the leaders of the Walt Disney Company and the French government and territorial collectivities on 24 March 1987 . Construction began in August 1988 , and in December 1990 , an information centre named `` Espace Euro Disney '' was opened to show the public what was being constructed . Plans for a theme park next to Euro Disneyland based on the entertainment industry , Disney - MGM Studios Europe , quickly went into development , scheduled to open in 1996 with a construction budget of US $2.3 billion . The construction manager was Bovis .\", sentence_starts=[0, 263, 411, 582, 803], selected_sent={'start': 582, 'end': 803, 'string': 'Plans for a theme park next to Euro Disneyland based on the entertainment industry , Disney - MGM Studios Europe , quickly went into development , scheduled to open in 1996 with a construction budget of US $2.3 billion . '}, answer=[Entity(start_offset=760, end_offset=800, type='context', text='a construction budget of US $2.3 billion', normalized_text='construction budget of us 23 billion')], nq_answers=[[Entity(start_offset=760, end_offset=800, type='context', text='a construction budget of US $2.3 billion', normalized_text='construction budget of us 23 billion')]], aligned_nps=[(Entity(start_offset=13, end_offset=29, type='question', text='disneyland paris', normalized_text='disneyland paris'), Entity(start_offset=592, end_offset=604, type='context', text='a theme park', normalized_text='theme park'))], explanation_type='single_sentence'),\n",
       " -2440461470906841040: QEDExample(example_id=-2440461470906841040, title='Matthew Lillard', question='who played shaggy in the new scooby doo movie', passage='Matthew Lyn Lillard ( born January 24 , 1970 ) is an American actor , voice actor , director , and producer . He is best known for portraying Chip in Serial Mom ( 1994 ) , Stu in Scream ( 1996 ) , Stevo in SLC Punk ! ( 1998 ) , Jerry Conlaine in Without a Paddle ( 2004 ) and Shaggy Rogers in both Scooby - Doo ( 2002 ) and Scooby - Doo 2 : Monsters Unleashed ( 2004 ) . In animation , he has been the current voice of Shaggy since veteran actor Casey Kasem retired from the role .', sentence_starts=[0, 110, 217, 371], selected_sent={'start': 110, 'end': 371, 'string': 'He is best known for portraying Chip in Serial Mom ( 1994 ) , Stu in Scream ( 1996 ) , Stevo in SLC Punk ! ( 1998 ) , Jerry Conlaine in Without a Paddle ( 2004 ) and Shaggy Rogers in both Scooby - Doo ( 2002 ) and Scooby - Doo 2 : Monsters Unleashed ( 2004 ) . '}, answer=[Entity(start_offset=0, end_offset=19, type='context', text='Matthew Lyn Lillard', normalized_text='matthew lyn lillard')], nq_answers=[[Entity(start_offset=0, end_offset=19, type='context', text='Matthew Lyn Lillard', normalized_text='matthew lyn lillard')]], aligned_nps=[(Entity(start_offset=11, end_offset=17, type='question', text='shaggy', normalized_text='shaggy'), Entity(start_offset=276, end_offset=289, type='context', text='Shaggy Rogers', normalized_text='shaggy rogers')), (Entity(start_offset=21, end_offset=45, type='question', text='the new scooby doo movie', normalized_text='new scooby doo movie'), Entity(start_offset=324, end_offset=368, type='context', text='Scooby - Doo 2 : Monsters Unleashed ( 2004 )', normalized_text='scooby doo 2 monsters unleashed 2004'))], explanation_type='single_sentence'),\n",
       " -3568942573258999273: QEDExample(example_id=-3568942573258999273, title='Financial management', question='what is the ultimate objective of financial management', passage=\"Financial management refers to the efficient and effective management of money ( funds ) in such a manner as to accomplish the objectives of the organization . It is the specialized function directly associated with the top management . The significance of this function is not seen in the ' Line ' but also in the capacity of the ' Staff ' in overall of a company . It has been defined differently by different experts in the field .\", sentence_starts=[0, 160, 237, 367], selected_sent={'start': 0, 'end': 160, 'string': 'Financial management refers to the efficient and effective management of money ( funds ) in such a manner as to accomplish the objectives of the organization . '}, answer=[Entity(start_offset=123, end_offset=157, type='context', text='the objectives of the organization', normalized_text='objectives of organization')], nq_answers=[[Entity(start_offset=112, end_offset=157, type='context', text='accomplish the objectives of the organization', normalized_text='accomplish objectives of organization')]], aligned_nps=[(Entity(start_offset=34, end_offset=54, type='question', text='financial management', normalized_text='financial management'), Entity(start_offset=0, end_offset=20, type='context', text='Financial management', normalized_text='financial management'))], explanation_type='single_sentence'),\n",
       " 179878424839453416: QEDExample(example_id=179878424839453416, title='List of European Cup and UEFA Champions League finals', question='how many times have real madrid won the champions league in a row', passage='A total of 22 clubs have won the Champions League / European Cup . Real Madrid hold the record for the most victories , having won the competition 12 times , including the inaugural competition . They have also won the competition the most times in a row , winning it five times from 1956 to 1960 . Juventus have been runners - up the most times , losing seven finals . Atlético Madrid is the only team to reach three finals without having won the trophy while Stade de Reims and Valencia have finished as runners - up twice without winning . Spain has provided the most champions , with 17 wins from two clubs . Italy have produced 12 winners from three clubs and England have produced 12 winners from five clubs . English teams were banned from the competition for five years following the Heysel disaster in 1985 . The current champions are Real Madrid , who beat Juventus in the 2017 final .', sentence_starts=[0, 67, 196, 299, 370, 543, 613, 716, 818], selected_sent={'start': 196, 'end': 299, 'string': 'They have also won the competition the most times in a row , winning it five times from 1956 to 1960 . '}, answer=[Entity(start_offset=268, end_offset=272, type='context', text='five', normalized_text='five')], nq_answers=[[Entity(start_offset=268, end_offset=272, type='context', text='five', normalized_text='five')], [Entity(start_offset=268, end_offset=278, type='context', text='five times', normalized_text='five times')]], aligned_nps=[(Entity(start_offset=20, end_offset=31, type='question', text='real madrid', normalized_text='real madrid'), Entity(start_offset=196, end_offset=200, type='context', text='They', normalized_text='they')), (Entity(start_offset=36, end_offset=56, type='question', text='the champions league', normalized_text='champions league'), Entity(start_offset=215, end_offset=230, type='context', text='the competition', normalized_text='competition'))], explanation_type='single_sentence'),\n",
       " 1560261279486353160: QEDExample(example_id=1560261279486353160, title=\"Cashier's check\", question='where do you get a cashiers check from', passage=\"A cashier 's check or cheque is a cheque guaranteed by a bank , drawn on the bank 's own funds and signed by a cashier . Cashier 's checks are treated as guaranteed funds because the bank , rather than the purchaser , is responsible for paying the amount . They are commonly required for real estate and brokerage transactions .\", sentence_starts=[0, 121, 257], selected_sent={'start': 0, 'end': 121, 'string': \"A cashier 's check or cheque is a cheque guaranteed by a bank , drawn on the bank 's own funds and signed by a cashier . \"}, answer=[Entity(start_offset=55, end_offset=61, type='context', text='a bank', normalized_text='bank')], nq_answers=[[Entity(start_offset=55, end_offset=61, type='context', text='a bank', normalized_text='bank')], [Entity(start_offset=57, end_offset=61, type='context', text='bank', normalized_text='bank')], [Entity(start_offset=41, end_offset=118, type='context', text=\"guaranteed by a bank , drawn on the bank 's own funds and signed by a cashier\", normalized_text='guaranteed by bank drawn on bank s own funds and signed by cashier')]], aligned_nps=[(Entity(start_offset=17, end_offset=33, type='question', text='a cashiers check', normalized_text='cashiers check'), Entity(start_offset=0, end_offset=28, type='context', text=\"A cashier 's check or cheque\", normalized_text='cashier s check or cheque'))], explanation_type='single_sentence'),\n",
       " 8519168409080529801: QEDExample(example_id=8519168409080529801, title='Rick and Morty', question='what state does rick and morty take place in', passage=\"The show revolves around the adventures of the members of the Smith household , which consists of parents Jerry and Beth , their kids Summer and Morty , and Beth 's father , Rick Sanchez , who lives with them as a guest . According to Justin Roiland , the family lives outside of Seattle in the U.S. state of Washington . The adventures of Rick and Morty , however , take place across an infinite number of realities , with the characters travelling to other planets and dimensions through portals and Rick 's flying car .\", sentence_starts=[0, 222, 322], selected_sent={'start': 222, 'end': 322, 'string': 'According to Justin Roiland , the family lives outside of Seattle in the U.S. state of Washington . '}, answer=[Entity(start_offset=309, end_offset=319, type='context', text='Washington', normalized_text='washington')], nq_answers=[[Entity(start_offset=309, end_offset=319, type='context', text='Washington', normalized_text='washington')], [Entity(start_offset=291, end_offset=319, type='context', text='the U.S. state of Washington', normalized_text='us state of washington')]], aligned_nps=[(Entity(start_offset=16, end_offset=30, type='question', text='rick and morty', normalized_text='rick and morty'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -1535821556179322605: QEDExample(example_id=-1535821556179322605, title='Jumping the shark', question='where does the phrase jumping the shark come from', passage='Popularized by radio personality Jon Hein in the 1990s and early 2000s , the phrase derives from a scene in a fifth - season episode of the sitcom Happy Days in which the character Fonzie jumps over a shark while on water - skis . This was deemed a ratings ploy , for it was outside the original thrust of the sitcom .', sentence_starts=[0, 231], selected_sent={'start': 0, 'end': 231, 'string': 'Popularized by radio personality Jon Hein in the 1990s and early 2000s , the phrase derives from a scene in a fifth - season episode of the sitcom Happy Days in which the character Fonzie jumps over a shark while on water - skis . '}, answer=[Entity(start_offset=92, end_offset=228, type='context', text='from a scene in a fifth - season episode of the sitcom Happy Days in which the character Fonzie jumps over a shark while on water - skis', normalized_text='from scene in fifth season episode of sitcom happy days in which character fonzie jumps over shark while on water skis')], nq_answers=[[Entity(start_offset=97, end_offset=228, type='context', text='a scene in a fifth - season episode of the sitcom Happy Days in which the character Fonzie jumps over a shark while on water - skis', normalized_text='scene in fifth season episode of sitcom happy days in which character fonzie jumps over shark while on water skis')]], aligned_nps=[(Entity(start_offset=11, end_offset=39, type='question', text='the phrase jumping the shark', normalized_text='phrase jumping shark'), Entity(start_offset=73, end_offset=83, type='context', text='the phrase', normalized_text='phrase'))], explanation_type='single_sentence'),\n",
       " 1608609734415271187: QEDExample(example_id=1608609734415271187, title='FaZe Clan', question='who has the most subscribers in faze clan', passage=\"The FaZe Clan began its existence through YouTube in 2010 . FaZe started as a clan that would perform trick shots in Call of Duty and post clips and montages on YouTube . As the members ' personalities and audience preferences changed , so did the video content . The FaZe YouTubers -- including FaZe Banks , FaZe Apex , FaZe Blaze , FaZe Rug , FaZe Adapt , FaZe Censor , and FaZe Rain -- started to vlog and do creative skits to further develop their channels . Although the FaZe YouTubers are the more famous FaZe Clan members , they do not compete in any competitive gaming for FaZe . These YouTubers strictly make YouTube videos in order to extend the FaZe Clan brand and entertain their fans . Currently , each major FaZe member has over 1 million subscribers on YouTube , with some having between three and five million subscribers . The official FaZe Clan YouTube channel has 4.8 million subscribers , while FaZe Rug has the most subscribers out of all the FaZe Members with 8 million subscribers .\", sentence_starts=[0, 60, 171, 264, 463, 588, 699, 840], selected_sent={'start': 840, 'end': 1005, 'string': 'The official FaZe Clan YouTube channel has 4.8 million subscribers , while FaZe Rug has the most subscribers out of all the FaZe Members with 8 million subscribers .'}, answer=[Entity(start_offset=915, end_offset=923, type='context', text='FaZe Rug', normalized_text='faze rug')], nq_answers=[[Entity(start_offset=915, end_offset=923, type='context', text='FaZe Rug', normalized_text='faze rug')]], aligned_nps=[(Entity(start_offset=32, end_offset=41, type='question', text='faze clan', normalized_text='faze clan'), Entity(start_offset=853, end_offset=862, type='context', text='FaZe Clan', normalized_text='faze clan'))], explanation_type='single_sentence'),\n",
       " -8779917413777030409: QEDExample(example_id=-8779917413777030409, title=\"Don't Worry, Be Happy\", question='who was in dont worry be happy video', passage='The comedic original music video for the song stars McFerrin , Robin Williams , and Bill Irwin , and is somewhat shorter than the album version .', sentence_starts=[0], selected_sent={'start': 0, 'end': 145, 'string': 'The comedic original music video for the song stars McFerrin , Robin Williams , and Bill Irwin , and is somewhat shorter than the album version .'}, answer=[Entity(start_offset=52, end_offset=94, type='context', text='McFerrin , Robin Williams , and Bill Irwin', normalized_text='mcferrin robin williams and bill irwin')], nq_answers=[[Entity(start_offset=52, end_offset=94, type='context', text='McFerrin , Robin Williams , and Bill Irwin', normalized_text='mcferrin robin williams and bill irwin')], [Entity(start_offset=52, end_offset=60, type='context', text='McFerrin', normalized_text='mcferrin'), Entity(start_offset=63, end_offset=77, type='context', text='Robin Williams', normalized_text='robin williams'), Entity(start_offset=84, end_offset=94, type='context', text='Bill Irwin', normalized_text='bill irwin')]], aligned_nps=[(Entity(start_offset=11, end_offset=36, type='question', text='dont worry be happy video', normalized_text='dont worry be happy video'), Entity(start_offset=0, end_offset=45, type='context', text='The comedic original music video for the song', normalized_text='comedic original music video for song'))], explanation_type='single_sentence'),\n",
       " 4432617520373099396: QEDExample(example_id=4432617520373099396, title='List of sitting judges of the Supreme Court of India', question='total strength of judges in supreme court of india', passage='This is a list of judges of the Supreme Court of India , the highest court in the Republic of India . The list is ordered according to seniority . There are currently 24 judges , against a maximum possible strength of 31 . As per the Constitution of India , judges of the Supreme Court judges retire at age 65 .', sentence_starts=[0, 102, 147, 223], selected_sent={'start': 147, 'end': 223, 'string': 'There are currently 24 judges , against a maximum possible strength of 31 . '}, answer=[Entity(start_offset=167, end_offset=169, type='context', text='24', normalized_text='24')], nq_answers=[[Entity(start_offset=167, end_offset=176, type='context', text='24 judges', normalized_text='24 judges')], [Entity(start_offset=167, end_offset=169, type='context', text='24', normalized_text='24')]], aligned_nps=[(Entity(start_offset=28, end_offset=50, type='question', text='supreme court of india', normalized_text='supreme court of india'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 306074923032581824: QEDExample(example_id=306074923032581824, title='Just When I Needed You Most', question='who is the original singer of just when i needed you most', passage=\"`` Just When I Needed You Most '' is the title of a 1979 hit single by the American singer - songwriter Randy VanWarmer .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 121, 'string': \"`` Just When I Needed You Most '' is the title of a 1979 hit single by the American singer - songwriter Randy VanWarmer .\"}, answer=[Entity(start_offset=104, end_offset=119, type='context', text='Randy VanWarmer', normalized_text='randy vanwarmer')], nq_answers=[[Entity(start_offset=104, end_offset=119, type='context', text='Randy VanWarmer', normalized_text='randy vanwarmer')], [Entity(start_offset=75, end_offset=119, type='context', text='American singer - songwriter Randy VanWarmer', normalized_text='american singer songwriter randy vanwarmer')]], aligned_nps=[(Entity(start_offset=30, end_offset=57, type='question', text='just when i needed you most', normalized_text='just when i needed you most'), Entity(start_offset=3, end_offset=30, type='context', text='Just When I Needed You Most', normalized_text='just when i needed you most'))], explanation_type='single_sentence'),\n",
       " -6099485871335011666: QEDExample(example_id=-6099485871335011666, title='History of manga', question='what was the first form of manga in japan', passage=\"The history of manga is said to originate from scrolls dating back to the 12th century , and it is believed they represent the basis for the right - to - left reading style . The word first came into common usage in the late 18th century . Manga is a Japanese term that can be translated as `` comic '' ; Historians and writers on manga history have described two broad and complementary processes shaping modern manga . Their views differ in the relative importance they attribute to the role of cultural and historical events following World War II versus the role of pre-war , Meiji , and pre-Meiji Japanese culture and art .\", sentence_starts=[0, 175, 240, 421], selected_sent={'start': 0, 'end': 175, 'string': 'The history of manga is said to originate from scrolls dating back to the 12th century , and it is believed they represent the basis for the right - to - left reading style . '}, answer=[Entity(start_offset=47, end_offset=86, type='context', text='scrolls dating back to the 12th century', normalized_text='scrolls dating back to 12th century')], nq_answers=[[Entity(start_offset=47, end_offset=86, type='context', text='scrolls dating back to the 12th century', normalized_text='scrolls dating back to 12th century')]], aligned_nps=[(Entity(start_offset=27, end_offset=32, type='question', text='manga', normalized_text='manga'), Entity(start_offset=15, end_offset=20, type='context', text='manga', normalized_text='manga')), (Entity(start_offset=36, end_offset=41, type='question', text='japan', normalized_text='japan'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -337261340919997771: QEDExample(example_id=-337261340919997771, title='Peach', question='where do peaches come from in the us', passage=\"The U.S. state of Georgia is known as the `` Peach State '' due to its significant production of peaches as early as 1571 , with exports to other states occurring around 1858 . In 2014 , Georgia was third in US peach production behind California and South Carolina .\", sentence_starts=[0, 177], selected_sent={'start': 177, 'end': 266, 'string': 'In 2014 , Georgia was third in US peach production behind California and South Carolina .'}, answer=[Entity(start_offset=187, end_offset=194, type='context', text='Georgia', normalized_text='georgia'), Entity(start_offset=235, end_offset=245, type='context', text='California', normalized_text='california'), Entity(start_offset=250, end_offset=264, type='context', text='South Carolina', normalized_text='south carolina')], nq_answers=[[Entity(start_offset=235, end_offset=245, type='context', text='California', normalized_text='california'), Entity(start_offset=250, end_offset=264, type='context', text='South Carolina', normalized_text='south carolina'), Entity(start_offset=187, end_offset=194, type='context', text='Georgia', normalized_text='georgia')], [Entity(start_offset=18, end_offset=25, type='context', text='Georgia', normalized_text='georgia'), Entity(start_offset=235, end_offset=245, type='context', text='California', normalized_text='california'), Entity(start_offset=250, end_offset=264, type='context', text='South Carolina', normalized_text='south carolina'), Entity(start_offset=140, end_offset=152, type='context', text='other states', normalized_text='other states')], [Entity(start_offset=18, end_offset=25, type='context', text='Georgia', normalized_text='georgia'), Entity(start_offset=235, end_offset=245, type='context', text='California', normalized_text='california'), Entity(start_offset=250, end_offset=264, type='context', text='South Carolina', normalized_text='south carolina')]], aligned_nps=[(Entity(start_offset=30, end_offset=36, type='question', text='the us', normalized_text='us'), Entity(start_offset=208, end_offset=210, type='context', text='US', normalized_text='us')), (Entity(start_offset=9, end_offset=16, type='question', text='peaches', normalized_text='peaches'), Entity(start_offset=211, end_offset=216, type='context', text='peach', normalized_text='peach'))], explanation_type='single_sentence'),\n",
       " 7742806606709612020: QEDExample(example_id=7742806606709612020, title='Lead-based paint in the United Kingdom', question='when did they stop putting lead in paint', passage='Most lead - based paint in the United Kingdom was banned from sale to the general public in 1992 , apart from for specialist uses . Prior to this lead compounds had been used as the pigment and drying agent in different types of paint , for example brick and some tile paints', sentence_starts=[0, 132], selected_sent={'start': 0, 'end': 132, 'string': 'Most lead - based paint in the United Kingdom was banned from sale to the general public in 1992 , apart from for specialist uses . '}, answer=[Entity(start_offset=92, end_offset=96, type='context', text='1992', normalized_text='1992')], nq_answers=[[Entity(start_offset=92, end_offset=96, type='context', text='1992', normalized_text='1992')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3875958317236683310: QEDExample(example_id=-3875958317236683310, title='Battles of Lexington and Concord', question='when did the battles of lexington and concord happen', passage='The Battles of Lexington and Concord were the first military engagements of the American Revolutionary War . The battles were fought on April 19 , 1775 in Middlesex County , Province of Massachusetts Bay , within the towns of Lexington , Concord , Lincoln , Menotomy ( present - day Arlington ) , and Cambridge . They marked the outbreak of armed conflict between the Kingdom of Great Britain and its thirteen colonies in America .', sentence_starts=[0, 109, 313], selected_sent={'start': 109, 'end': 313, 'string': 'The battles were fought on April 19 , 1775 in Middlesex County , Province of Massachusetts Bay , within the towns of Lexington , Concord , Lincoln , Menotomy ( present - day Arlington ) , and Cambridge . '}, answer=[Entity(start_offset=136, end_offset=151, type='context', text='April 19 , 1775', normalized_text='april 19 1775')], nq_answers=[[Entity(start_offset=136, end_offset=151, type='context', text='April 19 , 1775', normalized_text='april 19 1775')]], aligned_nps=[(Entity(start_offset=9, end_offset=45, type='question', text='the battles of lexington and concord', normalized_text='battles of lexington and concord'), Entity(start_offset=109, end_offset=120, type='context', text='The battles', normalized_text='battles'))], explanation_type='single_sentence'),\n",
       " -3475538705836210704: QEDExample(example_id=-3475538705836210704, title='Scientific method', question='in the process of science hypotheses lead most directly to', passage='Though there are diverse models for the scientific method available , in general there is a continuous process that includes observations about the natural world . People are naturally inquisitive , so they often come up with questions about things they see or hear , and they often develop ideas or hypotheses about why things are the way they are . The best hypotheses lead to predictions that can be tested in various ways . The most conclusive testing of hypotheses comes from reasoning based on carefully controlled experimental data . Depending on how well additional tests match the predictions , the original hypothesis may require refinement , alteration , expansion or even rejection . If a particular hypothesis becomes very well supported , a general theory may be developed .', sentence_starts=[0, 164, 351, 428, 541, 696], selected_sent={'start': 351, 'end': 428, 'string': 'The best hypotheses lead to predictions that can be tested in various ways . '}, answer=[Entity(start_offset=379, end_offset=425, type='context', text='predictions that can be tested in various ways', normalized_text='predictions that can be tested in various ways')], nq_answers=[[Entity(start_offset=379, end_offset=425, type='context', text='predictions that can be tested in various ways', normalized_text='predictions that can be tested in various ways')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 432399360594227490: QEDExample(example_id=432399360594227490, title=\"Director's cut\", question=\"what is the director's cut of a movie\", passage=\"A director 's cut is an edited version of a film ( or television episode , music video , commercial , or video game ) that is supposed to represent the director 's own approved edit . ' Cut ' explicitly refers to the process of film editing ; in preparing a film for release , the director 's cut is preceded by the assembly and rough editor 's cut and usually followed by the final cut meant for the public film release .\", sentence_starts=[0, 184], selected_sent={'start': 0, 'end': 184, 'string': \"A director 's cut is an edited version of a film ( or television episode , music video , commercial , or video game ) that is supposed to represent the director 's own approved edit . \"}, answer=[Entity(start_offset=21, end_offset=181, type='context', text=\"an edited version of a film ( or television episode , music video , commercial , or video game ) that is supposed to represent the director 's own approved edit\", normalized_text='edited version of film or television episode music video commercial or video game that is supposed to represent director s own approved edit')], nq_answers=[[Entity(start_offset=21, end_offset=181, type='context', text=\"an edited version of a film ( or television episode , music video , commercial , or video game ) that is supposed to represent the director 's own approved edit\", normalized_text='edited version of film or television episode music video commercial or video game that is supposed to represent director s own approved edit')], [Entity(start_offset=24, end_offset=181, type='context', text=\"edited version of a film ( or television episode , music video , commercial , or video game ) that is supposed to represent the director 's own approved edit\", normalized_text='edited version of film or television episode music video commercial or video game that is supposed to represent director s own approved edit')], [Entity(start_offset=148, end_offset=181, type='context', text=\"the director 's own approved edit\", normalized_text='director s own approved edit')]], aligned_nps=[(Entity(start_offset=8, end_offset=37, type='question', text=\"the director's cut of a movie\", normalized_text='directors cut of movie'), Entity(start_offset=0, end_offset=17, type='context', text=\"A director 's cut\", normalized_text='director s cut'))], explanation_type='single_sentence'),\n",
       " 4826133206438959478: QEDExample(example_id=4826133206438959478, title='National Recovery Administration', question='who was appointed to manage the national recovery administration', passage=\"The first director of the NRA was Hugh S. Johnson , a retired United States Army general and a successful businessman . He was named Time magazine 's `` Man of the Year '' in 1933 . Johnson saw the NRA as a national crusade designed to restore employment and regenerate industry .\", sentence_starts=[0, 120, 182], selected_sent={'start': 0, 'end': 120, 'string': 'The first director of the NRA was Hugh S. Johnson , a retired United States Army general and a successful businessman . '}, answer=[Entity(start_offset=34, end_offset=49, type='context', text='Hugh S. Johnson', normalized_text='hugh s johnson')], nq_answers=[[Entity(start_offset=34, end_offset=49, type='context', text='Hugh S. Johnson', normalized_text='hugh s johnson')], [Entity(start_offset=34, end_offset=117, type='context', text='Hugh S. Johnson , a retired United States Army general and a successful businessman', normalized_text='hugh s johnson retired united states army general and successful businessman')]], aligned_nps=[(Entity(start_offset=28, end_offset=64, type='question', text='the national recovery administration', normalized_text='national recovery administration'), Entity(start_offset=22, end_offset=29, type='context', text='the NRA', normalized_text='nra'))], explanation_type='single_sentence'),\n",
       " -2743701347497238377: QEDExample(example_id=-2743701347497238377, title='Pulmonary circulation', question='how oxygenated blood returns to the heart from the lungs', passage='The pulmonary circulation is the portion of the circulatory system which carries deoxygenated blood away from the right ventricle of the heart , to the lungs , and returns oxygenated blood to the left atrium and ventricle of the heart . The term pulmonary circulation is readily paired and contrasted with the systemic circulation . The vessels of the pulmonary circulation are the pulmonary arteries and the pulmonary veins .', sentence_starts=[0, 237, 333], selected_sent={'start': 0, 'end': 237, 'string': 'The pulmonary circulation is the portion of the circulatory system which carries deoxygenated blood away from the right ventricle of the heart , to the lungs , and returns oxygenated blood to the left atrium and ventricle of the heart . '}, answer=[Entity(start_offset=0, end_offset=25, type='context', text='The pulmonary circulation', normalized_text='pulmonary circulation')], nq_answers=[[Entity(start_offset=4, end_offset=25, type='context', text='pulmonary circulation', normalized_text='pulmonary circulation')]], aligned_nps=[(Entity(start_offset=32, end_offset=41, type='question', text='the heart', normalized_text='heart'), Entity(start_offset=225, end_offset=234, type='context', text='the heart', normalized_text='heart')), (Entity(start_offset=4, end_offset=20, type='question', text='oxygenated blood', normalized_text='oxygenated blood'), Entity(start_offset=172, end_offset=188, type='context', text='oxygenated blood', normalized_text='oxygenated blood'))], explanation_type='single_sentence'),\n",
       " -2839661864110242676: QEDExample(example_id=-2839661864110242676, title='Statue of Liberty', question='where was the statue of liberty originally built', passage=\"The torch - bearing arm was displayed at the Centennial Exposition in Philadelphia in 1876 , and in Madison Square Park in Manhattan from 1876 to 1882 . Fundraising proved difficult , especially for the Americans , and by 1885 work on the pedestal was threatened by lack of funds . Publisher Joseph Pulitzer , of the New York World , started a drive for donations to finish the project and attracted more than 120,000 contributors , most of whom gave less than a dollar . The statue was built in France , shipped overseas in crates , and assembled on the completed pedestal on what was then called Bedloe 's Island . The statue 's completion was marked by New York 's first ticker - tape parade and a dedication ceremony presided over by President Grover Cleveland .\", sentence_starts=[0, 153, 282, 472, 617], selected_sent={'start': 472, 'end': 617, 'string': \"The statue was built in France , shipped overseas in crates , and assembled on the completed pedestal on what was then called Bedloe 's Island . \"}, answer=[Entity(start_offset=496, end_offset=502, type='context', text='France', normalized_text='france')], nq_answers=[[Entity(start_offset=496, end_offset=502, type='context', text='France', normalized_text='france')]], aligned_nps=[(Entity(start_offset=10, end_offset=31, type='question', text='the statue of liberty', normalized_text='statue of liberty'), Entity(start_offset=472, end_offset=482, type='context', text='The statue', normalized_text='statue'))], explanation_type='single_sentence'),\n",
       " -1403561686055024600: QEDExample(example_id=-1403561686055024600, title='Olympic Hymn', question='what language is the olympic anthem sang in', passage=\"The anthem has been recorded and performed in many different languages , usually as a result of the hosting of either form of the Games in various countries . The IOC does n't require that the anthem be performed in either English or Greek . But in the 2008 Olympic opening and closing ceremonies in Beijing , China , Greek was sung instead of the host country 's official language , Mandarin . Also in the 2016 Olympic opening ceremonies in Rio de Janeiro , Brazil , English was also sung instead of host country 's official language , Portuguese .\", sentence_starts=[0, 159, 242, 395], selected_sent={'start': 0, 'end': 159, 'string': 'The anthem has been recorded and performed in many different languages , usually as a result of the hosting of either form of the Games in various countries . '}, answer=[Entity(start_offset=46, end_offset=156, type='context', text='many different languages , usually as a result of the hosting of either form of the Games in various countries', normalized_text='many different languages usually as result of hosting of either form of games in various countries')], nq_answers=[[Entity(start_offset=318, end_offset=323, type='context', text='Greek', normalized_text='greek')]], aligned_nps=[(Entity(start_offset=17, end_offset=35, type='question', text='the olympic anthem', normalized_text='olympic anthem'), Entity(start_offset=0, end_offset=10, type='context', text='The anthem', normalized_text='anthem'))], explanation_type='single_sentence'),\n",
       " -6081006991734955423: QEDExample(example_id=-6081006991734955423, title='USS Bonhomme Richard (1765)', question='where did the battle of bonhomme richard take place', passage=\"On 23 September 1779 , the squadron encountered the Baltic Fleet of 41 sail under convoy of the HMS Serapis and HM hired armed vessel Countess of Scarborough near Flamborough Head . The Bonhomme Richard and Serapis entered a bitter engagement at about 6 : 00 p.m. The battle continued for the next four hours , costing the lives of nearly half of the American and British crews . British victory seemed inevitable , as the more heavily armed Serapis used its firepower to rake Bonhomme Richard with devastating effect . The commander of the Serapis finally called on Jones to surrender . He replied , `` Sir , I have not yet begun to fight ! '' Jones eventually managed to lash the ships together , nullifying his opponent 's greater maneuverability and allowing him to take advantage of the larger size and considerably more numerous crew of Bonhomme Richard . An attempt by the Americans to board Serapis was repulsed , as was an attempt by the British to board Bonhomme Richard . Finally , after another of Jones 's ships joined the fight , the British captain was forced to surrender at about 10 : 30 p.m. The Bonhomme Richard -- shattered , on fire , leaking badly -- defied all efforts to save her and sank about 36 hours later at 11 : 00 a.m. on Saturday , 25 September 1779 . Jones sailed the captured Serapis to the Dutch United Provinces for repairs .\", sentence_starts=[0, 182, 264, 380, 520, 588, 645, 862, 983, 1110, 1284], selected_sent={'start': 264, 'end': 380, 'string': 'The battle continued for the next four hours , costing the lives of nearly half of the American and British crews . '}, answer=[Entity(start_offset=158, end_offset=179, type='context', text='near Flamborough Head', normalized_text='near flamborough head')], nq_answers=[[Entity(start_offset=158, end_offset=179, type='context', text='near Flamborough Head', normalized_text='near flamborough head')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='the battle of bonhomme richard', normalized_text='battle of bonhomme richard'), Entity(start_offset=264, end_offset=274, type='context', text='The battle', normalized_text='battle'))], explanation_type='single_sentence'),\n",
       " -7341804957038262139: QEDExample(example_id=-7341804957038262139, title='Ohio River', question='where does the ohio river and the mississippi river meet', passage='The river then follows a roughly southwest and then west - northwest course until Cincinnati , before bending to a west - southwest course for most of its length . The course forms the northern borders of West Virginia and Kentucky ; and the southern borders of Ohio , Indiana and Illinois , until it joins the Mississippi River near the city of Cairo , Illinois .', sentence_starts=[0, 164], selected_sent={'start': 164, 'end': 364, 'string': 'The course forms the northern borders of West Virginia and Kentucky ; and the southern borders of Ohio , Indiana and Illinois , until it joins the Mississippi River near the city of Cairo , Illinois .'}, answer=[Entity(start_offset=329, end_offset=362, type='context', text='near the city of Cairo , Illinois', normalized_text='near city of cairo illinois')], nq_answers=[[Entity(start_offset=329, end_offset=362, type='context', text='near the city of Cairo , Illinois', normalized_text='near city of cairo illinois')]], aligned_nps=[(Entity(start_offset=11, end_offset=25, type='question', text='the ohio river', normalized_text='ohio river'), Entity(start_offset=298, end_offset=300, type='context', text='it', normalized_text='it')), (Entity(start_offset=30, end_offset=51, type='question', text='the mississippi river', normalized_text='mississippi river'), Entity(start_offset=307, end_offset=328, type='context', text='the Mississippi River', normalized_text='mississippi river'))], explanation_type='single_sentence'),\n",
       " 2875495346792993998: QEDExample(example_id=2875495346792993998, title='Michael Moriarty', question='who was the actor that played ben stone on law and order', passage=\"Michael Moriarty ( born April 5 , 1941 ) is an American - Canadian stage and screen actor and jazz musician . He received an Emmy Award and Golden Globe Award for his first acting role on American television as a Nazi SS officer in the 1978 mini-series Holocaust , and he played Executive Assistant District Attorney Benjamin Stone for the first four seasons ( 1990 -- 1994 ) on the television show Law & Order . Moriarty is also known for his roles in films such as Bang the Drum Slowly , Who 'll Stop the Rain , Q : The Winged Serpent , The Stuff , Pale Rider , Troll , Courage Under Fire , and Shiloh .\", sentence_starts=[0, 110, 413], selected_sent={'start': 110, 'end': 413, 'string': 'He received an Emmy Award and Golden Globe Award for his first acting role on American television as a Nazi SS officer in the 1978 mini-series Holocaust , and he played Executive Assistant District Attorney Benjamin Stone for the first four seasons ( 1990 -- 1994 ) on the television show Law & Order . '}, answer=[Entity(start_offset=0, end_offset=16, type='context', text='Michael Moriarty', normalized_text='michael moriarty')], nq_answers=[[Entity(start_offset=0, end_offset=16, type='context', text='Michael Moriarty', normalized_text='michael moriarty')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -302450126325076130: QEDExample(example_id=-302450126325076130, title='Scheria', question='where do the phaeacians live in the odyssey', passage=\"Scheria ( / ˈskɛriə / ; Ancient Greek : Σχερίη or Σχερία ) -- also known as Scherie or Phaeacia -- was a region in Greek mythology , first mentioned in Homer 's Odyssey as the home of the Phaeacians and the last destination of Odysseus in his 10 - year journey before returning home to Ithaca .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 294, 'string': \"Scheria ( / ˈskɛriə / ; Ancient Greek : Σχερίη or Σχερία ) -- also known as Scherie or Phaeacia -- was a region in Greek mythology , first mentioned in Homer 's Odyssey as the home of the Phaeacians and the last destination of Odysseus in his 10 - year journey before returning home to Ithaca .\"}, answer=[Entity(start_offset=0, end_offset=7, type='context', text='Scheria', normalized_text='scheria')], nq_answers=[[Entity(start_offset=0, end_offset=7, type='context', text='Scheria', normalized_text='scheria')], [Entity(start_offset=0, end_offset=95, type='context', text='Scheria ( / ˈskɛriə / ; Ancient Greek : Σχερίη or Σχερία ) -- also known as Scherie or Phaeacia', normalized_text='scheria ˈskɛriə ancient greek σχερίη or σχερία also known as scherie or phaeacia')]], aligned_nps=[(Entity(start_offset=32, end_offset=43, type='question', text='the odyssey', normalized_text='odyssey'), Entity(start_offset=152, end_offset=168, type='context', text=\"Homer 's Odyssey\", normalized_text='homer s odyssey')), (Entity(start_offset=9, end_offset=23, type='question', text='the phaeacians', normalized_text='phaeacians'), Entity(start_offset=184, end_offset=198, type='context', text='the Phaeacians', normalized_text='phaeacians'))], explanation_type='single_sentence'),\n",
       " -3344403727454433038: QEDExample(example_id=-3344403727454433038, title='Princess Leia', question='when do we find out luke and leia are siblings', passage=\"Princess Leia Organa of Alderaan ( also Senator Leia Organa or General Leia Organa ) is a fictional character in the Star Wars franchise , portrayed in films by Carrie Fisher . Introduced in the original Star Wars film in 1977 , Leia is princess of the planet Alderaan , a member of the Imperial Senate and an agent of the Rebel Alliance . She thwarts the sinister Sith Lord Darth Vader and helps bring about the destruction of the Empire 's cataclysmic superweapon , the Death Star . In The Empire Strikes Back ( 1980 ) , Leia commands a Rebel base and evades Vader as she falls in love with the smuggler , Han Solo . In Return of the Jedi ( 1983 ) , Leia leads the operation to rescue Han from the crime lord Jabba the Hutt , and is revealed to be Vader 's daughter and the twin sister of Luke Skywalker . The prequel film Revenge of the Sith ( 2005 ) establishes that the twins ' mother is Senator ( and former queen ) Padmé Amidala of Naboo , who dies after childbirth . Leia is adopted by Senator Bail and Queen Breha Organa of Alderaan . In The Force Awakens ( 2015 ) and The Last Jedi ( 2017 ) , Leia is the founder and General of the Resistance against the First Order . She and Han have a son named Ben , who adopted the name Kylo Ren after turning to the dark side of the Force .\", sentence_starts=[0, 177, 340, 485, 619, 808, 975, 1044, 1179], selected_sent={'start': 619, 'end': 808, 'string': \"In Return of the Jedi ( 1983 ) , Leia leads the operation to rescue Han from the crime lord Jabba the Hutt , and is revealed to be Vader 's daughter and the twin sister of Luke Skywalker . \"}, answer=[Entity(start_offset=619, end_offset=649, type='context', text='In Return of the Jedi ( 1983 )', normalized_text='in return of jedi 1983')], nq_answers=[[Entity(start_offset=619, end_offset=649, type='context', text='In Return of the Jedi ( 1983 )', normalized_text='in return of jedi 1983')], [Entity(start_offset=619, end_offset=640, type='context', text='In Return of the Jedi', normalized_text='in return of jedi')], [Entity(start_offset=622, end_offset=640, type='context', text='Return of the Jedi', normalized_text='return of jedi')]], aligned_nps=[(Entity(start_offset=29, end_offset=33, type='question', text='leia', normalized_text='leia'), Entity(start_offset=652, end_offset=656, type='context', text='Leia', normalized_text='leia')), (Entity(start_offset=20, end_offset=24, type='question', text='luke', normalized_text='luke'), Entity(start_offset=791, end_offset=805, type='context', text='Luke Skywalker', normalized_text='luke skywalker'))], explanation_type='single_sentence'),\n",
       " 3610488274381813727: QEDExample(example_id=3610488274381813727, title='Precipitation', question='what are the four main types of precipitation', passage=\"In meteorology , precipitation is any product of the condensation of atmospheric water vapor that falls under gravity . The main forms of precipitation include drizzle , rain , sleet , snow , graupel and hail . Precipitation occurs when a portion of the atmosphere becomes saturated with water vapor , so that the water condenses and `` precipitates '' . Thus , fog and mist are not precipitation but suspensions , because the water vapor does not condense sufficiently to precipitate . Two processes , possibly acting together , can lead to air becoming saturated : cooling the air or adding water vapor to the air . Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud . Short , intense periods of rain in scattered locations are called `` showers . ''\", sentence_starts=[0, 120, 211, 355, 487, 618, 736], selected_sent={'start': 120, 'end': 211, 'string': 'The main forms of precipitation include drizzle , rain , sleet , snow , graupel and hail . '}, answer=[Entity(start_offset=160, end_offset=208, type='context', text='drizzle , rain , sleet , snow , graupel and hail', normalized_text='drizzle rain sleet snow graupel and hail')], nq_answers=[[Entity(start_offset=160, end_offset=167, type='context', text='drizzle', normalized_text='drizzle'), Entity(start_offset=170, end_offset=174, type='context', text='rain', normalized_text='rain'), Entity(start_offset=177, end_offset=182, type='context', text='sleet', normalized_text='sleet'), Entity(start_offset=185, end_offset=189, type='context', text='snow', normalized_text='snow'), Entity(start_offset=192, end_offset=199, type='context', text='graupel', normalized_text='graupel'), Entity(start_offset=204, end_offset=208, type='context', text='hail', normalized_text='hail')]], aligned_nps=[(Entity(start_offset=32, end_offset=45, type='question', text='precipitation', normalized_text='precipitation'), Entity(start_offset=138, end_offset=151, type='context', text='precipitation', normalized_text='precipitation'))], explanation_type='single_sentence'),\n",
       " -2528164310441623185: QEDExample(example_id=-2528164310441623185, title=\"Figure skating at the 2018 Winter Olympics – Men's singles\", question=\"who won the men's ice skating 2018\", passage=\"With his victory at the 2018 Winter Olympics , Yuzuru Hanyu became the first male figure skater to win two consecutive gold medals after Dick Button , who did so in 1952 . Fellow countryman Shoma Uno won the silver medal , and Spain 's Javier Fernández won the bronze medal . Fernández won Spain 's first figure skating medal and fourth medal at the Winter Olympics .\", sentence_starts=[0, 172, 276], selected_sent={'start': 0, 'end': 172, 'string': 'With his victory at the 2018 Winter Olympics , Yuzuru Hanyu became the first male figure skater to win two consecutive gold medals after Dick Button , who did so in 1952 . '}, answer=[Entity(start_offset=47, end_offset=59, type='context', text='Yuzuru Hanyu', normalized_text='yuzuru hanyu')], nq_answers=[[Entity(start_offset=47, end_offset=59, type='context', text='Yuzuru Hanyu', normalized_text='yuzuru hanyu')]], aligned_nps=[(Entity(start_offset=30, end_offset=34, type='question', text='2018', normalized_text='2018'), Entity(start_offset=24, end_offset=28, type='context', text='2018', normalized_text='2018')), (Entity(start_offset=8, end_offset=29, type='question', text=\"the men's ice skating\", normalized_text='mens ice skating'), Entity(start_offset=20, end_offset=44, type='context', text='the 2018 Winter Olympics', normalized_text='2018 winter olympics'))], explanation_type='single_sentence'),\n",
       " -7052052953885262396: QEDExample(example_id=-7052052953885262396, title='Permanent members of the United Nations Security Council', question='who are the permanent member of un security council', passage=\"The permanent members of the United Nations Security Council ( also known as the Permanent Five , Big Five , or P5 ) are the five states which the UN Charter of 1945 grants a permanent seat on the UN Security Council ( UNSC ) : China ( formerly the Republic of China ) , Russia ( formerly the Soviet Union ) , France , the United Kingdom , and the United States . These countries were all allies in World War II , which they won . They are also all nuclear weapons states . A total of 15 UN member states serve on the UNSC , the remainder of which are elected . Only the five permanent members have the power of veto , which enables them to prevent the adoption of any `` substantive '' draft Council resolution , regardless of its level of international support .\", sentence_starts=[0, 364, 431, 474, 562], selected_sent={'start': 0, 'end': 364, 'string': 'The permanent members of the United Nations Security Council ( also known as the Permanent Five , Big Five , or P5 ) are the five states which the UN Charter of 1945 grants a permanent seat on the UN Security Council ( UNSC ) : China ( formerly the Republic of China ) , Russia ( formerly the Soviet Union ) , France , the United Kingdom , and the United States . '}, answer=[Entity(start_offset=228, end_offset=361, type='context', text='China ( formerly the Republic of China ) , Russia ( formerly the Soviet Union ) , France , the United Kingdom , and the United States', normalized_text='china formerly republic of china russia formerly soviet union france united kingdom and united states')], nq_answers=[[Entity(start_offset=228, end_offset=361, type='context', text='China ( formerly the Republic of China ) , Russia ( formerly the Soviet Union ) , France , the United Kingdom , and the United States', normalized_text='china formerly republic of china russia formerly soviet union france united kingdom and united states')], [Entity(start_offset=228, end_offset=233, type='context', text='China', normalized_text='china'), Entity(start_offset=271, end_offset=277, type='context', text='Russia', normalized_text='russia'), Entity(start_offset=310, end_offset=316, type='context', text='France', normalized_text='france'), Entity(start_offset=323, end_offset=337, type='context', text='United Kingdom', normalized_text='united kingdom'), Entity(start_offset=348, end_offset=361, type='context', text='United States', normalized_text='united states')]], aligned_nps=[(Entity(start_offset=8, end_offset=51, type='question', text='the permanent member of un security council', normalized_text='permanent member of un security council'), Entity(start_offset=0, end_offset=60, type='context', text='The permanent members of the United Nations Security Council', normalized_text='permanent members of united nations security council'))], explanation_type='single_sentence'),\n",
       " 4826602256490942616: QEDExample(example_id=4826602256490942616, title='University of Miami', question='what is the enrollment at university of miami', passage=\"The University of Miami ( informally referred to as UM , U of M , or The U ) is a private , nonsectarian research university in Coral Gables , Florida , United States . As of 2016 , the university enrolls 16,801 students in 12 separate colleges / schools , including the Leonard M. Miller School of Medicine in Miami 's Health District , a law school on the main campus , and the Rosenstiel School of Marine and Atmospheric Science focused on the study of oceanography and atmospheric sciences on Virginia Key , with research facilities at the Richmond Facility in southern Miami - Dade County .\", sentence_starts=[0, 169], selected_sent={'start': 169, 'end': 595, 'string': \"As of 2016 , the university enrolls 16,801 students in 12 separate colleges / schools , including the Leonard M. Miller School of Medicine in Miami 's Health District , a law school on the main campus , and the Rosenstiel School of Marine and Atmospheric Science focused on the study of oceanography and atmospheric sciences on Virginia Key , with research facilities at the Richmond Facility in southern Miami - Dade County .\"}, answer=[Entity(start_offset=205, end_offset=220, type='context', text='16,801 students', normalized_text='16801 students')], nq_answers=[[Entity(start_offset=205, end_offset=220, type='context', text='16,801 students', normalized_text='16801 students')], [Entity(start_offset=205, end_offset=211, type='context', text='16,801', normalized_text='16801')]], aligned_nps=[(Entity(start_offset=26, end_offset=45, type='question', text='university of miami', normalized_text='university of miami'), Entity(start_offset=182, end_offset=196, type='context', text='the university', normalized_text='university'))], explanation_type='single_sentence'),\n",
       " 1928973707594149608: QEDExample(example_id=1928973707594149608, title='Beauty and the Beast (2017 film)', question='who does the voice of the beast in the new movie', passage=\"Beauty and the Beast is a 2017 American musical romantic fantasy film directed by Bill Condon from a screenplay written by Stephen Chbosky and Evan Spiliotopoulos , and co-produced by Walt Disney Pictures and Mandeville Films . The film is based on Disney 's 1991 animated film of the same name , itself an adaptation of Jeanne - Marie Leprince de Beaumont 's eighteenth - century fairy tale . The film features an ensemble cast that includes Emma Watson and Dan Stevens as the titular characters with Luke Evans , Kevin Kline , Josh Gad , Ewan McGregor , Stanley Tucci , Audra McDonald , Gugu Mbatha - Raw , Ian McKellen , and Emma Thompson in supporting roles .\", sentence_starts=[0, 228, 394], selected_sent={'start': 394, 'end': 663, 'string': 'The film features an ensemble cast that includes Emma Watson and Dan Stevens as the titular characters with Luke Evans , Kevin Kline , Josh Gad , Ewan McGregor , Stanley Tucci , Audra McDonald , Gugu Mbatha - Raw , Ian McKellen , and Emma Thompson in supporting roles .'}, answer=[Entity(start_offset=459, end_offset=470, type='context', text='Dan Stevens', normalized_text='dan stevens')], nq_answers=[[Entity(start_offset=459, end_offset=470, type='context', text='Dan Stevens', normalized_text='dan stevens')]], aligned_nps=[(Entity(start_offset=35, end_offset=48, type='question', text='the new movie', normalized_text='new movie'), Entity(start_offset=394, end_offset=402, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " -5548201381317088445: QEDExample(example_id=-5548201381317088445, title='Adidas Yeezy', question='when did the first pair of yeezys come out', passage=\"Adidas Yeezy Boost is the official collaboration sneaker by Kanye West and Adidas . The Adidas Yeezy 750 Boost `` Light Brown '' was the first sneaker to release from this collaboration on February 14 , 2015 . The second shoe to release was the Adidas Yeezy Boost 350 `` Turtle Dove '' . `` Yeezy Season 1 '' was the first and only apparel collection to release from this collaboration . It was officially released on October 29 , 2015 . The Adidas Yeezy 950 Boost was also part of this collection and it was released in four different colorways .\", sentence_starts=[0, 84, 210, 288, 388, 438], selected_sent={'start': 84, 'end': 210, 'string': \"The Adidas Yeezy 750 Boost `` Light Brown '' was the first sneaker to release from this collaboration on February 14 , 2015 . \"}, answer=[Entity(start_offset=189, end_offset=207, type='context', text='February 14 , 2015', normalized_text='february 14 2015')], nq_answers=[[Entity(start_offset=189, end_offset=207, type='context', text='February 14 , 2015', normalized_text='february 14 2015')]], aligned_nps=[(Entity(start_offset=9, end_offset=33, type='question', text='the first pair of yeezys', normalized_text='first pair of yeezys'), Entity(start_offset=84, end_offset=128, type='context', text=\"The Adidas Yeezy 750 Boost `` Light Brown ''\", normalized_text='adidas yeezy 750 boost light brown'))], explanation_type='single_sentence'),\n",
       " -7778233237890403173: QEDExample(example_id=-7778233237890403173, title='The Crossing (TV series)', question='where did they film the show the crossing', passage='The Crossing is an American science fiction thriller series that airs on ABC and CTV . The series debuted on April 2 , 2018 . On March 20 , 2018 , ABC released the pilot episode on their website . The series is filmed in British Columbia , Canada .', sentence_starts=[0, 87, 126, 197], selected_sent={'start': 197, 'end': 248, 'string': 'The series is filmed in British Columbia , Canada .'}, answer=[Entity(start_offset=221, end_offset=246, type='context', text='British Columbia , Canada', normalized_text='british columbia canada')], nq_answers=[[Entity(start_offset=221, end_offset=246, type='context', text='British Columbia , Canada', normalized_text='british columbia canada')]], aligned_nps=[(Entity(start_offset=20, end_offset=41, type='question', text='the show the crossing', normalized_text='show crossing'), Entity(start_offset=197, end_offset=207, type='context', text='The series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " -5631645752168123789: QEDExample(example_id=-5631645752168123789, title='Cool Hand Luke', question='when was the movie cool hand luke made', passage='Cool Hand Luke is a 1967 American prison drama film directed by Stuart Rosenberg , starring Paul Newman and featuring George Kennedy in an Oscar - winning performance . Newman stars in the title role as Luke , a prisoner in a Florida prison camp who refuses to submit to the system .', sentence_starts=[0, 169], selected_sent={'start': 0, 'end': 169, 'string': 'Cool Hand Luke is a 1967 American prison drama film directed by Stuart Rosenberg , starring Paul Newman and featuring George Kennedy in an Oscar - winning performance . '}, answer=[Entity(start_offset=20, end_offset=24, type='context', text='1967', normalized_text='1967')], nq_answers=[[Entity(start_offset=20, end_offset=24, type='context', text='1967', normalized_text='1967')]], aligned_nps=[(Entity(start_offset=9, end_offset=33, type='question', text='the movie cool hand luke', normalized_text='movie cool hand luke'), Entity(start_offset=0, end_offset=14, type='context', text='Cool Hand Luke', normalized_text='cool hand luke'))], explanation_type='single_sentence'),\n",
       " 8838716539218945006: QEDExample(example_id=8838716539218945006, title='A rose by any other name would smell as sweet', question='who says that which we call a rose', passage=\"`` A rose by any other name would smell as sweet '' is a popular reference to William Shakespeare 's play Romeo and Juliet , in which Juliet seems to argue that it does not matter that Romeo is from her family 's rival house of Montague , that is , that he is named `` Montague '' . The reference is often used to imply that the names of things do not affect what they really are . This formulation is , however , a paraphrase of Shakespeare 's actual language . Juliet compares Romeo to a rose saying that if he was not named Romeo he would still be handsome and be Juliet 's love . This states that if he was not Romeo , then he would not be a Montague and she would be able to get married with no problem at all .\", sentence_starts=[0, 283, 382, 463, 584], selected_sent={'start': 0, 'end': 283, 'string': \"`` A rose by any other name would smell as sweet '' is a popular reference to William Shakespeare 's play Romeo and Juliet , in which Juliet seems to argue that it does not matter that Romeo is from her family 's rival house of Montague , that is , that he is named `` Montague '' . \"}, answer=[Entity(start_offset=134, end_offset=140, type='context', text='Juliet', normalized_text='juliet')], nq_answers=[[Entity(start_offset=134, end_offset=140, type='context', text='Juliet', normalized_text='juliet')], [Entity(start_offset=78, end_offset=97, type='context', text='William Shakespeare', normalized_text='william shakespeare'), Entity(start_offset=463, end_offset=469, type='context', text='Juliet', normalized_text='juliet')]], aligned_nps=[(Entity(start_offset=9, end_offset=34, type='question', text='that which we call a rose', normalized_text='that which we call rose'), Entity(start_offset=3, end_offset=48, type='context', text='A rose by any other name would smell as sweet', normalized_text='rose by any other name would smell as sweet'))], explanation_type='single_sentence'),\n",
       " 5191402605768653295: QEDExample(example_id=5191402605768653295, title='Put Your Hand in the Hand', question='who wrote put your hand in the hand of the man who stilled the water', passage=\"`` Put Your Hand in the Hand '' is a gospel pop song composed by Gene MacLellan and first recorded by Canadian singer Anne Murray from her third studio album Honey , Wheat and Laughter .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 186, 'string': \"`` Put Your Hand in the Hand '' is a gospel pop song composed by Gene MacLellan and first recorded by Canadian singer Anne Murray from her third studio album Honey , Wheat and Laughter .\"}, answer=[Entity(start_offset=65, end_offset=79, type='context', text='Gene MacLellan', normalized_text='gene maclellan')], nq_answers=[[Entity(start_offset=65, end_offset=79, type='context', text='Gene MacLellan', normalized_text='gene maclellan')]], aligned_nps=[(Entity(start_offset=10, end_offset=68, type='question', text='put your hand in the hand of the man who stilled the water', normalized_text='put your hand in hand of man who stilled water'), Entity(start_offset=3, end_offset=28, type='context', text='Put Your Hand in the Hand', normalized_text='put your hand in hand'))], explanation_type='single_sentence'),\n",
       " 2223188268381215709: QEDExample(example_id=2223188268381215709, title='Joint Session of Indian Parliament', question='who presides over the joint sessions of parliament', passage='The Parliament of India is bicameral . Concurrence of both houses are required to pass any bill . However , the authors of the Constitution of India visualised situations of deadlock between the upper house i.e. Rajya Sabha and the lower house i.e. Lok Sabha . Therefore , the Constitution of India provides for Joint sittings of both the Houses to break this deadlock . The joint sitting of the Parliament is called by the President and is presided over by the Speaker or , in his absence , by the Deputy Speaker of the Lok Sabha or in his absence , the Deputy - Chairman of the Rajya Sabha . If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House .', sentence_starts=[0, 39, 98, 212, 249, 261, 371, 594], selected_sent={'start': 371, 'end': 594, 'string': 'The joint sitting of the Parliament is called by the President and is presided over by the Speaker or , in his absence , by the Deputy Speaker of the Lok Sabha or in his absence , the Deputy - Chairman of the Rajya Sabha . '}, answer=[Entity(start_offset=458, end_offset=591, type='context', text='the Speaker or , in his absence , by the Deputy Speaker of the Lok Sabha or in his absence , the Deputy - Chairman of the Rajya Sabha', normalized_text='speaker or in his absence by deputy speaker of lok sabha or in his absence deputy chairman of rajya sabha')], nq_answers=[[Entity(start_offset=424, end_offset=433, type='context', text='President', normalized_text='president')]], aligned_nps=[(Entity(start_offset=18, end_offset=50, type='question', text='the joint sessions of parliament', normalized_text='joint sessions of parliament'), Entity(start_offset=371, end_offset=406, type='context', text='The joint sitting of the Parliament', normalized_text='joint sitting of parliament'))], explanation_type='single_sentence'),\n",
       " 6762133121441037463: QEDExample(example_id=6762133121441037463, title='Lips of an Angel', question='who is the girl in the hinder video lips of an angel', passage=\"Premiering in early 2007 , the music video for `` Lips of an Angel '' was directed by Shaun Silva and largely follows the narrative of the song 's lyrics , focusing on a late night phone call between the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui ) .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 278, 'string': \"Premiering in early 2007 , the music video for `` Lips of an Angel '' was directed by Shaun Silva and largely follows the narrative of the song 's lyrics , focusing on a late night phone call between the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui ) .\"}, answer=[Entity(start_offset=256, end_offset=274, type='context', text='Emmanuelle Chriqui', normalized_text='emmanuelle chriqui')], nq_answers=[[Entity(start_offset=256, end_offset=274, type='context', text='Emmanuelle Chriqui', normalized_text='emmanuelle chriqui')]], aligned_nps=[(Entity(start_offset=7, end_offset=52, type='question', text='the girl in the hinder video lips of an angel', normalized_text='girl in hinder video lips of angel'), Entity(start_offset=237, end_offset=253, type='context', text='his former lover', normalized_text='his former lover'))], explanation_type='single_sentence'),\n",
       " -2566265789668921137: QEDExample(example_id=-2566265789668921137, title='Romanticism', question='when did the romanticism period start and end', passage='Romanticism ( also the Romantic era or the Romantic period ) was an artistic , literary , musical and intellectual movement that originated in Europe toward the end of the 18th century , and in most areas was at its peak in the approximate period from 1800 to 1850 . Romanticism was characterized by its emphasis on emotion and individualism as well as glorification of all the past and nature , preferring the medieval rather than the classical . It was partly a reaction to the Industrial Revolution , the aristocratic social and political norms of the Age of Enlightenment , and the scientific rationalization of nature -- all components of modernity . It was embodied most strongly in the visual arts , music , and literature , but had a major impact on historiography , education , and the natural sciences . It had a significant and complex effect on politics , with romantic thinkers influencing liberalism , radicalism , conservatism and nationalism .', sentence_starts=[0, 267, 448, 656, 814], selected_sent={'start': 0, 'end': 267, 'string': 'Romanticism ( also the Romantic era or the Romantic period ) was an artistic , literary , musical and intellectual movement that originated in Europe toward the end of the 18th century , and in most areas was at its peak in the approximate period from 1800 to 1850 . '}, answer=[Entity(start_offset=129, end_offset=264, type='context', text='originated in Europe toward the end of the 18th century , and in most areas was at its peak in the approximate period from 1800 to 1850', normalized_text='originated in europe toward end of 18th century and in most areas was at its peak in approximate period from 1800 to 1850')], nq_answers=[[Entity(start_offset=221, end_offset=264, type='context', text='in the approximate period from 1800 to 1850', normalized_text='in approximate period from 1800 to 1850')], [Entity(start_offset=129, end_offset=264, type='context', text='originated in Europe toward the end of the 18th century , and in most areas was at its peak in the approximate period from 1800 to 1850', normalized_text='originated in europe toward end of 18th century and in most areas was at its peak in approximate period from 1800 to 1850')]], aligned_nps=[(Entity(start_offset=9, end_offset=31, type='question', text='the romanticism period', normalized_text='romanticism period'), Entity(start_offset=0, end_offset=11, type='context', text='Romanticism', normalized_text='romanticism'))], explanation_type='single_sentence'),\n",
       " 3867705141367202061: QEDExample(example_id=3867705141367202061, title='A Thousand Years (Christina Perri song)', question='who sings ive loved you for a thousand years', passage=\"`` A Thousand Years '' is a song by American singer - songwriter Christina Perri and David Hodges . It is taken from the album The Twilight Saga : Breaking Dawn -- Part 1 : Original Motion Picture Soundtrack . The song serves as the second single from the album . The song was released as a digital download on October 18 , 2011 worldwide . Perri re-recorded the song with vocals from Steve Kazee for The Twilight Saga : Breaking Dawn -- Part 2 : Original Motion Picture Soundtrack titled A Thousand Years , Pt. 2 .\", sentence_starts=[0, 100, 210, 264, 341], selected_sent={'start': 0, 'end': 100, 'string': \"`` A Thousand Years '' is a song by American singer - songwriter Christina Perri and David Hodges . \"}, answer=[Entity(start_offset=65, end_offset=97, type='context', text='Christina Perri and David Hodges', normalized_text='christina perri and david hodges')], nq_answers=[[Entity(start_offset=65, end_offset=80, type='context', text='Christina Perri', normalized_text='christina perri')]], aligned_nps=[(Entity(start_offset=10, end_offset=44, type='question', text='ive loved you for a thousand years', normalized_text='ive loved you for thousand years'), Entity(start_offset=3, end_offset=19, type='context', text='A Thousand Years', normalized_text='thousand years'))], explanation_type='single_sentence'),\n",
       " -1546147308403024577: QEDExample(example_id=-1546147308403024577, title='Vincenzo Peruggia', question='who stole the mona lisa from the louvre in 1911', passage='Vincenzo Peruggia ( October 8 , 1881 -- October 8 , 1925 ) was an Italian thief , most famous for stealing the Mona Lisa on 21 August 1911 . Born in Dumenza , Varese , Italy , he died in Saint - Maur - des - Fossés , France .', sentence_starts=[0, 141], selected_sent={'start': 0, 'end': 141, 'string': 'Vincenzo Peruggia ( October 8 , 1881 -- October 8 , 1925 ) was an Italian thief , most famous for stealing the Mona Lisa on 21 August 1911 . '}, answer=[Entity(start_offset=0, end_offset=17, type='context', text='Vincenzo Peruggia', normalized_text='vincenzo peruggia')], nq_answers=[[Entity(start_offset=0, end_offset=17, type='context', text='Vincenzo Peruggia', normalized_text='vincenzo peruggia')]], aligned_nps=[(Entity(start_offset=10, end_offset=23, type='question', text='the mona lisa', normalized_text='mona lisa'), Entity(start_offset=107, end_offset=120, type='context', text='the Mona Lisa', normalized_text='mona lisa')), (Entity(start_offset=43, end_offset=47, type='question', text='1911', normalized_text='1911'), Entity(start_offset=124, end_offset=138, type='context', text='21 August 1911', normalized_text='21 august 1911'))], explanation_type='single_sentence'),\n",
       " 3497042947752645554: QEDExample(example_id=3497042947752645554, title='Fiddler on the Roof', question='who sings far from the home i love in fiddler on the roof', passage=\"Tevye explains these events to an astonished Golde . `` Love , '' he says , `` it 's the new style . '' Tevye asks Golde , despite their own arranged marriage , `` Do You Love Me ? '' After dismissing Tevye 's question as foolish , she eventually admits that , after 25 years of living and struggling together and raising five daughters , she does . Meanwhile , Yente tells Tzeitel that she saw Chava with Fyedka . News spreads quickly in Anatevka that Perchik has been arrested and exiled to Siberia ( `` The Rumor / I Just Heard '' ) , and Hodel is determined to join him there . At the railway station , she explains to her father that her home is with her beloved , wherever he may be , although she will always love her family ( `` Far From the Home I Love '' ) .\", sentence_starts=[0, 53, 104, 184, 350, 415, 582], selected_sent={'start': 582, 'end': 768, 'string': \"At the railway station , she explains to her father that her home is with her beloved , wherever he may be , although she will always love her family ( `` Far From the Home I Love '' ) .\"}, answer=[Entity(start_offset=542, end_offset=547, type='context', text='Hodel', normalized_text='hodel')], nq_answers=[[Entity(start_offset=542, end_offset=547, type='context', text='Hodel', normalized_text='hodel')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text='far from the home i love', normalized_text='far from home i love'), Entity(start_offset=737, end_offset=761, type='context', text='Far From the Home I Love', normalized_text='far from home i love')), (Entity(start_offset=38, end_offset=57, type='question', text='fiddler on the roof', normalized_text='fiddler on roof'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 5751999721029016250: QEDExample(example_id=5751999721029016250, title=\"Billy Don't Be a Hero\", question=\"when did billy don't be a hero come out\", passage=\"`` Billy Do n't Be a Hero '' is a 1974 pop song that was first a UK hit for Paper Lace and then , some months later , a US hit for Bo Donaldson and The Heywoods . The song was written and composed by two British songwriters , Mitch Murray and Peter Callander .\", sentence_starts=[0, 163], selected_sent={'start': 0, 'end': 163, 'string': \"`` Billy Do n't Be a Hero '' is a 1974 pop song that was first a UK hit for Paper Lace and then , some months later , a US hit for Bo Donaldson and The Heywoods . \"}, answer=[Entity(start_offset=34, end_offset=38, type='context', text='1974', normalized_text='1974')], nq_answers=[[Entity(start_offset=34, end_offset=38, type='context', text='1974', normalized_text='1974')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text=\"billy don't be a hero\", normalized_text='billy dont be hero'), Entity(start_offset=3, end_offset=25, type='context', text=\"Billy Do n't Be a Hero\", normalized_text='billy do nt be hero'))], explanation_type='single_sentence'),\n",
       " -6669308254741746858: QEDExample(example_id=-6669308254741746858, title='Somewhere (song)', question=\"who wrote somewhere there's a place for us\", passage=\"`` Somewhere '' , sometimes referred to as `` Somewhere ( There 's a Place for Us ) '' or simply `` There 's a Place for Us '' , is a song from the 1957 Broadway musical West Side Story that was made into a film in 1961 . The music is composed by Leonard Bernstein with lyrics by Stephen Sondheim , and takes a phrase from the slow movement of Beethoven 's ' Emperor ' Piano Concerto , which forms the start of the melody , and also a longer phrase from the main theme of Pyotr Tchaikovsky 's Swan Lake .\", sentence_starts=[0, 222], selected_sent={'start': 222, 'end': 504, 'string': \"The music is composed by Leonard Bernstein with lyrics by Stephen Sondheim , and takes a phrase from the slow movement of Beethoven 's ' Emperor ' Piano Concerto , which forms the start of the melody , and also a longer phrase from the main theme of Pyotr Tchaikovsky 's Swan Lake .\"}, answer=[Entity(start_offset=222, end_offset=296, type='context', text='The music is composed by Leonard Bernstein with lyrics by Stephen Sondheim', normalized_text='music is composed by leonard bernstein with lyrics by stephen sondheim')], nq_answers=[[Entity(start_offset=247, end_offset=264, type='context', text='Leonard Bernstein', normalized_text='leonard bernstein'), Entity(start_offset=280, end_offset=296, type='context', text='Stephen Sondheim', normalized_text='stephen sondheim')], [Entity(start_offset=222, end_offset=264, type='context', text='The music is composed by Leonard Bernstein', normalized_text='music is composed by leonard bernstein'), Entity(start_offset=270, end_offset=296, type='context', text='lyrics by Stephen Sondheim', normalized_text='lyrics by stephen sondheim')]], aligned_nps=[(Entity(start_offset=10, end_offset=42, type='question', text=\"somewhere there's a place for us\", normalized_text='somewhere theres place for us'), Entity(start_offset=222, end_offset=231, type='context', text='The music', normalized_text='music'))], explanation_type='single_sentence'),\n",
       " -2650037553681702646: QEDExample(example_id=-2650037553681702646, title='Weekly Torah portion', question='what is the torah portion of the week', passage=\"The weekly Torah portion ( Hebrew : פָּרָשַׁת הַשָּׁבוּעַ \\u202c Parashat ha - Shavua ) , popularly just parashah ( or parshah / pɑːrʃə / or parsha ) and also known as a Sidra ( or Sedra / sɛdrə / ) is a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week . It is chanted publicly by a designated reader ( ba'al koreh ) in Jewish prayer services , starting with a partial reading on the afternoon of Shabbat ( Saturday , the Jewish Sabbath ) , again during the Monday and Thursday morning services , and ending with a full reading during the following Shabbat morning services . The weekly reading is pre-empted by a special reading on major religious holidays . The Saturday morning and holiday readings are followed by a reading ( Haftarah ) from the Book of Prophets ( Nevi'im ) . There are 54 weekly parashiyot ( plural ) or parshahs ( anglicized pluralization ) in Judaism , and the full cycle is read over the course of one Jewish year .\", sentence_starts=[0, 290, 611, 695, 816], selected_sent={'start': 0, 'end': 290, 'string': 'The weekly Torah portion ( Hebrew : פָּרָשַׁת הַשָּׁבוּעַ \\u202c Parashat ha - Shavua ) , popularly just parashah ( or parshah / pɑːrʃə / or parsha ) and also known as a Sidra ( or Sedra / sɛdrə / ) is a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week . '}, answer=[Entity(start_offset=197, end_offset=287, type='context', text='a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week', normalized_text='section of torah five books of moses used in jewish liturgy during single week')], nq_answers=[[Entity(start_offset=197, end_offset=287, type='context', text='a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week', normalized_text='section of torah five books of moses used in jewish liturgy during single week')]], aligned_nps=[(Entity(start_offset=8, end_offset=37, type='question', text='the torah portion of the week', normalized_text='torah portion of week'), Entity(start_offset=0, end_offset=24, type='context', text='The weekly Torah portion', normalized_text='weekly torah portion'))], explanation_type='single_sentence'),\n",
       " -2454338314238497026: QEDExample(example_id=-2454338314238497026, title='Pradyumna', question='what is the name of son of lord krishna', passage='Affliation = Avatara of Kamadeva . Pradyumna ( Sanskrit : प्रद्युम्न ) is the name of a character in the Srimad Bhagavatam . He was the son of Lord Krishna and Rukmini . Pradyumna is considered as one of the four vyuha avatars of Vishnu . According to some accounts , Pradyumna was an incarnation of Kamadeva , the god of love . Pradyumna is also a name of the Hindu god Vishnu , being referred to as Vishnu Ankar Gupta . He is one in 24 Keshava Namas ( names ) , praised in all pujas . It is also the only name in Sanskrit with all the 3 letters joint ( referred as जोडाक्षर )', sentence_starts=[0, 35, 125, 170, 239, 329, 422, 487], selected_sent={'start': 125, 'end': 170, 'string': 'He was the son of Lord Krishna and Rukmini . '}, answer=[Entity(start_offset=35, end_offset=44, type='context', text='Pradyumna', normalized_text='pradyumna')], nq_answers=[[Entity(start_offset=35, end_offset=44, type='context', text='Pradyumna', normalized_text='pradyumna')]], aligned_nps=[(Entity(start_offset=20, end_offset=39, type='question', text='son of lord krishna', normalized_text='son of lord krishna'), Entity(start_offset=132, end_offset=167, type='context', text='the son of Lord Krishna and Rukmini', normalized_text='son of lord krishna and rukmini'))], explanation_type='single_sentence'),\n",
       " -8026170650461141114: QEDExample(example_id=-8026170650461141114, title='Constitution of India', question='who is considered as architect of india constitution', passage='The Constitution of India is the supreme law of India . It lays down the framework defining fundamental political principles , establishes the structure , procedures , powers and duties of government institutions and sets out fundamental rights , directive principles and the duties of citizens . It is the longest written constitution of any sovereign country in the world . B.R. Ambedkar , the chairman of the Drafting Committee , is widely considered to be its chief architect .', sentence_starts=[0, 56, 297, 376, 381], selected_sent={'start': 376, 'end': 481, 'string': 'B.R. Ambedkar , the chairman of the Drafting Committee , is widely considered to be its chief architect .'}, answer=[Entity(start_offset=376, end_offset=389, type='context', text='B.R. Ambedkar', normalized_text='br ambedkar')], nq_answers=[[Entity(start_offset=376, end_offset=430, type='context', text='B.R. Ambedkar , the chairman of the Drafting Committee', normalized_text='br ambedkar chairman of drafting committee')], [Entity(start_offset=376, end_offset=389, type='context', text='B.R. Ambedkar', normalized_text='br ambedkar')]], aligned_nps=[(Entity(start_offset=21, end_offset=52, type='question', text='architect of india constitution', normalized_text='architect of india constitution'), Entity(start_offset=460, end_offset=479, type='context', text='its chief architect', normalized_text='its chief architect'))], explanation_type='single_sentence'),\n",
       " 4235501567333822185: QEDExample(example_id=4235501567333822185, title='Diastema', question='what is the name of the gap between two front teeth', passage='A diastema ( plural diastemata ) is a space or gap between two teeth . Many species of mammals have diastemata as a normal feature , most commonly between the incisors and molars . Diastemata are common for children and can exist in adult teeth as well . Diastemata are primarily caused by imbalance in the relationship between the jaw and the size of teeth . If the labial frenulum ( lip tissue ) pulls , it can also push the teeth apart and cause a diastema between the center of the two front teeth .', sentence_starts=[0, 71, 181, 255, 360], selected_sent={'start': 0, 'end': 71, 'string': 'A diastema ( plural diastemata ) is a space or gap between two teeth . '}, answer=[Entity(start_offset=0, end_offset=10, type='context', text='A diastema', normalized_text='diastema')], nq_answers=[[Entity(start_offset=2, end_offset=10, type='context', text='diastema', normalized_text='diastema')], [Entity(start_offset=2, end_offset=32, type='context', text='diastema ( plural diastemata )', normalized_text='diastema plural diastemata')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -727723498305027307: QEDExample(example_id=-727723498305027307, title='CN Tower', question='how many steps does the cn tower have', passage='A metal staircase reaches the main deck level after 1,776 steps , and the SkyPod 100 m ( 328 ft ) above after 2,579 steps ; it is the tallest metal staircase on Earth . These stairs are intended for emergency use only and are not open to the public , except for two times per year for charity stair - climb events . The average climber takes approximately 30 minutes to climb to the base of the radome , but the fastest climb on record is 7 minutes and 52 seconds in 1989 by Brendan Keenoy , an Ontario Provincial Police officer . In 2002 , Canadian Olympian and Paralympic champion Jeff Adams climbed the stairs of the tower in a specially designed wheelchair . The stairs were originally on one of the three sides of the tower ( facing north ) , with a glass view , but these were later replaced with the third elevator pair and the stairs were moved to the inside of the core . Top climbs on the new , windowless stairwell used since around 2003 have generally been over ten minutes .', sentence_starts=[0, 169, 316, 531, 663, 881], selected_sent={'start': 0, 'end': 169, 'string': 'A metal staircase reaches the main deck level after 1,776 steps , and the SkyPod 100 m ( 328 ft ) above after 2,579 steps ; it is the tallest metal staircase on Earth . '}, answer=[Entity(start_offset=0, end_offset=121, type='context', text='A metal staircase reaches the main deck level after 1,776 steps , and the SkyPod 100 m ( 328 ft ) above after 2,579 steps', normalized_text='metal staircase reaches main deck level after 1776 steps and skypod 100 m 328 ft above after 2579 steps')], nq_answers=[[Entity(start_offset=110, end_offset=115, type='context', text='2,579', normalized_text='2579')], [Entity(start_offset=110, end_offset=121, type='context', text='2,579 steps', normalized_text='2579 steps')]], aligned_nps=[(Entity(start_offset=20, end_offset=32, type='question', text='the cn tower', normalized_text='cn tower'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 4003112133897014732: QEDExample(example_id=4003112133897014732, title='Live in the City of Light', question='simple minds live in the city of light album cover', passage=\"Live In The City Of Light was released as a double vinyl album with the band 's logo in gold lettering over black sleeve . The package featured a 12 '' x 12 '' attached giant - sized booklet with state - of - the - art photography of the band 's performance and outdoor session pictures . This art could not be reproduced faithfully on later CD releases ( an original 1st pressing on double - fat jewel case and the USA version packaged in a long box on two separate discs ) .\", sentence_starts=[0, 123, 289], selected_sent={'start': 0, 'end': 123, 'string': \"Live In The City Of Light was released as a double vinyl album with the band 's logo in gold lettering over black sleeve . \"}, answer=[Entity(start_offset=68, end_offset=120, type='context', text=\"the band 's logo in gold lettering over black sleeve\", normalized_text='band s logo in gold lettering over black sleeve')], nq_answers=[[Entity(start_offset=68, end_offset=120, type='context', text=\"the band 's logo in gold lettering over black sleeve\", normalized_text='band s logo in gold lettering over black sleeve')]], aligned_nps=[(Entity(start_offset=0, end_offset=44, type='question', text='simple minds live in the city of light album', normalized_text='simple minds live in city of light album'), Entity(start_offset=42, end_offset=120, type='context', text=\"a double vinyl album with the band 's logo in gold lettering over black sleeve\", normalized_text='double vinyl album with band s logo in gold lettering over black sleeve'))], explanation_type='single_sentence'),\n",
       " -8883866849303680195: QEDExample(example_id=-8883866849303680195, title='My Three Sons', question=\"who plays steve's wife on my three sons\", passage=\"The following year in the tenth season , 1969 - 1970 , Steve remarries , taking widowed teacher Barbara Harper ( Beverly Garland ) as his wife ; she brings with her a 5 - year - old daughter , Dorothy `` Dodie '' ( Dawn Lyn ) , so Steven now had a stepdaughter whom he also subsequently adopts . ( Dodie is wary of Steve at first , believing that he wants her to simply forget her late father , until he explains that he wants her to always remember and love him , but since he 's no longer alive , Steve wants to raise her in his place , and hopes she 'll come to love him also . ) Also , the last year - and - a-half of the series feature fewer appearances of both Don Grady and Stanley Livingston . Grady 's character was written out of the show at the end of the 11th season , which allowed for his wife Katie and their triplet sons to remain within the Douglas household the following season ( as a structural engineer Robbie was working on a bridge construction in Peru ) . Chip and his teenaged wife Polly ( Ronne Troup ) ( who eloped after Polly 's disciplinarian father refused to sanction their marriage ) move into their own apartment .\", sentence_starts=[0, 296, 583, 702, 980], selected_sent={'start': 0, 'end': 296, 'string': \"The following year in the tenth season , 1969 - 1970 , Steve remarries , taking widowed teacher Barbara Harper ( Beverly Garland ) as his wife ; she brings with her a 5 - year - old daughter , Dorothy `` Dodie '' ( Dawn Lyn ) , so Steven now had a stepdaughter whom he also subsequently adopts . \"}, answer=[Entity(start_offset=113, end_offset=128, type='context', text='Beverly Garland', normalized_text='beverly garland')], nq_answers=[[Entity(start_offset=113, end_offset=128, type='context', text='Beverly Garland', normalized_text='beverly garland')]], aligned_nps=[(Entity(start_offset=10, end_offset=22, type='question', text=\"steve's wife\", normalized_text='steves wife'), Entity(start_offset=134, end_offset=142, type='context', text='his wife', normalized_text='his wife')), (Entity(start_offset=26, end_offset=39, type='question', text='my three sons', normalized_text='my three sons'), Entity(start_offset=22, end_offset=38, type='context', text='the tenth season', normalized_text='tenth season'))], explanation_type='single_sentence'),\n",
       " -8160637999448921796: QEDExample(example_id=-8160637999448921796, title='Cuban Missile Crisis', question='where were the soviet missiles located in cuba', passage='When the reconnaissance missions were reauthorized on October 9 , poor weather kept the planes from flying . The US first obtained U-2 photographic evidence of the missiles on October 14 , when a U-2 flight piloted by Major Richard Heyser took 928 pictures on a path selected by DIA analysts , capturing images of what turned out to be an SS - 4 construction site at San Cristóbal , Pinar del Río Province ( now in Artemisa Province ) , in western Cuba .', sentence_starts=[0, 109], selected_sent={'start': 109, 'end': 454, 'string': 'The US first obtained U-2 photographic evidence of the missiles on October 14 , when a U-2 flight piloted by Major Richard Heyser took 928 pictures on a path selected by DIA analysts , capturing images of what turned out to be an SS - 4 construction site at San Cristóbal , Pinar del Río Province ( now in Artemisa Province ) , in western Cuba .'}, answer=[Entity(start_offset=367, end_offset=452, type='context', text='San Cristóbal , Pinar del Río Province ( now in Artemisa Province ) , in western Cuba', normalized_text='san cristóbal pinar del río province now in artemisa province in western cuba')], nq_answers=[[Entity(start_offset=367, end_offset=452, type='context', text='San Cristóbal , Pinar del Río Province ( now in Artemisa Province ) , in western Cuba', normalized_text='san cristóbal pinar del río province now in artemisa province in western cuba')]], aligned_nps=[(Entity(start_offset=11, end_offset=30, type='question', text='the soviet missiles', normalized_text='soviet missiles'), Entity(start_offset=160, end_offset=172, type='context', text='the missiles', normalized_text='missiles')), (Entity(start_offset=42, end_offset=46, type='question', text='cuba', normalized_text='cuba'), Entity(start_offset=448, end_offset=452, type='context', text='Cuba', normalized_text='cuba'))], explanation_type='single_sentence'),\n",
       " -1082778473368520364: QEDExample(example_id=-1082778473368520364, title='How now brown cow', question='where did the phrase how now brown cow come from', passage=\"`` How now brown cow '' ( / ˈhaʊ ˈnaʊ ˈbraʊn ˈkaʊ / ) is a phrase used in elocution teaching to demonstrate rounded vowel sounds . Each `` ow '' sound in the phrase represents the diphthong / aʊ / . Although orthographies for each of the four words in this utterance is represented by the English spelling `` ow '' , the articulation required to create this same diphthong represented by the International Phonetic Association 's phonetic alphabet as / aʊ / is also represented by the spelling `` ou '' . Some examples of these homophonic / aʊ / 's are the English words `` house '' , `` blouse '' , `` noun '' , and `` cloud '' . The use of the phrase `` how now brown cow '' in teaching elocution can be dated back to at least 1926 . Although not in use today , the phrase `` how now '' is a greeting , short for `` how say you now '' , and can be found in archaic literature , such as the plays of William Shakespeare .\", sentence_starts=[0, 131, 199, 505, 631, 736], selected_sent={'start': 0, 'end': 131, 'string': \"`` How now brown cow '' ( / ˈhaʊ ˈnaʊ ˈbraʊn ˈkaʊ / ) is a phrase used in elocution teaching to demonstrate rounded vowel sounds . \"}, answer=[Entity(start_offset=74, end_offset=128, type='context', text='elocution teaching to demonstrate rounded vowel sounds', normalized_text='elocution teaching to demonstrate rounded vowel sounds')], nq_answers=[[Entity(start_offset=57, end_offset=128, type='context', text='a phrase used in elocution teaching to demonstrate rounded vowel sounds', normalized_text='phrase used in elocution teaching to demonstrate rounded vowel sounds')]], aligned_nps=[(Entity(start_offset=10, end_offset=38, type='question', text='the phrase how now brown cow', normalized_text='phrase how now brown cow'), Entity(start_offset=3, end_offset=20, type='context', text='How now brown cow', normalized_text='how now brown cow'))], explanation_type='single_sentence'),\n",
       " 7851442863470339390: QEDExample(example_id=7851442863470339390, title='John Hancock', question='who signed the largest on the declaration of independence', passage=\"John Hancock ( January 23 , 1737 ( O.S. January 12 , 1736 ) -- October 8 , 1793 ) was an American merchant , statesman , and prominent Patriot of the American Revolution . He served as president of the Second Continental Congress and was the first and third Governor of the Commonwealth of Massachusetts . He is remembered for his large and stylish signature on the United States Declaration of Independence , so much so that the term John Hancock has become a synonym in the United States for one 's signature .\", sentence_starts=[0, 40, 172, 306], selected_sent={'start': 306, 'end': 512, 'string': \"He is remembered for his large and stylish signature on the United States Declaration of Independence , so much so that the term John Hancock has become a synonym in the United States for one 's signature .\"}, answer=[Entity(start_offset=0, end_offset=12, type='context', text='John Hancock', normalized_text='john hancock')], nq_answers=[[Entity(start_offset=0, end_offset=12, type='context', text='John Hancock', normalized_text='john hancock')]], aligned_nps=[(Entity(start_offset=26, end_offset=57, type='question', text='the declaration of independence', normalized_text='declaration of independence'), Entity(start_offset=362, end_offset=407, type='context', text='the United States Declaration of Independence', normalized_text='united states declaration of independence'))], explanation_type='single_sentence'),\n",
       " -1413547797481632580: QEDExample(example_id=-1413547797481632580, title='United Nations Conference on Sustainable Development', question='when was the r10+20 summit in rio de janeiro held', passage='The United Nations Conference on Sustainable Development ( UNCSD ) , also known as Rio 2012 , Rio + 20 ( Portuguese pronunciation : ( ˈʁi. u ˈmajʒ ˈvĩtʃi ) ) , or Earth Summit 2012 was the third international conference on sustainable development aimed at reconciling the economic and environmental goals of the global community . Hosted by Brazil in Rio de Janeiro from 13 to 22 June 2012 , Rio + 20 was a 20 - year follow - up to the 1992 Earth Summit / United Nations Conference on Environment and Development ( UNCED ) held in the same city , and the 10th anniversary of the 2002 World Summit on Sustainable Development ( WSSD ) in Johannesburg .', sentence_starts=[0, 331], selected_sent={'start': 331, 'end': 650, 'string': 'Hosted by Brazil in Rio de Janeiro from 13 to 22 June 2012 , Rio + 20 was a 20 - year follow - up to the 1992 Earth Summit / United Nations Conference on Environment and Development ( UNCED ) held in the same city , and the 10th anniversary of the 2002 World Summit on Sustainable Development ( WSSD ) in Johannesburg .'}, answer=[Entity(start_offset=371, end_offset=389, type='context', text='13 to 22 June 2012', normalized_text='13 to 22 june 2012')], nq_answers=[[Entity(start_offset=371, end_offset=389, type='context', text='13 to 22 June 2012', normalized_text='13 to 22 june 2012')], [Entity(start_offset=380, end_offset=389, type='context', text='June 2012', normalized_text='june 2012')]], aligned_nps=[(Entity(start_offset=9, end_offset=44, type='question', text='the r10+20 summit in rio de janeiro', normalized_text='r1020 summit in rio de janeiro'), Entity(start_offset=392, end_offset=400, type='context', text='Rio + 20', normalized_text='rio 20'))], explanation_type='single_sentence'),\n",
       " 2312273655863950790: QEDExample(example_id=2312273655863950790, title='Small Steps (novel)', question='where did the book small steps take place', passage=\"Two years after his release from Camp Green Lake , Theodore `` Armpit '' Johnson is living in Austin , Texas trying to build a stable lifestyle by digging deep holes and caring for his neighbor Ginny McDonald , a ten - year - old girl with cerebral palsy . While working at the mayor 's home , he is approached by Rex `` X-Ray '' Washburn , one of his friends from Camp Green Lake , who wants Armpit to loan him money for a ticket scalping scheme for an upcoming concert by teen pop star Kaira Deleon . Armpit agrees , and at first the scheme seems to go as planned .\", sentence_starts=[0, 257, 503], selected_sent={'start': 0, 'end': 257, 'string': \"Two years after his release from Camp Green Lake , Theodore `` Armpit '' Johnson is living in Austin , Texas trying to build a stable lifestyle by digging deep holes and caring for his neighbor Ginny McDonald , a ten - year - old girl with cerebral palsy . \"}, answer=[Entity(start_offset=94, end_offset=108, type='context', text='Austin , Texas', normalized_text='austin texas')], nq_answers=[[Entity(start_offset=94, end_offset=108, type='context', text='Austin , Texas', normalized_text='austin texas')]], aligned_nps=[(Entity(start_offset=10, end_offset=30, type='question', text='the book small steps', normalized_text='book small steps'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 947093291536268916: QEDExample(example_id=947093291536268916, title='Pretty Little Liars (season 7)', question='how many episodes are in season 7 of pretty little liars', passage=\"The season consisted of 20 episodes , in which ten episodes aired in the summer of 2016 , with the remaining ten episodes aired from April 2017 . The season 's premiere aired on June 21 , 2016 , on Freeform . Production and filming began in the end of March 2016 , which was confirmed by showrunner I. Marlene King . The season premiere was written by I. Marlene King and directed by Ron Lagomarsino . King revealed the title of the premiere on Twitter on March 17 , 2016 . On August 29 , 2016 , it was confirmed that this would be the final season of the series .\", sentence_starts=[0, 146, 209, 317, 402, 474], selected_sent={'start': 0, 'end': 146, 'string': 'The season consisted of 20 episodes , in which ten episodes aired in the summer of 2016 , with the remaining ten episodes aired from April 2017 . '}, answer=[Entity(start_offset=24, end_offset=26, type='context', text='20', normalized_text='20')], nq_answers=[[Entity(start_offset=24, end_offset=26, type='context', text='20', normalized_text='20')]], aligned_nps=[(Entity(start_offset=25, end_offset=56, type='question', text='season 7 of pretty little liars', normalized_text='season 7 of pretty little liars'), Entity(start_offset=0, end_offset=10, type='context', text='The season', normalized_text='season'))], explanation_type='single_sentence'),\n",
       " -4036894528440923365: QEDExample(example_id=-4036894528440923365, title='Robot', question=\"where did the term 'robot' come from\", passage=\"The term comes from a Czech word , robota , meaning `` forced labor '' ; the word ' robot ' was first used to denote a fictional humanoid in a 1920 play R.U.R. by the Czech writer , Karel Čapek but it was Karel 's brother Josef Čapek who was the word 's true inventor . Electronics evolved into the driving force of development with the advent of the first electronic autonomous robots created by William Grey Walter in Bristol , England in 1948 , as well as Computer Numerical Control ( CNC ) machine tools in the late 1940s by John T. Parsons and Frank L. Stulen . The first commercial , digital and programmable robot was built by George Devol in 1954 and was named the Unimate . It was sold to General Motors in 1961 where it was used to lift pieces of hot metal from die casting machines at the Inland Fisher Guide Plant in the West Trenton section of Ewing Township , New Jersey .\", sentence_starts=[0, 160, 270, 567, 683], selected_sent={'start': 0, 'end': 160, 'string': \"The term comes from a Czech word , robota , meaning `` forced labor '' ; the word ' robot ' was first used to denote a fictional humanoid in a 1920 play R.U.R. \"}, answer=[Entity(start_offset=15, end_offset=70, type='context', text=\"from a Czech word , robota , meaning `` forced labor ''\", normalized_text='from czech word robota meaning forced labor')], nq_answers=[[Entity(start_offset=15, end_offset=70, type='context', text=\"from a Czech word , robota , meaning `` forced labor ''\", normalized_text='from czech word robota meaning forced labor')], [Entity(start_offset=22, end_offset=27, type='context', text='Czech', normalized_text='czech')], [Entity(start_offset=141, end_offset=193, type='context', text='a 1920 play R.U.R. by the Czech writer , Karel Čapek', normalized_text='1920 play rur by czech writer karel čapek')]], aligned_nps=[(Entity(start_offset=10, end_offset=26, type='question', text=\"the term 'robot'\", normalized_text='term robot'), Entity(start_offset=0, end_offset=8, type='context', text='The term', normalized_text='term'))], explanation_type='single_sentence'),\n",
       " 4479358397781065399: QEDExample(example_id=4479358397781065399, title='South Pole', question='where is south pole located on a map', passage=\"The Geographic South Pole is located on the continent of Antarctica ( although this has not been the case for all of Earth 's history because of continental drift ) . It sits atop a featureless , barren , windswept and icy plateau at an altitude of 2,835 metres ( 9,301 ft ) above sea level , and is located about 1,300 km ( 800 mi ) from the nearest open sea at Bay of Whales . The ice is estimated to be about 2,700 metres ( 9,000 ft ) thick at the Pole , so the land surface under the ice sheet is actually near sea level .\", sentence_starts=[0, 167, 379], selected_sent={'start': 0, 'end': 167, 'string': \"The Geographic South Pole is located on the continent of Antarctica ( although this has not been the case for all of Earth 's history because of continental drift ) . \"}, answer=[Entity(start_offset=37, end_offset=67, type='context', text='on the continent of Antarctica', normalized_text='on continent of antarctica')], nq_answers=[[Entity(start_offset=37, end_offset=67, type='context', text='on the continent of Antarctica', normalized_text='on continent of antarctica')]], aligned_nps=[(Entity(start_offset=9, end_offset=19, type='question', text='south pole', normalized_text='south pole'), Entity(start_offset=0, end_offset=25, type='context', text='The Geographic South Pole', normalized_text='geographic south pole'))], explanation_type='single_sentence'),\n",
       " 2448678927070663694: QEDExample(example_id=2448678927070663694, title='Roger Dean Stadium', question='where do the florida marlins have spring training', passage='Roger Dean Stadium is one of only two stadiums in Florida to host two Major League Baseball teams annually for spring training : the Miami Marlins and St. Louis Cardinals ( the other is The Ballpark of The Palm Beaches , which opened in 2017 , hosting the Washington Nationals and Houston Astros ) . In both venues , the teams share the main stadium where the games are played . However , the teams have their own practice fields , outdoor batting cages , several pitching mounds , and state - of - the - art conditioning rooms .', sentence_starts=[0, 300, 379], selected_sent={'start': 0, 'end': 300, 'string': 'Roger Dean Stadium is one of only two stadiums in Florida to host two Major League Baseball teams annually for spring training : the Miami Marlins and St. Louis Cardinals ( the other is The Ballpark of The Palm Beaches , which opened in 2017 , hosting the Washington Nationals and Houston Astros ) . '}, answer=[Entity(start_offset=0, end_offset=18, type='context', text='Roger Dean Stadium', normalized_text='roger dean stadium')], nq_answers=[[Entity(start_offset=0, end_offset=18, type='context', text='Roger Dean Stadium', normalized_text='roger dean stadium')]], aligned_nps=[(Entity(start_offset=9, end_offset=28, type='question', text='the florida marlins', normalized_text='florida marlins'), Entity(start_offset=129, end_offset=146, type='context', text='the Miami Marlins', normalized_text='miami marlins'))], explanation_type='single_sentence'),\n",
       " 5719567211015639388: QEDExample(example_id=5719567211015639388, title='The Nightmare Before Christmas', question='who is the director of nightmare before christmas', passage=\"The Nightmare Before Christmas ( also known as Tim Burton 's The Nightmare Before Christmas ) is a 1993 American stop - motion animated musical dark fantasy film directed by Henry Selick , and produced and conceived by Tim Burton . It tells the story of Jack Skellington , a resident from `` Halloween Town '' who stumbles through a portal to `` Christmas Town '' and decides to celebrate the holiday , with some dastardly and comical consequences . Danny Elfman wrote the songs and score , and provided the singing voice of Jack . The principal voice cast also includes Chris Sarandon , Catherine O'Hara , William Hickey , Ken Page , Paul Reubens , and Glenn Shadix .\", sentence_starts=[0, 232, 450, 532], selected_sent={'start': 0, 'end': 232, 'string': \"The Nightmare Before Christmas ( also known as Tim Burton 's The Nightmare Before Christmas ) is a 1993 American stop - motion animated musical dark fantasy film directed by Henry Selick , and produced and conceived by Tim Burton . \"}, answer=[Entity(start_offset=174, end_offset=186, type='context', text='Henry Selick', normalized_text='henry selick')], nq_answers=[[Entity(start_offset=174, end_offset=186, type='context', text='Henry Selick', normalized_text='henry selick')]], aligned_nps=[(Entity(start_offset=23, end_offset=49, type='question', text='nightmare before christmas', normalized_text='nightmare before christmas'), Entity(start_offset=0, end_offset=30, type='context', text='The Nightmare Before Christmas', normalized_text='nightmare before christmas'))], explanation_type='single_sentence'),\n",
       " 206259850951848123: QEDExample(example_id=206259850951848123, title='Baaghi (2016 film)', question='tiger shroff and shraddha kapoor new movie name', passage='Baaghi ( English : Rebel ) is a 2016 Indian martial arts film directed by Sabbir Khan and produced by Sajid Nadiadwala under his banner Nadiadwala Grandson Entertainment . It features Tiger Shroff and Shraddha Kapoor in lead roles , with Sudheer Babu and Sunil Grover in supporting roles . Journalists noted similarities between the film and the 2011 Indonesian film The Raid : Redemption and the 2004 Telugu - language Indian film Varsham .', sentence_starts=[0, 172, 290], selected_sent={'start': 172, 'end': 290, 'string': 'It features Tiger Shroff and Shraddha Kapoor in lead roles , with Sudheer Babu and Sunil Grover in supporting roles . '}, answer=[Entity(start_offset=0, end_offset=26, type='context', text='Baaghi ( English : Rebel )', normalized_text='baaghi english rebel')], nq_answers=[[Entity(start_offset=0, end_offset=26, type='context', text='Baaghi ( English : Rebel )', normalized_text='baaghi english rebel')]], aligned_nps=[(Entity(start_offset=0, end_offset=12, type='question', text='tiger shroff', normalized_text='tiger shroff'), Entity(start_offset=184, end_offset=196, type='context', text='Tiger Shroff', normalized_text='tiger shroff')), (Entity(start_offset=17, end_offset=32, type='question', text='shraddha kapoor', normalized_text='shraddha kapoor'), Entity(start_offset=201, end_offset=216, type='context', text='Shraddha Kapoor', normalized_text='shraddha kapoor'))], explanation_type='single_sentence'),\n",
       " -454207605481343797: QEDExample(example_id=-454207605481343797, title='Social justice', question='when was the term social justice first used', passage=\"While the concept of social justice can be traced through the theology of Augustine of Hippo and the philosophy of Thomas Paine , the term `` social justice '' became used explicitly from the 1840s . A Jesuit priest named Luigi Taparelli is typically credited with coining the term , and it spread during the revolutions of 1848 with the work of Antonio Rosmini - Serbati . In the late industrial revolution , progressive American legal scholars began to use the term more , particularly Louis Brandeis and Roscoe Pound . From the early 20th century it was also embedded in international law and institutions ; the preamble to establish the International Labour Organization recalled that `` universal and lasting peace can be established only if it is based upon social justice . '' In the later 20th century , social justice was made central to the philosophy of the social contract , primarily by John Rawls in A Theory of Justice ( 1971 ) . In 1993 , the Vienna Declaration and Programme of Action treats social justice as a purpose of human rights education .\", sentence_starts=[0, 200, 374, 522, 784, 945], selected_sent={'start': 0, 'end': 200, 'string': \"While the concept of social justice can be traced through the theology of Augustine of Hippo and the philosophy of Thomas Paine , the term `` social justice '' became used explicitly from the 1840s . \"}, answer=[Entity(start_offset=188, end_offset=197, type='context', text='the 1840s', normalized_text='1840s')], nq_answers=[[Entity(start_offset=192, end_offset=197, type='context', text='1840s', normalized_text='1840s')]], aligned_nps=[(Entity(start_offset=9, end_offset=32, type='question', text='the term social justice', normalized_text='term social justice'), Entity(start_offset=130, end_offset=159, type='context', text=\"the term `` social justice ''\", normalized_text='term social justice'))], explanation_type='single_sentence'),\n",
       " -8508097902776503936: QEDExample(example_id=-8508097902776503936, title='Middle-Eastern cuisine', question='what is the word for clarified butter in the balkans and middle east', passage='Butter and clarified butter ( also known as smen ) are , traditionally , the preferred medium of cooking . Olive oil is prevalent in the Mediterranean coastal areas . Christians use it during Lent , when meat and dairy products are excluded , and Jews use it in place of animal fats such as butter to avoid mixing meat and dairy products .', sentence_starts=[0, 107, 167], selected_sent={'start': 0, 'end': 107, 'string': 'Butter and clarified butter ( also known as smen ) are , traditionally , the preferred medium of cooking . '}, answer=[Entity(start_offset=44, end_offset=48, type='context', text='smen', normalized_text='smen')], nq_answers=[[Entity(start_offset=44, end_offset=48, type='context', text='smen', normalized_text='smen')]], aligned_nps=[(Entity(start_offset=41, end_offset=68, type='question', text='the balkans and middle east', normalized_text='balkans and middle east'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 679914466501587278: QEDExample(example_id=679914466501587278, title='Sebastian Shaw (actor)', question='who is under the mask of darth vader', passage='Shaw was particularly known for his performances in productions of Shakespeare plays which were considered daring and ahead of their time . In 1966 , he joined the Royal Shakespeare Company , where he remained for a decade and delivered some of his most acclaimed performances . He also wrote several poems and a novel , The Christening , in 1975 . He is also known for his brief but important performance in Return of the Jedi , the original third installment in the Star Wars franchise , in which he portrayed an unmasked and redeemed Anakin Skywalker ( formerly Darth Vader ) , and his ghost in the original version of the film .', sentence_starts=[0, 140, 279, 349], selected_sent={'start': 349, 'end': 632, 'string': 'He is also known for his brief but important performance in Return of the Jedi , the original third installment in the Star Wars franchise , in which he portrayed an unmasked and redeemed Anakin Skywalker ( formerly Darth Vader ) , and his ghost in the original version of the film .'}, answer=[Entity(start_offset=537, end_offset=553, type='context', text='Anakin Skywalker', normalized_text='anakin skywalker')], nq_answers=[[Entity(start_offset=537, end_offset=553, type='context', text='Anakin Skywalker', normalized_text='anakin skywalker')]], aligned_nps=[(Entity(start_offset=25, end_offset=36, type='question', text='darth vader', normalized_text='darth vader'), Entity(start_offset=565, end_offset=576, type='context', text='Darth Vader', normalized_text='darth vader'))], explanation_type='single_sentence'),\n",
       " 3411217364166344563: QEDExample(example_id=3411217364166344563, title=\"Harry Potter and the Philosopher's Stone\", question='when was harry potter and the philosophers stone published', passage=\"Harry Potter and the Philosopher 's Stone is a fantasy novel written by British author J.K. Rowling . It is the first novel in the Harry Potter series and Rowling 's debut novel , first published in 1997 by Bloomsbury . It was published in the United States as Harry Potter and the Sorcerer 's Stone by Scholastic Corporation in 1998 . The plot follows Harry Potter , a young wizard who discovers his magical heritage as he makes close friends and a few enemies in his first year at the Hogwarts School of Witchcraft and Wizardry . With the help of his friends , Harry faces an attempted comeback by the dark wizard Lord Voldemort , who killed Harry 's parents , but failed to kill Harry when he was just 15 months old .\", sentence_starts=[0, 92, 102, 220, 336, 532], selected_sent={'start': 102, 'end': 220, 'string': \"It is the first novel in the Harry Potter series and Rowling 's debut novel , first published in 1997 by Bloomsbury . \"}, answer=[Entity(start_offset=199, end_offset=203, type='context', text='1997', normalized_text='1997')], nq_answers=[[Entity(start_offset=199, end_offset=203, type='context', text='1997', normalized_text='1997')], [Entity(start_offset=196, end_offset=203, type='context', text='in 1997', normalized_text='in 1997')]], aligned_nps=[(Entity(start_offset=9, end_offset=48, type='question', text='harry potter and the philosophers stone', normalized_text='harry potter and philosophers stone'), Entity(start_offset=102, end_offset=104, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -3476455683698256952: QEDExample(example_id=-3476455683698256952, title='Jimmy Flynn', question='who played the judge in good will hunting', passage=\"Flynn appeared in many films shot in the New England area . In show business he goes by the name ' James P. Flynn ' . Flynn was cast as a judge in the Boston - based film Good Will Hunting in 1997 . Later , he acted in the 1999 film The Cider House Rules and What 's the Worst That Could Happen ? in 2001 . He was also a truck driver for movie production equipment during the filming of My Best Friend 's Girl in 2008 . Boston actor Tom Kemp remarked : `` ( The film The Departed ) would n't be a Boston movie without me , a Wahlberg , and Jimmy Flynn from the teamsters . ''\", sentence_starts=[0, 60, 118, 199, 297, 307, 420], selected_sent={'start': 118, 'end': 199, 'string': 'Flynn was cast as a judge in the Boston - based film Good Will Hunting in 1997 . '}, answer=[Entity(start_offset=99, end_offset=113, type='context', text='James P. Flynn', normalized_text='james p flynn')], nq_answers=[[Entity(start_offset=99, end_offset=113, type='context', text='James P. Flynn', normalized_text='james p flynn')]], aligned_nps=[(Entity(start_offset=11, end_offset=20, type='question', text='the judge', normalized_text='judge'), Entity(start_offset=136, end_offset=143, type='context', text='a judge', normalized_text='judge')), (Entity(start_offset=24, end_offset=41, type='question', text='good will hunting', normalized_text='good will hunting'), Entity(start_offset=147, end_offset=188, type='context', text='the Boston - based film Good Will Hunting', normalized_text='boston based film good will hunting'))], explanation_type='single_sentence'),\n",
       " 2351468410839009011: QEDExample(example_id=2351468410839009011, title=\"Daddy's Home 2\", question=\"what state did they film daddy's home 2\", passage='Principal photography on the film began in Massachusetts in March 2017 and it was released in the United States by Paramount Pictures on November 10 , 2017 . Although the film received unfavorable reviews , it has grossed over $180 million worldwide on a $69 million budget .', sentence_starts=[0, 158], selected_sent={'start': 0, 'end': 158, 'string': 'Principal photography on the film began in Massachusetts in March 2017 and it was released in the United States by Paramount Pictures on November 10 , 2017 . '}, answer=[Entity(start_offset=43, end_offset=56, type='context', text='Massachusetts', normalized_text='massachusetts')], nq_answers=[[Entity(start_offset=43, end_offset=56, type='context', text='Massachusetts', normalized_text='massachusetts')]], aligned_nps=[(Entity(start_offset=25, end_offset=39, type='question', text=\"daddy's home 2\", normalized_text='daddys home 2'), Entity(start_offset=25, end_offset=33, type='context', text='the film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " -295049090356671696: QEDExample(example_id=-295049090356671696, title='Does He Love You', question='who sang the song with reba does he love you', passage=\"`` Does He Love You '' is a song written by Sandy Knox and Billy Stritch , and recorded as a duet by American country music artists Reba McEntire and Linda Davis . It was released in August 1993 as the first single from Reba 's album Greatest Hits Volume Two . It is one of country music 's several songs about a love triangle .\", sentence_starts=[0, 164, 261], selected_sent={'start': 0, 'end': 164, 'string': \"`` Does He Love You '' is a song written by Sandy Knox and Billy Stritch , and recorded as a duet by American country music artists Reba McEntire and Linda Davis . \"}, answer=[Entity(start_offset=132, end_offset=161, type='context', text='Reba McEntire and Linda Davis', normalized_text='reba mcentire and linda davis')], nq_answers=[[Entity(start_offset=150, end_offset=161, type='context', text='Linda Davis', normalized_text='linda davis')]], aligned_nps=[(Entity(start_offset=9, end_offset=44, type='question', text='the song with reba does he love you', normalized_text='song with reba does he love you'), Entity(start_offset=3, end_offset=19, type='context', text='Does He Love You', normalized_text='does he love you'))], explanation_type='single_sentence'),\n",
       " -2202492303403575297: QEDExample(example_id=-2202492303403575297, title='Accounts receivable', question='what is the source of information for account receivables', passage='Accounts receivable is a legally enforceable claim for payment held by a business for goods supplied and / or services rendered that customers / clients have ordered but not paid for . These are generally in the form of invoices raised by a business and delivered to the customer for payment within an agreed time frame . Accounts receivable is shown in a balance sheet as an asset . It is one of a series of accounting transactions dealing with the billing of a customer for goods and services that the customer has ordered . These may be distinguished from notes receivable , which are debts created through formal legal instruments called promissory notes .', sentence_starts=[0, 185, 322, 384, 527], selected_sent={'start': 185, 'end': 322, 'string': 'These are generally in the form of invoices raised by a business and delivered to the customer for payment within an agreed time frame . '}, answer=[Entity(start_offset=220, end_offset=228, type='context', text='invoices', normalized_text='invoices')], nq_answers=[[Entity(start_offset=220, end_offset=228, type='context', text='invoices', normalized_text='invoices')], [Entity(start_offset=220, end_offset=319, type='context', text='invoices raised by a business and delivered to the customer for payment within an agreed time frame', normalized_text='invoices raised by business and delivered to customer for payment within agreed time frame')]], aligned_nps=[(Entity(start_offset=38, end_offset=57, type='question', text='account receivables', normalized_text='account receivables'), Entity(start_offset=185, end_offset=190, type='context', text='These', normalized_text='these'))], explanation_type='single_sentence'),\n",
       " -2212094428102896502: QEDExample(example_id=-2212094428102896502, title='Stratum lucidum', question='skin that covers the palms fingertips and soles of the feet', passage=\"The stratum lucidum ( Latin for `` clear layer '' ) is a thin , clear layer of dead skin cells in the epidermis named for its translucent appearance under a microscope . It is readily visible by light microscopy only in areas of thick skin , which are found on the palms of the hands and the soles of the feet .\", sentence_starts=[0, 170], selected_sent={'start': 170, 'end': 311, 'string': 'It is readily visible by light microscopy only in areas of thick skin , which are found on the palms of the hands and the soles of the feet .'}, answer=[Entity(start_offset=0, end_offset=51, type='context', text=\"The stratum lucidum ( Latin for `` clear layer '' )\", normalized_text='stratum lucidum latin for clear layer')], nq_answers=[[Entity(start_offset=0, end_offset=51, type='context', text=\"The stratum lucidum ( Latin for `` clear layer '' )\", normalized_text='stratum lucidum latin for clear layer')], [Entity(start_offset=4, end_offset=19, type='context', text='stratum lucidum', normalized_text='stratum lucidum')]], aligned_nps=[(Entity(start_offset=17, end_offset=26, type='question', text='the palms', normalized_text='palms'), Entity(start_offset=261, end_offset=283, type='context', text='the palms of the hands', normalized_text='palms of hands')), (Entity(start_offset=42, end_offset=59, type='question', text='soles of the feet', normalized_text='soles of feet'), Entity(start_offset=288, end_offset=309, type='context', text='the soles of the feet', normalized_text='soles of feet'))], explanation_type='single_sentence'),\n",
       " -7478789317953347820: QEDExample(example_id=-7478789317953347820, title='History of the Indian National Congress', question='who laid the foundation for indian national congress', passage='From its foundation on 28 December 1885 by 72 individuals with the active help by A.O Hume , a retired British officer , until the time of independence of India on 15 August 1947 , the Indian National Congress was considered to be the largest and most prominent Indian public organization , and central and defining influence of the Indian Independence Movement .', sentence_starts=[0], selected_sent={'start': 0, 'end': 363, 'string': 'From its foundation on 28 December 1885 by 72 individuals with the active help by A.O Hume , a retired British officer , until the time of independence of India on 15 August 1947 , the Indian National Congress was considered to be the largest and most prominent Indian public organization , and central and defining influence of the Indian Independence Movement .'}, answer=[Entity(start_offset=82, end_offset=118, type='context', text='A.O Hume , a retired British officer', normalized_text='ao hume retired british officer')], nq_answers=[[Entity(start_offset=82, end_offset=118, type='context', text='A.O Hume , a retired British officer', normalized_text='ao hume retired british officer')]], aligned_nps=[(Entity(start_offset=28, end_offset=52, type='question', text='indian national congress', normalized_text='indian national congress'), Entity(start_offset=181, end_offset=209, type='context', text='the Indian National Congress', normalized_text='indian national congress'))], explanation_type='single_sentence'),\n",
       " -2666014283344944039: QEDExample(example_id=-2666014283344944039, title='The Lost City of Z (film)', question='who dies in the lost city of z', passage=\"Murray survives and , in front of the RGS trustees , accuses Fawcett of abandoning him in the jungle . Fawcett elects to resign from the society rather than apologize . World War I breaks out in Europe , and Fawcett goes to France to fight . Manley dies in the trenches at the Battle of the Somme , and Fawcett is temporarily blinded in a chlorine gas attack . Jack , Fawcett 's eldest son -- who had long accused Fawcett of abandoning the family -- reconciles with his father as he recovers .\", sentence_starts=[0, 103, 169, 242, 361], selected_sent={'start': 242, 'end': 361, 'string': 'Manley dies in the trenches at the Battle of the Somme , and Fawcett is temporarily blinded in a chlorine gas attack . '}, answer=[Entity(start_offset=242, end_offset=248, type='context', text='Manley', normalized_text='manley')], nq_answers=[[Entity(start_offset=242, end_offset=248, type='context', text='Manley', normalized_text='manley')]], aligned_nps=[(Entity(start_offset=12, end_offset=30, type='question', text='the lost city of z', normalized_text='lost city of z'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 7383354502292277568: QEDExample(example_id=7383354502292277568, title='List of Oklahoma Sooners football championships', question='when was the last time oklahoma won a national championship in football', passage='The team has captured 47 conference titles , including 14 in a row between 1946 -- 59 , eight divisional titles , and seven claimed national championships : 1950 , 1955 , 1956 , 1974 , 1975 , 1985 , 2000 . In addition to the seven claimed national titles the NCAA also recognizes 10 others : 1915 , 1949 , 1953 , 1957 , 1967 , 1973 , 1978 , 1980 , 1986 , and 2003 .', sentence_starts=[0, 206], selected_sent={'start': 0, 'end': 206, 'string': 'The team has captured 47 conference titles , including 14 in a row between 1946 -- 59 , eight divisional titles , and seven claimed national championships : 1950 , 1955 , 1956 , 1974 , 1975 , 1985 , 2000 . '}, answer=[Entity(start_offset=199, end_offset=203, type='context', text='2000', normalized_text='2000')], nq_answers=[[Entity(start_offset=199, end_offset=203, type='context', text='2000', normalized_text='2000')], [Entity(start_offset=359, end_offset=363, type='context', text='2003', normalized_text='2003')]], aligned_nps=[(Entity(start_offset=23, end_offset=31, type='question', text='oklahoma', normalized_text='oklahoma'), Entity(start_offset=0, end_offset=8, type='context', text='The team', normalized_text='team'))], explanation_type='single_sentence'),\n",
       " 9148233787183514779: QEDExample(example_id=9148233787183514779, title=\"It's My Party (Lesley Gore song)\", question=\"who sang it my party and i'll cry if i want to in the 80\", passage='In 1981 , a remake by British artists Dave Stewart and Barbara Gaskin was a UK number one hit single for four weeks and was also a major hit in Austria ( # 3 ) , Germany ( # 3 ) , the Netherlands ( # 20 ) , New Zealand ( # 1 ) , South Africa ( # 3 ) and Switzerland ( # 6 ) . The track reached # 72 in the US . This was the first version of the song to reach # 1 in the UK . The video for the Stewart / Gaskin version contained a cameo by Thomas Dolby as Johnny , Judy being played by Gaskin in a blond wig .', sentence_starts=[0, 276, 311, 375], selected_sent={'start': 0, 'end': 276, 'string': 'In 1981 , a remake by British artists Dave Stewart and Barbara Gaskin was a UK number one hit single for four weeks and was also a major hit in Austria ( # 3 ) , Germany ( # 3 ) , the Netherlands ( # 20 ) , New Zealand ( # 1 ) , South Africa ( # 3 ) and Switzerland ( # 6 ) . '}, answer=[Entity(start_offset=38, end_offset=69, type='context', text='Dave Stewart and Barbara Gaskin', normalized_text='dave stewart and barbara gaskin')], nq_answers=[[Entity(start_offset=38, end_offset=69, type='context', text='Dave Stewart and Barbara Gaskin', normalized_text='dave stewart and barbara gaskin')], [Entity(start_offset=38, end_offset=50, type='context', text='Dave Stewart', normalized_text='dave stewart'), Entity(start_offset=55, end_offset=69, type='context', text='Barbara Gaskin', normalized_text='barbara gaskin')], [Entity(start_offset=22, end_offset=69, type='context', text='British artists Dave Stewart and Barbara Gaskin', normalized_text='british artists dave stewart and barbara gaskin')]], aligned_nps=[(Entity(start_offset=9, end_offset=46, type='question', text=\"it my party and i'll cry if i want to\", normalized_text='it my party and ill cry if i want to'), Entity(start_offset=10, end_offset=18, type='context', text='a remake', normalized_text='remake'))], explanation_type='single_sentence'),\n",
       " 4046851836203380467: QEDExample(example_id=4046851836203380467, title='Data Protection Act 1998', question='legislation regarding data protection and security in uk', passage='The Data Protection Act 1998 ( c 29 ) is a United Kingdom Act of Parliament designed to protect personal data stored on computers or in an organised paper filing system . It follows the EU Data Protection Directive 1995 protection , processing and movement of data . Individuals have legal rights to control information about themselves . Most of the Act does not apply to domestic use , for example keeping a personal address book . Anyone holding personal data for other purposes is legally obliged to comply with this Act , subject to some exemptions . The Act defines eight data protection principles to ensure that information is processed lawfully .', sentence_starts=[0, 171, 267, 339, 434, 556], selected_sent={'start': 0, 'end': 171, 'string': 'The Data Protection Act 1998 ( c 29 ) is a United Kingdom Act of Parliament designed to protect personal data stored on computers or in an organised paper filing system . '}, answer=[Entity(start_offset=0, end_offset=37, type='context', text='The Data Protection Act 1998 ( c 29 )', normalized_text='data protection act 1998 c 29')], nq_answers=[[Entity(start_offset=0, end_offset=28, type='context', text='The Data Protection Act 1998', normalized_text='data protection act 1998')], [Entity(start_offset=4, end_offset=28, type='context', text='Data Protection Act 1998', normalized_text='data protection act 1998')]], aligned_nps=[(Entity(start_offset=54, end_offset=56, type='question', text='uk', normalized_text='uk'), Entity(start_offset=43, end_offset=57, type='context', text='United Kingdom', normalized_text='united kingdom'))], explanation_type='single_sentence'),\n",
       " 2845443756485516190: QEDExample(example_id=2845443756485516190, title='Eurostar', question='where does the eurostar train arrives in london', passage='The London terminus is St Pancras International , the other British calling points being Ebbsfleet International and Ashford International in Kent . Intermediate calling points in France are Calais - Fréthun and Lille - Europe , with trains to Paris terminating at Gare du Nord . Trains to Belgium terminate at Midi / Zuid station in Brussels . The only intermediate calling point in the Netherlands is Rotterdam Centraal , with trains terminating at Amsterdam Centraal . In addition , there are limited services from London to Disneyland Paris at Marne - la - Vallée -- Chessy , direct services to southern France ( Lyon , Avignon and Marseille ) from May to September ( launched on 1 May 2015 ) , and seasonal direct services to the French Alps in winter ( December to April ) .', sentence_starts=[0, 149, 280, 345, 472], selected_sent={'start': 0, 'end': 149, 'string': 'The London terminus is St Pancras International , the other British calling points being Ebbsfleet International and Ashford International in Kent . '}, answer=[Entity(start_offset=23, end_offset=47, type='context', text='St Pancras International', normalized_text='st pancras international')], nq_answers=[[Entity(start_offset=23, end_offset=47, type='context', text='St Pancras International', normalized_text='st pancras international')]], aligned_nps=[(Entity(start_offset=41, end_offset=47, type='question', text='london', normalized_text='london'), Entity(start_offset=4, end_offset=10, type='context', text='London', normalized_text='london')), (Entity(start_offset=11, end_offset=29, type='question', text='the eurostar train', normalized_text='eurostar train'), Entity(start_offset=0, end_offset=19, type='context', text='The London terminus', normalized_text='london terminus'))], explanation_type='single_sentence'),\n",
       " 6179269244500661868: QEDExample(example_id=6179269244500661868, title='Free Trade Area of the Americas', question='what would the free trade agreement of the americas (ftaa) do', passage='The Free Trade Area of the Americas ( FTAA ; Spanish : Área de Libre Comercio de las Américas , ALCA ; French : Zone de libre - échange des Amériques , ZLÉA ; Portuguese : Área de Livre Comércio das Américas , ALCA ; Dutch : Vrijhandelszone van Amerika ) was a proposed agreement to eliminate or reduce the trade barriers among all countries in the Americas , excluding Cuba .', sentence_starts=[0], selected_sent={'start': 0, 'end': 376, 'string': 'The Free Trade Area of the Americas ( FTAA ; Spanish : Área de Libre Comercio de las Américas , ALCA ; French : Zone de libre - échange des Amériques , ZLÉA ; Portuguese : Área de Livre Comércio das Américas , ALCA ; Dutch : Vrijhandelszone van Amerika ) was a proposed agreement to eliminate or reduce the trade barriers among all countries in the Americas , excluding Cuba .'}, answer=[Entity(start_offset=283, end_offset=374, type='context', text='eliminate or reduce the trade barriers among all countries in the Americas , excluding Cuba', normalized_text='eliminate or reduce trade barriers among all countries in americas excluding cuba')], nq_answers=[[Entity(start_offset=283, end_offset=374, type='context', text='eliminate or reduce the trade barriers among all countries in the Americas , excluding Cuba', normalized_text='eliminate or reduce trade barriers among all countries in americas excluding cuba')], [Entity(start_offset=280, end_offset=374, type='context', text='to eliminate or reduce the trade barriers among all countries in the Americas , excluding Cuba', normalized_text='to eliminate or reduce trade barriers among all countries in americas excluding cuba')]], aligned_nps=[(Entity(start_offset=11, end_offset=58, type='question', text='the free trade agreement of the americas (ftaa)', normalized_text='free trade agreement of americas ftaa'), Entity(start_offset=0, end_offset=35, type='context', text='The Free Trade Area of the Americas', normalized_text='free trade area of americas'))], explanation_type='single_sentence'),\n",
       " 4403328729170059703: QEDExample(example_id=4403328729170059703, title='Krypton-85', question='krypton-85 decays by emission of a beta particle. the product of this decay is', passage='It has a half - life of 10.756 years and a maximum decay energy of 687 keV . It decays into stable , non-radioactive rubidium - 85 . Its most common decay ( 99.57 % ) is by beta particle emission with maximum energy of 687 keV and an average energy of 251 keV . The second most common decay ( 0.43 % ) is by beta particle emission ( maximum energy of 173 keV ) followed by gamma ray emission ( energy of 514 keV ) . Other decay modes have very small probabilities and emit less energetic gammas . There are 33 other known isotopes of krypton .', sentence_starts=[0, 77, 133, 262, 416, 497], selected_sent={'start': 77, 'end': 133, 'string': 'It decays into stable , non-radioactive rubidium - 85 . '}, answer=[Entity(start_offset=92, end_offset=130, type='context', text='stable , non-radioactive rubidium - 85', normalized_text='stable nonradioactive rubidium 85')], nq_answers=[[Entity(start_offset=117, end_offset=130, type='context', text='rubidium - 85', normalized_text='rubidium 85')], [Entity(start_offset=92, end_offset=130, type='context', text='stable , non-radioactive rubidium - 85', normalized_text='stable nonradioactive rubidium 85')]], aligned_nps=[(Entity(start_offset=0, end_offset=10, type='question', text='krypton-85', normalized_text='krypton85'), Entity(start_offset=77, end_offset=79, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -5462359833619124697: QEDExample(example_id=-5462359833619124697, title='Every Light in the House', question='who sings every light in the house is on', passage=\"`` Every Light in the House '' is a song written by Kent Robbins and recorded by American country music artist Trace Adkins . It was released in August 1996 as the second single from his debut album Dreamin ' Out Loud . It was his first Top 5 single on the Hot Country Singles & Tracks ( now Hot Country Songs ) chart , where it peaked at # 3 .\", sentence_starts=[0, 126, 220], selected_sent={'start': 0, 'end': 126, 'string': \"`` Every Light in the House '' is a song written by Kent Robbins and recorded by American country music artist Trace Adkins . \"}, answer=[Entity(start_offset=111, end_offset=123, type='context', text='Trace Adkins', normalized_text='trace adkins')], nq_answers=[[Entity(start_offset=111, end_offset=123, type='context', text='Trace Adkins', normalized_text='trace adkins')], [Entity(start_offset=81, end_offset=123, type='context', text='American country music artist Trace Adkins', normalized_text='american country music artist trace adkins')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='every light in the house is on', normalized_text='every light in house is on'), Entity(start_offset=3, end_offset=27, type='context', text='Every Light in the House', normalized_text='every light in house'))], explanation_type='single_sentence'),\n",
       " 1446099047596356015: QEDExample(example_id=1446099047596356015, title=\"Lowe's\", question='how many stores does lowes have in canada', passage=\"Based in Toronto , Ontario , Lowe 's opened its first three stores in Canada on December 10 , 2007 , in Hamilton , Brampton and Brantford . On February 1 , 2008 , they opened three more stores in Toronto , East Gwillimbury , and a second store in Brampton as well as a new location in Maple ( Vaughan ) . Currently , additional stores are under construction , with 19 now open in the province of Ontario . Lowe 's also recently announced expansion into Western Canada , starting with three new stores in Calgary , Alberta . One of the three locations opened in late September 2010 . The other two opened in early 2011 . There are now stores in British Columbia , Manitoba and Saskatchewan . To date ( 2018 ) Lowe 's has 62 locations in Canada . Each store represents an average investment of $20.5 million ( $20.4 million USD ) .\", sentence_starts=[0, 140, 305, 406, 524, 583, 620, 691, 745], selected_sent={'start': 691, 'end': 745, 'string': \"To date ( 2018 ) Lowe 's has 62 locations in Canada . \"}, answer=[Entity(start_offset=720, end_offset=722, type='context', text='62', normalized_text='62')], nq_answers=[[Entity(start_offset=720, end_offset=722, type='context', text='62', normalized_text='62')]], aligned_nps=[(Entity(start_offset=21, end_offset=26, type='question', text='lowes', normalized_text='lowes'), Entity(start_offset=708, end_offset=715, type='context', text=\"Lowe 's\", normalized_text='lowe s')), (Entity(start_offset=35, end_offset=41, type='question', text='canada', normalized_text='canada'), Entity(start_offset=736, end_offset=742, type='context', text='Canada', normalized_text='canada'))], explanation_type='single_sentence'),\n",
       " 7019297080476133879: QEDExample(example_id=7019297080476133879, title='Water cycle', question='what is a another name for the water cycle', passage='The water cycle , also known as the hydrological cycle or the hydrologic cycle , describes the continuous movement of water on , above and below the surface of the Earth . The mass of water on Earth remains fairly constant over time but the partitioning of the water into the major reservoirs of ice , fresh water , saline water and atmospheric water is variable depending on a wide range of climatic variables . The water moves from one reservoir to another , such as from river to ocean , or from the ocean to the atmosphere , by the physical processes of evaporation , condensation , precipitation , infiltration , surface runoff , and subsurface flow . In doing so , the water goes through different forms : liquid , solid ( ice ) and vapor .', sentence_starts=[0, 172, 413, 657], selected_sent={'start': 0, 'end': 172, 'string': 'The water cycle , also known as the hydrological cycle or the hydrologic cycle , describes the continuous movement of water on , above and below the surface of the Earth . '}, answer=[Entity(start_offset=32, end_offset=78, type='context', text='the hydrological cycle or the hydrologic cycle', normalized_text='hydrological cycle or hydrologic cycle')], nq_answers=[[Entity(start_offset=32, end_offset=78, type='context', text='the hydrological cycle or the hydrologic cycle', normalized_text='hydrological cycle or hydrologic cycle')], [Entity(start_offset=36, end_offset=54, type='context', text='hydrological cycle', normalized_text='hydrological cycle'), Entity(start_offset=62, end_offset=78, type='context', text='hydrologic cycle', normalized_text='hydrologic cycle')], [Entity(start_offset=32, end_offset=54, type='context', text='the hydrological cycle', normalized_text='hydrological cycle'), Entity(start_offset=58, end_offset=78, type='context', text='the hydrologic cycle', normalized_text='hydrologic cycle')]], aligned_nps=[(Entity(start_offset=27, end_offset=42, type='question', text='the water cycle', normalized_text='water cycle'), Entity(start_offset=0, end_offset=15, type='context', text='The water cycle', normalized_text='water cycle'))], explanation_type='single_sentence'),\n",
       " 3287927783117323026: QEDExample(example_id=3287927783117323026, title='Wonder (film)', question='what is the meaning of the movie wonder', passage='Wonder is a 2017 American drama film directed by Stephen Chbosky and written by Jack Thorne , Steve Conrad , and Stephen Chbosky , based on the 2012 novel of the same name by R.J. Palacio . The film stars Julia Roberts , Owen Wilson , and Jacob Tremblay . The film follows a child with Treacher Collins syndrome trying to fit in . Wonder was released in the United States on November 17 , 2017 , by Lionsgate and has grossed over $248 million worldwide on a $20 million budget . At the 90th Academy Awards , the film was nominated for Best Makeup and Hairstyling .', sentence_starts=[0, 180, 190, 256, 331, 479], selected_sent={'start': 256, 'end': 331, 'string': 'The film follows a child with Treacher Collins syndrome trying to fit in . '}, answer=[Entity(start_offset=273, end_offset=328, type='context', text='a child with Treacher Collins syndrome trying to fit in', normalized_text='child with treacher collins syndrome trying to fit in')], nq_answers=[[Entity(start_offset=273, end_offset=328, type='context', text='a child with Treacher Collins syndrome trying to fit in', normalized_text='child with treacher collins syndrome trying to fit in')]], aligned_nps=[(Entity(start_offset=23, end_offset=39, type='question', text='the movie wonder', normalized_text='movie wonder'), Entity(start_offset=256, end_offset=264, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " -8111631832195028942: QEDExample(example_id=-8111631832195028942, title='Climate of Venezuela', question='what is the biggest determinant of climate in venezuela', passage='The Climate of Venezuela is characterized for being tropical and isothermal as a result of its geographical location near the Equator , but because of the topography and the dominant wind direction , several climatic types occur which can be the same as found in temperate latitudes , and even polar regions . Latitude exerts little influence on the Venezuelan climate , but the altitude changes it dramatically , particularly the temperature , reaching values very different according to the presence of different thermal floors .', sentence_starts=[0, 310], selected_sent={'start': 310, 'end': 531, 'string': 'Latitude exerts little influence on the Venezuelan climate , but the altitude changes it dramatically , particularly the temperature , reaching values very different according to the presence of different thermal floors .'}, answer=[Entity(start_offset=379, end_offset=387, type='context', text='altitude', normalized_text='altitude')], nq_answers=[[Entity(start_offset=379, end_offset=387, type='context', text='altitude', normalized_text='altitude')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 4323871331649279373: QEDExample(example_id=4323871331649279373, title='Printing press', question='who invented the printing press and in what year', passage='The printing press was invented in the Holy Roman Empire by the German Johannes Gutenberg around 1440 , based on existing screw presses . Gutenberg , a goldsmith by profession , developed a printing system , by adapting existing technologies to printing purposes , as well as making inventions of his own . His newly devised hand mould made possible the precise and rapid creation of metal movable type in large quantities . Movable type had been hitherto unknown in Europe . In East Asia , where it was invented , the usefulness of movable type was limited by the complexity of the writing system and , without the hand mould , the production of sorts ( individual letters of type ) was slow . In Europe , the two inventions , the hand mould and the printing press , together drastically reduced the cost of printing books and other documents , particularly in short print runs .', sentence_starts=[0, 138, 307, 425, 476, 695], selected_sent={'start': 0, 'end': 138, 'string': 'The printing press was invented in the Holy Roman Empire by the German Johannes Gutenberg around 1440 , based on existing screw presses . '}, answer=[Entity(start_offset=60, end_offset=101, type='context', text='the German Johannes Gutenberg around 1440', normalized_text='german johannes gutenberg around 1440')], nq_answers=[[Entity(start_offset=71, end_offset=101, type='context', text='Johannes Gutenberg around 1440', normalized_text='johannes gutenberg around 1440')], [Entity(start_offset=60, end_offset=89, type='context', text='the German Johannes Gutenberg', normalized_text='german johannes gutenberg'), Entity(start_offset=90, end_offset=101, type='context', text='around 1440', normalized_text='around 1440')], [Entity(start_offset=71, end_offset=89, type='context', text='Johannes Gutenberg', normalized_text='johannes gutenberg'), Entity(start_offset=97, end_offset=101, type='context', text='1440', normalized_text='1440')]], aligned_nps=[(Entity(start_offset=13, end_offset=31, type='question', text='the printing press', normalized_text='printing press'), Entity(start_offset=0, end_offset=18, type='context', text='The printing press', normalized_text='printing press'))], explanation_type='single_sentence'),\n",
       " 7792739727631752488: QEDExample(example_id=7792739727631752488, title='Apostles', question='where in the bible are the 12 disciples', passage=\"Each of the four listings of apostles in the New Testament ( Mark 3 : 13 -- 19 , Matthew 10 : 1 -- 4 , Luke 6 : 12 -- 16 , and Acts 1 : 13 ) indicate that all the apostles were men . The canonical gospels and the book of Acts give varying names of the twelve apostles . The list in the Gospel of Luke differs from Matthew and Mark at two points . It lists `` Judas the son of James '' instead of `` Thaddeus '' . ( For more information , see Jude the Apostle . ) Unlike the Synoptic Gospels , the Gospel of John does not offer a formal list of apostles . Although it refers to `` the Twelve '' ( John 6 : 67 -- 71 ) , the gospel does not present any elaboration of who these twelve actually were , and the author of the Gospel of John does not mention them all by name . There is also no separation of the terms `` apostles '' and `` disciples '' in John .\", sentence_starts=[0, 183, 270, 347, 413, 463, 555, 771], selected_sent={'start': 0, 'end': 183, 'string': 'Each of the four listings of apostles in the New Testament ( Mark 3 : 13 -- 19 , Matthew 10 : 1 -- 4 , Luke 6 : 12 -- 16 , and Acts 1 : 13 ) indicate that all the apostles were men . '}, answer=[Entity(start_offset=61, end_offset=138, type='context', text='Mark 3 : 13 -- 19 , Matthew 10 : 1 -- 4 , Luke 6 : 12 -- 16 , and Acts 1 : 13', normalized_text='mark 3 13 19 matthew 10 1 4 luke 6 12 16 and acts 1 13')], nq_answers=[[Entity(start_offset=61, end_offset=78, type='context', text='Mark 3 : 13 -- 19', normalized_text='mark 3 13 19'), Entity(start_offset=81, end_offset=100, type='context', text='Matthew 10 : 1 -- 4', normalized_text='matthew 10 1 4'), Entity(start_offset=103, end_offset=120, type='context', text='Luke 6 : 12 -- 16', normalized_text='luke 6 12 16'), Entity(start_offset=127, end_offset=138, type='context', text='Acts 1 : 13', normalized_text='acts 1 13'), Entity(start_offset=596, end_offset=613, type='context', text='John 6 : 67 -- 71', normalized_text='john 6 67 71')]], aligned_nps=[(Entity(start_offset=23, end_offset=39, type='question', text='the 12 disciples', normalized_text='12 disciples'), Entity(start_offset=159, end_offset=171, type='context', text='the apostles', normalized_text='apostles'))], explanation_type='single_sentence'),\n",
       " -7243720341959076675: QEDExample(example_id=-7243720341959076675, title='Saint Alphonsa', question='who is the first indian woman to be canonized as a saint', passage='Saint Alphonsa , F.C.C. , ( born Anna Muttathupadathu ; 19 August 1910 -- 28 July 1946 ) was an Indian religious sister and educator . She was the first woman of Indian origin to be canonised as a saint by the Catholic Church , and the first canonised saint of the Syro - Malabar Catholic Church , an Eastern Catholic Church based in India . Her feast day is observed on July 28th .', sentence_starts=[0, 135, 342], selected_sent={'start': 135, 'end': 342, 'string': 'She was the first woman of Indian origin to be canonised as a saint by the Catholic Church , and the first canonised saint of the Syro - Malabar Catholic Church , an Eastern Catholic Church based in India . '}, answer=[Entity(start_offset=0, end_offset=88, type='context', text='Saint Alphonsa , F.C.C. , ( born Anna Muttathupadathu ; 19 August 1910 -- 28 July 1946 )', normalized_text='saint alphonsa fcc born anna muttathupadathu 19 august 1910 28 july 1946')], nq_answers=[[Entity(start_offset=0, end_offset=88, type='context', text='Saint Alphonsa , F.C.C. , ( born Anna Muttathupadathu ; 19 August 1910 -- 28 July 1946 )', normalized_text='saint alphonsa fcc born anna muttathupadathu 19 august 1910 28 july 1946')], [Entity(start_offset=0, end_offset=14, type='context', text='Saint Alphonsa', normalized_text='saint alphonsa')], [Entity(start_offset=0, end_offset=53, type='context', text='Saint Alphonsa , F.C.C. , ( born Anna Muttathupadathu', normalized_text='saint alphonsa fcc born anna muttathupadathu')]], aligned_nps=[(Entity(start_offset=7, end_offset=56, type='question', text='the first indian woman to be canonized as a saint', normalized_text='first indian woman to be canonized as saint'), Entity(start_offset=143, end_offset=225, type='context', text='the first woman of Indian origin to be canonised as a saint by the Catholic Church', normalized_text='first woman of indian origin to be canonised as saint by catholic church'))], explanation_type='single_sentence'),\n",
       " 500081949393316899: QEDExample(example_id=500081949393316899, title='Coat of arms of Ireland', question='what is the meaning of the harp in ireland', passage=\"However , reference to the harp as the arms of the king of Ireland can be found in one of the oldest medieval rolls of arms . The Wijnbergen Roll , a French roll of arms dating from c. 1280 and preserved in The Hague , Netherlands , attributed `` D'azure a la harpe d'or '' ( English : Blue with a harp of gold ) to the King of Ireland ( `` le Roi d'Irlande '' ) . The harp , traditionally associated with King David , was a rare charge on medieval rolls and only two arms with a harp are listed in a collection of 19 early rolls . Triangular devices appeared on medieval Irish coinage by kings John and Edward I in the 12th and 13th centuries . These devices may have been crude harps or it may be that the harp developed from the use of triangles to distinguish Irish coins . The idea of a harp being the arms of Ireland may have originated as a reference to a fictional character , le roi d'irelande , in the courtly legend cycle of Tristan . Alternatively , it may have derived from a celebrated 13th century bardic poem , Tabhroidh Chugam Cruit mo Riogh , dedicated to the Donnchadh Cairbreach O'Briain ( d . 1242 ) , a Gaelic King of Thomond .\", sentence_starts=[0, 126, 365, 532, 646, 778, 946, 1114], selected_sent={'start': 0, 'end': 126, 'string': 'However , reference to the harp as the arms of the king of Ireland can be found in one of the oldest medieval rolls of arms . '}, answer=[Entity(start_offset=35, end_offset=66, type='context', text='the arms of the king of Ireland', normalized_text='arms of king of ireland')], nq_answers=[[Entity(start_offset=803, end_offset=822, type='context', text='the arms of Ireland', normalized_text='arms of ireland')]], aligned_nps=[(Entity(start_offset=23, end_offset=31, type='question', text='the harp', normalized_text='harp'), Entity(start_offset=23, end_offset=31, type='context', text='the harp', normalized_text='harp')), (Entity(start_offset=35, end_offset=42, type='question', text='ireland', normalized_text='ireland'), Entity(start_offset=59, end_offset=66, type='context', text='Ireland', normalized_text='ireland'))], explanation_type='single_sentence'),\n",
       " 5575695503847666333: QEDExample(example_id=5575695503847666333, title='Celsius', question='what is the origin of the word celsius', passage='The Celsius scale , previously known as the centigrade scale , is a temperature scale used by the International System of Units ( SI ) . As an SI derived unit , it is used by all countries in the world , except the United States , Myanmar , and Liberia . It is named after the Swedish astronomer Anders Celsius ( 1701 -- 1744 ) , who developed a similar temperature scale . The degree Celsius ( symbol : ° C ) can refer to a specific temperature on the Celsius scale as well as a unit to indicate a temperature interval , a difference between two temperatures or an uncertainty . Before being renamed to honor Anders Celsius in 1948 , the unit was called centigrade , from the Latin centum , which means 100 , and gradus , which means steps .', sentence_starts=[0, 137, 255, 374, 580], selected_sent={'start': 255, 'end': 374, 'string': 'It is named after the Swedish astronomer Anders Celsius ( 1701 -- 1744 ) , who developed a similar temperature scale . '}, answer=[Entity(start_offset=273, end_offset=310, type='context', text='the Swedish astronomer Anders Celsius', normalized_text='swedish astronomer anders celsius')], nq_answers=[[Entity(start_offset=261, end_offset=310, type='context', text='named after the Swedish astronomer Anders Celsius', normalized_text='named after swedish astronomer anders celsius')], [Entity(start_offset=273, end_offset=310, type='context', text='the Swedish astronomer Anders Celsius', normalized_text='swedish astronomer anders celsius')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6810329884310977510: QEDExample(example_id=-6810329884310977510, title='Keeley Hawes', question='who plays lindsay denton in line of duty', passage='Keeley Clare Julia Hawes ( born 10 February 1976 ) is an English actress . She starred in the film version of The Last September ( 1999 ) and has voiced roles in video games , such as Lara Croft in several of the Tomb Raider games . She is also known for her roles as Kitty Butler in Tipping the Velvet , Zoe Reynolds in Spooks ( 2002 -- 2004 ) , Alex Drake in Ashes to Ashes ( 2008 -- 2010 ) , Lady Agnes in the 2010 reboot of Upstairs , Downstairs , Detective Inspector Lindsay Denton in the second and third series of Line of Duty ( 2014 -- 2016 ) , as a mother in search of her abducted child in the BBC series The Missing , and as Louisa Durrell in the ITV series The Durrells .', sentence_starts=[0, 75, 233], selected_sent={'start': 233, 'end': 683, 'string': 'She is also known for her roles as Kitty Butler in Tipping the Velvet , Zoe Reynolds in Spooks ( 2002 -- 2004 ) , Alex Drake in Ashes to Ashes ( 2008 -- 2010 ) , Lady Agnes in the 2010 reboot of Upstairs , Downstairs , Detective Inspector Lindsay Denton in the second and third series of Line of Duty ( 2014 -- 2016 ) , as a mother in search of her abducted child in the BBC series The Missing , and as Louisa Durrell in the ITV series The Durrells .'}, answer=[Entity(start_offset=0, end_offset=24, type='context', text='Keeley Clare Julia Hawes', normalized_text='keeley clare julia hawes')], nq_answers=[[Entity(start_offset=0, end_offset=24, type='context', text='Keeley Clare Julia Hawes', normalized_text='keeley clare julia hawes')]], aligned_nps=[(Entity(start_offset=10, end_offset=24, type='question', text='lindsay denton', normalized_text='lindsay denton'), Entity(start_offset=452, end_offset=486, type='context', text='Detective Inspector Lindsay Denton', normalized_text='detective inspector lindsay denton')), (Entity(start_offset=28, end_offset=40, type='question', text='line of duty', normalized_text='line of duty'), Entity(start_offset=521, end_offset=533, type='context', text='Line of Duty', normalized_text='line of duty'))], explanation_type='single_sentence'),\n",
       " 8201122484810466598: QEDExample(example_id=8201122484810466598, title='Rudolph the Red-Nosed Reindeer (song)', question='origin of rudolph the red nosed reindeer song', passage=\"`` Rudolph , the Red - Nosed Reindeer '' is a song by songwriter Johnny Marks based on the 1939 story Rudolph the Red - Nosed Reindeer published by the Montgomery Ward Company . Gene Autry 's recording hit No. 1 on the U.S. charts the week of Christmas 1949 .\", sentence_starts=[0, 178], selected_sent={'start': 0, 'end': 178, 'string': \"`` Rudolph , the Red - Nosed Reindeer '' is a song by songwriter Johnny Marks based on the 1939 story Rudolph the Red - Nosed Reindeer published by the Montgomery Ward Company . \"}, answer=[Entity(start_offset=87, end_offset=175, type='context', text='the 1939 story Rudolph the Red - Nosed Reindeer published by the Montgomery Ward Company', normalized_text='1939 story rudolph red nosed reindeer published by montgomery ward company')], nq_answers=[[Entity(start_offset=54, end_offset=134, type='context', text='songwriter Johnny Marks based on the 1939 story Rudolph the Red - Nosed Reindeer', normalized_text='songwriter johnny marks based on 1939 story rudolph red nosed reindeer')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='rudolph the red nosed reindeer song', normalized_text='rudolph red nosed reindeer song'), Entity(start_offset=3, end_offset=37, type='context', text='Rudolph , the Red - Nosed Reindeer', normalized_text='rudolph red nosed reindeer'))], explanation_type='single_sentence'),\n",
       " -7205494399914538839: QEDExample(example_id=-7205494399914538839, title=\"The Hitchhiker's Guide to the Galaxy\", question=\"when was hitchhiker's guide to the galaxy made\", passage=\"The Hitchhiker 's Guide to the Galaxy ( sometimes referred to as HG2G , HHGTTG or H2G2 ) is a comedy science fiction series created by Douglas Adams . Originally a radio comedy broadcast on BBC Radio 4 in 1978 , it was later adapted to other formats , including stage shows , novels , comic books , a 1981 TV series , a 1984 video game , and 2005 feature film .\", sentence_starts=[0, 151], selected_sent={'start': 151, 'end': 361, 'string': 'Originally a radio comedy broadcast on BBC Radio 4 in 1978 , it was later adapted to other formats , including stage shows , novels , comic books , a 1981 TV series , a 1984 video game , and 2005 feature film .'}, answer=[Entity(start_offset=205, end_offset=209, type='context', text='1978', normalized_text='1978')], nq_answers=[[Entity(start_offset=205, end_offset=209, type='context', text='1978', normalized_text='1978')], [Entity(start_offset=342, end_offset=346, type='context', text='2005', normalized_text='2005')]], aligned_nps=[(Entity(start_offset=9, end_offset=41, type='question', text=\"hitchhiker's guide to the galaxy\", normalized_text='hitchhikers guide to galaxy'), Entity(start_offset=212, end_offset=214, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 4705803842367216340: QEDExample(example_id=4705803842367216340, title='Chlorofluorocarbon', question=\"what is the full form of cfc's\", passage='Chlorofluorocarbons ( CFCs ) are fully halogenated paraffin hydrocarbons that contain only carbon , chlorine , and fluorine , produced as volatile derivative of methane , ethane , and propane . They are also commonly known by the DuPont brand name Freon . The most common representative is dichlorodifluoromethane ( R - 12 or Freon - 12 ) . Many CFCs have been widely used as refrigerants , propellants ( in aerosol applications ) , and solvents . Because CFCs contribute to ozone depletion in the upper atmosphere , the manufacture of such compounds has been phased out under the Montreal Protocol , and they are being replaced with other products such as hydrofluorocarbons ( HFCs ) ( e.g. , R - 410A ) and R - 134a .', sentence_starts=[0, 194, 256, 341, 448], selected_sent={'start': 0, 'end': 194, 'string': 'Chlorofluorocarbons ( CFCs ) are fully halogenated paraffin hydrocarbons that contain only carbon , chlorine , and fluorine , produced as volatile derivative of methane , ethane , and propane . '}, answer=[Entity(start_offset=0, end_offset=19, type='context', text='Chlorofluorocarbons', normalized_text='chlorofluorocarbons')], nq_answers=[[Entity(start_offset=0, end_offset=19, type='context', text='Chlorofluorocarbons', normalized_text='chlorofluorocarbons')]], aligned_nps=[(Entity(start_offset=25, end_offset=30, type='question', text=\"cfc's\", normalized_text='cfcs'), Entity(start_offset=22, end_offset=26, type='context', text='CFCs', normalized_text='cfcs'))], explanation_type='single_sentence'),\n",
       " -366326691424887969: QEDExample(example_id=-366326691424887969, title='Madea', question=\"when does madea's family funeral come out\", passage='Tyler Perry has confirmed that in A Madea Family Funeral ( 2018 ) Madea has another brother named Heathrow ( Also played by Perry ) . A Vietnam war veteran .', sentence_starts=[0, 134], selected_sent={'start': 0, 'end': 134, 'string': 'Tyler Perry has confirmed that in A Madea Family Funeral ( 2018 ) Madea has another brother named Heathrow ( Also played by Perry ) . '}, answer=[Entity(start_offset=59, end_offset=63, type='context', text='2018', normalized_text='2018')], nq_answers=[[Entity(start_offset=59, end_offset=63, type='context', text='2018', normalized_text='2018')]], aligned_nps=[(Entity(start_offset=10, end_offset=32, type='question', text=\"madea's family funeral\", normalized_text='madeas family funeral'), Entity(start_offset=34, end_offset=56, type='context', text='A Madea Family Funeral', normalized_text='madea family funeral'))], explanation_type='single_sentence'),\n",
       " 3642025747201578819: QEDExample(example_id=3642025747201578819, title='Battles of Saratoga', question='who won the battle of saratoga in 1777', passage='The Battles of Saratoga ( September 19 and October 7 , 1777 ) marked the climax of the Saratoga campaign , giving a decisive victory to the Americans over the British in the American Revolutionary War . British General John Burgoyne led a large invasion army southward from Canada in the Champlain Valley , hoping to meet a similar British force marching northward from New York City and another British force marching eastward from Lake Ontario ; the southern and western forces never arrived , and Burgoyne was surrounded by American forces in upstate New York . He fought two small battles to break out which took place 18 days apart on the same ground , 9 miles ( 14 km ) south of Saratoga , New York . They both failed .', sentence_starts=[0, 203, 565, 707], selected_sent={'start': 0, 'end': 203, 'string': 'The Battles of Saratoga ( September 19 and October 7 , 1777 ) marked the climax of the Saratoga campaign , giving a decisive victory to the Americans over the British in the American Revolutionary War . '}, answer=[Entity(start_offset=136, end_offset=149, type='context', text='the Americans', normalized_text='americans')], nq_answers=[[Entity(start_offset=136, end_offset=149, type='context', text='the Americans', normalized_text='americans')], [Entity(start_offset=140, end_offset=149, type='context', text='Americans', normalized_text='americans')]], aligned_nps=[(Entity(start_offset=8, end_offset=30, type='question', text='the battle of saratoga', normalized_text='battle of saratoga'), Entity(start_offset=0, end_offset=23, type='context', text='The Battles of Saratoga', normalized_text='battles of saratoga')), (Entity(start_offset=34, end_offset=38, type='question', text='1777', normalized_text='1777'), Entity(start_offset=55, end_offset=59, type='context', text='1777', normalized_text='1777'))], explanation_type='single_sentence'),\n",
       " -288937641151618309: QEDExample(example_id=-288937641151618309, title='Shameless (season 8)', question='when does season 8 of shameless come back', passage='The eighth season of Shameless , an American comedy - drama television series based on the award - winning British series of the same name by Paul Abbott , was announced on December 19 , 2016 , a day after the seventh season finale . The season will consist of a total of 12 episodes . It is slated to premiere on November 5 , 2017 .', sentence_starts=[0, 234, 286], selected_sent={'start': 286, 'end': 333, 'string': 'It is slated to premiere on November 5 , 2017 .'}, answer=[Entity(start_offset=314, end_offset=331, type='context', text='November 5 , 2017', normalized_text='november 5 2017')], nq_answers=[[Entity(start_offset=314, end_offset=331, type='context', text='November 5 , 2017', normalized_text='november 5 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=31, type='question', text='season 8 of shameless', normalized_text='season 8 of shameless'), Entity(start_offset=286, end_offset=288, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 8663125622899433567: QEDExample(example_id=8663125622899433567, title='Super Bowl 50 halftime show', question='who is playing halftime show super bowl 50', passage=\"The Super Bowl 50 Halftime Show took place on February 7 , 2016 , at Levi 's Stadium in Santa Clara , California as part of Super Bowl 50 . It was headlined by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars , who previously had headlined the Super Bowl XLVII and Super Bowl XLVIII halftime shows , respectively .\", sentence_starts=[0, 140], selected_sent={'start': 140, 'end': 350, 'string': 'It was headlined by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars , who previously had headlined the Super Bowl XLVII and Super Bowl XLVIII halftime shows , respectively .'}, answer=[Entity(start_offset=160, end_offset=244, type='context', text='the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars', normalized_text='british rock group coldplay with special guest performers beyoncé and bruno mars')], nq_answers=[[Entity(start_offset=183, end_offset=191, type='context', text='Coldplay', normalized_text='coldplay'), Entity(start_offset=222, end_offset=229, type='context', text='Beyoncé', normalized_text='beyoncé'), Entity(start_offset=234, end_offset=244, type='context', text='Bruno Mars', normalized_text='bruno mars')], [Entity(start_offset=160, end_offset=191, type='context', text='the British rock group Coldplay', normalized_text='british rock group coldplay'), Entity(start_offset=197, end_offset=244, type='context', text='special guest performers Beyoncé and Bruno Mars', normalized_text='special guest performers beyoncé and bruno mars')]], aligned_nps=[(Entity(start_offset=15, end_offset=42, type='question', text='halftime show super bowl 50', normalized_text='halftime show super bowl 50'), Entity(start_offset=140, end_offset=142, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 8633446439194247784: QEDExample(example_id=8633446439194247784, title='List of Indianapolis 500 winners', question='who was the winner of the first indianapolis 500', passage='The first Indianapolis 500 was held in 1911 , where Ray Harroun was declared the first winner , driving the Marmon Wasp . The race has been run annually since 1911 ( with exceptions during World War I and World War II ) and 71 drivers have been crowned champions of the 500 - mile race over the course of 101 races . The most race victories held by a single driver is four , which has been accomplished only by A.J. Foyt , Al Unser and Rick Mears . The Indianapolis 500 has also drawn many international drivers to the Indianapolis Motor Speedway over the years , with 26 of the winners coming from outside of the United States , representing nine separate countries . The most recent champion of the Indianapolis 500 is Takuma Sato , winner of the 2017 race .', sentence_starts=[0, 122, 317, 416, 449, 669], selected_sent={'start': 0, 'end': 122, 'string': 'The first Indianapolis 500 was held in 1911 , where Ray Harroun was declared the first winner , driving the Marmon Wasp . '}, answer=[Entity(start_offset=52, end_offset=63, type='context', text='Ray Harroun', normalized_text='ray harroun')], nq_answers=[[Entity(start_offset=52, end_offset=63, type='context', text='Ray Harroun', normalized_text='ray harroun')]], aligned_nps=[(Entity(start_offset=8, end_offset=48, type='question', text='the winner of the first indianapolis 500', normalized_text='winner of first indianapolis 500'), Entity(start_offset=77, end_offset=93, type='context', text='the first winner', normalized_text='first winner'))], explanation_type='single_sentence'),\n",
       " -9098816910125455707: QEDExample(example_id=-9098816910125455707, title='United States territorial acquisitions', question='when did the united states acquired puerto rico', passage='Puerto Rico , Guam , and the Philippines ( for which the United States compensated Spain $20 million , equivalent to $588 million in present - day terms ) , were ceded by Spain after the Spanish -- American War in the 1898 Treaty of Paris . Spain relinquished all claim of sovereignty over Cuba , but did not cede it to the United States , so it became a protectorate . All four of these areas were under United States Military Government ( USMG ) for extended periods . Cuba became an independent nation in 1902 , and the Philippines became an independent nation in 1946 .', sentence_starts=[0, 241, 370, 471], selected_sent={'start': 0, 'end': 241, 'string': 'Puerto Rico , Guam , and the Philippines ( for which the United States compensated Spain $20 million , equivalent to $588 million in present - day terms ) , were ceded by Spain after the Spanish -- American War in the 1898 Treaty of Paris . '}, answer=[Entity(start_offset=218, end_offset=222, type='context', text='1898', normalized_text='1898')], nq_answers=[[Entity(start_offset=177, end_offset=238, type='context', text='after the Spanish -- American War in the 1898 Treaty of Paris', normalized_text='after spanish american war in 1898 treaty of paris')], [Entity(start_offset=218, end_offset=222, type='context', text='1898', normalized_text='1898')]], aligned_nps=[(Entity(start_offset=36, end_offset=47, type='question', text='puerto rico', normalized_text='puerto rico'), Entity(start_offset=0, end_offset=11, type='context', text='Puerto Rico', normalized_text='puerto rico')), (Entity(start_offset=9, end_offset=26, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=57, end_offset=70, type='context', text='United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 1301404612765075489: QEDExample(example_id=1301404612765075489, title='Jason Gideon', question='which episode does gideon die in criminal minds', passage=\"In the season ten episode `` Nelson 's Sparrow '' , Gideon was murdered off - screen , having been shot dead at a close range by a serial killer named Donnie Mallick ( Arye Gross ) , which prompts the BAU team to investigate Gideon 's murder . During the flashbacks focusing on a young version of him for the episode which show him working at the BAU in 1978 , he is played by Ben Savage .\", sentence_starts=[0, 244], selected_sent={'start': 0, 'end': 244, 'string': \"In the season ten episode `` Nelson 's Sparrow '' , Gideon was murdered off - screen , having been shot dead at a close range by a serial killer named Donnie Mallick ( Arye Gross ) , which prompts the BAU team to investigate Gideon 's murder . \"}, answer=[Entity(start_offset=3, end_offset=49, type='context', text=\"the season ten episode `` Nelson 's Sparrow ''\", normalized_text='season ten episode nelson s sparrow')], nq_answers=[[Entity(start_offset=3, end_offset=49, type='context', text=\"the season ten episode `` Nelson 's Sparrow ''\", normalized_text='season ten episode nelson s sparrow')], [Entity(start_offset=26, end_offset=49, type='context', text=\"`` Nelson 's Sparrow ''\", normalized_text='nelson s sparrow')], [Entity(start_offset=29, end_offset=46, type='context', text=\"Nelson 's Sparrow\", normalized_text='nelson s sparrow')]], aligned_nps=[(Entity(start_offset=19, end_offset=25, type='question', text='gideon', normalized_text='gideon'), Entity(start_offset=52, end_offset=58, type='context', text='Gideon', normalized_text='gideon')), (Entity(start_offset=33, end_offset=47, type='question', text='criminal minds', normalized_text='criminal minds'), Entity(start_offset=0, end_offset=49, type='context', text=\"In the season ten episode `` Nelson 's Sparrow ''\", normalized_text='in season ten episode nelson s sparrow'))], explanation_type='single_sentence'),\n",
       " 3903631751397750234: QEDExample(example_id=3903631751397750234, title='Ghost of Christmas Present', question='what does the ghost of christmas present sprinkle from his torch', passage=\"The spirit transports Scrooge around the city , showing him scenes of festivity and also deprivation that are happening as they watch , sprinkling a little warmth from his torch as he travels . Amongst the visits are Scrooge 's nephew , and the family of his impoverished clerk , Bob Cratchit . Scrooge takes an interest in Cratchit 's desperately - ill son , Tiny Tim , and asks the Ghost if Tim will live . The Ghost first states that `` If these shadows remain unaltered by the Future , the child will die , '' and then -- quick to use Scrooge 's past heartless comments to two charitable solicitors against him -- states , `` What then ? If he be like to die , he had better do it , and decrease the surplus population . '' The spirit then warns Scrooge to `` forebear that wicked tongue until you have discovered for yourself what the surplus is , and where it is . '' and chillingly tells him `` It may be , that in the sight of heaven , you are more worthless and less fit to live than MILLIONS like this poor man 's child . ''\", sentence_starts=[0, 194, 295, 409, 642, 728, 874], selected_sent={'start': 0, 'end': 194, 'string': 'The spirit transports Scrooge around the city , showing him scenes of festivity and also deprivation that are happening as they watch , sprinkling a little warmth from his torch as he travels . '}, answer=[Entity(start_offset=147, end_offset=162, type='context', text='a little warmth', normalized_text='little warmth')], nq_answers=[[Entity(start_offset=147, end_offset=162, type='context', text='a little warmth', normalized_text='little warmth')], [Entity(start_offset=156, end_offset=162, type='context', text='warmth', normalized_text='warmth')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='the ghost of christmas present', normalized_text='ghost of christmas present'), Entity(start_offset=0, end_offset=10, type='context', text='The spirit', normalized_text='spirit')), (Entity(start_offset=55, end_offset=64, type='question', text='his torch', normalized_text='his torch'), Entity(start_offset=168, end_offset=177, type='context', text='his torch', normalized_text='his torch'))], explanation_type='single_sentence'),\n",
       " -631926128215110114: QEDExample(example_id=-631926128215110114, title='Royal Rumble (2018)', question=\"who won the 2018 women's royal rumble match\", passage=\"Nine matches were contested at the event , including three on the pre-show . In the main event , Asuka won the first - ever women 's Royal Rumble match , which was also the second women 's match to main event a WWE pay - per - view , and the first to main event one of WWE 's `` Big Four '' pay - per - views . The men 's Royal Rumble match was won by Shinsuke Nakamura . Other prominent matches included Brock Lesnar retaining the Universal Championship in a triple threat match against Braun Strowman and Kane , and AJ Styles retained the WWE Championship against Kevin Owens and Sami Zayn in a handicap match . The event was also notable for the surprise appearance of former UFC star Ronda Rousey following the women 's match , officially confirming that she had signed full - time with WWE .\", sentence_starts=[0, 77, 311, 372, 614], selected_sent={'start': 77, 'end': 311, 'string': \"In the main event , Asuka won the first - ever women 's Royal Rumble match , which was also the second women 's match to main event a WWE pay - per - view , and the first to main event one of WWE 's `` Big Four '' pay - per - views . \"}, answer=[Entity(start_offset=97, end_offset=102, type='context', text='Asuka', normalized_text='asuka')], nq_answers=[[Entity(start_offset=97, end_offset=102, type='context', text='Asuka', normalized_text='asuka')]], aligned_nps=[(Entity(start_offset=8, end_offset=43, type='question', text=\"the 2018 women's royal rumble match\", normalized_text='2018 womens royal rumble match'), Entity(start_offset=107, end_offset=151, type='context', text=\"the first - ever women 's Royal Rumble match\", normalized_text='first ever women s royal rumble match'))], explanation_type='single_sentence'),\n",
       " 72470187726524890: QEDExample(example_id=72470187726524890, title='The Endless Summer', question='where was part of the classic surfing movie endless summer filmed', passage='Filmmaker / narrator Bruce Brown follows two surfers , Mike Hynson and Robert August , on a surfing trip around the world . Despite the balmy climate of their native California , cold ocean currents make local beaches inhospitable during the winter . They travel to the coasts of Australia , New Zealand , Tahiti , Hawaii , Senegal , Ghana , Nigeria and South Africa in a quest for new surf spots and introduce locals to the sport . Other important surfers of the time , such as Miki Dora , Phil Edwards and Butch Van Artsdalen also appear .', sentence_starts=[0, 124, 251, 433], selected_sent={'start': 251, 'end': 433, 'string': 'They travel to the coasts of Australia , New Zealand , Tahiti , Hawaii , Senegal , Ghana , Nigeria and South Africa in a quest for new surf spots and introduce locals to the sport . '}, answer=[Entity(start_offset=280, end_offset=366, type='context', text='Australia , New Zealand , Tahiti , Hawaii , Senegal , Ghana , Nigeria and South Africa', normalized_text='australia new zealand tahiti hawaii senegal ghana nigeria and south africa')], nq_answers=[[Entity(start_offset=280, end_offset=289, type='context', text='Australia', normalized_text='australia'), Entity(start_offset=292, end_offset=303, type='context', text='New Zealand', normalized_text='new zealand'), Entity(start_offset=306, end_offset=312, type='context', text='Tahiti', normalized_text='tahiti'), Entity(start_offset=315, end_offset=321, type='context', text='Hawaii', normalized_text='hawaii'), Entity(start_offset=324, end_offset=331, type='context', text='Senegal', normalized_text='senegal'), Entity(start_offset=334, end_offset=339, type='context', text='Ghana', normalized_text='ghana'), Entity(start_offset=342, end_offset=349, type='context', text='Nigeria', normalized_text='nigeria'), Entity(start_offset=354, end_offset=366, type='context', text='South Africa', normalized_text='south africa')], [Entity(start_offset=266, end_offset=366, type='context', text='the coasts of Australia , New Zealand , Tahiti , Hawaii , Senegal , Ghana , Nigeria and South Africa', normalized_text='coasts of australia new zealand tahiti hawaii senegal ghana nigeria and south africa')]], aligned_nps=[(Entity(start_offset=18, end_offset=58, type='question', text='the classic surfing movie endless summer', normalized_text='classic surfing movie endless summer'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -5266947057771511513: QEDExample(example_id=-5266947057771511513, title='Judith Keppel', question='who was the first woman to win who wants to be a millionaire', passage='Judith Cynthia Aline Keppel ( born 18 August 1942 ) was the first one - million - pound winner on the television game show Who Wants to Be a Millionaire ? in the United Kingdom . She is also the only woman in the United Kingdom to have won it and also the first person to win a million pounds or more on a British television game show . She has appeared on the BBC Two quiz show Eggheads since 2003 .', sentence_starts=[0, 155, 179, 337], selected_sent={'start': 0, 'end': 155, 'string': 'Judith Cynthia Aline Keppel ( born 18 August 1942 ) was the first one - million - pound winner on the television game show Who Wants to Be a Millionaire ? '}, answer=[Entity(start_offset=0, end_offset=27, type='context', text='Judith Cynthia Aline Keppel', normalized_text='judith cynthia aline keppel')], nq_answers=[[Entity(start_offset=0, end_offset=27, type='context', text='Judith Cynthia Aline Keppel', normalized_text='judith cynthia aline keppel')]], aligned_nps=[(Entity(start_offset=31, end_offset=60, type='question', text='who wants to be a millionaire', normalized_text='who wants to be millionaire'), Entity(start_offset=123, end_offset=154, type='context', text='Who Wants to Be a Millionaire ?', normalized_text='who wants to be millionaire'))], explanation_type='single_sentence'),\n",
       " 4784420206031467202: QEDExample(example_id=4784420206031467202, title=\"He Ain't Heavy, He's My Brother\", question=\"who wrote he ain't heavy he's my brother lyrics\", passage=\"`` He Ai n't Heavy , He 's My Brother '' is a popular music ballad written by Bobby Scott and Bob Russell . Originally recorded by Kelly Gordon in 1969 , the song became a worldwide hit for The Hollies later that year and again for Neil Diamond in 1970 . It has been covered by many artists in subsequent years . The Hollies ' and Rufus Wainwright 's versions of the song were featured in the film Zoolander .\", sentence_starts=[0, 108, 255, 313], selected_sent={'start': 0, 'end': 108, 'string': \"`` He Ai n't Heavy , He 's My Brother '' is a popular music ballad written by Bobby Scott and Bob Russell . \"}, answer=[Entity(start_offset=78, end_offset=105, type='context', text='Bobby Scott and Bob Russell', normalized_text='bobby scott and bob russell')], nq_answers=[[Entity(start_offset=78, end_offset=89, type='context', text='Bobby Scott', normalized_text='bobby scott'), Entity(start_offset=94, end_offset=105, type='context', text='Bob Russell', normalized_text='bob russell')], [Entity(start_offset=78, end_offset=89, type='context', text='Bobby Scott', normalized_text='bobby scott'), Entity(start_offset=78, end_offset=89, type='context', text='Bobby Scott', normalized_text='bobby scott')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text=\"he ain't heavy he's my brother\", normalized_text='he aint heavy hes my brother'), Entity(start_offset=3, end_offset=37, type='context', text=\"He Ai n't Heavy , He 's My Brother\", normalized_text='he ai nt heavy he s my brother'))], explanation_type='single_sentence'),\n",
       " 2308037668603022608: QEDExample(example_id=2308037668603022608, title='United States Senate', question='what determines the number of senate seats held by each state', passage='The composition and powers of the Senate are established by Article One of the United States Constitution . The Senate is composed of senators , each of whom represents a single state in its entirety , with each state being equally represented by two senators , regardless of its population , serving staggered terms of six years ; with fifty states presently in the Union , there are 100 U.S. Senators . From 1789 until 1913 , Senators were appointed by legislatures of the states they represented ; following the ratification of the Seventeenth Amendment in 1913 , they are now popularly elected . The Senate chamber is located in the north wing of the Capitol , in Washington , D.C.', sentence_starts=[0, 108, 405, 600], selected_sent={'start': 0, 'end': 108, 'string': 'The composition and powers of the Senate are established by Article One of the United States Constitution . '}, answer=[Entity(start_offset=60, end_offset=105, type='context', text='Article One of the United States Constitution', normalized_text='article one of united states constitution')], nq_answers=[[Entity(start_offset=60, end_offset=105, type='context', text='Article One of the United States Constitution', normalized_text='article one of united states constitution')]], aligned_nps=[(Entity(start_offset=30, end_offset=36, type='question', text='senate', normalized_text='senate'), Entity(start_offset=30, end_offset=40, type='context', text='the Senate', normalized_text='senate'))], explanation_type='single_sentence'),\n",
       " -2055788643958254872: QEDExample(example_id=-2055788643958254872, title='Lupus Foundation of America', question='when was the lupus foundation of america founded', passage=\"The Lupus Foundation of America ( LFA ) , founded in 1977 , is a national voluntary health organization based in Washington , D.C. with a network of chapters , offices and support groups located in communities throughout the United States . The Foundation is devoted to solving the mystery of lupus , one of the world 's cruelest , most unpredictable and devastating diseases , while giving caring support to those who suffer from its brutal impact . Its mission is to improve the quality of life for all people affected by lupus through programs of research , education , support and advocacy .\", sentence_starts=[0, 241, 451], selected_sent={'start': 0, 'end': 241, 'string': 'The Lupus Foundation of America ( LFA ) , founded in 1977 , is a national voluntary health organization based in Washington , D.C. with a network of chapters , offices and support groups located in communities throughout the United States . '}, answer=[Entity(start_offset=53, end_offset=57, type='context', text='1977', normalized_text='1977')], nq_answers=[[Entity(start_offset=53, end_offset=57, type='context', text='1977', normalized_text='1977')]], aligned_nps=[(Entity(start_offset=9, end_offset=40, type='question', text='the lupus foundation of america', normalized_text='lupus foundation of america'), Entity(start_offset=0, end_offset=31, type='context', text='The Lupus Foundation of America', normalized_text='lupus foundation of america'))], explanation_type='single_sentence'),\n",
       " 2316219466458554937: QEDExample(example_id=2316219466458554937, title='Aphasia', question='aphasia is a term defining difficulty or loss of ability to', passage=\"Aphasia is an inability to comprehend and formulate language because of damage to specific brain regions . This damage is typically caused by a cerebral vascular accident ( stroke ) , or head trauma ; however , these are not the only possible causes . To be diagnosed with aphasia , a person 's speech or language must be significantly impaired in one ( or several ) of the four communication modalities following acquired brain injury or have significant decline over a short time period ( progressive aphasia ) . The four communication modalities are auditory comprehension , verbal expression , reading and writing , and functional communication .\", sentence_starts=[0, 107, 252, 515], selected_sent={'start': 0, 'end': 107, 'string': 'Aphasia is an inability to comprehend and formulate language because of damage to specific brain regions . '}, answer=[Entity(start_offset=27, end_offset=60, type='context', text='comprehend and formulate language', normalized_text='comprehend and formulate language')], nq_answers=[[Entity(start_offset=27, end_offset=60, type='context', text='comprehend and formulate language', normalized_text='comprehend and formulate language')], [Entity(start_offset=27, end_offset=104, type='context', text='comprehend and formulate language because of damage to specific brain regions', normalized_text='comprehend and formulate language because of damage to specific brain regions')], [Entity(start_offset=42, end_offset=60, type='context', text='formulate language', normalized_text='formulate language')]], aligned_nps=[(Entity(start_offset=0, end_offset=7, type='question', text='aphasia', normalized_text='aphasia'), Entity(start_offset=0, end_offset=7, type='context', text='Aphasia', normalized_text='aphasia'))], explanation_type='single_sentence'),\n",
       " -1833051064924762940: QEDExample(example_id=-1833051064924762940, title='Kelly Reno', question='who plays alec ramsay in the black stallion', passage='Kelly Reno ( born June 19 , 1966 , in Pueblo , Colorado ) is a former child actor who was cast at age 11 in the role of Alec Ramsey , the young boy who is marooned on a deserted island along with a horse , in The Black Stallion ( based on the novel by Walter Farley ) . The film was made in 1977 .', sentence_starts=[0, 270], selected_sent={'start': 0, 'end': 270, 'string': 'Kelly Reno ( born June 19 , 1966 , in Pueblo , Colorado ) is a former child actor who was cast at age 11 in the role of Alec Ramsey , the young boy who is marooned on a deserted island along with a horse , in The Black Stallion ( based on the novel by Walter Farley ) . '}, answer=[Entity(start_offset=0, end_offset=10, type='context', text='Kelly Reno', normalized_text='kelly reno')], nq_answers=[[Entity(start_offset=0, end_offset=10, type='context', text='Kelly Reno', normalized_text='kelly reno')]], aligned_nps=[(Entity(start_offset=10, end_offset=21, type='question', text='alec ramsay', normalized_text='alec ramsay'), Entity(start_offset=120, end_offset=131, type='context', text='Alec Ramsey', normalized_text='alec ramsey')), (Entity(start_offset=25, end_offset=43, type='question', text='the black stallion', normalized_text='black stallion'), Entity(start_offset=209, end_offset=227, type='context', text='The Black Stallion', normalized_text='black stallion'))], explanation_type='single_sentence'),\n",
       " 891746977133226745: QEDExample(example_id=891746977133226745, title='You Must Have Been a Beautiful Baby', question='who wrote you must have been a beautiful baby', passage=\"`` You Must Have Been a Beautiful Baby '' is a popular song with music by Harry Warren and lyrics by Johnny Mercer , published in 1938 by Remick Music Corporation . It was featured in the Warner Brothers movie Hard to Get , released November 1938 , in which it was sung by Dick Powell .\", sentence_starts=[0, 165], selected_sent={'start': 0, 'end': 165, 'string': \"`` You Must Have Been a Beautiful Baby '' is a popular song with music by Harry Warren and lyrics by Johnny Mercer , published in 1938 by Remick Music Corporation . \"}, answer=[Entity(start_offset=65, end_offset=114, type='context', text='music by Harry Warren and lyrics by Johnny Mercer', normalized_text='music by harry warren and lyrics by johnny mercer')], nq_answers=[[Entity(start_offset=65, end_offset=86, type='context', text='music by Harry Warren', normalized_text='music by harry warren'), Entity(start_offset=91, end_offset=114, type='context', text='lyrics by Johnny Mercer', normalized_text='lyrics by johnny mercer')], [Entity(start_offset=74, end_offset=86, type='context', text='Harry Warren', normalized_text='harry warren'), Entity(start_offset=101, end_offset=114, type='context', text='Johnny Mercer', normalized_text='johnny mercer')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='you must have been a beautiful baby', normalized_text='you must have been beautiful baby'), Entity(start_offset=3, end_offset=38, type='context', text='You Must Have Been a Beautiful Baby', normalized_text='you must have been beautiful baby'))], explanation_type='single_sentence'),\n",
       " -909543708804159189: QEDExample(example_id=-909543708804159189, title='Rosencrantz and Guildenstern Are Dead', question='when was rosencrantz and guildenstern are dead written', passage=\"Rosencrantz and Guildenstern Are Dead , often referred to as just Rosencrantz and Guildenstern , is an absurdist , existentialist tragicomedy by Tom Stoppard , first staged at the Edinburgh Festival Fringe in 1966 . The play expands upon the exploits of two minor characters from Shakespeare 's Hamlet , the courtiers Rosencrantz and Guildenstern . The action of Stoppard 's play takes place mainly `` in the wings '' of Shakespeare 's , with brief appearances of major characters from Hamlet who enact fragments of the original 's scenes . Between these episodes the two protagonists voice their confusion at the progress of events occurring onstage without them in Hamlet , of which they have no direct knowledge .\", sentence_starts=[0, 216, 349, 541], selected_sent={'start': 0, 'end': 216, 'string': 'Rosencrantz and Guildenstern Are Dead , often referred to as just Rosencrantz and Guildenstern , is an absurdist , existentialist tragicomedy by Tom Stoppard , first staged at the Edinburgh Festival Fringe in 1966 . '}, answer=[Entity(start_offset=209, end_offset=213, type='context', text='1966', normalized_text='1966')], nq_answers=[[Entity(start_offset=209, end_offset=213, type='context', text='1966', normalized_text='1966')]], aligned_nps=[(Entity(start_offset=9, end_offset=46, type='question', text='rosencrantz and guildenstern are dead', normalized_text='rosencrantz and guildenstern are dead'), Entity(start_offset=0, end_offset=37, type='context', text='Rosencrantz and Guildenstern Are Dead', normalized_text='rosencrantz and guildenstern are dead'))], explanation_type='single_sentence'),\n",
       " 1862639185051508137: QEDExample(example_id=1862639185051508137, title='A Madea Christmas (film)', question=\"who plays connor's mom in madeas christmas\", passage=\"Connor 's parents , Buddy ( Larry the Cable Guy ) , and Kim ( Kathy Najimy ) , arrive at Connor and Lacey 's house , as they have come to visit him for Christmas and are told that they must not mention that he and Lacey are married , as they do not know that Eileen has never wanted Lacey to marry a white man . Meanwhile , Eileen decides to get a Christmas tree and cuts down one with a yellow ribbon wrapped around it in the backyard , not knowing that Kim planted the tree in memory of her deceased father . When Eileen learns of this , she expresses no remorse , upsetting Kim . That night , Eileen walks in on Buddy and Kim , seeing Buddy with a sheet over his head , convincing her that Buddy is in the KKK . Now scared , she bars the door to the room that she and Madea are sharing .\", sentence_starts=[0, 312, 511, 583, 715], selected_sent={'start': 0, 'end': 312, 'string': \"Connor 's parents , Buddy ( Larry the Cable Guy ) , and Kim ( Kathy Najimy ) , arrive at Connor and Lacey 's house , as they have come to visit him for Christmas and are told that they must not mention that he and Lacey are married , as they do not know that Eileen has never wanted Lacey to marry a white man . \"}, answer=[Entity(start_offset=62, end_offset=74, type='context', text='Kathy Najimy', normalized_text='kathy najimy')], nq_answers=[[Entity(start_offset=62, end_offset=74, type='context', text='Kathy Najimy', normalized_text='kathy najimy')]], aligned_nps=[(Entity(start_offset=10, end_offset=22, type='question', text=\"connor's mom\", normalized_text='connors mom'), Entity(start_offset=56, end_offset=59, type='context', text='Kim', normalized_text='kim')), (Entity(start_offset=26, end_offset=42, type='question', text='madeas christmas', normalized_text='madeas christmas'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 5185978890489959594: QEDExample(example_id=5185978890489959594, title='Michael McDowell (racing driver)', question='who drives the number 95 car in nascar', passage='Michael Christopher McDowell ( born December 21 , 1984 ) is an American professional stock car racing driver . He currently competes full - time in the Monster Energy NASCAR Cup Series , driving the No. 95 Chevrolet SS for Leavine Family Racing .', sentence_starts=[0, 111], selected_sent={'start': 111, 'end': 246, 'string': 'He currently competes full - time in the Monster Energy NASCAR Cup Series , driving the No. 95 Chevrolet SS for Leavine Family Racing .'}, answer=[Entity(start_offset=0, end_offset=28, type='context', text='Michael Christopher McDowell', normalized_text='michael christopher mcdowell')], nq_answers=[[Entity(start_offset=0, end_offset=28, type='context', text='Michael Christopher McDowell', normalized_text='michael christopher mcdowell')]], aligned_nps=[(Entity(start_offset=32, end_offset=38, type='question', text='nascar', normalized_text='nascar'), Entity(start_offset=167, end_offset=173, type='context', text='NASCAR', normalized_text='nascar')), (Entity(start_offset=11, end_offset=28, type='question', text='the number 95 car', normalized_text='number 95 car'), Entity(start_offset=195, end_offset=218, type='context', text='the No. 95 Chevrolet SS', normalized_text='no 95 chevrolet ss'))], explanation_type='single_sentence'),\n",
       " -1180168003678804636: QEDExample(example_id=-1180168003678804636, title='Omar Khayyam', question='i was a great islamic scholar and mathematician who died in 1131 ce', passage='Omar Khayyam ( Persian pronunciation : ( xæjˈjɑːm ) ; عمر خیّام ( Persian ) ; 18 May 1048 -- 4 December 1131 ) was a Persian mathematician , astronomer , and poet .', sentence_starts=[0], selected_sent={'start': 0, 'end': 164, 'string': 'Omar Khayyam ( Persian pronunciation : ( xæjˈjɑːm ) ; عمر خیّام ( Persian ) ; 18 May 1048 -- 4 December 1131 ) was a Persian mathematician , astronomer , and poet .'}, answer=[Entity(start_offset=0, end_offset=12, type='context', text='Omar Khayyam', normalized_text='omar khayyam')], nq_answers=[[Entity(start_offset=0, end_offset=12, type='context', text='Omar Khayyam', normalized_text='omar khayyam')]], aligned_nps=[(Entity(start_offset=60, end_offset=67, type='question', text='1131 ce', normalized_text='1131 ce'), Entity(start_offset=104, end_offset=108, type='context', text='1131', normalized_text='1131'))], explanation_type='single_sentence'),\n",
       " 7225402972374213361: QEDExample(example_id=7225402972374213361, title='Sleeping Freshmen Never Lie', question='where does sleeping freshmen never lie take place', passage=\"Scott Hudson enters J.P. Zenger High as a freshman , along with his three best friends , Mitch , Patrick , and Kyle , and quickly realizes that it is very different from middle school . Upperclassmen are intimidating and will steal any lunch money along with loose change if you stand in the wrong place . Scott gets put in advanced classes , including an Honors English class which , despite the amount of homework , is his favorite class . His teacher , Mr. Franka , becomes a mentor to him . Scott finds out that he 's not in classes with his friends since he 's carrying all honors and college prep classes . He tries his best from the very start to get the attention of Julia Baskins , a girl who was in his kindergarten class and has recently become very beautiful over the summer . Because of her beauty she quickly blends in with the popular girls and is attracted to the football players who are often bullying Scott . Scott is also connected to another classmate named Louden , who is better known as Mouth . Scott tries every attempt to get Julia 's attention such as joining the school paper , because he thinks that she is part of the staff , only to discover that she has written only a single column for the paper . He then runs for student council , after finding out that Julia is also running as well , and wins a seat , only to find out that she has not won . Because of this , Scott resigns from his position on the student council . It turns out that a lot of other members also resigned including the president meaning Julia who happened to have the 2nd most amount of votes is now president . He also auditions for the school play and is selected as a member of the crew , thinking that Julia is also auditioning for the play . However , Julia has not been selected as a member of the cast or crew . Soon , a new girl named Lee arrives at school , who wears face pins and weird clothes , and has wildly colored hair . Both soon realize that they share the same interests , but he ca n't get past his crush on Julia . Scott suddenly has another `` friend '' named Wesley , a high school senior . Though they share some interests , they have little in common . Then to put the cherry on top of all this excitement going on in his life , his mother announces that she is pregnant . He copes with all of this by creating a tip book for his soon - to - be baby sibling to help him , or her , survive high school when they get to it . In his entries to the baby , he often shows disdain by using degrading terms to talk to it such as `` Smelly '' or `` Blob of unformed goo '' . But he writes it to be a good older brother to this new baby since Scott 's own brother was never very present . As time goes by , Scott tries to find his place , but he starts to lose his best friends . Mitch finds a girlfriend and soon forgets the group , Patrick moves to Texas , then to Japan , and Kyle joins the wrestling team and soon puts Scott down for having a crush on Julia . Soon , Julia 's boyfriend Vernon beats up Scott after finding out from Kyle ( who lost a fight with Scott ) that Scott has a crush on his girlfriend . Scott realizes that what a person says and does can affect the life of another after Mouth attempts to commit suicide . Later , he learns that not everything is what it seems once he finds out that his older brother , Bobby , who is struggling to find a job , can barely read . Scott 's mother eventually gives birth to a new baby boy , whom they name Sean . Meanwhile , Bobby finds a job through guitar - playing and Julia eventually starts dating a nicer guy , though she is now close to Scott enough to give him a kiss on the cheek .\", sentence_starts=[0, 186, 306, 442, 495, 613, 789, 928, 1019, 1231, 1379, 1454, 1616, 1751, 1823, 1941, 2040, 2118, 2182, 2302, 2452, 2596, 2709, 2800, 2984, 3135, 3255, 3413, 3494], selected_sent={'start': 0, 'end': 186, 'string': 'Scott Hudson enters J.P. Zenger High as a freshman , along with his three best friends , Mitch , Patrick , and Kyle , and quickly realizes that it is very different from middle school . '}, answer=[Entity(start_offset=20, end_offset=36, type='context', text='J.P. Zenger High', normalized_text='jp zenger high')], nq_answers=[[Entity(start_offset=20, end_offset=36, type='context', text='J.P. Zenger High', normalized_text='jp zenger high')]], aligned_nps=[(Entity(start_offset=11, end_offset=38, type='question', text='sleeping freshmen never lie', normalized_text='sleeping freshmen never lie'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2659168512523622985: QEDExample(example_id=-2659168512523622985, title='Scottish independence referendum, 2014', question='who was allowed to vote in scottish referendum', passage='The Scottish Independence Referendum Act 2013 , setting out the arrangements for the referendum , was passed by the Scottish Parliament in November 2013 , following an agreement between the Scottish Government and the United Kingdom government . To pass , the independence proposal required a simple majority . With some exceptions , European Union ( EU ) or Commonwealth citizens resident in Scotland aged sixteen years or over could vote , a total of almost 4,300,000 people . This was the first time that the electoral franchise was extended to include sixteen and seventeen year olds in Scotland .', sentence_starts=[0, 246, 311, 479], selected_sent={'start': 311, 'end': 479, 'string': 'With some exceptions , European Union ( EU ) or Commonwealth citizens resident in Scotland aged sixteen years or over could vote , a total of almost 4,300,000 people . '}, answer=[Entity(start_offset=311, end_offset=428, type='context', text='With some exceptions , European Union ( EU ) or Commonwealth citizens resident in Scotland aged sixteen years or over', normalized_text='with some exceptions european union eu or commonwealth citizens resident in scotland aged sixteen years or over')], nq_answers=[[Entity(start_offset=334, end_offset=476, type='context', text='European Union ( EU ) or Commonwealth citizens resident in Scotland aged sixteen years or over could vote , a total of almost 4,300,000 people', normalized_text='european union eu or commonwealth citizens resident in scotland aged sixteen years or over could vote total of almost 4300000 people')], [Entity(start_offset=334, end_offset=428, type='context', text='European Union ( EU ) or Commonwealth citizens resident in Scotland aged sixteen years or over', normalized_text='european union eu or commonwealth citizens resident in scotland aged sixteen years or over')]], aligned_nps=[(Entity(start_offset=27, end_offset=46, type='question', text='scottish referendum', normalized_text='scottish referendum'), Entity(start_offset=435, end_offset=439, type='context', text='vote', normalized_text='vote'))], explanation_type='single_sentence'),\n",
       " 9188359206780164872: QEDExample(example_id=9188359206780164872, title='Reaper', question='when was the reaper invented by cyrus mccormick', passage=\"The McCormick Reaper was designed by Robert McCormick in Walnut Grove , Virginia . However , Robert became frustrated when he was unable to perfect his new device . His son Cyrus asked for permission to try to complete his father 's project . With permission granted , the McCormick Reaper was patented by his son Cyrus McCormick in 1837 as a horse - drawn farm implement to cut small grain crops . This McCormick reaper machine had several special elements :\", sentence_starts=[0, 83, 165, 243, 399], selected_sent={'start': 243, 'end': 399, 'string': 'With permission granted , the McCormick Reaper was patented by his son Cyrus McCormick in 1837 as a horse - drawn farm implement to cut small grain crops . '}, answer=[Entity(start_offset=333, end_offset=337, type='context', text='1837', normalized_text='1837')], nq_answers=[[Entity(start_offset=333, end_offset=337, type='context', text='1837', normalized_text='1837')]], aligned_nps=[(Entity(start_offset=9, end_offset=19, type='question', text='the reaper', normalized_text='reaper'), Entity(start_offset=269, end_offset=289, type='context', text='the McCormick Reaper', normalized_text='mccormick reaper')), (Entity(start_offset=32, end_offset=47, type='question', text='cyrus mccormick', normalized_text='cyrus mccormick'), Entity(start_offset=306, end_offset=329, type='context', text='his son Cyrus McCormick', normalized_text='his son cyrus mccormick'))], explanation_type='single_sentence'),\n",
       " -2832609809473486311: QEDExample(example_id=-2832609809473486311, title='Flag of the United States', question='what does the stars and stripes mean on the american flag', passage=\"The flag of the United States of America , often referred to as the American flag , is the national flag of the United States . It consists of thirteen equal horizontal stripes of red ( top and bottom ) alternating with white , with a blue rectangle in the canton ( referred to specifically as the `` union '' ) bearing fifty small , white , five - pointed stars arranged in nine offset horizontal rows , where rows of six stars ( top and bottom ) alternate with rows of five stars . The 50 stars on the flag represent the 50 states of the United States of America , and the 13 stripes represent the thirteen British colonies that declared independence from the Kingdom of Great Britain , and became the first states in the U.S. Nicknames for the flag include The Stars and Stripes , Old Glory , and The Star - Spangled Banner .\", sentence_starts=[0, 128, 484], selected_sent={'start': 484, 'end': 828, 'string': 'The 50 stars on the flag represent the 50 states of the United States of America , and the 13 stripes represent the thirteen British colonies that declared independence from the Kingdom of Great Britain , and became the first states in the U.S. Nicknames for the flag include The Stars and Stripes , Old Glory , and The Star - Spangled Banner .'}, answer=[Entity(start_offset=484, end_offset=728, type='context', text='The 50 stars on the flag represent the 50 states of the United States of America , and the 13 stripes represent the thirteen British colonies that declared independence from the Kingdom of Great Britain , and became the first states in the U.S.', normalized_text='50 stars on flag represent 50 states of united states of america and 13 stripes represent thirteen british colonies that declared independence from kingdom of great britain and became first states in us')], nq_answers=[[Entity(start_offset=519, end_offset=564, type='context', text='the 50 states of the United States of America', normalized_text='50 states of united states of america'), Entity(start_offset=596, end_offset=728, type='context', text='the thirteen British colonies that declared independence from the Kingdom of Great Britain , and became the first states in the U.S.', normalized_text='thirteen british colonies that declared independence from kingdom of great britain and became first states in us')], [Entity(start_offset=596, end_offset=728, type='context', text='the thirteen British colonies that declared independence from the Kingdom of Great Britain , and became the first states in the U.S.', normalized_text='thirteen british colonies that declared independence from kingdom of great britain and became first states in us')]], aligned_nps=[(Entity(start_offset=40, end_offset=57, type='question', text='the american flag', normalized_text='american flag'), Entity(start_offset=500, end_offset=508, type='context', text='the flag', normalized_text='flag'))], explanation_type='single_sentence'),\n",
       " 3780798490838700655: QEDExample(example_id=3780798490838700655, title='Seattle Slew', question='when did seattle slew win the triple crown', passage='Seattle Slew ( February 15 , 1974 -- May 7 , 2002 ) was an American Thoroughbred race horse who won the Triple Crown in 1977 -- the tenth of twelve horses to accomplish the feat . He is the only horse to have won the Triple Crown while having been undefeated in any race previous . Honored as the 1977 Horse of the Year , he was also a champion at age two , three and four . In the Blood - Horse magazine List of the Top 100 U.S. Racehorses of the 20th Century Seattle Slew was ranked ninth .', sentence_starts=[0, 180, 282, 375], selected_sent={'start': 0, 'end': 180, 'string': 'Seattle Slew ( February 15 , 1974 -- May 7 , 2002 ) was an American Thoroughbred race horse who won the Triple Crown in 1977 -- the tenth of twelve horses to accomplish the feat . '}, answer=[Entity(start_offset=120, end_offset=124, type='context', text='1977', normalized_text='1977')], nq_answers=[[Entity(start_offset=120, end_offset=124, type='context', text='1977', normalized_text='1977')], [Entity(start_offset=117, end_offset=124, type='context', text='in 1977', normalized_text='in 1977')]], aligned_nps=[(Entity(start_offset=9, end_offset=21, type='question', text='seattle slew', normalized_text='seattle slew'), Entity(start_offset=0, end_offset=12, type='context', text='Seattle Slew', normalized_text='seattle slew')), (Entity(start_offset=26, end_offset=42, type='question', text='the triple crown', normalized_text='triple crown'), Entity(start_offset=100, end_offset=116, type='context', text='the Triple Crown', normalized_text='triple crown'))], explanation_type='single_sentence'),\n",
       " 6403936039868410763: QEDExample(example_id=6403936039868410763, title='Teenage Mutant Ninja Turtles', question='when did teenage mutant ninja turtles come out', passage=\"The Teenage Mutant Ninja Turtles first appeared in an American comic book published by Mirage Studios in 1984 in Dover , New Hampshire . The concept arose from a humorous drawing sketched out by Eastman during a casual evening of brainstorming and bad television with Laird . Using money from a tax refund , together with a loan from Eastman 's uncle , the young artists self - published a single - issue comic intended to parody four of the most popular comics of the early 1980s : Marvel Comics ' Daredevil and New Mutants , Dave Sim 's Cerebus , and Frank Miller 's Ronin . The TMNT comic book series has been published in various incarnations by various comic book companies since 1984 .\", sentence_starts=[0, 137, 276, 577], selected_sent={'start': 0, 'end': 137, 'string': 'The Teenage Mutant Ninja Turtles first appeared in an American comic book published by Mirage Studios in 1984 in Dover , New Hampshire . '}, answer=[Entity(start_offset=105, end_offset=109, type='context', text='1984', normalized_text='1984')], nq_answers=[[Entity(start_offset=105, end_offset=109, type='context', text='1984', normalized_text='1984')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='teenage mutant ninja turtles', normalized_text='teenage mutant ninja turtles'), Entity(start_offset=0, end_offset=32, type='context', text='The Teenage Mutant Ninja Turtles', normalized_text='teenage mutant ninja turtles'))], explanation_type='single_sentence'),\n",
       " -1769528362781268772: QEDExample(example_id=-1769528362781268772, title='History of Jamestown, Virginia (1607–99)', question='who lived in jamestown before the arrival of the english', passage=\"Despite the immediate area of Jamestown being uninhabited , the settlers were attacked less than two weeks after their arrival on May 14 , by Paspahegh Indians who succeeded in killing one of the settlers and wounding eleven more . Within a month , James Fort covered an acre on Jamestown Island . By June 15 , the settlers finished building the triangular James Fort . The wooden palisaded walls formed a triangle around a storehouse , church , and a number of houses . A week later , Newport sailed back for London on Susan Constant with a load of pyrite ( `` fools ' gold '' ) and other supposedly precious minerals , leaving behind 104 colonists and Discovery .\", sentence_starts=[0, 232, 298, 370, 471], selected_sent={'start': 0, 'end': 232, 'string': 'Despite the immediate area of Jamestown being uninhabited , the settlers were attacked less than two weeks after their arrival on May 14 , by Paspahegh Indians who succeeded in killing one of the settlers and wounding eleven more . '}, answer=[Entity(start_offset=46, end_offset=57, type='context', text='uninhabited', normalized_text='uninhabited')], nq_answers=[[Entity(start_offset=46, end_offset=57, type='context', text='uninhabited', normalized_text='uninhabited')]], aligned_nps=[(Entity(start_offset=13, end_offset=22, type='question', text='jamestown', normalized_text='jamestown'), Entity(start_offset=30, end_offset=39, type='context', text='Jamestown', normalized_text='jamestown')), (Entity(start_offset=45, end_offset=56, type='question', text='the english', normalized_text='english'), Entity(start_offset=60, end_offset=72, type='context', text='the settlers', normalized_text='settlers'))], explanation_type='single_sentence'),\n",
       " 6788315330567276031: QEDExample(example_id=6788315330567276031, title='List of Girl Meets World characters', question='who plays the dad in girl meets world', passage=\"Cory Matthews ( Ben Savage ) is Riley and Auggie 's father and Topanga 's husband . He has taken a job as a history teacher at John Quincy Adams Middle School for the first two seasons and then Abigail Adams High School beginning the third season . In both settings , his class consists of his daughter and her friends and his history lessons relate to their lives , becoming life lessons for them . In addition to being Riley 's father , he often acts as a father figure to Maya . He also acts as a mentor to his students , much like Mr. Feeny was to Cory , Topanga , and Shawn in Boy Meets World .\", sentence_starts=[0, 84, 249, 400, 482], selected_sent={'start': 0, 'end': 84, 'string': \"Cory Matthews ( Ben Savage ) is Riley and Auggie 's father and Topanga 's husband . \"}, answer=[Entity(start_offset=16, end_offset=26, type='context', text='Ben Savage', normalized_text='ben savage')], nq_answers=[[Entity(start_offset=16, end_offset=26, type='context', text='Ben Savage', normalized_text='ben savage')], [Entity(start_offset=0, end_offset=13, type='context', text='Cory Matthews', normalized_text='cory matthews')]], aligned_nps=[(Entity(start_offset=10, end_offset=17, type='question', text='the dad', normalized_text='dad'), Entity(start_offset=32, end_offset=58, type='context', text=\"Riley and Auggie 's father\", normalized_text='riley and auggie s father')), (Entity(start_offset=21, end_offset=37, type='question', text='girl meets world', normalized_text='girl meets world'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -8518155586522600846: QEDExample(example_id=-8518155586522600846, title=\"Assassin's Creed IV: Black Flag\", question=\"who are you in assassin's creed 4\", passage=\"The plot is set in a fictional history of real world events and follows the centuries - old struggle between the Assassins , who fight for peace with free will , and the Templars , who desire peace through control . The framing story is set in the 21st century and describes the player as an Abstergo agent . The main story is set in the 18th century Caribbean during the Golden Age of Piracy , and follows notorious Welsh pirate Edward Kenway , grandfather and father of Assassin 's Creed III protagonist and antagonist Ratonhnhaké : ton and Haytham Kenway respectively , who stumbles upon the Assassin / Templar conflict . The attempted establishment of a Republic of Pirates utopia ( free from either British or Spanish rule ) is a significant plot element .\", sentence_starts=[0, 216, 309, 625], selected_sent={'start': 216, 'end': 309, 'string': 'The framing story is set in the 21st century and describes the player as an Abstergo agent . '}, answer=[Entity(start_offset=289, end_offset=306, type='context', text='an Abstergo agent', normalized_text='abstergo agent')], nq_answers=[[Entity(start_offset=289, end_offset=306, type='context', text='an Abstergo agent', normalized_text='abstergo agent')]], aligned_nps=[(Entity(start_offset=15, end_offset=33, type='question', text=\"assassin's creed 4\", normalized_text='assassins creed 4'), Entity(start_offset=216, end_offset=233, type='context', text='The framing story', normalized_text='framing story'))], explanation_type='single_sentence'),\n",
       " -1602930054930299018: QEDExample(example_id=-1602930054930299018, title='Harold & Kumar Go to White Castle', question='where is the white castle that harold and kumar go to', passage=\"Investment banker Harold Lee is persuaded by his colleagues to do their work while they leave for the weekend . Kumar Patel attends a medical school interview , but intentionally botches it to prevent getting accepted . Harold is attracted to his neighbor , Maria , but is unable to admit his feelings . After smoking marijuana with Kumar , and seeing an advertisement for White Castle , the pair decide to get hamburgers . After traveling to the nearest White Castle in New Brunswick , they find it replaced by `` Burger Shack '' but learn of another White Castle in Cherry Hill .\", sentence_starts=[0, 112, 220, 304, 424], selected_sent={'start': 424, 'end': 581, 'string': \"After traveling to the nearest White Castle in New Brunswick , they find it replaced by `` Burger Shack '' but learn of another White Castle in Cherry Hill .\"}, answer=[Entity(start_offset=568, end_offset=579, type='context', text='Cherry Hill', normalized_text='cherry hill')], nq_answers=[[Entity(start_offset=565, end_offset=579, type='context', text='in Cherry Hill', normalized_text='in cherry hill')]], aligned_nps=[(Entity(start_offset=31, end_offset=47, type='question', text='harold and kumar', normalized_text='harold and kumar'), Entity(start_offset=487, end_offset=491, type='context', text='they', normalized_text='they')), (Entity(start_offset=9, end_offset=25, type='question', text='the white castle', normalized_text='white castle'), Entity(start_offset=544, end_offset=564, type='context', text='another White Castle', normalized_text='another white castle'))], explanation_type='single_sentence'),\n",
       " 243685073103458654: QEDExample(example_id=243685073103458654, title='Transition economy', question='what was the initial effect of the transition from command to market economies in eastern europe', passage='Inequality of opportunity was higher in the transition economies of Central and Eastern Europe and Central Asia than in some other developed economies in Western Europe ( except France , where inequality of opportunity was relatively high ) . The highest inequality of opportunity was found in the Balkans and Central Asia . In terms of legal regulations and access to education and health services , inequality of opportunity related to gender was low in Europe and Central Asia but medium to high in respect of labour practices , employment and entrepreneurship and in access to finance . In Central Asia women also experienced significant lack of access to health services , as was the case in Arab countries . While many transition economies performed well with respect to primary and secondary education , and matched that available in many other developed economies , they were weaker when it came to training and tertiary education .', sentence_starts=[0, 243, 325, 591, 714], selected_sent={'start': 0, 'end': 243, 'string': 'Inequality of opportunity was higher in the transition economies of Central and Eastern Europe and Central Asia than in some other developed economies in Western Europe ( except France , where inequality of opportunity was relatively high ) . '}, answer=[Entity(start_offset=0, end_offset=25, type='context', text='Inequality of opportunity', normalized_text='inequality of opportunity')], nq_answers=[[Entity(start_offset=0, end_offset=25, type='context', text='Inequality of opportunity', normalized_text='inequality of opportunity')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 5041227796109703758: QEDExample(example_id=5041227796109703758, title='One More Light', question='when did linkin park release one more light', passage=\"One More Light is the seventh studio album by American rock band Linkin Park . It was released on May 19 , 2017 through Warner Bros. and Machine Shop . It is the last Linkin Park record produced before lead vocalist Chester Bennington 's death on July 20 , 2017 .\", sentence_starts=[0, 79, 152], selected_sent={'start': 79, 'end': 152, 'string': 'It was released on May 19 , 2017 through Warner Bros. and Machine Shop . '}, answer=[Entity(start_offset=98, end_offset=111, type='context', text='May 19 , 2017', normalized_text='may 19 2017')], nq_answers=[[Entity(start_offset=98, end_offset=111, type='context', text='May 19 , 2017', normalized_text='may 19 2017')]], aligned_nps=[(Entity(start_offset=29, end_offset=43, type='question', text='one more light', normalized_text='one more light'), Entity(start_offset=79, end_offset=81, type='context', text='It', normalized_text='it')), (Entity(start_offset=9, end_offset=20, type='question', text='linkin park', normalized_text='linkin park'), Entity(start_offset=86, end_offset=94, type='context', text='released', normalized_text='released'))], explanation_type='single_sentence'),\n",
       " -9039792036843684255: QEDExample(example_id=-9039792036843684255, title='Disputed status of Gibraltar', question='what territory is spain and the united kingdom in a dispute over', passage='Gibraltar , a British Overseas Territory , located at the southern tip of the Iberian Peninsula , is the subject of an irredentist territorial claim by Spain . It was captured in 1704 during the War of the Spanish Succession ( 1701 -- 1714 ) . The Spanish Crown formally ceded the territory in perpetuity to the British Crown in 1713 , under Article X of the Treaty of Utrecht . Spain later attempted to recapture the territory during the thirteenth siege ( 1727 ) and the Great siege ( 1779 -- 1783 ) . British sovereignty over Gibraltar was confirmed in later treaties signed in Seville ( 1729 ) and the Treaty of Paris ( 1783 ) .', sentence_starts=[0, 160, 244, 379, 504], selected_sent={'start': 0, 'end': 160, 'string': 'Gibraltar , a British Overseas Territory , located at the southern tip of the Iberian Peninsula , is the subject of an irredentist territorial claim by Spain . '}, answer=[Entity(start_offset=0, end_offset=9, type='context', text='Gibraltar', normalized_text='gibraltar')], nq_answers=[[Entity(start_offset=0, end_offset=9, type='context', text='Gibraltar', normalized_text='gibraltar')], [Entity(start_offset=0, end_offset=95, type='context', text='Gibraltar , a British Overseas Territory , located at the southern tip of the Iberian Peninsula', normalized_text='gibraltar british overseas territory located at southern tip of iberian peninsula')]], aligned_nps=[(Entity(start_offset=18, end_offset=23, type='question', text='spain', normalized_text='spain'), Entity(start_offset=152, end_offset=157, type='context', text='Spain', normalized_text='spain'))], explanation_type='single_sentence'),\n",
       " -7583855073136179893: QEDExample(example_id=-7583855073136179893, title='David Akers', question='when did david akers kick the 63 yard field goal', passage='On September 9 , 2012 , Akers tied the NFL record for the longest field goal by kicking a 63 - yard field goal off the crossbar against the Green Bay Packers at Lambeau Field . The record was originally set by Tom Dempsey and was shared with Jason Elam and Sebastian Janikowski until Broncos kicker Matt Prater broke the record with a 64 - yard field goal on December 8 , 2013 .', sentence_starts=[0, 177], selected_sent={'start': 0, 'end': 177, 'string': 'On September 9 , 2012 , Akers tied the NFL record for the longest field goal by kicking a 63 - yard field goal off the crossbar against the Green Bay Packers at Lambeau Field . '}, answer=[Entity(start_offset=3, end_offset=21, type='context', text='September 9 , 2012', normalized_text='september 9 2012')], nq_answers=[[Entity(start_offset=3, end_offset=21, type='context', text='September 9 , 2012', normalized_text='september 9 2012')]], aligned_nps=[(Entity(start_offset=9, end_offset=20, type='question', text='david akers', normalized_text='david akers'), Entity(start_offset=24, end_offset=29, type='context', text='Akers', normalized_text='akers')), (Entity(start_offset=26, end_offset=48, type='question', text='the 63 yard field goal', normalized_text='63 yard field goal'), Entity(start_offset=88, end_offset=110, type='context', text='a 63 - yard field goal', normalized_text='63 yard field goal'))], explanation_type='single_sentence'),\n",
       " -163195825366469164: QEDExample(example_id=-163195825366469164, title='Dermis', question='where does the papillary layer of the skin lie', passage='The dermis or corium is a layer of skin between the epidermis ( with which it makes up the cutis ) and subcutaneous tissues , that primarily consists of dense irregular connective tissue and cushions the body from stress and strain . It is divided into two layers , the superficial area adjacent to the epidermis called the papillary region and a deep thicker area known as the reticular dermis . The dermis is tightly connected to the epidermis through a basement membrane . Structural components of the dermis are collagen , elastic fibers , and extrafibrillar matrix . It also contains mechanoreceptors that provide the sense of touch and thermoreceptors that provide the sense of heat . In addition , hair follicles , sweat glands , sebaceous glands , apocrine glands , lymphatic vessels and blood vessels are present in the dermis . Those blood vessels provide nourishment and waste removal for both dermal and epidermal cells .', sentence_starts=[0, 234, 397, 476, 572, 691, 838], selected_sent={'start': 234, 'end': 397, 'string': 'It is divided into two layers , the superficial area adjacent to the epidermis called the papillary region and a deep thicker area known as the reticular dermis . '}, answer=[Entity(start_offset=287, end_offset=312, type='context', text='adjacent to the epidermis', normalized_text='adjacent to epidermis')], nq_answers=[[Entity(start_offset=287, end_offset=312, type='context', text='adjacent to the epidermis', normalized_text='adjacent to epidermis')]], aligned_nps=[(Entity(start_offset=11, end_offset=42, type='question', text='the papillary layer of the skin', normalized_text='papillary layer of skin'), Entity(start_offset=320, end_offset=340, type='context', text='the papillary region', normalized_text='papillary region'))], explanation_type='single_sentence'),\n",
       " -1975115150327235272: QEDExample(example_id=-1975115150327235272, title='Kudzu in the United States', question='when was kudzu introduced to the united states', passage=\"The kudzu plant was introduced to the United States from Japan in 1876 at the Centennial Exposition in Philadelphia . Kudzu was introduced to the Southeast in 1883 at the New Orleans Exposition . The vine was widely marketed in the Southeast as an ornamental plant to be used to shade porches , and in the first half of the 20th century , kudzu was distributed as a high - protein content cattle fodder and as a cover plant to prevent soil erosion . It was cultivated by Civilian Conservation Corps workers as a solution for the erosion during the Dust Bowl . The Soil Erosion Service recommended the use of kudzu to help control erosion of slopes which led to the government - aided distribution of 85 million seedlings and government - funded plantings of kudzu which paid $19.75 per hectare . By 1946 , it was estimated that 1,200,000 hectares ( 3,000,000 acres ) of kudzu had been planted . When boll weevil infestations and the failure of cotton crops caused farmers to abandon their farms , kudzu plantings were left unattended . The climate and environment of the Southeastern United States allowed the kudzu to grow virtually unchecked . In 1953 the United States Department of Agriculture removed kudzu from a list of suggested cover plants and listed it as a weed in 1970 . By 1997 , the vine was placed on the `` Federal Noxious Weed List '' . Today , kudzu is estimated to cover 3,000,000 hectares ( 7,400,000 acres ) of land in the southeastern United States , mostly in Alabama , Georgia , Tennessee , Florida , North Carolina , South Carolina and Mississippi . It has been recorded in Nova Scotia , Canada , in Columbus , Ohio , and in all five boroughs of New York City .\", sentence_starts=[0, 118, 196, 450, 560, 796, 895, 1036, 1146, 1284, 1355, 1576], selected_sent={'start': 0, 'end': 118, 'string': 'The kudzu plant was introduced to the United States from Japan in 1876 at the Centennial Exposition in Philadelphia . '}, answer=[Entity(start_offset=66, end_offset=70, type='context', text='1876', normalized_text='1876')], nq_answers=[[Entity(start_offset=66, end_offset=70, type='context', text='1876', normalized_text='1876')], [Entity(start_offset=63, end_offset=70, type='context', text='in 1876', normalized_text='in 1876')]], aligned_nps=[(Entity(start_offset=9, end_offset=14, type='question', text='kudzu', normalized_text='kudzu'), Entity(start_offset=0, end_offset=15, type='context', text='The kudzu plant', normalized_text='kudzu plant')), (Entity(start_offset=29, end_offset=46, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=34, end_offset=51, type='context', text='the United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 4911813695697896179: QEDExample(example_id=4911813695697896179, title='Alveolar process', question='the radiographic term used to describe the dense bone of the socket and septal crest is', passage='The alveolar process ( / ælˈviːələr / ) ( alveolar bone ) is the thickened ridge of bone that contains the tooth sockets ( dental alveoli ) on bones that hold teeth . In humans , the tooth - bearing bones are the maxillae and the mandible .', sentence_starts=[0, 167], selected_sent={'start': 0, 'end': 167, 'string': 'The alveolar process ( / ælˈviːələr / ) ( alveolar bone ) is the thickened ridge of bone that contains the tooth sockets ( dental alveoli ) on bones that hold teeth . '}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='The alveolar process', normalized_text='alveolar process')], nq_answers=[[Entity(start_offset=4, end_offset=20, type='context', text='alveolar process', normalized_text='alveolar process')]], aligned_nps=[(Entity(start_offset=39, end_offset=84, type='question', text='the dense bone of the socket and septal crest', normalized_text='dense bone of socket and septal crest'), Entity(start_offset=61, end_offset=164, type='context', text='the thickened ridge of bone that contains the tooth sockets ( dental alveoli ) on bones that hold teeth', normalized_text='thickened ridge of bone that contains tooth sockets dental alveoli on bones that hold teeth'))], explanation_type='single_sentence'),\n",
       " -4018525468901338278: QEDExample(example_id=-4018525468901338278, title='Guano Islands Act', question='what did the guano islands act allow the us to do', passage='The Guano Islands Act ( 11 Stat. 119 , enacted August 18 , 1856 , codified at 48 U.S.C. ch. 8 § § 1411 - 1419 ) is a United States federal law passed by the U.S. Congress that enables citizens of the United States to take possession of unclaimed islands containing guano deposits . The islands can be located anywhere , so long as they are not occupied and not within the jurisdiction of another government . It also empowers the President of the United States to use the military to protect such interests and establishes the criminal jurisdiction of the United States in these territories .', sentence_starts=[0, 88, 282, 409], selected_sent={'start': 0, 'end': 282, 'string': 'The Guano Islands Act ( 11 Stat. 119 , enacted August 18 , 1856 , codified at 48 U.S.C. ch. 8 § § 1411 - 1419 ) is a United States federal law passed by the U.S. Congress that enables citizens of the United States to take possession of unclaimed islands containing guano deposits . '}, answer=[Entity(start_offset=176, end_offset=279, type='context', text='enables citizens of the United States to take possession of unclaimed islands containing guano deposits', normalized_text='enables citizens of united states to take possession of unclaimed islands containing guano deposits')], nq_answers=[[Entity(start_offset=176, end_offset=279, type='context', text='enables citizens of the United States to take possession of unclaimed islands containing guano deposits', normalized_text='enables citizens of united states to take possession of unclaimed islands containing guano deposits')], [Entity(start_offset=217, end_offset=279, type='context', text='take possession of unclaimed islands containing guano deposits', normalized_text='take possession of unclaimed islands containing guano deposits'), Entity(start_offset=464, end_offset=506, type='context', text='use the military to protect such interests', normalized_text='use military to protect such interests'), Entity(start_offset=511, end_offset=590, type='context', text='establishes the criminal jurisdiction of the United States in these territories', normalized_text='establishes criminal jurisdiction of united states in these territories')], [Entity(start_offset=214, end_offset=279, type='context', text='to take possession of unclaimed islands containing guano deposits', normalized_text='to take possession of unclaimed islands containing guano deposits')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text='the guano islands act', normalized_text='guano islands act'), Entity(start_offset=0, end_offset=21, type='context', text='The Guano Islands Act', normalized_text='guano islands act')), (Entity(start_offset=37, end_offset=43, type='question', text='the us', normalized_text='us'), Entity(start_offset=117, end_offset=130, type='context', text='United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 3490824095431420580: QEDExample(example_id=3490824095431420580, title='Friday Night Lights (TV series)', question='where was the tv show friday night lights filmed', passage=\"All five seasons of Friday Night Lights were filmed in Austin and Pflugerville . With the show yielding roughly $33 million a year in revenue , other states courted the production company after the state of Texas failed to pay all the rebates it had promised to the show 's producers . The Texas legislature authorized funding to match the offers of other states , and the production company preferred to stay near Austin , so the show remained in Texas .\", sentence_starts=[0, 81, 286], selected_sent={'start': 0, 'end': 81, 'string': 'All five seasons of Friday Night Lights were filmed in Austin and Pflugerville . '}, answer=[Entity(start_offset=55, end_offset=78, type='context', text='Austin and Pflugerville', normalized_text='austin and pflugerville')], nq_answers=[[Entity(start_offset=55, end_offset=61, type='context', text='Austin', normalized_text='austin'), Entity(start_offset=66, end_offset=78, type='context', text='Pflugerville', normalized_text='pflugerville')]], aligned_nps=[(Entity(start_offset=10, end_offset=41, type='question', text='the tv show friday night lights', normalized_text='tv show friday night lights'), Entity(start_offset=20, end_offset=39, type='context', text='Friday Night Lights', normalized_text='friday night lights'))], explanation_type='single_sentence'),\n",
       " -8363239742768997492: QEDExample(example_id=-8363239742768997492, title='Siege of Yorktown', question='who led an attack that allowed for american victory at yorktown', passage='The Siege of Yorktown , also known as the Battle of Yorktown , the Surrender at Yorktown , German Battle or the Siege of Little York , ending on October 19 , 1781 , at Yorktown , Virginia , was a decisive victory by a combined force of American Continental Army troops led by General George Washington and French Army troops led by the Comte de Rochambeau over a British Army commanded by British peer and Lieutenant General Charles Cornwallis . The culmination of the Yorktown campaign , the siege proved to be the last major land battle of the American Revolutionary War in the North American theater , as the surrender by Cornwallis , and the capture of both him and his army , prompted the British government to negotiate an end to the conflict . The battle boosted faltering American morale and revived French enthusiasm for the war , as well as undermining popular support for the conflict in Great Britain .', sentence_starts=[0, 446, 751], selected_sent={'start': 0, 'end': 446, 'string': 'The Siege of Yorktown , also known as the Battle of Yorktown , the Surrender at Yorktown , German Battle or the Siege of Little York , ending on October 19 , 1781 , at Yorktown , Virginia , was a decisive victory by a combined force of American Continental Army troops led by General George Washington and French Army troops led by the Comte de Rochambeau over a British Army commanded by British peer and Lieutenant General Charles Cornwallis . '}, answer=[Entity(start_offset=236, end_offset=355, type='context', text='American Continental Army troops led by General George Washington and French Army troops led by the Comte de Rochambeau', normalized_text='american continental army troops led by general george washington and french army troops led by comte de rochambeau')], nq_answers=[[Entity(start_offset=236, end_offset=355, type='context', text='American Continental Army troops led by General George Washington and French Army troops led by the Comte de Rochambeau', normalized_text='american continental army troops led by general george washington and french army troops led by comte de rochambeau')], [Entity(start_offset=236, end_offset=301, type='context', text='American Continental Army troops led by General George Washington', normalized_text='american continental army troops led by general george washington'), Entity(start_offset=306, end_offset=355, type='context', text='French Army troops led by the Comte de Rochambeau', normalized_text='french army troops led by comte de rochambeau')], [Entity(start_offset=284, end_offset=301, type='context', text='George Washington', normalized_text='george washington'), Entity(start_offset=336, end_offset=355, type='context', text='Comte de Rochambeau', normalized_text='comte de rochambeau')]], aligned_nps=[(Entity(start_offset=55, end_offset=63, type='question', text='yorktown', normalized_text='yorktown'), Entity(start_offset=168, end_offset=176, type='context', text='Yorktown', normalized_text='yorktown'))], explanation_type='single_sentence'),\n",
       " 9104579908306893648: QEDExample(example_id=9104579908306893648, title=\"Queen of Hearts (Alice's Adventures in Wonderland)\", question='who is the queen of hearts in alice in wonderland', passage=\"The Queen of Hearts is a fictional character from the book Alice 's Adventures in Wonderland by the writer Lewis Carroll , in which she appears as the primary antagonist . She is a foul - tempered monarch whom Carroll himself describes as `` a blind fury '' , and who is quick to give death sentences at the slightest offense . One of her most famous lines she states often is `` Off with their heads ! ''\", sentence_starts=[0, 172, 328], selected_sent={'start': 172, 'end': 328, 'string': \"She is a foul - tempered monarch whom Carroll himself describes as `` a blind fury '' , and who is quick to give death sentences at the slightest offense . \"}, answer=[Entity(start_offset=179, end_offset=325, type='context', text=\"a foul - tempered monarch whom Carroll himself describes as `` a blind fury '' , and who is quick to give death sentences at the slightest offense\", normalized_text='foul tempered monarch whom carroll himself describes as blind fury and who is quick to give death sentences at slightest offense')], nq_answers=[[Entity(start_offset=147, end_offset=169, type='context', text='the primary antagonist', normalized_text='primary antagonist'), Entity(start_offset=179, end_offset=325, type='context', text=\"a foul - tempered monarch whom Carroll himself describes as `` a blind fury '' , and who is quick to give death sentences at the slightest offense\", normalized_text='foul tempered monarch whom carroll himself describes as blind fury and who is quick to give death sentences at slightest offense')]], aligned_nps=[(Entity(start_offset=7, end_offset=49, type='question', text='the queen of hearts in alice in wonderland', normalized_text='queen of hearts in alice in wonderland'), Entity(start_offset=172, end_offset=175, type='context', text='She', normalized_text='she'))], explanation_type='single_sentence'),\n",
       " -89839634525298434: QEDExample(example_id=-89839634525298434, title='Darlene Cates', question=\"who played the mom on what's eating gilbert grape\", passage=\"Darlene Cates ( born Rita Darlene Guthrie ; December 13 , 1947 -- March 26 , 2017 ) was an American actress . She was best known for her role in the 1993 film What 's Eating Gilbert Grape , in which she played the title character 's housebound mother .\", sentence_starts=[0, 110], selected_sent={'start': 110, 'end': 252, 'string': \"She was best known for her role in the 1993 film What 's Eating Gilbert Grape , in which she played the title character 's housebound mother .\"}, answer=[Entity(start_offset=0, end_offset=13, type='context', text='Darlene Cates', normalized_text='darlene cates')], nq_answers=[[Entity(start_offset=0, end_offset=13, type='context', text='Darlene Cates', normalized_text='darlene cates')], [Entity(start_offset=0, end_offset=41, type='context', text='Darlene Cates ( born Rita Darlene Guthrie', normalized_text='darlene cates born rita darlene guthrie')]], aligned_nps=[(Entity(start_offset=22, end_offset=49, type='question', text=\"what's eating gilbert grape\", normalized_text='whats eating gilbert grape'), Entity(start_offset=145, end_offset=187, type='context', text=\"the 1993 film What 's Eating Gilbert Grape\", normalized_text='1993 film what s eating gilbert grape')), (Entity(start_offset=11, end_offset=18, type='question', text='the mom', normalized_text='mom'), Entity(start_offset=210, end_offset=250, type='context', text=\"the title character 's housebound mother\", normalized_text='title character s housebound mother'))], explanation_type='single_sentence'),\n",
       " -8828538942223020699: QEDExample(example_id=-8828538942223020699, title='As the crow flies', question='where does the expression as the crow flies come from', passage=\"As the crow flies , similar to in a beeline , is an idiom for the most direct path between two points . This meaning is attested from the early 19th century , and appeared in Charles Dickens 's novel Oliver Twist :\", sentence_starts=[0, 104], selected_sent={'start': 104, 'end': 214, 'string': \"This meaning is attested from the early 19th century , and appeared in Charles Dickens 's novel Oliver Twist :\"}, answer=[Entity(start_offset=134, end_offset=156, type='context', text='the early 19th century', normalized_text='early 19th century')], nq_answers=[[Entity(start_offset=175, end_offset=212, type='context', text=\"Charles Dickens 's novel Oliver Twist\", normalized_text='charles dickens s novel oliver twist')]], aligned_nps=[(Entity(start_offset=11, end_offset=43, type='question', text='the expression as the crow flies', normalized_text='expression as crow flies'), Entity(start_offset=104, end_offset=116, type='context', text='This meaning', normalized_text='this meaning'))], explanation_type='single_sentence'),\n",
       " 6792980250224411482: QEDExample(example_id=6792980250224411482, title='Ministry of Local Government and Urban Development (Zimbabwe)', question='who is the minister of local government in zimbabwe', passage='The Ministry of Local Government , Rural and Urban Development is a government ministry , responsible for local government in Zimbabwe . The incumbent minister is Hon July Moyo and the deputy minister is Sesel Zvidzai . It oversees :', sentence_starts=[0, 137, 220], selected_sent={'start': 137, 'end': 220, 'string': 'The incumbent minister is Hon July Moyo and the deputy minister is Sesel Zvidzai . '}, answer=[Entity(start_offset=163, end_offset=176, type='context', text='Hon July Moyo', normalized_text='hon july moyo')], nq_answers=[[Entity(start_offset=163, end_offset=176, type='context', text='Hon July Moyo', normalized_text='hon july moyo')]], aligned_nps=[(Entity(start_offset=7, end_offset=51, type='question', text='the minister of local government in zimbabwe', normalized_text='minister of local government in zimbabwe'), Entity(start_offset=137, end_offset=159, type='context', text='The incumbent minister', normalized_text='incumbent minister'))], explanation_type='single_sentence'),\n",
       " -6558090229319450246: QEDExample(example_id=-6558090229319450246, title='International Monetary Fund', question='what are the roles of international monetary fund', passage=\"The International Monetary Fund ( IMF ) is an international organization headquartered in Washington , D.C. , of `` 189 countries working to foster global monetary cooperation , secure financial stability , facilitate international trade , promote high employment and sustainable economic growth , and reduce poverty around the world . '' Formed in 1945 at the Bretton Woods Conference primarily by the ideas of Harry Dexter White and John Maynard Keynes , it came into formal existence in 1945 with 29 member countries and the goal of reconstructing the international payment system . It now plays a central role in the management of balance of payments difficulties and international financial crises . Countries contribute funds to a pool through a quota system from which countries experiencing balance of payments problems can borrow money . As of 2016 , the fund had SDR 477 billion ( about $668 billion ) .\", sentence_starts=[0, 339, 586, 705, 847], selected_sent={'start': 0, 'end': 339, 'string': \"The International Monetary Fund ( IMF ) is an international organization headquartered in Washington , D.C. , of `` 189 countries working to foster global monetary cooperation , secure financial stability , facilitate international trade , promote high employment and sustainable economic growth , and reduce poverty around the world . '' \"}, answer=[Entity(start_offset=141, end_offset=333, type='context', text='foster global monetary cooperation , secure financial stability , facilitate international trade , promote high employment and sustainable economic growth , and reduce poverty around the world', normalized_text='foster global monetary cooperation secure financial stability facilitate international trade promote high employment and sustainable economic growth and reduce poverty around world')], nq_answers=[[Entity(start_offset=138, end_offset=175, type='context', text='to foster global monetary cooperation', normalized_text='to foster global monetary cooperation'), Entity(start_offset=178, end_offset=204, type='context', text='secure financial stability', normalized_text='secure financial stability'), Entity(start_offset=207, end_offset=237, type='context', text='facilitate international trade', normalized_text='facilitate international trade'), Entity(start_offset=240, end_offset=295, type='context', text='promote high employment and sustainable economic growth', normalized_text='promote high employment and sustainable economic growth'), Entity(start_offset=302, end_offset=333, type='context', text='reduce poverty around the world', normalized_text='reduce poverty around world')], [Entity(start_offset=141, end_offset=175, type='context', text='foster global monetary cooperation', normalized_text='foster global monetary cooperation'), Entity(start_offset=178, end_offset=204, type='context', text='secure financial stability', normalized_text='secure financial stability'), Entity(start_offset=207, end_offset=237, type='context', text='facilitate international trade', normalized_text='facilitate international trade'), Entity(start_offset=240, end_offset=295, type='context', text='promote high employment and sustainable economic growth', normalized_text='promote high employment and sustainable economic growth'), Entity(start_offset=302, end_offset=333, type='context', text='reduce poverty around the world', normalized_text='reduce poverty around world')]], aligned_nps=[(Entity(start_offset=22, end_offset=49, type='question', text='international monetary fund', normalized_text='international monetary fund'), Entity(start_offset=0, end_offset=39, type='context', text='The International Monetary Fund ( IMF )', normalized_text='international monetary fund imf'))], explanation_type='single_sentence'),\n",
       " -628291178392259442: QEDExample(example_id=-628291178392259442, title='List of Star Wars films and television series', question='when was the first star wars film released', passage='The Star Wars films include two complete trilogies : the original trilogy released between 1977 and 1983 , and the prequel trilogy released between 1999 and 2005 . A third trilogy that follows the first two began in 2015 . Other films have taken or will take place between the trilogy films . There have also been several Star Wars television series and films , with the first being released in 1978 .', sentence_starts=[0, 164, 223, 293], selected_sent={'start': 0, 'end': 164, 'string': 'The Star Wars films include two complete trilogies : the original trilogy released between 1977 and 1983 , and the prequel trilogy released between 1999 and 2005 . '}, answer=[Entity(start_offset=91, end_offset=95, type='context', text='1977', normalized_text='1977')], nq_answers=[[Entity(start_offset=91, end_offset=95, type='context', text='1977', normalized_text='1977')]], aligned_nps=[(Entity(start_offset=19, end_offset=28, type='question', text='star wars', normalized_text='star wars'), Entity(start_offset=4, end_offset=13, type='context', text='Star Wars', normalized_text='star wars'))], explanation_type='single_sentence'),\n",
       " 9199587263422732891: QEDExample(example_id=9199587263422732891, title='Ted Levine', question='who was the bad guy in silence of the lambs', passage=\"Frank Theodore `` Ted '' Levine ( born May 29 , 1957 ) is an American actor . He is known for his roles as Buffalo Bill in The Silence of the Lambs and as Captain Leland Stottlemeyer in the television series Monk .\", sentence_starts=[0, 78], selected_sent={'start': 78, 'end': 214, 'string': 'He is known for his roles as Buffalo Bill in The Silence of the Lambs and as Captain Leland Stottlemeyer in the television series Monk .'}, answer=[Entity(start_offset=107, end_offset=119, type='context', text='Buffalo Bill', normalized_text='buffalo bill')], nq_answers=[[Entity(start_offset=107, end_offset=119, type='context', text='Buffalo Bill', normalized_text='buffalo bill')]], aligned_nps=[(Entity(start_offset=8, end_offset=19, type='question', text='the bad guy', normalized_text='bad guy'), Entity(start_offset=107, end_offset=119, type='context', text='Buffalo Bill', normalized_text='buffalo bill')), (Entity(start_offset=23, end_offset=43, type='question', text='silence of the lambs', normalized_text='silence of lambs'), Entity(start_offset=123, end_offset=147, type='context', text='The Silence of the Lambs', normalized_text='silence of lambs'))], explanation_type='single_sentence'),\n",
       " -5562718362522355071: QEDExample(example_id=-5562718362522355071, title='Plasmodesma', question='what are plasmodesmata and what is their function', passage='Plasmodesmata ( singular : plasmodesma ) are microscopic channels which traverse the cell walls of plant cells and some algal cells , enabling transport and communication between them . Plasmodesmata evolved independently in several lineages , and species that have these structures include members of the Charophyceae , Charales , Coleochaetales and Phaeophyceae ( which are all algae ) , as well as all embryophytes , better known as land plants . Unlike animal cells , almost every plant cell is surrounded by a polysaccharide cell wall . Neighbouring plant cells are therefore separated by a pair of cell walls and the intervening middle lamella , forming an extracellular domain known as the apoplast . Although cell walls are permeable to small soluble proteins and other solutes , plasmodesmata enable direct , regulated , symplastic transport of substances between cells . There are two forms of plasmodesmata : primary plasmodesmata , which are formed during cell division , and secondary plasmodesmata , which can form between mature cells .', sentence_starts=[0, 186, 450, 542, 708, 881], selected_sent={'start': 0, 'end': 186, 'string': 'Plasmodesmata ( singular : plasmodesma ) are microscopic channels which traverse the cell walls of plant cells and some algal cells , enabling transport and communication between them . '}, answer=[Entity(start_offset=45, end_offset=183, type='context', text='microscopic channels which traverse the cell walls of plant cells and some algal cells , enabling transport and communication between them', normalized_text='microscopic channels which traverse cell walls of plant cells and some algal cells enabling transport and communication between them')], nq_answers=[[Entity(start_offset=45, end_offset=131, type='context', text='microscopic channels which traverse the cell walls of plant cells and some algal cells', normalized_text='microscopic channels which traverse cell walls of plant cells and some algal cells'), Entity(start_offset=134, end_offset=183, type='context', text='enabling transport and communication between them', normalized_text='enabling transport and communication between them')], [Entity(start_offset=45, end_offset=183, type='context', text='microscopic channels which traverse the cell walls of plant cells and some algal cells , enabling transport and communication between them', normalized_text='microscopic channels which traverse cell walls of plant cells and some algal cells enabling transport and communication between them')]], aligned_nps=[(Entity(start_offset=9, end_offset=22, type='question', text='plasmodesmata', normalized_text='plasmodesmata'), Entity(start_offset=0, end_offset=13, type='context', text='Plasmodesmata', normalized_text='plasmodesmata'))], explanation_type='single_sentence'),\n",
       " 4492033271398413517: QEDExample(example_id=4492033271398413517, title='Puente Hills Mall', question='what mall did they use in back to the future', passage='Puente Hills Mall , located in the City of Industry , California , United States , is a major regional shopping center in the San Gabriel Valley region of Los Angeles County . It is most famous for serving as the filming site for the Twin Pines / Lone Pine Mall for the 1985 movie Back to the Future starring Michael J. Fox and Christopher Lloyd .', sentence_starts=[0, 176], selected_sent={'start': 176, 'end': 347, 'string': 'It is most famous for serving as the filming site for the Twin Pines / Lone Pine Mall for the 1985 movie Back to the Future starring Michael J. Fox and Christopher Lloyd .'}, answer=[Entity(start_offset=0, end_offset=17, type='context', text='Puente Hills Mall', normalized_text='puente hills mall')], nq_answers=[[Entity(start_offset=0, end_offset=17, type='context', text='Puente Hills Mall', normalized_text='puente hills mall')], [Entity(start_offset=0, end_offset=80, type='context', text='Puente Hills Mall , located in the City of Industry , California , United States', normalized_text='puente hills mall located in city of industry california united states')]], aligned_nps=[(Entity(start_offset=26, end_offset=44, type='question', text='back to the future', normalized_text='back to future'), Entity(start_offset=266, end_offset=345, type='context', text='the 1985 movie Back to the Future starring Michael J. Fox and Christopher Lloyd', normalized_text='1985 movie back to future starring michael j fox and christopher lloyd'))], explanation_type='single_sentence'),\n",
       " -3719623571078658627: QEDExample(example_id=-3719623571078658627, title='R/T', question='what does rt mean on a dodge car', passage=\"R / T is the performance marker used on Dodge automobiles since the 1960s ( much like Chevrolet Super Sport ) . R / T stands for Road / Track ( no `` and '' ) . R / T models usually come with R / T badging and a combination of upgraded suspension , tires , brakes , and often more powerful engines . Many models have also come with monotone paint and stripes as well as aggressive body kits . In 2004 the Chrysler SRT Division ( Chrysler Corp . SRT Vehicles ) replaced R / T as the high performance auto group for Dodge vehicles , though the trim level is still in use on many current models .\", sentence_starts=[0, 112, 161, 300, 393, 445], selected_sent={'start': 112, 'end': 161, 'string': \"R / T stands for Road / Track ( no `` and '' ) . \"}, answer=[Entity(start_offset=129, end_offset=158, type='context', text=\"Road / Track ( no `` and '' )\", normalized_text='road track no and')], nq_answers=[[Entity(start_offset=129, end_offset=141, type='context', text='Road / Track', normalized_text='road track')]], aligned_nps=[(Entity(start_offset=10, end_offset=12, type='question', text='rt', normalized_text='rt'), Entity(start_offset=112, end_offset=117, type='context', text='R / T', normalized_text='r t')), (Entity(start_offset=21, end_offset=32, type='question', text='a dodge car', normalized_text='dodge car'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -6477588851233520447: QEDExample(example_id=-6477588851233520447, title='Queen Máxima of the Netherlands', question='who is the king and queen of the netherlands', passage='Queen Máxima of the Netherlands ( born Máxima Zorreguieta Cerruti ; 17 May 1971 ) is the wife of King Willem - Alexander .', sentence_starts=[0], selected_sent={'start': 0, 'end': 122, 'string': 'Queen Máxima of the Netherlands ( born Máxima Zorreguieta Cerruti ; 17 May 1971 ) is the wife of King Willem - Alexander .'}, answer=[Entity(start_offset=0, end_offset=31, type='context', text='Queen Máxima of the Netherlands', normalized_text='queen máxima of netherlands'), Entity(start_offset=97, end_offset=120, type='context', text='King Willem - Alexander', normalized_text='king willem alexander')], nq_answers=[[Entity(start_offset=97, end_offset=120, type='context', text='King Willem - Alexander', normalized_text='king willem alexander'), Entity(start_offset=0, end_offset=81, type='context', text='Queen Máxima of the Netherlands ( born Máxima Zorreguieta Cerruti ; 17 May 1971 )', normalized_text='queen máxima of netherlands born máxima zorreguieta cerruti 17 may 1971')], [Entity(start_offset=0, end_offset=31, type='context', text='Queen Máxima of the Netherlands', normalized_text='queen máxima of netherlands'), Entity(start_offset=97, end_offset=120, type='context', text='King Willem - Alexander', normalized_text='king willem alexander')]], aligned_nps=[(Entity(start_offset=29, end_offset=44, type='question', text='the netherlands', normalized_text='netherlands'), Entity(start_offset=16, end_offset=31, type='context', text='the Netherlands', normalized_text='netherlands'))], explanation_type='single_sentence'),\n",
       " 7281701387754006749: QEDExample(example_id=7281701387754006749, title='Talmud', question='what written material is included in the talmud', passage=\"The Talmud has two components ; the Mishnah ( Hebrew : משנה , c. 200 CE ) , a written compendium of Rabbinic Judaism 's Oral Torah ; and the Gemara ( c. 500 CE ) , an elucidation of the Mishnah and related Tannaitic writings that often ventures onto other subjects and expounds broadly on the Hebrew Bible . `` Talmud '' translates literally as `` instruction '' in Hebrew , and the term may refer to either the Gemara alone , or the Mishnah and Gemara together .\", sentence_starts=[0, 308], selected_sent={'start': 0, 'end': 308, 'string': \"The Talmud has two components ; the Mishnah ( Hebrew : משנה , c. 200 CE ) , a written compendium of Rabbinic Judaism 's Oral Torah ; and the Gemara ( c. 500 CE ) , an elucidation of the Mishnah and related Tannaitic writings that often ventures onto other subjects and expounds broadly on the Hebrew Bible . \"}, answer=[Entity(start_offset=32, end_offset=305, type='context', text=\"the Mishnah ( Hebrew : משנה , c. 200 CE ) , a written compendium of Rabbinic Judaism 's Oral Torah ; and the Gemara ( c. 500 CE ) , an elucidation of the Mishnah and related Tannaitic writings that often ventures onto other subjects and expounds broadly on the Hebrew Bible\", normalized_text='mishnah hebrew משנה c 200 ce written compendium of rabbinic judaism s oral torah and gemara c 500 ce elucidation of mishnah and related tannaitic writings that often ventures onto other subjects and expounds broadly on hebrew bible')], nq_answers=[[Entity(start_offset=32, end_offset=130, type='context', text=\"the Mishnah ( Hebrew : משנה , c. 200 CE ) , a written compendium of Rabbinic Judaism 's Oral Torah\", normalized_text='mishnah hebrew משנה c 200 ce written compendium of rabbinic judaism s oral torah'), Entity(start_offset=137, end_offset=305, type='context', text='the Gemara ( c. 500 CE ) , an elucidation of the Mishnah and related Tannaitic writings that often ventures onto other subjects and expounds broadly on the Hebrew Bible', normalized_text='gemara c 500 ce elucidation of mishnah and related tannaitic writings that often ventures onto other subjects and expounds broadly on hebrew bible')], [Entity(start_offset=32, end_offset=43, type='context', text='the Mishnah', normalized_text='mishnah'), Entity(start_offset=137, end_offset=147, type='context', text='the Gemara', normalized_text='gemara')]], aligned_nps=[(Entity(start_offset=37, end_offset=47, type='question', text='the talmud', normalized_text='talmud'), Entity(start_offset=0, end_offset=10, type='context', text='The Talmud', normalized_text='talmud'))], explanation_type='single_sentence'),\n",
       " 1915885935757407192: QEDExample(example_id=1915885935757407192, title='Blood volume', question='what is the approximate volume of blood in your body', passage='A typical adult has a blood volume of approximately 5 liters , with females generally having less blood volume than males . Blood volume is regulated by the kidneys .', sentence_starts=[0, 124], selected_sent={'start': 0, 'end': 124, 'string': 'A typical adult has a blood volume of approximately 5 liters , with females generally having less blood volume than males . '}, answer=[Entity(start_offset=38, end_offset=121, type='context', text='approximately 5 liters , with females generally having less blood volume than males', normalized_text='approximately 5 liters with females generally having less blood volume than males')], nq_answers=[[Entity(start_offset=38, end_offset=121, type='context', text='approximately 5 liters , with females generally having less blood volume than males', normalized_text='approximately 5 liters with females generally having less blood volume than males')], [Entity(start_offset=38, end_offset=60, type='context', text='approximately 5 liters', normalized_text='approximately 5 liters')]], aligned_nps=[(Entity(start_offset=8, end_offset=52, type='question', text='the approximate volume of blood in your body', normalized_text='approximate volume of blood in your body'), Entity(start_offset=20, end_offset=34, type='context', text='a blood volume', normalized_text='blood volume'))], explanation_type='single_sentence'),\n",
       " -1116288849470511210: QEDExample(example_id=-1116288849470511210, title='Occupation of the Ruhr', question='when did france and belgium invade the ruhr', passage=\"The Occupation of the Ruhr ( German : Ruhrbesetzung ) was a period of military occupation of the German Ruhr valley by France and Belgium between 1923 and 1925 in response to the Weimar Republic 's failure to continue its reparation payments in the aftermath of World War I .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 275, 'string': \"The Occupation of the Ruhr ( German : Ruhrbesetzung ) was a period of military occupation of the German Ruhr valley by France and Belgium between 1923 and 1925 in response to the Weimar Republic 's failure to continue its reparation payments in the aftermath of World War I .\"}, answer=[Entity(start_offset=146, end_offset=150, type='context', text='1923', normalized_text='1923')], nq_answers=[[Entity(start_offset=146, end_offset=150, type='context', text='1923', normalized_text='1923')]], aligned_nps=[(Entity(start_offset=35, end_offset=43, type='question', text='the ruhr', normalized_text='ruhr'), Entity(start_offset=93, end_offset=115, type='context', text='the German Ruhr valley', normalized_text='german ruhr valley')), (Entity(start_offset=9, end_offset=27, type='question', text='france and belgium', normalized_text='france and belgium'), Entity(start_offset=119, end_offset=137, type='context', text='France and Belgium', normalized_text='france and belgium'))], explanation_type='single_sentence'),\n",
       " 134587584998146088: QEDExample(example_id=134587584998146088, title='Army Service Uniform', question='when do you get your dress blues in the army', passage='The Army currently uses the blue Army Service Uniform . According to Army Regulation 670 - 1 : Wear and Appearance of Army Uniforms and Insignia , Army White , and Army Blue uniforms are considered Dress Uniforms . The Army Service Uniform seeks to combine these distinctions through wear stipulations . Possession and use of the blue ASU is now mandatory for all soldiers as of October 1 , 2015 , when the green class A was retired . As of fall 2010 , enlisted soldiers receive the blue service uniform as part of their basic clothing bag issue when they enter the army during initial entry training . The army further provides active - duty enlisted soldiers an annual clothing allowance to maintain proper fit and appearance of their basic clothing bag issue items . The army includes a series of stipends in this annual clothing allowance towards the replacement of the green service uniform and all basic clothing bag items .', sentence_starts=[0, 56, 215, 304, 435, 603, 770], selected_sent={'start': 435, 'end': 603, 'string': 'As of fall 2010 , enlisted soldiers receive the blue service uniform as part of their basic clothing bag issue when they enter the army during initial entry training . '}, answer=[Entity(start_offset=546, end_offset=600, type='context', text='when they enter the army during initial entry training', normalized_text='when they enter army during initial entry training')], nq_answers=[[Entity(start_offset=571, end_offset=600, type='context', text='during initial entry training', normalized_text='during initial entry training')]], aligned_nps=[(Entity(start_offset=16, end_offset=32, type='question', text='your dress blues', normalized_text='your dress blues'), Entity(start_offset=479, end_offset=503, type='context', text='the blue service uniform', normalized_text='blue service uniform')), (Entity(start_offset=36, end_offset=44, type='question', text='the army', normalized_text='army'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 7075559602853408649: QEDExample(example_id=7075559602853408649, title='Once More, with Feeling (Buffy the Vampire Slayer)', question='when does buffy tell her friends she was in heaven', passage=\"Meeting Sweet at The Bronze , Buffy offers a deal to Sweet : she will take the place of her sister if she ca n't kill him . When asked by Sweet what she thinks about life , Buffy gives her pessimistic take on its meaning ( `` Something to Sing About '' ) . When the others arrive , she divulges that Willow took her from heaven , and Willow reacts with horror at finding out what she 's done . Upon divulging this truth , Buffy gives up on singing and dances so frenetically that she begins to smoke -- on the verge of combusting as Sweet 's other victims have been shown to do -- until Spike stops her , telling her that the only way to go forward is to just keep living her life . Xander then reveals that he , not Dawn , called Sweet , hoping he would be shown a happy ending for his marriage plans . Sweet , after releasing Xander from the obligation to be Sweet 's `` bride '' , tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears . The Scoobies realize that their relationships have been changed irreversibly by the secrets revealed in their songs ( `` Where Do We Go from Here ? '' ) . Spike leaves The Bronze , but Buffy follows him out , and they kiss ( `` Coda '' ) .\", sentence_starts=[0, 124, 257, 394, 683, 804, 980, 1135], selected_sent={'start': 257, 'end': 394, 'string': \"When the others arrive , she divulges that Willow took her from heaven , and Willow reacts with horror at finding out what she 's done . \"}, answer=[Entity(start_offset=226, end_offset=249, type='context', text='Something to Sing About', normalized_text='something to sing about')], nq_answers=[[Entity(start_offset=226, end_offset=249, type='context', text='Something to Sing About', normalized_text='something to sing about')]], aligned_nps=[(Entity(start_offset=10, end_offset=15, type='question', text='buffy', normalized_text='buffy'), Entity(start_offset=282, end_offset=285, type='context', text='she', normalized_text='she')), (Entity(start_offset=44, end_offset=50, type='question', text='heaven', normalized_text='heaven'), Entity(start_offset=321, end_offset=327, type='context', text='heaven', normalized_text='heaven'))], explanation_type='single_sentence'),\n",
       " 6709331549884586945: QEDExample(example_id=6709331549884586945, title='Jnanpith Award', question='the recipient of first jnanpith award was an author which language', passage=\"From 1965 till 1981 , the award was given to the authors for their `` most outstanding work '' and consisted of a citation plaque , a cash prize of ₹ 1 lakh ( equivalent to ₹ 48 lakh or US $75,000 in 2017 ) , and a bronze replica of Saraswati , the Hindu goddess of knowledge and wisdom . The first recipient of the award was the Malayalam writer G. Sankara Kurup who received the award in 1965 for his collection of poems , Odakkuzhal ( The Bamboo Flute ) , published in 1950 . The rules were revised in subsequent years to consider only works published during the preceding twenty years , excluding the year for which the award was to be given and the cash prize was increased to ₹ 1.5 lakh ( equivalent to ₹ 22 lakh or US $34,000 in 2017 ) from 1981 .\", sentence_starts=[0, 289, 479], selected_sent={'start': 289, 'end': 479, 'string': 'The first recipient of the award was the Malayalam writer G. Sankara Kurup who received the award in 1965 for his collection of poems , Odakkuzhal ( The Bamboo Flute ) , published in 1950 . '}, answer=[Entity(start_offset=330, end_offset=339, type='context', text='Malayalam', normalized_text='malayalam')], nq_answers=[[Entity(start_offset=330, end_offset=339, type='context', text='Malayalam', normalized_text='malayalam')]], aligned_nps=[(Entity(start_offset=0, end_offset=37, type='question', text='the recipient of first jnanpith award', normalized_text='recipient of first jnanpith award'), Entity(start_offset=289, end_offset=321, type='context', text='The first recipient of the award', normalized_text='first recipient of award'))], explanation_type='single_sentence'),\n",
       " 4835361556991861440: QEDExample(example_id=4835361556991861440, title='Indian Rebellion of 1857', question='who was the first to declare the mutiny against the british', passage=\"The rebellion began on 10 May 1857 in the form of a mutiny of sepoys of the Company 's army in the garrison town of Meerut , 40 miles northeast of Delhi ( now Old Delhi ) . It then erupted into other mutinies and civilian rebellions chiefly in the upper Gangetic plain and central India , though incidents of revolt also occurred farther north and east . The rebellion posed a considerable threat to British power in that region , and was contained only with the rebels ' defeat in Gwalior on 20 June 1858 . On 1 November 1858 , the British granted amnesty to all rebels not involved in murder , though they did not declare the hostilities formally to have ended until 8 July 1859 .\", sentence_starts=[0, 173, 355, 508], selected_sent={'start': 0, 'end': 173, 'string': \"The rebellion began on 10 May 1857 in the form of a mutiny of sepoys of the Company 's army in the garrison town of Meerut , 40 miles northeast of Delhi ( now Old Delhi ) . \"}, answer=[Entity(start_offset=62, end_offset=122, type='context', text=\"sepoys of the Company 's army in the garrison town of Meerut\", normalized_text='sepoys of company s army in garrison town of meerut')], nq_answers=[[Entity(start_offset=62, end_offset=91, type='context', text=\"sepoys of the Company 's army\", normalized_text='sepoys of company s army')], [Entity(start_offset=62, end_offset=170, type='context', text=\"sepoys of the Company 's army in the garrison town of Meerut , 40 miles northeast of Delhi ( now Old Delhi )\", normalized_text='sepoys of company s army in garrison town of meerut 40 miles northeast of delhi now old delhi')]], aligned_nps=[(Entity(start_offset=29, end_offset=59, type='question', text='the mutiny against the british', normalized_text='mutiny against british'), Entity(start_offset=0, end_offset=13, type='context', text='The rebellion', normalized_text='rebellion'))], explanation_type='single_sentence'),\n",
       " -5800244801360835363: QEDExample(example_id=-5800244801360835363, title='Jennifer Jareau', question='criminal minds episode where jj becomes a profiler', passage='The season seven premiere reveals that JJ has returned to the Behavioral Analysis Unit , having received the training to become a full - time profiler , instead of the Media Liaison , a position which has been split between Hotch and Garcia .', sentence_starts=[0], selected_sent={'start': 0, 'end': 242, 'string': 'The season seven premiere reveals that JJ has returned to the Behavioral Analysis Unit , having received the training to become a full - time profiler , instead of the Media Liaison , a position which has been split between Hotch and Garcia .'}, answer=[Entity(start_offset=0, end_offset=25, type='context', text='The season seven premiere', normalized_text='season seven premiere')], nq_answers=[[Entity(start_offset=0, end_offset=25, type='context', text='The season seven premiere', normalized_text='season seven premiere')], [Entity(start_offset=4, end_offset=25, type='context', text='season seven premiere', normalized_text='season seven premiere')]], aligned_nps=[(Entity(start_offset=29, end_offset=31, type='question', text='jj', normalized_text='jj'), Entity(start_offset=39, end_offset=41, type='context', text='JJ', normalized_text='jj'))], explanation_type='single_sentence'),\n",
       " -3197375005297250079: QEDExample(example_id=-3197375005297250079, title='Parenteral nutrition', question='which condition would most likely require nutrition delivered through tpn', passage=\"TPN may be the only feasible option for providing nutrition to patients who do not have a functioning gastrointestinal tract or who have disorders requiring complete bowel rest , including bowel obstruction , short bowel syndrome , gastroschisis , prolonged diarrhea regardless of its cause , high - output fistula , very severe Crohn 's disease or ulcerative colitis , and certain pediatric GI disorders including congenital GI anomalies and necrotizing enterocolitis .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 470, 'string': \"TPN may be the only feasible option for providing nutrition to patients who do not have a functioning gastrointestinal tract or who have disorders requiring complete bowel rest , including bowel obstruction , short bowel syndrome , gastroschisis , prolonged diarrhea regardless of its cause , high - output fistula , very severe Crohn 's disease or ulcerative colitis , and certain pediatric GI disorders including congenital GI anomalies and necrotizing enterocolitis .\"}, answer=[Entity(start_offset=137, end_offset=468, type='context', text=\"disorders requiring complete bowel rest , including bowel obstruction , short bowel syndrome , gastroschisis , prolonged diarrhea regardless of its cause , high - output fistula , very severe Crohn 's disease or ulcerative colitis , and certain pediatric GI disorders including congenital GI anomalies and necrotizing enterocolitis\", normalized_text='disorders requiring complete bowel rest including bowel obstruction short bowel syndrome gastroschisis prolonged diarrhea regardless of its cause high output fistula very severe crohn s disease or ulcerative colitis and certain pediatric gi disorders including congenital gi anomalies and necrotizing enterocolitis')], nq_answers=[[Entity(start_offset=189, end_offset=206, type='context', text='bowel obstruction', normalized_text='bowel obstruction'), Entity(start_offset=209, end_offset=229, type='context', text='short bowel syndrome', normalized_text='short bowel syndrome'), Entity(start_offset=232, end_offset=245, type='context', text='gastroschisis', normalized_text='gastroschisis'), Entity(start_offset=248, end_offset=266, type='context', text='prolonged diarrhea', normalized_text='prolonged diarrhea'), Entity(start_offset=293, end_offset=314, type='context', text='high - output fistula', normalized_text='high output fistula'), Entity(start_offset=317, end_offset=345, type='context', text=\"very severe Crohn 's disease\", normalized_text='very severe crohn s disease'), Entity(start_offset=349, end_offset=367, type='context', text='ulcerative colitis', normalized_text='ulcerative colitis'), Entity(start_offset=374, end_offset=468, type='context', text='certain pediatric GI disorders including congenital GI anomalies and necrotizing enterocolitis', normalized_text='certain pediatric gi disorders including congenital gi anomalies and necrotizing enterocolitis')]], aligned_nps=[(Entity(start_offset=70, end_offset=73, type='question', text='tpn', normalized_text='tpn'), Entity(start_offset=0, end_offset=3, type='context', text='TPN', normalized_text='tpn'))], explanation_type='single_sentence'),\n",
       " -1059932910092423631: QEDExample(example_id=-1059932910092423631, title='Gestalt psychology', question='today gestalt psychology ideas are part of which branch of psychology', passage=\"Gestalt psychology or gestaltism ( German : Gestalt ( ɡəˈʃtalt ) `` shape , form '' ) is a philosophy of mind of the Berlin School of experimental psychology . Gestalt psychology is an attempt to understand the laws behind the ability to acquire and maintain meaningful perceptions in an apparently chaotic world . The central principle of gestalt psychology is that the mind forms a global whole with self - organizing tendencies . The assumed physiological mechanisms on which Gestalt theory rests are poorly defined and support for their existence is lacking . The Gestalt theory of perception has been criticized as being descriptive of the end products of perception without providing much insight into the processes that lead to perception . In the introduction to a 2016 special issue of the journal Vision Research on Gestalt perception , the authors concluded that `` even though they study the same phenomena as earlier Gestaltists , there is little theoretical coherence . What happened to the Gestalt school that always aspired to provide a unified vision of psychology ? Perhaps there is , in fact , little that holds the classic phenomena of Gestalt psychology together . ''\", sentence_starts=[0, 160, 315, 433, 564, 748, 984, 1084], selected_sent={'start': 0, 'end': 160, 'string': \"Gestalt psychology or gestaltism ( German : Gestalt ( ɡəˈʃtalt ) `` shape , form '' ) is a philosophy of mind of the Berlin School of experimental psychology . \"}, answer=[Entity(start_offset=113, end_offset=157, type='context', text='the Berlin School of experimental psychology', normalized_text='berlin school of experimental psychology')], nq_answers=[[Entity(start_offset=117, end_offset=157, type='context', text='Berlin School of experimental psychology', normalized_text='berlin school of experimental psychology')], [Entity(start_offset=113, end_offset=157, type='context', text='the Berlin School of experimental psychology', normalized_text='berlin school of experimental psychology')], [Entity(start_offset=134, end_offset=157, type='context', text='experimental psychology', normalized_text='experimental psychology')]], aligned_nps=[(Entity(start_offset=6, end_offset=24, type='question', text='gestalt psychology', normalized_text='gestalt psychology'), Entity(start_offset=0, end_offset=32, type='context', text='Gestalt psychology or gestaltism', normalized_text='gestalt psychology or gestaltism'))], explanation_type='single_sentence'),\n",
       " -8179137917755764249: QEDExample(example_id=-8179137917755764249, title='Sneaky Pete', question='who is the actor that plays sneaky pete', passage='Sneaky Pete is an American crime drama series created by David Shore and Bryan Cranston . The series follows Marius Josipović ( Giovanni Ribisi ) , a released convict who adopts the identity of his cell mate , Pete Murphy , in order to avoid his past life . The series also stars Marin Ireland , Shane McRae , Libe Barer , Michael Drayer , Peter Gerety , and Margo Martindale . The pilot debuted on August 7 , 2015 , and was followed by a full series order that September . Shore left the project in early 2016 and was replaced by Graham Yost , who served as executive producer and showrunner for the remaining nine episodes . The first season premiered in its entirety on January 13 , 2017 , exclusively on Amazon Video . On January 19 , 2017 , Amazon announced that Sneaky Pete had been renewed for a second season , which was released on March 9 , 2018 .', sentence_starts=[0, 90, 258, 378, 474, 627, 723], selected_sent={'start': 90, 'end': 258, 'string': 'The series follows Marius Josipović ( Giovanni Ribisi ) , a released convict who adopts the identity of his cell mate , Pete Murphy , in order to avoid his past life . '}, answer=[Entity(start_offset=128, end_offset=143, type='context', text='Giovanni Ribisi', normalized_text='giovanni ribisi')], nq_answers=[[Entity(start_offset=128, end_offset=143, type='context', text='Giovanni Ribisi', normalized_text='giovanni ribisi')]], aligned_nps=[(Entity(start_offset=28, end_offset=39, type='question', text='sneaky pete', normalized_text='sneaky pete'), Entity(start_offset=109, end_offset=125, type='context', text='Marius Josipović', normalized_text='marius josipović'))], explanation_type='single_sentence'),\n",
       " -99722774431057184: QEDExample(example_id=-99722774431057184, title='Arctic Circle', question='where is the arctic circle located on a world map', passage='The Arctic Circle is the most northerly of the five major circles of latitude as shown on maps of Earth . It marks the northernmost point at which the noon sun is just visible on the December solstice and the southernmost point at which the midnight sun is just visible on the June solstice . The region north of this circle is known as the Arctic , and the zone just to the south is called the Northern Temperate Zone .', sentence_starts=[0, 106, 293], selected_sent={'start': 0, 'end': 106, 'string': 'The Arctic Circle is the most northerly of the five major circles of latitude as shown on maps of Earth . '}, answer=[Entity(start_offset=21, end_offset=77, type='context', text='the most northerly of the five major circles of latitude', normalized_text='most northerly of five major circles of latitude')], nq_answers=[[Entity(start_offset=25, end_offset=103, type='context', text='most northerly of the five major circles of latitude as shown on maps of Earth', normalized_text='most northerly of five major circles of latitude as shown on maps of earth')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='the arctic circle', normalized_text='arctic circle'), Entity(start_offset=0, end_offset=17, type='context', text='The Arctic Circle', normalized_text='arctic circle')), (Entity(start_offset=38, end_offset=49, type='question', text='a world map', normalized_text='world map'), Entity(start_offset=90, end_offset=103, type='context', text='maps of Earth', normalized_text='maps of earth'))], explanation_type='single_sentence'),\n",
       " -488573928094288904: QEDExample(example_id=-488573928094288904, title='My Summer Story', question='sequel to a christmas story it runs in the family', passage='My Summer Story , originally released in theaters as It Runs in the Family , is a 1994 film that follows the further adventures of the Parker family from A Christmas Story . Like the previous film , it is based on semi-autobiographical stories by Jean Shepherd , primarily from his book In God We Trust , All Others Pay Cash .', sentence_starts=[0, 174], selected_sent={'start': 0, 'end': 174, 'string': 'My Summer Story , originally released in theaters as It Runs in the Family , is a 1994 film that follows the further adventures of the Parker family from A Christmas Story . '}, answer=[Entity(start_offset=0, end_offset=15, type='context', text='My Summer Story', normalized_text='my summer story')], nq_answers=[[Entity(start_offset=0, end_offset=15, type='context', text='My Summer Story', normalized_text='my summer story')]], aligned_nps=[(Entity(start_offset=0, end_offset=49, type='question', text='sequel to a christmas story it runs in the family', normalized_text='sequel to christmas story it runs in family'), Entity(start_offset=53, end_offset=74, type='context', text='It Runs in the Family', normalized_text='it runs in family'))], explanation_type='single_sentence'),\n",
       " -194799562820656921: QEDExample(example_id=-194799562820656921, title='Mind your Ps and Qs', question=\"what does watch your p's and q's\", passage=\"Mind your Ps and Qs is an English expression meaning `` mind your manners '' , `` mind your language '' , `` be on your best behaviour '' or similar .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 150, 'string': \"Mind your Ps and Qs is an English expression meaning `` mind your manners '' , `` mind your language '' , `` be on your best behaviour '' or similar .\"}, answer=[Entity(start_offset=53, end_offset=148, type='context', text=\"`` mind your manners '' , `` mind your language '' , `` be on your best behaviour '' or similar\", normalized_text='mind your manners mind your language be on your best behaviour or similar')], nq_answers=[[Entity(start_offset=53, end_offset=148, type='context', text=\"`` mind your manners '' , `` mind your language '' , `` be on your best behaviour '' or similar\", normalized_text='mind your manners mind your language be on your best behaviour or similar')]], aligned_nps=[(Entity(start_offset=10, end_offset=32, type='question', text=\"watch your p's and q's\", normalized_text='watch your ps and qs'), Entity(start_offset=0, end_offset=19, type='context', text='Mind your Ps and Qs', normalized_text='mind your ps and qs'))], explanation_type='single_sentence'),\n",
       " -4649146182478016322: QEDExample(example_id=-4649146182478016322, title='Virgin Australia', question='when did virgin australia (formerly virgin blue) commence flying in australia', passage=\"Virgin Australia Airlines Pty Ltd , formerly Virgin Blue Airlines , is Australia 's second - largest airline after Qantas and it is the largest airline by fleet size to use the ' Virgin ' brand . Now based in Bowen Hills , Brisbane , the airline was co-founded by British businessman Richard Branson , the founder of parent Virgin Group and former Virgin Blue CEO Brett Godfrey . It was established in November 1999 with two aircraft operating on a single route , and suddenly found itself catapulted to the position of Australia 's second airline after the collapse of Ansett Australia in September 2001 . The airline has grown to directly serve 29 cities in Australia from hubs in Brisbane , Melbourne and Sydney , using a fleet of narrow - body Boeing and Embraer jets ; and Airbus and Boeing widebody jets .\", sentence_starts=[0, 196, 380, 607], selected_sent={'start': 380, 'end': 607, 'string': \"It was established in November 1999 with two aircraft operating on a single route , and suddenly found itself catapulted to the position of Australia 's second airline after the collapse of Ansett Australia in September 2001 . \"}, answer=[Entity(start_offset=402, end_offset=415, type='context', text='November 1999', normalized_text='november 1999')], nq_answers=[[Entity(start_offset=402, end_offset=415, type='context', text='November 1999', normalized_text='november 1999')]], aligned_nps=[(Entity(start_offset=9, end_offset=48, type='question', text='virgin australia (formerly virgin blue)', normalized_text='virgin australia formerly virgin blue'), Entity(start_offset=380, end_offset=382, type='context', text='It', normalized_text='it')), (Entity(start_offset=68, end_offset=77, type='question', text='australia', normalized_text='australia'), Entity(start_offset=520, end_offset=529, type='context', text='Australia', normalized_text='australia'))], explanation_type='single_sentence'),\n",
       " -7386387080002447998: QEDExample(example_id=-7386387080002447998, title='Roman Empire', question='a political leader during the roman empire was called', passage=\"The Roman Empire ( Latin : Imperium Rōmānum , Classical Latin : ( ɪmˈpɛ. ri. ũː roːˈmaː. nũː ) ; Koine and Medieval Greek : Βασιλεία τῶν Ῥωμαίων , tr . Basileia tōn Rhōmaiōn ) was the post-Roman Republic period of the ancient Roman civilization , characterized by government headed by emperors and large territorial holdings around the Mediterranean Sea in Europe , Africa and Asia . The city of Rome was the largest city in the world c. 100 BC -- c . AD 400 , with Constantinople ( New Rome ) becoming the largest around AD 500 , and the Empire 's populace grew to an estimated 50 to 90 million inhabitants ( roughly 20 % of the world 's population at the time ) . The 500 - year - old republic which preceded it was severely destabilized in a series of civil wars and political conflict , during which Julius Caesar was appointed as perpetual dictator and then assassinated in 44 BC . Civil wars and executions continued , culminating in the victory of Octavian , Caesar 's adopted son , over Mark Antony and Cleopatra at the Battle of Actium in 31 BC and the annexation of Egypt . Octavian 's power was then unassailable and in 27 BC the Roman Senate formally granted him overarching power and the new title Augustus , effectively marking the end of the Roman Republic .\", sentence_starts=[0, 152, 384, 452, 666, 887, 1084], selected_sent={'start': 0, 'end': 384, 'string': 'The Roman Empire ( Latin : Imperium Rōmānum , Classical Latin : ( ɪmˈpɛ. ri. ũː roːˈmaː. nũː ) ; Koine and Medieval Greek : Βασιλεία τῶν Ῥωμαίων , tr . Basileia tōn Rhōmaiōn ) was the post-Roman Republic period of the ancient Roman civilization , characterized by government headed by emperors and large territorial holdings around the Mediterranean Sea in Europe , Africa and Asia . '}, answer=[Entity(start_offset=285, end_offset=293, type='context', text='emperors', normalized_text='emperors')], nq_answers=[[Entity(start_offset=285, end_offset=293, type='context', text='emperors', normalized_text='emperors')]], aligned_nps=[(Entity(start_offset=26, end_offset=42, type='question', text='the roman empire', normalized_text='roman empire'), Entity(start_offset=0, end_offset=16, type='context', text='The Roman Empire', normalized_text='roman empire'))], explanation_type='single_sentence'),\n",
       " -7419926784062257102: QEDExample(example_id=-7419926784062257102, title='Condenser (optics)', question='where is the condenser located on a microscope', passage=\"Condensers are located above the light source and under the sample in an upright microscope , and above the stage and below the light source in an inverted microscope . They act to gather light from the microscope 's light source and concentrate it into a cone of light that illuminates the specimen . The aperture and angle of the light cone must be adjusted ( via the size of the diaphragm ) for each different objective lens with different numerical apertures .\", sentence_starts=[0, 169, 302], selected_sent={'start': 0, 'end': 169, 'string': 'Condensers are located above the light source and under the sample in an upright microscope , and above the stage and below the light source in an inverted microscope . '}, answer=[Entity(start_offset=23, end_offset=166, type='context', text='above the light source and under the sample in an upright microscope , and above the stage and below the light source in an inverted microscope', normalized_text='above light source and under sample in upright microscope and above stage and below light source in inverted microscope')], nq_answers=[[Entity(start_offset=23, end_offset=166, type='context', text='above the light source and under the sample in an upright microscope , and above the stage and below the light source in an inverted microscope', normalized_text='above light source and under sample in upright microscope and above stage and below light source in inverted microscope')]], aligned_nps=[(Entity(start_offset=9, end_offset=22, type='question', text='the condenser', normalized_text='condenser'), Entity(start_offset=0, end_offset=10, type='context', text='Condensers', normalized_text='condensers'))], explanation_type='single_sentence'),\n",
       " -8743280518479013381: QEDExample(example_id=-8743280518479013381, title='Only in My Dreams', question='who sings the song only in my dreams', passage=\"`` Only in My Dreams '' is the debut single for American singer - songwriter - actress Debbie Gibson . Released December 16 , 1986 , as a maxi single ( Atlantic DM 86744 ) , and then in remixed form ( Vocal / 3 : 50 , as described herein ) February 1987 , the song was written by Gibson herself in 1984 , two years before she recorded it . Produced by Fred Zarr and engineered by Don Feinberg for BiZarr Music , Inc. , mixed by `` Little '' Louie Vega and mastered by Herb `` Pump '' Powers , the dance - pop song reached number four on the U.S. Billboard Hot 100 singles chart in the summer of 1987 . Douglas Breitbart for Broadbeard Productions , Inc. served as executive producer ( see also Debbie Gibson ) .\", sentence_starts=[0, 103, 340, 602], selected_sent={'start': 0, 'end': 103, 'string': \"`` Only in My Dreams '' is the debut single for American singer - songwriter - actress Debbie Gibson . \"}, answer=[Entity(start_offset=87, end_offset=100, type='context', text='Debbie Gibson', normalized_text='debbie gibson')], nq_answers=[[Entity(start_offset=87, end_offset=100, type='context', text='Debbie Gibson', normalized_text='debbie gibson')], [Entity(start_offset=48, end_offset=100, type='context', text='American singer - songwriter - actress Debbie Gibson', normalized_text='american singer songwriter actress debbie gibson')]], aligned_nps=[(Entity(start_offset=10, end_offset=36, type='question', text='the song only in my dreams', normalized_text='song only in my dreams'), Entity(start_offset=3, end_offset=20, type='context', text='Only in My Dreams', normalized_text='only in my dreams'))], explanation_type='single_sentence'),\n",
       " 8015709437014232395: QEDExample(example_id=8015709437014232395, title='Alabama', question='where is the capital city of alabama located', passage=\"Alabama is nicknamed the Yellowhammer State , after the state bird . Alabama is also known as the `` Heart of Dixie '' and the Cotton State . The state tree is the longleaf pine , and the state flower is the camellia . Alabama 's capital is Montgomery . The largest city by population is Birmingham , which has long been the most industrialized city ; the largest city by land area is Huntsville . The oldest city is Mobile , founded by French colonists in 1702 as the capital of French Louisiana .\", sentence_starts=[0, 69, 142, 219, 254, 398], selected_sent={'start': 219, 'end': 254, 'string': \"Alabama 's capital is Montgomery . \"}, answer=[Entity(start_offset=241, end_offset=251, type='context', text='Montgomery', normalized_text='montgomery')], nq_answers=[[Entity(start_offset=241, end_offset=251, type='context', text='Montgomery', normalized_text='montgomery')]], aligned_nps=[(Entity(start_offset=9, end_offset=36, type='question', text='the capital city of alabama', normalized_text='capital city of alabama'), Entity(start_offset=219, end_offset=237, type='context', text=\"Alabama 's capital\", normalized_text='alabama s capital'))], explanation_type='single_sentence'),\n",
       " -7741834825578210187: QEDExample(example_id=-7741834825578210187, title='History of coffee', question='when was coffee first made into a drink', passage='The origin and history of coffee dates back to the 10th century , and possibly earlier with a number of reports and legends surrounding its first use . The native ( undomesticated ) origin of coffee is thought to have been Ethiopia . The earliest substantiated evidence of either coffee drinking or knowledge of the coffee tree is from the 15th century , in the Sufi monasteries of Yemen . By the 16th century , it had reached the rest of the Middle East , South India ( Coorg ) , Persia , Turkey , Horn of Africa , and northern Africa . Coffee then spread to the Balkans , Italy and to the rest of Europe , to South East Asia and then to America .', sentence_starts=[0, 152, 234, 390, 538], selected_sent={'start': 234, 'end': 390, 'string': 'The earliest substantiated evidence of either coffee drinking or knowledge of the coffee tree is from the 15th century , in the Sufi monasteries of Yemen . '}, answer=[Entity(start_offset=336, end_offset=352, type='context', text='the 15th century', normalized_text='15th century')], nq_answers=[[Entity(start_offset=336, end_offset=352, type='context', text='the 15th century', normalized_text='15th century')], [Entity(start_offset=340, end_offset=352, type='context', text='15th century', normalized_text='15th century')]], aligned_nps=[(Entity(start_offset=9, end_offset=15, type='question', text='coffee', normalized_text='coffee'), Entity(start_offset=280, end_offset=286, type='context', text='coffee', normalized_text='coffee'))], explanation_type='single_sentence'),\n",
       " -2756184966764635962: QEDExample(example_id=-2756184966764635962, title='Tim Hortons', question='when did tim hortons open in the usa', passage=\"Initially , the US stores were the result of natural expansion in Canada -- US border areas ( e.g. , stores in Maine and the Buffalo , New York area where Horton played from 1972 to 1974 as a member of the Buffalo Sabres ) . The first United States locations were opened in Deerfield Beach , Florida and Pompano Beach , Florida in 1981 , but they proved unsuccessful and were closed . In 1985 , the chain returned to the US with a location on Niagara Falls Boulevard in the Buffalo suburb of Amherst , New York . Starting in the mid-1990s , however , the chain began expanding in the US by acquiring former locations from fast food chains . In 1996 and 1997 , thirty - seven former Rax Restaurants locations in Ohio , Kentucky , and West Virginia were bought by Wendy 's International Inc. ; 30 of these were converted to Tim Hortons , while the others became Wendy 's franchise locations . Thirty - five closed Hardee 's stores in the Detroit area were also purchased with the intention of being converted . By 2004 , the chain had also acquired 42 Bess Eaton coffee and doughnut restaurants situated in southern New England . Several combination Wendy 's / Tim Hortons units were opened in the US ; both in the `` traditional '' markets of Maine and Buffalo , where there were well over 180 locations as of 2011 , and in the markets entered through acquisition .\", sentence_starts=[0, 225, 385, 513, 641, 891, 1009, 1128], selected_sent={'start': 225, 'end': 385, 'string': 'The first United States locations were opened in Deerfield Beach , Florida and Pompano Beach , Florida in 1981 , but they proved unsuccessful and were closed . '}, answer=[Entity(start_offset=331, end_offset=335, type='context', text='1981', normalized_text='1981')], nq_answers=[[Entity(start_offset=331, end_offset=335, type='context', text='1981', normalized_text='1981')]], aligned_nps=[(Entity(start_offset=29, end_offset=36, type='question', text='the usa', normalized_text='usa'), Entity(start_offset=235, end_offset=248, type='context', text='United States', normalized_text='united states')), (Entity(start_offset=9, end_offset=20, type='question', text='tim hortons', normalized_text='tim hortons'), Entity(start_offset=225, end_offset=258, type='context', text='The first United States locations', normalized_text='first united states locations'))], explanation_type='single_sentence'),\n",
       " 7632941217874741929: QEDExample(example_id=7632941217874741929, title='Wah-Wah (song)', question='what is george harrison song wah wah about', passage=\"`` Wah - Wah '' is a song by English musician George Harrison , released on his 1970 triple album All Things Must Pass . Harrison wrote the song following his temporary departure from the Beatles in January 1969 , during the troubled Get Back sessions that resulted in their Let It Be album and film . The lyrics reflect his frustration with the atmosphere in the group at that time -- namely , Paul McCartney 's over-assertiveness and criticism of his guitar playing , John Lennon 's lack of engagement with the project and dismissal of Harrison as a songwriter , and Yoko Ono 's constant involvement in the band 's activities . Music critics and biographers recognise the song as Harrison 's statement of personal and artistic freedom from the Beatles . Its creation contrasted sharply with his rewarding collaborations outside the group in the months before the Get Back project , particularly with Bob Dylan and the Band in upstate New York .\", sentence_starts=[0, 121, 302, 630, 756], selected_sent={'start': 302, 'end': 630, 'string': \"The lyrics reflect his frustration with the atmosphere in the group at that time -- namely , Paul McCartney 's over-assertiveness and criticism of his guitar playing , John Lennon 's lack of engagement with the project and dismissal of Harrison as a songwriter , and Yoko Ono 's constant involvement in the band 's activities . \"}, answer=[Entity(start_offset=321, end_offset=382, type='context', text='his frustration with the atmosphere in the group at that time', normalized_text='his frustration with atmosphere in group at that time')], nq_answers=[[Entity(start_offset=321, end_offset=382, type='context', text='his frustration with the atmosphere in the group at that time', normalized_text='his frustration with atmosphere in group at that time')]], aligned_nps=[(Entity(start_offset=8, end_offset=36, type='question', text='george harrison song wah wah', normalized_text='george harrison song wah wah'), Entity(start_offset=302, end_offset=312, type='context', text='The lyrics', normalized_text='lyrics'))], explanation_type='single_sentence'),\n",
       " 448742752032961281: QEDExample(example_id=448742752032961281, title='God Save the Queen', question='why god save the queen and not king', passage=\"`` God Save the Queen '' ( alternatively `` God Save the King '' , depending on the gender of the reigning monarch ) is the national or royal anthem in a number of Commonwealth realms , their territories , and the British Crown Dependencies . The author of the tune is unknown and it may originate in plainchant , but a 1619 attribution to John Bull is sometimes made .\", sentence_starts=[0, 243], selected_sent={'start': 0, 'end': 243, 'string': \"`` God Save the Queen '' ( alternatively `` God Save the King '' , depending on the gender of the reigning monarch ) is the national or royal anthem in a number of Commonwealth realms , their territories , and the British Crown Dependencies . \"}, answer=[Entity(start_offset=80, end_offset=114, type='context', text='the gender of the reigning monarch', normalized_text='gender of reigning monarch')], nq_answers=[[Entity(start_offset=67, end_offset=114, type='context', text='depending on the gender of the reigning monarch', normalized_text='depending on gender of reigning monarch')]], aligned_nps=[(Entity(start_offset=4, end_offset=22, type='question', text='god save the queen', normalized_text='god save queen'), Entity(start_offset=3, end_offset=21, type='context', text='God Save the Queen', normalized_text='god save queen')), (Entity(start_offset=31, end_offset=35, type='question', text='king', normalized_text='king'), Entity(start_offset=44, end_offset=61, type='context', text='God Save the King', normalized_text='god save king'))], explanation_type='single_sentence'),\n",
       " 1471601930209559051: QEDExample(example_id=1471601930209559051, title=\"I'm a Celebrity...Get Me Out of Here! (UK TV series)\", question=\"who used to present i'm a celebrity now\", passage=\"I 'm a Celebrity ... Get Me Out Of Here ! ( often shortened to I 'm a Celebrity or I 'm a Celeb ) is a British survival reality television game show , first aired on 25 August 2002 , in which celebrities live in jungle conditions with few creature comforts . The show has been hosted by Ant & Dec since its inception and served as the inspiration for a franchise of the same name . It is filmed in Murwillumbah , New South Wales , Australia and broadcast on ITV in the United Kingdom .\", sentence_starts=[0, 21, 259, 382], selected_sent={'start': 259, 'end': 382, 'string': 'The show has been hosted by Ant & Dec since its inception and served as the inspiration for a franchise of the same name . '}, answer=[Entity(start_offset=287, end_offset=296, type='context', text='Ant & Dec', normalized_text='ant dec')], nq_answers=[[Entity(start_offset=287, end_offset=296, type='context', text='Ant & Dec', normalized_text='ant dec')]], aligned_nps=[(Entity(start_offset=20, end_offset=39, type='question', text=\"i'm a celebrity now\", normalized_text='im celebrity now'), Entity(start_offset=259, end_offset=267, type='context', text='The show', normalized_text='show'))], explanation_type='single_sentence'),\n",
       " 5150934530929664244: QEDExample(example_id=5150934530929664244, title='Spanish conquest of the Inca Empire', question='who led the conquest of the incas in south america', passage=\"The Spanish conquest of the Inca Empire was one of the most important campaigns in the Spanish colonization of the Americas . After years of preliminary exploration and military skirmishes , 180 Spanish soldiers under conquistador Francisco Pizarro , his brothers , and their native allies captured the Sapa Inca Atahualpa in the 1532 Battle of Cajamarca . It was the first step in a long campaign that took decades of fighting but ended in Spanish victory in 1572 and colonization of the region as the Viceroyalty of Peru . The conquest of the Inca Empire ( called `` Tahuantinsuyu '' or `` Tawantinsuyu '' in Quechua , meaning `` Realm of the Four Parts '' ) , led to spin - off campaigns into present - day Chile and Colombia , as well as expeditions towards the Amazon Basin .\", sentence_starts=[0, 126, 357, 525], selected_sent={'start': 126, 'end': 357, 'string': 'After years of preliminary exploration and military skirmishes , 180 Spanish soldiers under conquistador Francisco Pizarro , his brothers , and their native allies captured the Sapa Inca Atahualpa in the 1532 Battle of Cajamarca . '}, answer=[Entity(start_offset=231, end_offset=248, type='context', text='Francisco Pizarro', normalized_text='francisco pizarro')], nq_answers=[[Entity(start_offset=218, end_offset=248, type='context', text='conquistador Francisco Pizarro', normalized_text='conquistador francisco pizarro')], [Entity(start_offset=231, end_offset=248, type='context', text='Francisco Pizarro', normalized_text='francisco pizarro')]], aligned_nps=[(Entity(start_offset=37, end_offset=50, type='question', text='south america', normalized_text='south america'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 5255969991136559330: QEDExample(example_id=5255969991136559330, title='Jason Paige', question='who sings the pokemon theme song season 1', passage='Jason Paige ( born January 6 , 1969 ) is an American singer , writer , record producer , stage , film , and television actor . Paige is best known for singing the first theme song for the English version of the Pokémon television series .', sentence_starts=[0, 127], selected_sent={'start': 127, 'end': 238, 'string': 'Paige is best known for singing the first theme song for the English version of the Pokémon television series .'}, answer=[Entity(start_offset=0, end_offset=11, type='context', text='Jason Paige', normalized_text='jason paige')], nq_answers=[[Entity(start_offset=0, end_offset=11, type='context', text='Jason Paige', normalized_text='jason paige')]], aligned_nps=[(Entity(start_offset=10, end_offset=41, type='question', text='the pokemon theme song season 1', normalized_text='pokemon theme song season 1'), Entity(start_offset=159, end_offset=236, type='context', text='the first theme song for the English version of the Pokémon television series', normalized_text='first theme song for english version of pokémon television series'))], explanation_type='single_sentence'),\n",
       " -8781977407436236434: QEDExample(example_id=-8781977407436236434, title='Sockeye salmon', question='where does wild caught sockeye salmon come from', passage='Sockeye salmon ( Oncorhynchus nerka ) , also called red salmon , kokanee salmon , or blueback salmon , is an anadromous species of salmon found in the Northern Pacific Ocean and rivers discharging into it . This species is a Pacific salmon that is primarily red in hue during spawning . They can grow up to 84 cm ( 2 ft 9 in ) in length and weigh 2.3 to 7 kg ( 5.1 -- 15.4 lb ) . Juveniles remain in freshwater until they are ready to migrate to the ocean , over distances of up to 1,600 km ( 990 mi ) . Their diet consists primarily of zooplankton . Sockeye salmon are semelparous , dying after they spawn . Some populations , referred to as kokanee , do not migrate to the ocean and live their entire lives in freshwater .', sentence_starts=[0, 207, 287, 380, 504, 551, 609], selected_sent={'start': 0, 'end': 207, 'string': 'Sockeye salmon ( Oncorhynchus nerka ) , also called red salmon , kokanee salmon , or blueback salmon , is an anadromous species of salmon found in the Northern Pacific Ocean and rivers discharging into it . '}, answer=[Entity(start_offset=147, end_offset=204, type='context', text='the Northern Pacific Ocean and rivers discharging into it', normalized_text='northern pacific ocean and rivers discharging into it')], nq_answers=[[Entity(start_offset=151, end_offset=204, type='context', text='Northern Pacific Ocean and rivers discharging into it', normalized_text='northern pacific ocean and rivers discharging into it')], [Entity(start_offset=144, end_offset=204, type='context', text='in the Northern Pacific Ocean and rivers discharging into it', normalized_text='in northern pacific ocean and rivers discharging into it')], [Entity(start_offset=147, end_offset=173, type='context', text='the Northern Pacific Ocean', normalized_text='northern pacific ocean')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 349164000093084738: QEDExample(example_id=349164000093084738, title='Emergency Response Guidebook', question='what does the yellow section of the erg contain', passage='The second section , with yellow page borders , references the material in order of its assigned 4 - digit ID number / UN / NA number ( which is often placarded with the other hazardous materials placards ) and identifies the appropriate guide number to reference in the Orange Section ) . Items highlighted in green in this section will have evacuation distances included in the Green Section .', sentence_starts=[0, 290], selected_sent={'start': 0, 'end': 290, 'string': 'The second section , with yellow page borders , references the material in order of its assigned 4 - digit ID number / UN / NA number ( which is often placarded with the other hazardous materials placards ) and identifies the appropriate guide number to reference in the Orange Section ) . '}, answer=[Entity(start_offset=59, end_offset=287, type='context', text='the material in order of its assigned 4 - digit ID number / UN / NA number ( which is often placarded with the other hazardous materials placards ) and identifies the appropriate guide number to reference in the Orange Section )', normalized_text='material in order of its assigned 4 digit id number un na number which is often placarded with other hazardous materials placards and identifies appropriate guide number to reference in orange section')], nq_answers=[[Entity(start_offset=48, end_offset=133, type='context', text='references the material in order of its assigned 4 - digit ID number / UN / NA number', normalized_text='references material in order of its assigned 4 digit id number un na number')], [Entity(start_offset=59, end_offset=206, type='context', text='the material in order of its assigned 4 - digit ID number / UN / NA number ( which is often placarded with the other hazardous materials placards )', normalized_text='material in order of its assigned 4 digit id number un na number which is often placarded with other hazardous materials placards'), Entity(start_offset=222, end_offset=287, type='context', text='the appropriate guide number to reference in the Orange Section )', normalized_text='appropriate guide number to reference in orange section')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text='the yellow section of the erg', normalized_text='yellow section of erg'), Entity(start_offset=0, end_offset=45, type='context', text='The second section , with yellow page borders', normalized_text='second section with yellow page borders'))], explanation_type='single_sentence'),\n",
       " -4565661977175862394: QEDExample(example_id=-4565661977175862394, title='James S. Brady Press Briefing Room', question='who added a press room to the white house', passage='In 1969 , to accommodate the growing number of reporters assigned to the White House , President Richard Nixon had the indoor swimming pool , which had been installed by the March of Dimes for Franklin D. Roosevelt , covered and turned into press offices and a lounge that could double as a briefing room .', sentence_starts=[0], selected_sent={'start': 0, 'end': 306, 'string': 'In 1969 , to accommodate the growing number of reporters assigned to the White House , President Richard Nixon had the indoor swimming pool , which had been installed by the March of Dimes for Franklin D. Roosevelt , covered and turned into press offices and a lounge that could double as a briefing room .'}, answer=[Entity(start_offset=87, end_offset=110, type='context', text='President Richard Nixon', normalized_text='president richard nixon')], nq_answers=[[Entity(start_offset=87, end_offset=110, type='context', text='President Richard Nixon', normalized_text='president richard nixon')], [Entity(start_offset=97, end_offset=110, type='context', text='Richard Nixon', normalized_text='richard nixon')]], aligned_nps=[(Entity(start_offset=26, end_offset=41, type='question', text='the white house', normalized_text='white house'), Entity(start_offset=69, end_offset=84, type='context', text='the White House', normalized_text='white house'))], explanation_type='single_sentence'),\n",
       " 5306300389470118812: QEDExample(example_id=5306300389470118812, title='Muslim conquest of Persia', question='what was the religion in persia before islam', passage='The Muslim conquest of Persia , also known as the Arab conquest of Iran , , led to the end of the Sasanian Empire in 651 and the eventual decline of the Zoroastrian religion in Persia .', sentence_starts=[0], selected_sent={'start': 0, 'end': 185, 'string': 'The Muslim conquest of Persia , also known as the Arab conquest of Iran , , led to the end of the Sasanian Empire in 651 and the eventual decline of the Zoroastrian religion in Persia .'}, answer=[Entity(start_offset=149, end_offset=173, type='context', text='the Zoroastrian religion', normalized_text='zoroastrian religion')], nq_answers=[[Entity(start_offset=149, end_offset=173, type='context', text='the Zoroastrian religion', normalized_text='zoroastrian religion')], [Entity(start_offset=153, end_offset=164, type='context', text='Zoroastrian', normalized_text='zoroastrian')]], aligned_nps=[(Entity(start_offset=25, end_offset=31, type='question', text='persia', normalized_text='persia'), Entity(start_offset=177, end_offset=183, type='context', text='Persia', normalized_text='persia'))], explanation_type='single_sentence'),\n",
       " 4492088526674104172: QEDExample(example_id=4492088526674104172, title='Kerosene lamp', question='why does kerosene oil rise up in the wick of lantern', passage=\"A flat - wick lamp is a simple type of kerosene lamp , which burns kerosene drawn up through a wick by capillary action . If this type of lamp is broken , it can easily start a fire . A flat - wick lamp has a fuel tank ( fount ) , with the lamp burner attached . Attached to the fuel tank , four prongs hold the glass chimney , which acts to prevent the flame from being blown out and enhances a thermally induced draft . The glass chimney needs a `` throat '' , or slight constriction , to create the proper draft for complete combustion of the fuel ; the draft carries more air ( oxygen ) past the flame , helping to produce a smokeless light , which is brighter than an open flame would produce .\", sentence_starts=[0, 122, 184, 263, 422], selected_sent={'start': 0, 'end': 122, 'string': 'A flat - wick lamp is a simple type of kerosene lamp , which burns kerosene drawn up through a wick by capillary action . '}, answer=[Entity(start_offset=103, end_offset=119, type='context', text='capillary action', normalized_text='capillary action')], nq_answers=[[Entity(start_offset=103, end_offset=119, type='context', text='capillary action', normalized_text='capillary action')]], aligned_nps=[(Entity(start_offset=9, end_offset=21, type='question', text='kerosene oil', normalized_text='kerosene oil'), Entity(start_offset=67, end_offset=75, type='context', text='kerosene', normalized_text='kerosene')), (Entity(start_offset=33, end_offset=52, type='question', text='the wick of lantern', normalized_text='wick of lantern'), Entity(start_offset=93, end_offset=99, type='context', text='a wick', normalized_text='wick'))], explanation_type='single_sentence'),\n",
       " -4373262132142058334: QEDExample(example_id=-4373262132142058334, title='Proinsulin', question='mention the chemical change that proinsulin undergo to be able to act as mature insulin', passage='The post translational modification of proinsulin to mature insulin only occurs in the beta cells of the islets of Langerhans . When proinsulin is transported through the Golgi apparatus the C - peptide is cleaved . This cleavage occurs with the aid of two endoproteases . Type I endoproteases , PC1 and PC3 , disrupt the C peptide - B chain connection . PC2 , a type II endoprotease , cleaves the C peptide - A chain bond . The resulting molecule , now mature insulin , is stored as a hexamer in secretory vesicles and is stabilized with Z n 2 + ( \\\\ displaystyle Zn ^ ( 2 + ) ) molecules until it is secreted .', sentence_starts=[0, 128, 216, 273, 355, 425], selected_sent={'start': 0, 'end': 128, 'string': 'The post translational modification of proinsulin to mature insulin only occurs in the beta cells of the islets of Langerhans . '}, answer=[Entity(start_offset=4, end_offset=35, type='context', text='post translational modification', normalized_text='post translational modification')], nq_answers=[[Entity(start_offset=4, end_offset=35, type='context', text='post translational modification', normalized_text='post translational modification')]], aligned_nps=[(Entity(start_offset=33, end_offset=43, type='question', text='proinsulin', normalized_text='proinsulin'), Entity(start_offset=39, end_offset=49, type='context', text='proinsulin', normalized_text='proinsulin')), (Entity(start_offset=73, end_offset=87, type='question', text='mature insulin', normalized_text='mature insulin'), Entity(start_offset=53, end_offset=67, type='context', text='mature insulin', normalized_text='mature insulin'))], explanation_type='single_sentence'),\n",
       " -724426540432437711: QEDExample(example_id=-724426540432437711, title='Little Shop of Horrors (film)', question='what was the name of the plant on little shop of horrors', passage=\"A three - girl `` Greek chorus '' -- Crystal , Ronnette , and Chiffon -- introduce the movie , warning the audience that some horror is coming their way ( `` Prologue : Little Shop of Horrors '' ) . Seymour Krelborn ( Rick Moranis ) and his colleague , Audrey ( Ellen Greene ) , work at Mushnik 's Flower Shop in a run - down , rough neighborhood referred to as `` Skid Row '' in the slums of New York City . They lament that they can not escape the neighborhood ( `` Skid Row '' ( Downtown ) `` ) . Struggling from a lack of customers , Mr. Mushnik ( Vincent Gardenia ) decides to close the store , but Audrey suggests he may have more success by displaying an unusual plant that Seymour owns . Immediately attracting a customer , Seymour explains he bought the plant , which he dubbed `` Audrey II '' , from a Chinese flower shop during a solar eclipse ( `` Da - Doo '' ) . Attracting business to Mushnik 's shop , the plant soon starts dying , worrying Seymour . Accidentally pricking his finger , he then discovers Audrey II needs human blood to thrive ( `` Grow for Me '' ) .\", sentence_starts=[0, 199, 409, 500, 696, 876, 966], selected_sent={'start': 696, 'end': 876, 'string': \"Immediately attracting a customer , Seymour explains he bought the plant , which he dubbed `` Audrey II '' , from a Chinese flower shop during a solar eclipse ( `` Da - Doo '' ) . \"}, answer=[Entity(start_offset=790, end_offset=799, type='context', text='Audrey II', normalized_text='audrey ii')], nq_answers=[[Entity(start_offset=790, end_offset=799, type='context', text='Audrey II', normalized_text='audrey ii')]], aligned_nps=[(Entity(start_offset=21, end_offset=56, type='question', text='the plant on little shop of horrors', normalized_text='plant on little shop of horrors'), Entity(start_offset=759, end_offset=768, type='context', text='the plant', normalized_text='plant'))], explanation_type='single_sentence'),\n",
       " -6267746560439390778: QEDExample(example_id=-6267746560439390778, title='Star Wars Battlefront II (2017 video game)', question='who do you play as in star wars battlefront 2', passage=\"The game features a full campaign story mode unlike 2015 's Battlefront . The game 's single player protagonist , Iden Versio , leader of an Imperial Special Forces group known as Inferno Squad , participates in multiple events in the 30 years leading up to The Force Awakens . There will be segments in the campaign where the player will be able to control other characters such as Luke Skywalker and Kylo Ren . Players can also play in arcade mode -- an offline single player or local co-op where players can choose which side to play on and which battle to play in . Battles vary from team battles to onslaughts . Alternatively , players can choose to do a custom match , where they can change some of the settings and location .\", sentence_starts=[0, 74, 278, 413, 570, 617], selected_sent={'start': 74, 'end': 278, 'string': \"The game 's single player protagonist , Iden Versio , leader of an Imperial Special Forces group known as Inferno Squad , participates in multiple events in the 30 years leading up to The Force Awakens . \"}, answer=[Entity(start_offset=114, end_offset=193, type='context', text='Iden Versio , leader of an Imperial Special Forces group known as Inferno Squad', normalized_text='iden versio leader of imperial special forces group known as inferno squad')], nq_answers=[[Entity(start_offset=114, end_offset=193, type='context', text='Iden Versio , leader of an Imperial Special Forces group known as Inferno Squad', normalized_text='iden versio leader of imperial special forces group known as inferno squad')]], aligned_nps=[(Entity(start_offset=22, end_offset=45, type='question', text='star wars battlefront 2', normalized_text='star wars battlefront 2'), Entity(start_offset=74, end_offset=82, type='context', text='The game', normalized_text='game'))], explanation_type='single_sentence'),\n",
       " 7933002036740390435: QEDExample(example_id=7933002036740390435, title='Liberal arts education', question='where did the term liberal arts come from', passage=\"Liberal arts education ( Latin : liberalis , free and ars , art or principled practice ) can claim to be the oldest programme of higher education in Western history . It has its origin in the attempt to discover first principles -- ' those universal principles which are the condition of the possibility of the existence of anything and everything ' . The liberal arts are those subjects or skills that in classical antiquity were considered essential for a free person ( Latin : liberalis , `` worthy of a free person '' ) to know in order to take an active part in civic life , something that ( for Ancient Greece ) included participating in public debate , defending oneself in court , serving on juries , and most importantly , military service . Grammar , logic , and rhetoric were the core liberal arts ( the Trivium ) , while arithmetic , geometry , the theory of music , and astronomy also played a ( somewhat lesser ) part in education ( as the Quadrivium ) .\", sentence_starts=[0, 167, 352, 751], selected_sent={'start': 352, 'end': 751, 'string': \"The liberal arts are those subjects or skills that in classical antiquity were considered essential for a free person ( Latin : liberalis , `` worthy of a free person '' ) to know in order to take an active part in civic life , something that ( for Ancient Greece ) included participating in public debate , defending oneself in court , serving on juries , and most importantly , military service . \"}, answer=[Entity(start_offset=379, end_offset=577, type='context', text=\"subjects or skills that in classical antiquity were considered essential for a free person ( Latin : liberalis , `` worthy of a free person '' ) to know in order to take an active part in civic life\", normalized_text='subjects or skills that in classical antiquity were considered essential for free person latin liberalis worthy of free person to know in order to take active part in civic life')], nq_answers=[[Entity(start_offset=373, end_offset=469, type='context', text='those subjects or skills that in classical antiquity were considered essential for a free person', normalized_text='those subjects or skills that in classical antiquity were considered essential for free person')], [Entity(start_offset=472, end_offset=521, type='context', text=\"Latin : liberalis , `` worthy of a free person ''\", normalized_text='latin liberalis worthy of free person')], [Entity(start_offset=25, end_offset=86, type='context', text='Latin : liberalis , free and ars , art or principled practice', normalized_text='latin liberalis free and ars art or principled practice')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -2991400700385487821: QEDExample(example_id=-2991400700385487821, title='Government of West Virginia', question='who heads the executive department of west virginia government', passage='The Government of West Virginia is modeled after the Government of the United States , with three branches : the executive , consisting of the Governor of West Virginia and the other elected constitutional officers ; the legislative , consisting of the West Virginia Legislature which includes the Senate and the House of Delegates ; and the judicial , consisting of the West Virginia Supreme Court of Appeals and lower courts .', sentence_starts=[0], selected_sent={'start': 0, 'end': 428, 'string': 'The Government of West Virginia is modeled after the Government of the United States , with three branches : the executive , consisting of the Governor of West Virginia and the other elected constitutional officers ; the legislative , consisting of the West Virginia Legislature which includes the Senate and the House of Delegates ; and the judicial , consisting of the West Virginia Supreme Court of Appeals and lower courts .'}, answer=[Entity(start_offset=139, end_offset=168, type='context', text='the Governor of West Virginia', normalized_text='governor of west virginia')], nq_answers=[[Entity(start_offset=139, end_offset=168, type='context', text='the Governor of West Virginia', normalized_text='governor of west virginia')]], aligned_nps=[(Entity(start_offset=10, end_offset=62, type='question', text='the executive department of west virginia government', normalized_text='executive department of west virginia government'), Entity(start_offset=109, end_offset=122, type='context', text='the executive', normalized_text='executive'))], explanation_type='single_sentence'),\n",
       " -9186689755642837558: QEDExample(example_id=-9186689755642837558, title='Confederation Bridge', question='how long is the bridge between new brunswick and prince edward island', passage=\"The Confederation Bridge ( French : Pont de la Confédération ) spans the Abegweit Passage of Northumberland Strait . It links Prince Edward Island with mainland New Brunswick , Canada . Before its official naming , Prince Edward Islanders often referred to the bridge as the `` Fixed Link '' . Construction took place from October 1993 to May 1997 and cost C $ 1.3 billion . The 12.9 - kilometre ( 8 mi ) bridge opened on May 31 , 1997 .\", sentence_starts=[0, 117, 186, 294, 375], selected_sent={'start': 375, 'end': 437, 'string': 'The 12.9 - kilometre ( 8 mi ) bridge opened on May 31 , 1997 .'}, answer=[Entity(start_offset=379, end_offset=404, type='context', text='12.9 - kilometre ( 8 mi )', normalized_text='129 kilometre 8 mi')], nq_answers=[[Entity(start_offset=379, end_offset=404, type='context', text='12.9 - kilometre ( 8 mi )', normalized_text='129 kilometre 8 mi')], [Entity(start_offset=379, end_offset=395, type='context', text='12.9 - kilometre', normalized_text='129 kilometre')]], aligned_nps=[(Entity(start_offset=12, end_offset=69, type='question', text='the bridge between new brunswick and prince edward island', normalized_text='bridge between new brunswick and prince edward island'), Entity(start_offset=375, end_offset=411, type='context', text='The 12.9 - kilometre ( 8 mi ) bridge', normalized_text='129 kilometre 8 mi bridge'))], explanation_type='single_sentence'),\n",
       " 8029901619424338449: QEDExample(example_id=8029901619424338449, title='United Kingdom–United States relations', question='when did the uk and us become allies', passage='British -- American relations , also referred to as Anglo - American relations , encompass many complex relations ranging from two early wars to competition for world markets . Since 1940 they have been close military allies enjoying the Special Relationship built as wartime allies , and NATO partners .', sentence_starts=[0, 177], selected_sent={'start': 177, 'end': 304, 'string': 'Since 1940 they have been close military allies enjoying the Special Relationship built as wartime allies , and NATO partners .'}, answer=[Entity(start_offset=183, end_offset=187, type='context', text='1940', normalized_text='1940')], nq_answers=[[Entity(start_offset=183, end_offset=187, type='context', text='1940', normalized_text='1940')], [Entity(start_offset=177, end_offset=187, type='context', text='Since 1940', normalized_text='since 1940')]], aligned_nps=[(Entity(start_offset=9, end_offset=22, type='question', text='the uk and us', normalized_text='uk and us'), Entity(start_offset=188, end_offset=192, type='context', text='they', normalized_text='they'))], explanation_type='single_sentence'),\n",
       " 4828649525820722736: QEDExample(example_id=4828649525820722736, title='The Man with the Golden Gun (soundtrack)', question='who sang the theme song for the man with the golden gun', passage=\"The theme tune was performed by Lulu , composed by John Barry , and the lyrics to the song were written by Don Black . Alice Cooper claims his song `` The Man With The Golden Gun '' was to be used by the film 's producers until it was dropped for Lulu 's song instead . Cooper 's song appears on his album Muscle of Love .\", sentence_starts=[0, 119, 270], selected_sent={'start': 0, 'end': 119, 'string': 'The theme tune was performed by Lulu , composed by John Barry , and the lyrics to the song were written by Don Black . '}, answer=[Entity(start_offset=32, end_offset=36, type='context', text='Lulu', normalized_text='lulu')], nq_answers=[[Entity(start_offset=32, end_offset=36, type='context', text='Lulu', normalized_text='lulu')]], aligned_nps=[(Entity(start_offset=9, end_offset=55, type='question', text='the theme song for the man with the golden gun', normalized_text='theme song for man with golden gun'), Entity(start_offset=0, end_offset=14, type='context', text='The theme tune', normalized_text='theme tune'))], explanation_type='single_sentence'),\n",
       " 5819386267283467034: QEDExample(example_id=5819386267283467034, title=\"United States men's national ice hockey team\", question='what year did the us hockey team won the olympics', passage=\"The United States won gold medals at the 1960 and 1980 Winter Olympics and more recently , silver medals at the 2002 and 2010 Winter Olympics . The United States won the 1996 World Cup of Hockey . The team 's most recent medal at the World Championships came with a bronze in 2015 . They won the tournament in 1933 and 1960 . Unlike other nations , the United States does n't typically use its best NHL players in the World Championships even when they 're available . Instead , USA Hockey uses this tournament as a platform for young NHLers and college players .\", sentence_starts=[0, 144, 197, 283, 326, 469], selected_sent={'start': 0, 'end': 144, 'string': 'The United States won gold medals at the 1960 and 1980 Winter Olympics and more recently , silver medals at the 2002 and 2010 Winter Olympics . '}, answer=[Entity(start_offset=41, end_offset=54, type='context', text='1960 and 1980', normalized_text='1960 and 1980')], nq_answers=[[Entity(start_offset=41, end_offset=54, type='context', text='1960 and 1980', normalized_text='1960 and 1980')], [Entity(start_offset=41, end_offset=45, type='context', text='1960', normalized_text='1960'), Entity(start_offset=50, end_offset=54, type='context', text='1980', normalized_text='1980')]], aligned_nps=[(Entity(start_offset=14, end_offset=32, type='question', text='the us hockey team', normalized_text='us hockey team'), Entity(start_offset=0, end_offset=17, type='context', text='The United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 8770209312170080158: QEDExample(example_id=8770209312170080158, title='Suddenly (Olivia Newton-John and Cliff Richard song)', question='who sang the song suddenly with olivia newton john', passage=\"`` Suddenly '' is a song from the soundtrack album Xanadu , and is the love theme from the 1980 film of the same name . The song is performed as a duet between Olivia Newton - John and Cliff Richard . It was written by John Farrar who also produced the record . It was released on Jet Records and reached No. 15 in the UK charts in October 1980 and reached No. 20 in the US . The video shows them in a penthouse singing the song to each other .\", sentence_starts=[0, 120, 201, 262, 376], selected_sent={'start': 120, 'end': 201, 'string': 'The song is performed as a duet between Olivia Newton - John and Cliff Richard . '}, answer=[Entity(start_offset=176, end_offset=198, type='context', text='John and Cliff Richard', normalized_text='john and cliff richard')], nq_answers=[[Entity(start_offset=185, end_offset=198, type='context', text='Cliff Richard', normalized_text='cliff richard')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='the song suddenly', normalized_text='song suddenly'), Entity(start_offset=120, end_offset=128, type='context', text='The song', normalized_text='song')), (Entity(start_offset=32, end_offset=50, type='question', text='olivia newton john', normalized_text='olivia newton john'), Entity(start_offset=160, end_offset=173, type='context', text='Olivia Newton', normalized_text='olivia newton'))], explanation_type='single_sentence'),\n",
       " 2098168902147822379: QEDExample(example_id=2098168902147822379, title='List of Olympic Games host cities', question='where will the next summer and winter olympics be held', passage=\"This is a list of host cities of the Olympic Games , both summer and winter , since the modern Olympics began in 1896 . Since then , summer games have usually -- but not always -- celebrated a four - year period known as an Olympiad . There have been 28 Summer Olympic Games held in 23 cities , and 23 Winter Olympic Games held in 20 cities . In addition , three summer and two winter editions of the Games were scheduled to take place but later cancelled due to war : Berlin ( summer ) in 1916 ; Tokyo / Helsinki ( summer ) and Sapporo / Garmisch - Partenkirchen ( winter ) in 1940 ; and London ( summer ) and Cortina d'Ampezzo , Italy ( winter ) in 1944 . The 1906 Summer Olympics were officially sanctioned and held in Athens . However , in 1949 , the International Olympic Committee ( IOC ) , decided to unrecognize the 1906 Games . Four cities have been chosen by the IOC to host upcoming Olympic Games : Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics , Paris for the 2024 Summer Olympics , and Los Angeles for the 2028 Summer Olympics .\", sentence_starts=[0, 120, 235, 343, 658, 731, 837], selected_sent={'start': 837, 'end': 1069, 'string': 'Four cities have been chosen by the IOC to host upcoming Olympic Games : Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics , Paris for the 2024 Summer Olympics , and Los Angeles for the 2028 Summer Olympics .'}, answer=[Entity(start_offset=910, end_offset=983, type='context', text='Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics', normalized_text='tokyo for 2020 summer olympics beijing for 2022 winter olympics')], nq_answers=[[Entity(start_offset=910, end_offset=983, type='context', text='Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics', normalized_text='tokyo for 2020 summer olympics beijing for 2022 winter olympics')], [Entity(start_offset=910, end_offset=915, type='context', text='Tokyo', normalized_text='tokyo'), Entity(start_offset=947, end_offset=954, type='context', text='Beijing', normalized_text='beijing')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6861734002351236912: QEDExample(example_id=-6861734002351236912, title='Heaven (Los Lonely Boys song)', question='who sang the song how far is heaven', passage=\"`` Heaven '' is the debut single of American rock band Los Lonely Boys . The song was written by brothers Henry , Jojo and Ringo Garza , who comprise the foundation of the band , and it appears on their multi-platinum self - titled album .\", sentence_starts=[0, 73], selected_sent={'start': 0, 'end': 73, 'string': \"`` Heaven '' is the debut single of American rock band Los Lonely Boys . \"}, answer=[Entity(start_offset=55, end_offset=70, type='context', text='Los Lonely Boys', normalized_text='los lonely boys')], nq_answers=[[Entity(start_offset=55, end_offset=70, type='context', text='Los Lonely Boys', normalized_text='los lonely boys')], [Entity(start_offset=36, end_offset=70, type='context', text='American rock band Los Lonely Boys', normalized_text='american rock band los lonely boys')]], aligned_nps=[(Entity(start_offset=9, end_offset=35, type='question', text='the song how far is heaven', normalized_text='song how far is heaven'), Entity(start_offset=3, end_offset=9, type='context', text='Heaven', normalized_text='heaven'))], explanation_type='single_sentence'),\n",
       " -1722216190521937227: QEDExample(example_id=-1722216190521937227, title='Organ Mountains (New Mexico)', question='where are the organ mountains in new mexico', passage='The Organ Mountains are a rugged mountain range in southern New Mexico in the Southwestern United States . Organ Mountains - Desert Peaks National Monument was declared a national monument on May 21 , 2014 . They lie 10 miles ( 16 km ) east of the city of Las Cruces , in Doña Ana County .', sentence_starts=[0, 107, 208], selected_sent={'start': 208, 'end': 289, 'string': 'They lie 10 miles ( 16 km ) east of the city of Las Cruces , in Doña Ana County .'}, answer=[Entity(start_offset=217, end_offset=287, type='context', text='10 miles ( 16 km ) east of the city of Las Cruces , in Doña Ana County', normalized_text='10 miles 16 km east of city of las cruces in doña ana county')], nq_answers=[[Entity(start_offset=217, end_offset=287, type='context', text='10 miles ( 16 km ) east of the city of Las Cruces , in Doña Ana County', normalized_text='10 miles 16 km east of city of las cruces in doña ana county')], [Entity(start_offset=51, end_offset=70, type='context', text='southern New Mexico', normalized_text='southern new mexico')]], aligned_nps=[(Entity(start_offset=10, end_offset=29, type='question', text='the organ mountains', normalized_text='organ mountains'), Entity(start_offset=208, end_offset=212, type='context', text='They', normalized_text='they')), (Entity(start_offset=33, end_offset=43, type='question', text='new mexico', normalized_text='new mexico'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2717119588239727064: QEDExample(example_id=-2717119588239727064, title='Plagues of Egypt', question='where are the 10 plagues found in the bible', passage='The Plagues of Egypt ( Hebrew : מכות מצרים , Makot Mitzrayim ) , also called the ten biblical plagues , were ten calamities that , according to the biblical Book of Exodus , God inflicted upon Egypt to persuade the Pharaoh to release the ill - treated Israelites from slavery . The Pharaoh capitulated after the tenth plague , until which God had prevented him from being swayed , triggering the Exodus of the Hebrew people .', sentence_starts=[0, 278], selected_sent={'start': 0, 'end': 278, 'string': 'The Plagues of Egypt ( Hebrew : מכות מצרים , Makot Mitzrayim ) , also called the ten biblical plagues , were ten calamities that , according to the biblical Book of Exodus , God inflicted upon Egypt to persuade the Pharaoh to release the ill - treated Israelites from slavery . '}, answer=[Entity(start_offset=157, end_offset=171, type='context', text='Book of Exodus', normalized_text='book of exodus')], nq_answers=[[Entity(start_offset=157, end_offset=171, type='context', text='Book of Exodus', normalized_text='book of exodus')], [Entity(start_offset=165, end_offset=171, type='context', text='Exodus', normalized_text='exodus')]], aligned_nps=[(Entity(start_offset=10, end_offset=24, type='question', text='the 10 plagues', normalized_text='10 plagues'), Entity(start_offset=77, end_offset=101, type='context', text='the ten biblical plagues', normalized_text='ten biblical plagues'))], explanation_type='single_sentence'),\n",
       " 2988284357714596500: QEDExample(example_id=2988284357714596500, title='Red blood cell', question='where are red blood cells made in adults', passage=\"In humans , mature red blood cells are flexible and oval biconcave disks . They lack a cell nucleus and most organelles , in order to accommodate maximum space for hemoglobin ; they can be viewed as sacks of hemoglobin , with a plasma membrane as the sack . Approximately 2.4 million new erythrocytes are produced per second in human adults . The cells develop in the bone marrow and circulate for about 100 -- 120 days in the body before their components are recycled by macrophages . Each circulation takes about 60 seconds ( one minute ) . Approximately a quarter of the cells in the human body are red blood cells . Nearly half of the blood 's volume ( 40 % to 45 % ) is red blood cells .\", sentence_starts=[0, 75, 258, 343, 486, 543, 620], selected_sent={'start': 343, 'end': 486, 'string': 'The cells develop in the bone marrow and circulate for about 100 -- 120 days in the body before their components are recycled by macrophages . '}, answer=[Entity(start_offset=364, end_offset=379, type='context', text='the bone marrow', normalized_text='bone marrow')], nq_answers=[[Entity(start_offset=361, end_offset=379, type='context', text='in the bone marrow', normalized_text='in bone marrow')]], aligned_nps=[(Entity(start_offset=10, end_offset=25, type='question', text='red blood cells', normalized_text='red blood cells'), Entity(start_offset=343, end_offset=352, type='context', text='The cells', normalized_text='cells'))], explanation_type='single_sentence'),\n",
       " -4616596799374362422: QEDExample(example_id=-4616596799374362422, title='Kate Warne', question=\"who was the pinkerton detective agency's first female detective\", passage='Kate Warne ( 1833 -- January 28 , 1868 ) was the first female detective , in 1856 , in the Pinkerton Detective Agency and the United States .', sentence_starts=[0], selected_sent={'start': 0, 'end': 141, 'string': 'Kate Warne ( 1833 -- January 28 , 1868 ) was the first female detective , in 1856 , in the Pinkerton Detective Agency and the United States .'}, answer=[Entity(start_offset=0, end_offset=10, type='context', text='Kate Warne', normalized_text='kate warne')], nq_answers=[[Entity(start_offset=0, end_offset=10, type='context', text='Kate Warne', normalized_text='kate warne')]], aligned_nps=[(Entity(start_offset=8, end_offset=63, type='question', text=\"the pinkerton detective agency's first female detective\", normalized_text='pinkerton detective agencys first female detective'), Entity(start_offset=45, end_offset=71, type='context', text='the first female detective', normalized_text='first female detective'))], explanation_type='single_sentence'),\n",
       " -3650291155113659146: QEDExample(example_id=-3650291155113659146, title='List of Modern Family episodes', question='how many episodes are there in modern family', passage=\"Modern Family is an American family mockumentary comedy series that airs on ABC . It was created by Christopher Lloyd and Steven Levitan . The show follows the family lives of Jay Pritchett ( Ed O'Neill ) , his daughter Claire Dunphy ( Julie Bowen ) , and his son Mitchell Pritchett ( Jesse Tyler Ferguson ) , who all live in Los Angeles . Claire is married to Phil Dunphy ( Ty Burrell ) . They have three children : Haley ( Sarah Hyland ) , Alex ( Ariel Winter ) and Luke ( Nolan Gould ) . Jay is married to a much younger Colombian woman , Gloria ( Sofía Vergara ) , and is helping her raise her teenage son , Manny ( Rico Rodriguez ) along with their new baby Fulgencio `` Joe '' Pritchett ( Jeremy Maguire ) . Mitchell and his husband Cameron Tucker ( Eric Stonestreet ) have an adopted Vietnamese child , Lily Tucker - Pritchett ( Aubrey Anderson - Emmons ) . The series premiered on September 23 , 2009 . The series has been renewed for two additional seasons , with 22 episodes each , bringing the total amount of episodes up to 232 .\", sentence_starts=[0, 82, 139, 340, 390, 491, 714, 865, 911], selected_sent={'start': 911, 'end': 1041, 'string': 'The series has been renewed for two additional seasons , with 22 episodes each , bringing the total amount of episodes up to 232 .'}, answer=[Entity(start_offset=1036, end_offset=1039, type='context', text='232', normalized_text='232')], nq_answers=[[Entity(start_offset=1036, end_offset=1039, type='context', text='232', normalized_text='232')]], aligned_nps=[(Entity(start_offset=31, end_offset=44, type='question', text='modern family', normalized_text='modern family'), Entity(start_offset=911, end_offset=921, type='context', text='The series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " 3381924381590631417: QEDExample(example_id=3381924381590631417, title=\"Solomon's Temple\", question='who built the first temple for god in jerusalem', passage=\"The Hebrew Bible states that the temple was constructed under Solomon , king of the United Kingdom of Israel and Judah and that during the Kingdom of Judah , the temple was dedicated to Yahweh , and is said to have housed the Ark of the Covenant . Jewish historian Josephus says that `` the temple was burnt four hundred and seventy years , six months , and ten days after it was built '' , although rabbinic sources state that the First Temple stood for 410 years and , based on the 2nd - century work Seder Olam Rabbah , place construction in 832 BCE and destruction in 422 BCE , 165 years later than secular estimates .\", sentence_starts=[0, 248], selected_sent={'start': 0, 'end': 248, 'string': 'The Hebrew Bible states that the temple was constructed under Solomon , king of the United Kingdom of Israel and Judah and that during the Kingdom of Judah , the temple was dedicated to Yahweh , and is said to have housed the Ark of the Covenant . '}, answer=[Entity(start_offset=62, end_offset=118, type='context', text='Solomon , king of the United Kingdom of Israel and Judah', normalized_text='solomon king of united kingdom of israel and judah')], nq_answers=[[Entity(start_offset=62, end_offset=118, type='context', text='Solomon , king of the United Kingdom of Israel and Judah', normalized_text='solomon king of united kingdom of israel and judah')], [Entity(start_offset=62, end_offset=69, type='context', text='Solomon', normalized_text='solomon')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text='the first temple for god', normalized_text='first temple for god'), Entity(start_offset=29, end_offset=39, type='context', text='the temple', normalized_text='temple'))], explanation_type='single_sentence'),\n",
       " -154783694579651082: QEDExample(example_id=-154783694579651082, title='Google Maps pin', question='what is a dropped pin on google maps for', passage=\"The Google Maps pin is the inverted - drop - shaped icon that marks locations in Google Maps . The pin is protected under a U.S. design patent as `` teardrop - shaped marker icon including a shadow . '' Google has used the pin in various graphics , games , and promotional materials .\", sentence_starts=[0, 95, 203], selected_sent={'start': 0, 'end': 95, 'string': 'The Google Maps pin is the inverted - drop - shaped icon that marks locations in Google Maps . '}, answer=[Entity(start_offset=62, end_offset=77, type='context', text='marks locations', normalized_text='marks locations')], nq_answers=[[Entity(start_offset=62, end_offset=77, type='context', text='marks locations', normalized_text='marks locations')], [Entity(start_offset=62, end_offset=92, type='context', text='marks locations in Google Maps', normalized_text='marks locations in google maps')]], aligned_nps=[(Entity(start_offset=25, end_offset=36, type='question', text='google maps', normalized_text='google maps'), Entity(start_offset=81, end_offset=92, type='context', text='Google Maps', normalized_text='google maps'))], explanation_type='single_sentence'),\n",
       " 6915606477668963399: QEDExample(example_id=6915606477668963399, title='Therefore sign', question='what do the 3 dots mean in math', passage=\"In logical argument and mathematical proof , the therefore sign ( ∴ ) is generally used before a logical consequence , such as the conclusion of a syllogism . The symbol consists of three dots placed in an upright triangle and is read therefore . It is encoded at U + 2234 ∴ therefore ( HTML & # 8756 ; &there4 ; ) . For common use in Microsoft Office hold the ALT key and type `` 8756 '' . While it is not generally used in formal writing , it is used in mathematics and shorthand . It is complementary to U + 2235 ∵ because ( HTML & # 8757 ; ) .\", sentence_starts=[0, 159, 247, 303, 317, 391, 484], selected_sent={'start': 0, 'end': 159, 'string': 'In logical argument and mathematical proof , the therefore sign ( ∴ ) is generally used before a logical consequence , such as the conclusion of a syllogism . '}, answer=[Entity(start_offset=83, end_offset=156, type='context', text='used before a logical consequence , such as the conclusion of a syllogism', normalized_text='used before logical consequence such as conclusion of syllogism')], nq_answers=[[Entity(start_offset=45, end_offset=156, type='context', text='the therefore sign ( ∴ ) is generally used before a logical consequence , such as the conclusion of a syllogism', normalized_text='therefore sign ∴ is generally used before logical consequence such as conclusion of syllogism')], [Entity(start_offset=45, end_offset=63, type='context', text='the therefore sign', normalized_text='therefore sign')], [Entity(start_offset=95, end_offset=156, type='context', text='a logical consequence , such as the conclusion of a syllogism', normalized_text='logical consequence such as conclusion of syllogism')], [Entity(start_offset=49, end_offset=63, type='context', text='therefore sign', normalized_text='therefore sign')]], aligned_nps=[(Entity(start_offset=8, end_offset=18, type='question', text='the 3 dots', normalized_text='3 dots'), Entity(start_offset=45, end_offset=69, type='context', text='the therefore sign ( ∴ )', normalized_text='therefore sign ∴'))], explanation_type='single_sentence'),\n",
       " -5004457603684974952: QEDExample(example_id=-5004457603684974952, title='Super Bowl 50 halftime show', question='who is playing the halftime show at super bowl 2016', passage=\"The Super Bowl 50 Halftime Show took place on February 7 , 2016 , at Levi 's Stadium in Santa Clara , California as part of Super Bowl 50 . It was headlined by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars , who previously had headlined the Super Bowl XLVII and Super Bowl XLVIII halftime shows , respectively .\", sentence_starts=[0, 140], selected_sent={'start': 140, 'end': 350, 'string': 'It was headlined by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars , who previously had headlined the Super Bowl XLVII and Super Bowl XLVIII halftime shows , respectively .'}, answer=[Entity(start_offset=160, end_offset=244, type='context', text='the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars', normalized_text='british rock group coldplay with special guest performers beyoncé and bruno mars')], nq_answers=[[Entity(start_offset=183, end_offset=244, type='context', text='Coldplay with special guest performers Beyoncé and Bruno Mars', normalized_text='coldplay with special guest performers beyoncé and bruno mars')], [Entity(start_offset=183, end_offset=191, type='context', text='Coldplay', normalized_text='coldplay'), Entity(start_offset=222, end_offset=229, type='context', text='Beyoncé', normalized_text='beyoncé'), Entity(start_offset=234, end_offset=244, type='context', text='Bruno Mars', normalized_text='bruno mars')], [Entity(start_offset=164, end_offset=244, type='context', text='British rock group Coldplay with special guest performers Beyoncé and Bruno Mars', normalized_text='british rock group coldplay with special guest performers beyoncé and bruno mars')]], aligned_nps=[(Entity(start_offset=15, end_offset=51, type='question', text='the halftime show at super bowl 2016', normalized_text='halftime show at super bowl 2016'), Entity(start_offset=140, end_offset=142, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 8494342737238168262: QEDExample(example_id=8494342737238168262, title='Matt Lanter', question='star wars the clone wars anakin voice actor', passage=\"Matthew MacKendree `` Matt '' Lanter ( born April 1 , 1983 ) is an American actor , voice actor , and model . He gained fame by playing Liam Court in The CW hit teen drama series 90210 , a spin - off of the 1990s Fox series Beverly Hills , 90210 . He also appeared in some major released films , such as Star Wars : The Clone Wars , Disaster Movie , WarGames : The Dead Code , Sorority Row , Vampires Suck and The Roommate . He is the voice of Anakin Skywalker in Star Wars : The Clone Wars and Star Wars Rebels . He stars as soldier Wyatt Logan , a time traveler , in Timeless on NBC .\", sentence_starts=[0, 110, 248, 425, 514], selected_sent={'start': 425, 'end': 514, 'string': 'He is the voice of Anakin Skywalker in Star Wars : The Clone Wars and Star Wars Rebels . '}, answer=[Entity(start_offset=0, end_offset=36, type='context', text=\"Matthew MacKendree `` Matt '' Lanter\", normalized_text='matthew mackendree matt lanter')], nq_answers=[[Entity(start_offset=0, end_offset=36, type='context', text=\"Matthew MacKendree `` Matt '' Lanter\", normalized_text='matthew mackendree matt lanter')]], aligned_nps=[(Entity(start_offset=25, end_offset=31, type='question', text='anakin', normalized_text='anakin'), Entity(start_offset=444, end_offset=460, type='context', text='Anakin Skywalker', normalized_text='anakin skywalker')), (Entity(start_offset=0, end_offset=24, type='question', text='star wars the clone wars', normalized_text='star wars clone wars'), Entity(start_offset=464, end_offset=490, type='context', text='Star Wars : The Clone Wars', normalized_text='star wars clone wars'))], explanation_type='single_sentence'),\n",
       " 7217222058435937287: QEDExample(example_id=7217222058435937287, title='World Economic Forum', question='where was the world economic forum held this year', passage=\"The forum is best known for its annual meeting at the end of January in Davos , a mountain resort in Graubünden , in the eastern Alps region of Switzerland . The meeting brings together some 2,500 top business leaders , international political leaders , economists , celebrities and journalists for up to four days to discuss the most pressing issues facing the world . Often this location alone is used to identify meetings , participation , and participants , with such phrases as `` a Davos panel '' and `` Davos man '' being used .\", sentence_starts=[0, 158, 370], selected_sent={'start': 0, 'end': 158, 'string': 'The forum is best known for its annual meeting at the end of January in Davos , a mountain resort in Graubünden , in the eastern Alps region of Switzerland . '}, answer=[Entity(start_offset=72, end_offset=155, type='context', text='Davos , a mountain resort in Graubünden , in the eastern Alps region of Switzerland', normalized_text='davos mountain resort in graubünden in eastern alps region of switzerland')], nq_answers=[[Entity(start_offset=72, end_offset=155, type='context', text='Davos , a mountain resort in Graubünden , in the eastern Alps region of Switzerland', normalized_text='davos mountain resort in graubünden in eastern alps region of switzerland')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text='the world economic forum', normalized_text='world economic forum'), Entity(start_offset=0, end_offset=9, type='context', text='The forum', normalized_text='forum'))], explanation_type='single_sentence'),\n",
       " 5533906981191706877: QEDExample(example_id=5533906981191706877, title='List of Chief Ministers of West Bengal', question='who was the first chief minister of west bengal', passage=\"Since 1947 , there have been eight Chief Ministers of West Bengal . The first was Prafulla Chandra Ghosh of the Indian National Congress , who was succeeded by his party - mates Dr Bidhan Chandra Roy and Prafulla Chandra Sen. A decade of instability followed , marred by fractious coalition governments and frequent impositions of President 's rule . The instability ended with 1977 election victory of the Communist Party of India ( Marxist ) ( CPM ) . Headed by Jyoti Basu , the CPM - led Left Front government was in office for over 23 years ( 1977 -- 2000 ) . Left rule in West Bengal continued for another 10 years under Buddhadeb Bhattacharya , before its defeat in the 2011 election by the Trinamool Congress . Appointed on 20 May 2011 , Trinamool leader Mamata Banerjee is the current incumbent , the state 's first woman chief minister .\", sentence_starts=[0, 68, 351, 454, 564, 718], selected_sent={'start': 68, 'end': 351, 'string': \"The first was Prafulla Chandra Ghosh of the Indian National Congress , who was succeeded by his party - mates Dr Bidhan Chandra Roy and Prafulla Chandra Sen. A decade of instability followed , marred by fractious coalition governments and frequent impositions of President 's rule . \"}, answer=[Entity(start_offset=82, end_offset=104, type='context', text='Prafulla Chandra Ghosh', normalized_text='prafulla chandra ghosh')], nq_answers=[[Entity(start_offset=82, end_offset=136, type='context', text='Prafulla Chandra Ghosh of the Indian National Congress', normalized_text='prafulla chandra ghosh of indian national congress')], [Entity(start_offset=82, end_offset=104, type='context', text='Prafulla Chandra Ghosh', normalized_text='prafulla chandra ghosh')]], aligned_nps=[(Entity(start_offset=8, end_offset=47, type='question', text='the first chief minister of west bengal', normalized_text='first chief minister of west bengal'), Entity(start_offset=68, end_offset=77, type='context', text='The first', normalized_text='first'))], explanation_type='single_sentence'),\n",
       " 7901746249864619718: QEDExample(example_id=7901746249864619718, title=\"Grey's Anatomy (season 14)\", question=\"when does the 14th season of grey's anatomy come out\", passage=\"The fourteenth season of the American television medical drama Grey 's Anatomy was ordered on February 10 , 2017 , by American Broadcasting Company ( ABC ) , and premiered on September 28 , 2017 with a special two - hour premiere . The season will consist of 24 episodes , with the season 's seventh episode marking the 300th episode for the series overall . The season is produced by ABC Studios , in association with ShondaLand Production Company and The Mark Gordon Company ; the showrunner being Shonda Rhimes .\", sentence_starts=[0, 232, 359], selected_sent={'start': 0, 'end': 232, 'string': \"The fourteenth season of the American television medical drama Grey 's Anatomy was ordered on February 10 , 2017 , by American Broadcasting Company ( ABC ) , and premiered on September 28 , 2017 with a special two - hour premiere . \"}, answer=[Entity(start_offset=175, end_offset=194, type='context', text='September 28 , 2017', normalized_text='september 28 2017')], nq_answers=[[Entity(start_offset=175, end_offset=194, type='context', text='September 28 , 2017', normalized_text='september 28 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=43, type='question', text=\"the 14th season of grey's anatomy\", normalized_text='14th season of greys anatomy'), Entity(start_offset=0, end_offset=78, type='context', text=\"The fourteenth season of the American television medical drama Grey 's Anatomy\", normalized_text='fourteenth season of american television medical drama grey s anatomy'))], explanation_type='single_sentence'),\n",
       " 8044909700499569711: QEDExample(example_id=8044909700499569711, title='National debt of the United States', question='how much is the united states in debt to china', passage='On November 7 , 2016 , debt held by the public was $14.3 trillion or about 76 % of the previous 12 months of GDP . Intragovernmental holdings stood at $5.4 trillion , giving a combined total gross national debt of $19.8 trillion or about 106 % of the previous 12 months of GDP ; $6.2 trillion or approximately 45 % of the debt held by the public was owned by foreign investors , the largest of which were Japan and China at about $1.09 trillion for Japan and $1.06 trillion for China as of December 2016 .', sentence_starts=[0, 115], selected_sent={'start': 115, 'end': 505, 'string': 'Intragovernmental holdings stood at $5.4 trillion , giving a combined total gross national debt of $19.8 trillion or about 106 % of the previous 12 months of GDP ; $6.2 trillion or approximately 45 % of the debt held by the public was owned by foreign investors , the largest of which were Japan and China at about $1.09 trillion for Japan and $1.06 trillion for China as of December 2016 .'}, answer=[Entity(start_offset=459, end_offset=473, type='context', text='$1.06 trillion', normalized_text='106 trillion')], nq_answers=[[Entity(start_offset=459, end_offset=473, type='context', text='$1.06 trillion', normalized_text='106 trillion')]], aligned_nps=[(Entity(start_offset=41, end_offset=46, type='question', text='china', normalized_text='china'), Entity(start_offset=478, end_offset=483, type='context', text='China', normalized_text='china')), (Entity(start_offset=12, end_offset=29, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=115, end_offset=141, type='context', text='Intragovernmental holdings', normalized_text='intragovernmental holdings'))], explanation_type='single_sentence'),\n",
       " -3123234845590594961: QEDExample(example_id=-3123234845590594961, title='Grease (film)', question='where did the race in grease take place', passage=\"When Sandy finally tells everyone it was Danny Zuko , Rizzo arranges a surprise reunion for the two at a pep rally , where Sandy is cheering along with high - achiever and resident swot , Patty Simcox ( Susan Buckner ) . At the rally , Sandy catches the eye of a muscly member of the football team ( Lorenzo Lamas ) . When Sandy and Danny are reunited , they are initially elated , but Danny soon slips back into his greaser attitude , which offends Sandy . At the same rally , Kenickie reveals his new car , a dilapidated used jalopy , and announces he has entered it into a `` pinks '' street race at Thunder Road .\", sentence_starts=[0, 221, 318, 458], selected_sent={'start': 458, 'end': 617, 'string': \"At the same rally , Kenickie reveals his new car , a dilapidated used jalopy , and announces he has entered it into a `` pinks '' street race at Thunder Road .\"}, answer=[Entity(start_offset=603, end_offset=615, type='context', text='Thunder Road', normalized_text='thunder road')], nq_answers=[[Entity(start_offset=603, end_offset=615, type='context', text='Thunder Road', normalized_text='thunder road')]], aligned_nps=[(Entity(start_offset=10, end_offset=28, type='question', text='the race in grease', normalized_text='race in grease'), Entity(start_offset=574, end_offset=615, type='context', text=\"a `` pinks '' street race at Thunder Road\", normalized_text='pinks street race at thunder road'))], explanation_type='single_sentence'),\n",
       " 4326992806019599297: QEDExample(example_id=4326992806019599297, title='IEEE 802.11', question='what is the maximum data rate for the 802.11a standard select one', passage='The 802.11 a standard uses the same data link layer protocol and frame format as the original standard , but an OFDM based air interface ( physical layer ) . It operates in the 5 GHz band with a maximum net data rate of 54 Mbit / s , plus error correction code , which yields realistic net achievable throughput in the mid-20 Mbit / s .', sentence_starts=[0, 158], selected_sent={'start': 158, 'end': 336, 'string': 'It operates in the 5 GHz band with a maximum net data rate of 54 Mbit / s , plus error correction code , which yields realistic net achievable throughput in the mid-20 Mbit / s .'}, answer=[Entity(start_offset=220, end_offset=231, type='context', text='54 Mbit / s', normalized_text='54 mbit s')], nq_answers=[[Entity(start_offset=220, end_offset=231, type='context', text='54 Mbit / s', normalized_text='54 mbit s')]], aligned_nps=[(Entity(start_offset=8, end_offset=65, type='question', text='the maximum data rate for the 802.11a standard select one', normalized_text='maximum data rate for 80211a standard select one'), Entity(start_offset=193, end_offset=231, type='context', text='a maximum net data rate of 54 Mbit / s', normalized_text='maximum net data rate of 54 mbit s'))], explanation_type='single_sentence'),\n",
       " 6144099837933283715: QEDExample(example_id=6144099837933283715, title='Substitute good', question='a good that can be used in place of another good', passage='A substitute good is one good that can be used instead of another . In consumer theory , substitute goods or substitutes are products that a consumer perceives as similar or comparable , so that having more of one product makes them desire less of the other product . Formally , X and Y are substitutes if , when the price of X rises , the demand for Y rises .', sentence_starts=[0, 68, 268], selected_sent={'start': 0, 'end': 68, 'string': 'A substitute good is one good that can be used instead of another . '}, answer=[Entity(start_offset=0, end_offset=17, type='context', text='A substitute good', normalized_text='substitute good')], nq_answers=[[Entity(start_offset=2, end_offset=17, type='context', text='substitute good', normalized_text='substitute good')], [Entity(start_offset=0, end_offset=17, type='context', text='A substitute good', normalized_text='substitute good')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -4621948696356225060: QEDExample(example_id=-4621948696356225060, title=\"Lord's Prayer\", question=\"where in the bible can i find the lord's prayer\", passage=\"Two versions of this prayer are recorded : the long form in the Gospel of Matthew in the middle of the Sermon on the Mount , and the short form in the Gospel of Luke when `` one of his disciples said to him , ' Lord , teach us to pray , as John taught his disciples . ' ''\", sentence_starts=[0], selected_sent={'start': 0, 'end': 272, 'string': \"Two versions of this prayer are recorded : the long form in the Gospel of Matthew in the middle of the Sermon on the Mount , and the short form in the Gospel of Luke when `` one of his disciples said to him , ' Lord , teach us to pray , as John taught his disciples . ' ''\"}, answer=[Entity(start_offset=43, end_offset=265, type='context', text=\"the long form in the Gospel of Matthew in the middle of the Sermon on the Mount , and the short form in the Gospel of Luke when `` one of his disciples said to him , ' Lord , teach us to pray , as John taught his disciples\", normalized_text='long form in gospel of matthew in middle of sermon on mount and short form in gospel of luke when one of his disciples said to him lord teach us to pray as john taught his disciples')], nq_answers=[[Entity(start_offset=64, end_offset=122, type='context', text='Gospel of Matthew in the middle of the Sermon on the Mount', normalized_text='gospel of matthew in middle of sermon on mount'), Entity(start_offset=151, end_offset=265, type='context', text=\"Gospel of Luke when `` one of his disciples said to him , ' Lord , teach us to pray , as John taught his disciples\", normalized_text='gospel of luke when one of his disciples said to him lord teach us to pray as john taught his disciples')], [Entity(start_offset=60, end_offset=81, type='context', text='the Gospel of Matthew', normalized_text='gospel of matthew'), Entity(start_offset=147, end_offset=165, type='context', text='the Gospel of Luke', normalized_text='gospel of luke')]], aligned_nps=[(Entity(start_offset=30, end_offset=47, type='question', text=\"the lord's prayer\", normalized_text='lords prayer'), Entity(start_offset=16, end_offset=27, type='context', text='this prayer', normalized_text='this prayer'))], explanation_type='single_sentence'),\n",
       " -8955197065025093046: QEDExample(example_id=-8955197065025093046, title='Wipro', question='who become the ceo of it wipro company in 2016', passage=\"At the end of December 31 , 2015 , its employee strength was 170,664 . Abid Ali Neemuchwala was appointed as Wipro 's CEO after T.K. stepped down in early 2016 .\", sentence_starts=[0, 71, 133], selected_sent={'start': 71, 'end': 161, 'string': \"Abid Ali Neemuchwala was appointed as Wipro 's CEO after T.K. stepped down in early 2016 .\"}, answer=[Entity(start_offset=71, end_offset=91, type='context', text='Abid Ali Neemuchwala', normalized_text='abid ali neemuchwala')], nq_answers=[[Entity(start_offset=71, end_offset=91, type='context', text='Abid Ali Neemuchwala', normalized_text='abid ali neemuchwala')]], aligned_nps=[(Entity(start_offset=11, end_offset=38, type='question', text='the ceo of it wipro company', normalized_text='ceo of it wipro company'), Entity(start_offset=109, end_offset=121, type='context', text=\"Wipro 's CEO\", normalized_text='wipro s ceo')), (Entity(start_offset=42, end_offset=46, type='question', text='2016', normalized_text='2016'), Entity(start_offset=155, end_offset=159, type='context', text='2016', normalized_text='2016'))], explanation_type='single_sentence'),\n",
       " 9178789216794050377: QEDExample(example_id=9178789216794050377, title='Dog and pony show', question='where does the term dog and pony show come from', passage=\"The term was originally used in the United States in the late - 19th and early - 20th centuries to refer to small traveling circuses that toured through small towns and rural areas . The name derives from the common use of performing dogs and ponies as the main attractions of the events . Performances were generally held in open - air arenas , such as race tracks or public spaces in localities that were too small or remote to attract larger , more elaborate performers or performances . The most notorious was `` Prof. Gentry 's Famous Dog & Pony Show , '' started when teenager Henry Gentry and his brothers started touring in 1886 with their act , originally entitled `` Gentry 's Equine and Canine Paradox . '' It started small , but evolved into a full circus show . Other early dog and pony shows included Morris ' Equine and Canine Paradoxes ( 1883 ) and Hurlburt 's Dog and Pony Show ( late 1880s ) .\", sentence_starts=[0, 183, 290, 491, 718, 775], selected_sent={'start': 0, 'end': 183, 'string': 'The term was originally used in the United States in the late - 19th and early - 20th centuries to refer to small traveling circuses that toured through small towns and rural areas . '}, answer=[Entity(start_offset=32, end_offset=180, type='context', text='the United States in the late - 19th and early - 20th centuries to refer to small traveling circuses that toured through small towns and rural areas', normalized_text='united states in late 19th and early 20th centuries to refer to small traveling circuses that toured through small towns and rural areas')], nq_answers=[[Entity(start_offset=29, end_offset=95, type='context', text='in the United States in the late - 19th and early - 20th centuries', normalized_text='in united states in late 19th and early 20th centuries')]], aligned_nps=[(Entity(start_offset=11, end_offset=37, type='question', text='the term dog and pony show', normalized_text='term dog and pony show'), Entity(start_offset=0, end_offset=8, type='context', text='The term', normalized_text='term'))], explanation_type='single_sentence'),\n",
       " 5871681964137793716: QEDExample(example_id=5871681964137793716, title='Sasuke Uchiha', question='how old was sasuke when his clan died', passage=\"Sasuke is introduced in the third chapter of Naruto 's manga as a young ninja assigned to become a member of Team 7 alongside Naruto Uzumaki and Sakura Haruno . The trio are trained under the guidance of Kakashi Hatake . Although Sasuke is antisocial , he starts caring about Naruto and Sakura . During a mission , Sasuke awakens his Sharingan -- his clan 's inherited ability to see through illusions -- which allows him to learn imperceptible movements at a superhuman rate . It is revealed later that Sasuke is the sole survivor of the once - powerful Uchiha clan of Konohagakure . He , at the age of seven , survived the massacre of his clan perpetrated by his brother , Itachi , who spared Sasuke 's life because he did not consider him worth killing . Sasuke seeks strong fighting opponents to reassure himself his power is growing .\", sentence_starts=[0, 161, 221, 296, 478, 585, 758], selected_sent={'start': 585, 'end': 758, 'string': \"He , at the age of seven , survived the massacre of his clan perpetrated by his brother , Itachi , who spared Sasuke 's life because he did not consider him worth killing . \"}, answer=[Entity(start_offset=604, end_offset=609, type='context', text='seven', normalized_text='seven')], nq_answers=[[Entity(start_offset=604, end_offset=609, type='context', text='seven', normalized_text='seven')]], aligned_nps=[(Entity(start_offset=12, end_offset=18, type='question', text='sasuke', normalized_text='sasuke'), Entity(start_offset=585, end_offset=587, type='context', text='He', normalized_text='he')), (Entity(start_offset=24, end_offset=32, type='question', text='his clan', normalized_text='his clan'), Entity(start_offset=637, end_offset=645, type='context', text='his clan', normalized_text='his clan'))], explanation_type='single_sentence'),\n",
       " -2630525064809360052: QEDExample(example_id=-2630525064809360052, title='New Birth Missionary Baptist Church', question='who is the pastor of new birth missionary baptist church now', passage=\"On January 15 , 2017 , Bishop Eddie Long died from an aggressive form of cancer according to a statement released by the church . The church then announced Stephen A. Davis , pastor of New Birth Birmingham in Birmingham , Alabama would be Long 's successor at New Birth Missionary Baptist Church in Lithonia while remaining pastor of the Birmingham church .\", sentence_starts=[0, 130], selected_sent={'start': 130, 'end': 357, 'string': \"The church then announced Stephen A. Davis , pastor of New Birth Birmingham in Birmingham , Alabama would be Long 's successor at New Birth Missionary Baptist Church in Lithonia while remaining pastor of the Birmingham church .\"}, answer=[Entity(start_offset=164, end_offset=172, type='context', text='A. Davis', normalized_text='davis')], nq_answers=[[Entity(start_offset=156, end_offset=172, type='context', text='Stephen A. Davis', normalized_text='stephen davis')], [Entity(start_offset=156, end_offset=229, type='context', text='Stephen A. Davis , pastor of New Birth Birmingham in Birmingham , Alabama', normalized_text='stephen davis pastor of new birth birmingham in birmingham alabama')]], aligned_nps=[(Entity(start_offset=7, end_offset=56, type='question', text='the pastor of new birth missionary baptist church', normalized_text='pastor of new birth missionary baptist church'), Entity(start_offset=239, end_offset=307, type='context', text=\"Long 's successor at New Birth Missionary Baptist Church in Lithonia\", normalized_text='long s successor at new birth missionary baptist church in lithonia'))], explanation_type='single_sentence'),\n",
       " -1206653570097564556: QEDExample(example_id=-1206653570097564556, title='Proof of Life', question='where does the movie proof of life take place', passage=\"Alice Bowman ( Meg Ryan ) moves to the ( fictional ) South American country of Tecala because her engineer husband , Peter Bowman ( David Morse ) , has been hired to help build a new dam for oil company Quad Carbon . Though Alice is unhappy at this most recent move , she agrees to stay . While driving one morning through the city , Peter is caught in traffic and then ambushed and abducted by guerrilla rebels of the Liberation Army of Tecala ( ELT ) . Believing that Peter is working on Quad Carbon 's oil pipeline , ELT soldiers lead him through the jungle .\", sentence_starts=[0, 217, 289, 455], selected_sent={'start': 0, 'end': 217, 'string': 'Alice Bowman ( Meg Ryan ) moves to the ( fictional ) South American country of Tecala because her engineer husband , Peter Bowman ( David Morse ) , has been hired to help build a new dam for oil company Quad Carbon . '}, answer=[Entity(start_offset=35, end_offset=85, type='context', text='the ( fictional ) South American country of Tecala', normalized_text='fictional south american country of tecala')], nq_answers=[[Entity(start_offset=35, end_offset=85, type='context', text='the ( fictional ) South American country of Tecala', normalized_text='fictional south american country of tecala')]], aligned_nps=[(Entity(start_offset=11, end_offset=34, type='question', text='the movie proof of life', normalized_text='movie proof of life'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3790834797035922554: QEDExample(example_id=3790834797035922554, title='List of tie-breaking votes cast by vice presidents of the United States', question='who breaks a tie in the us senate', passage='The Vice President of the United States is the ex officio President of the Senate , as provided in Article I , Section 3 , Clause 4 , of the United States Constitution , but may only vote in order to break a tie . According to the U.S. Senate , as of February 28 , 2018 , a tie - breaking vote had been cast 264 times by 36 vice presidents .', sentence_starts=[0, 214], selected_sent={'start': 0, 'end': 214, 'string': 'The Vice President of the United States is the ex officio President of the Senate , as provided in Article I , Section 3 , Clause 4 , of the United States Constitution , but may only vote in order to break a tie . '}, answer=[Entity(start_offset=0, end_offset=39, type='context', text='The Vice President of the United States', normalized_text='vice president of united states')], nq_answers=[[Entity(start_offset=4, end_offset=39, type='context', text='Vice President of the United States', normalized_text='vice president of united states')], [Entity(start_offset=0, end_offset=39, type='context', text='The Vice President of the United States', normalized_text='vice president of united states')]], aligned_nps=[(Entity(start_offset=11, end_offset=33, type='question', text='a tie in the us senate', normalized_text='tie in us senate'), Entity(start_offset=206, end_offset=211, type='context', text='a tie', normalized_text='tie'))], explanation_type='single_sentence'),\n",
       " 6144521615402262404: QEDExample(example_id=6144521615402262404, title='U.S. Route 1', question='where does us highway 1 start and end', passage='U.S. Route 1 ( US 1 ) is a major north -- south U.S. Highway that serves the East Coast of the United States . It runs 2,369 miles ( 3,813 km ) , from Fort Kent , Maine , at the Canada -- US border , south to Key West , Florida , making it the longest north -- south road in the United States . US 1 is generally paralleled by Interstate 95 ( I - 95 ) , though the former is significantly farther west ( inland ) between Jacksonville , Florida , and Petersburg , Virginia . The highway connects most of the major cities of the East Coast -- including Miami , Jacksonville , Richmond , Washington , D.C. , Baltimore , Philadelphia , New York City and Boston , passing from the Southeastern United States to New England .', sentence_starts=[0, 111, 295, 474], selected_sent={'start': 111, 'end': 295, 'string': 'It runs 2,369 miles ( 3,813 km ) , from Fort Kent , Maine , at the Canada -- US border , south to Key West , Florida , making it the longest north -- south road in the United States . '}, answer=[Entity(start_offset=146, end_offset=227, type='context', text='from Fort Kent , Maine , at the Canada -- US border , south to Key West , Florida', normalized_text='from fort kent maine at canada us border south to key west florida')], nq_answers=[[Entity(start_offset=146, end_offset=227, type='context', text='from Fort Kent , Maine , at the Canada -- US border , south to Key West , Florida', normalized_text='from fort kent maine at canada us border south to key west florida')], [Entity(start_offset=146, end_offset=197, type='context', text='from Fort Kent , Maine , at the Canada -- US border', normalized_text='from fort kent maine at canada us border'), Entity(start_offset=206, end_offset=227, type='context', text='to Key West , Florida', normalized_text='to key west florida')], [Entity(start_offset=151, end_offset=168, type='context', text='Fort Kent , Maine', normalized_text='fort kent maine'), Entity(start_offset=209, end_offset=227, type='context', text='Key West , Florida', normalized_text='key west florida')]], aligned_nps=[(Entity(start_offset=11, end_offset=23, type='question', text='us highway 1', normalized_text='us highway 1'), Entity(start_offset=111, end_offset=113, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -8631190913794477985: QEDExample(example_id=-8631190913794477985, title='List of National Basketball Association single-game scoring leaders', question='who scored the most points in a single game in the nba', passage='This feat has been accomplished 68 times in NBA history . Twenty - five different players have scored 60 or more points in a game . Only four players have scored 60 or more points on more than one occasion : Wilt Chamberlain ( 32 times ) , Kobe Bryant ( 6 times ) , Michael Jordan ( 5 times ) , and Elgin Baylor ( 4 times ) . Chamberlain holds the single - game scoring record , having scored 100 in game in 1962 .', sentence_starts=[0, 58, 132, 326], selected_sent={'start': 326, 'end': 414, 'string': 'Chamberlain holds the single - game scoring record , having scored 100 in game in 1962 .'}, answer=[Entity(start_offset=208, end_offset=224, type='context', text='Wilt Chamberlain', normalized_text='wilt chamberlain')], nq_answers=[[Entity(start_offset=208, end_offset=224, type='context', text='Wilt Chamberlain', normalized_text='wilt chamberlain')]], aligned_nps=[(Entity(start_offset=47, end_offset=54, type='question', text='the nba', normalized_text='nba'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 8986775680996674901: QEDExample(example_id=8986775680996674901, title='Indian general election, 1951–52', question='when were the first general elections held in independent india', passage=\"The Indian general election of 1951 -- 52 elected the first Lok Sabha since India became independent in August 1947 . Until this point , the Indian Constituent Assembly had served as an interim legislature . See the ' Durations ' section below to find the time - range associated with these elections .\", sentence_starts=[0, 118, 208], selected_sent={'start': 0, 'end': 118, 'string': 'The Indian general election of 1951 -- 52 elected the first Lok Sabha since India became independent in August 1947 . '}, answer=[Entity(start_offset=31, end_offset=41, type='context', text='1951 -- 52', normalized_text='1951 52')], nq_answers=[[Entity(start_offset=31, end_offset=41, type='context', text='1951 -- 52', normalized_text='1951 52')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text='the first general elections', normalized_text='first general elections'), Entity(start_offset=0, end_offset=41, type='context', text='The Indian general election of 1951 -- 52', normalized_text='indian general election of 1951 52'))], explanation_type='single_sentence'),\n",
       " 700604097171850168: QEDExample(example_id=700604097171850168, title='Tower of London', question='what was the tower of london originally used for', passage=\"The Tower of London , officially Her Majesty 's Royal Palace and Fortress of the Tower of London , is a historic castle located on the north bank of the River Thames in central London . It lies within the London Borough of Tower Hamlets , separated from the eastern edge of the square mile of the City of London by the open space known as Tower Hill . It was founded towards the end of 1066 as part of the Norman Conquest of England . The White Tower , which gives the entire castle its name , was built by William the Conqueror in 1078 and was a resented symbol of oppression , inflicted upon London by the new ruling elite . The castle was used as a prison from 1100 ( Ranulf Flambard ) until 1952 ( Kray twins ) , although that was not its primary purpose . A grand palace early in its history , it served as a royal residence . As a whole , the Tower is a complex of several buildings set within two concentric rings of defensive walls and a moat . There were several phases of expansion , mainly under Kings Richard I , Henry III , and Edward I in the 12th and 13th centuries . The general layout established by the late 13th century remains despite later activity on the site .\", sentence_starts=[0, 186, 352, 435, 627, 761, 832, 953, 1083], selected_sent={'start': 761, 'end': 832, 'string': 'A grand palace early in its history , it served as a royal residence . '}, answer=[Entity(start_offset=812, end_offset=829, type='context', text='a royal residence', normalized_text='royal residence')], nq_answers=[[Entity(start_offset=812, end_offset=829, type='context', text='a royal residence', normalized_text='royal residence')], [Entity(start_offset=809, end_offset=829, type='context', text='as a royal residence', normalized_text='as royal residence')]], aligned_nps=[(Entity(start_offset=9, end_offset=28, type='question', text='the tower of london', normalized_text='tower of london'), Entity(start_offset=799, end_offset=801, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6745303307988470742: QEDExample(example_id=6745303307988470742, title='Zippo', question='what type of fuel goes in a zippo', passage='In 2002 , Zippo expanded its product line to include a variety of utility - style multi-purpose lighters , known as Zippo MPLs . This was followed in 2005 with the Outdoor Utility Lighter , known as the OUL . These lighters are fueled with butane . In August 2007 , Zippo released a new butane lighter called the Zippo BLU .', sentence_starts=[0, 129, 209, 249], selected_sent={'start': 209, 'end': 249, 'string': 'These lighters are fueled with butane . '}, answer=[Entity(start_offset=240, end_offset=246, type='context', text='butane', normalized_text='butane')], nq_answers=[[Entity(start_offset=240, end_offset=246, type='context', text='butane', normalized_text='butane')]], aligned_nps=[(Entity(start_offset=26, end_offset=33, type='question', text='a zippo', normalized_text='zippo'), Entity(start_offset=209, end_offset=223, type='context', text='These lighters', normalized_text='these lighters'))], explanation_type='single_sentence'),\n",
       " -2060506905455252030: QEDExample(example_id=-2060506905455252030, title='G. Sankara Kurup', question='first jnanpith award was an autor of which language', passage=\"G. Sankara Kurup , ( 3 June 1901 , Nayathode , Kingdom of Cochin ( now in Ernakulam district , Kerala , India ) -- 2 February 1978 , Vappalassery , Angamaly , Ernakulam district , Kerala ) , better known as Mahakavi G ( The Great Poet G ) , was the first winner of the Jnanpith Award , India 's highest literary award . He won the prize in 1965 for his collection of poems in Malayalam Odakkuzhal ( The Bamboo Flute , 1950 ) . With part of the prize money he established the literary award Odakkuzhal in 1968 . He was also the recipient of the Soviet Land Nehru Award , in 1967 , and the Padma Bhushan in 1968 . His poetry collection Viswadarshanam won the Kerala Sahitya Akademi Award in 1961 and Kendra Sahitya Akademi Award in 1963 .\", sentence_starts=[0, 320, 427, 511, 612], selected_sent={'start': 320, 'end': 427, 'string': 'He won the prize in 1965 for his collection of poems in Malayalam Odakkuzhal ( The Bamboo Flute , 1950 ) . '}, answer=[Entity(start_offset=376, end_offset=385, type='context', text='Malayalam', normalized_text='malayalam')], nq_answers=[[Entity(start_offset=376, end_offset=385, type='context', text='Malayalam', normalized_text='malayalam')]], aligned_nps=[(Entity(start_offset=0, end_offset=20, type='question', text='first jnanpith award', normalized_text='first jnanpith award'), Entity(start_offset=327, end_offset=336, type='context', text='the prize', normalized_text='prize'))], explanation_type='single_sentence'),\n",
       " -1650946015201779846: QEDExample(example_id=-1650946015201779846, title='Cracker Barrel', question='how many cracker barrels in the united states', passage=\"Cracker Barrel Old Country Store , Inc. is an American chain of combined restaurant and gift stores with a Southern country theme . The company was founded by Dan Evins in 1969 ; its first store was in Lebanon , Tennessee , which remains the company headquarters . The chain 's stores were at first positioned near Interstate highway exits in the Southeastern and Midwestern United States , but has expanded across the country during the 1990s and 2000s . As of September 18 , 2012 , the chain operates 639 stores in 43 states .\", sentence_starts=[0, 132, 265, 456], selected_sent={'start': 456, 'end': 528, 'string': 'As of September 18 , 2012 , the chain operates 639 stores in 43 states .'}, answer=[Entity(start_offset=503, end_offset=506, type='context', text='639', normalized_text='639')], nq_answers=[[Entity(start_offset=503, end_offset=506, type='context', text='639', normalized_text='639')]], aligned_nps=[(Entity(start_offset=28, end_offset=45, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=517, end_offset=526, type='context', text='43 states', normalized_text='43 states'))], explanation_type='single_sentence'),\n",
       " 5482012214308896475: QEDExample(example_id=5482012214308896475, title='Cadbury', question='how many countries does cadbury sell its products', passage=\"Cadbury , formerly Cadbury 's , is a British multinational confectionery company wholly owned by Mondelez International ( originally Kraft Foods ) since 2010 . It is the second - largest confectionery brand in the world after Wrigley 's . Cadbury is internationally headquartered in Uxbridge , West London , and operates in more than 50 countries worldwide . It is famous for its Dairy Milk chocolate , the Creme Egg and Roses selection box , and many other confectionery products . One of the best - known British brands , in 2013 The Daily Telegraph named Cadbury among Britain 's most successful exports .\", sentence_starts=[0, 160, 239, 359, 483], selected_sent={'start': 239, 'end': 359, 'string': 'Cadbury is internationally headquartered in Uxbridge , West London , and operates in more than 50 countries worldwide . '}, answer=[Entity(start_offset=324, end_offset=336, type='context', text='more than 50', normalized_text='more than 50')], nq_answers=[[Entity(start_offset=324, end_offset=356, type='context', text='more than 50 countries worldwide', normalized_text='more than 50 countries worldwide')], [Entity(start_offset=324, end_offset=336, type='context', text='more than 50', normalized_text='more than 50')]], aligned_nps=[(Entity(start_offset=24, end_offset=31, type='question', text='cadbury', normalized_text='cadbury'), Entity(start_offset=239, end_offset=246, type='context', text='Cadbury', normalized_text='cadbury'))], explanation_type='single_sentence'),\n",
       " -7175456993713717070: QEDExample(example_id=-7175456993713717070, title='ISTJ', question='what does istj mean in a personality test', passage='ISTJ ( By functions ; Introverted Sensing ( Si ) , Extroverted Thinking ( Te ) , Introverted Feeling ( Fi ) and Extroverted Intuition ( Ne ) ) is an abbreviation used in the publications of the Myers -- Briggs Type Indicator ( MBTI ) to refer to one of sixteen personality types . The MBTI assessment was developed from the work of prominent psychiatrist Carl G. Jung in his book Psychological Types . Jung proposed a psychological typology based on the theories of cognitive functions that he developed through his clinical observations .', sentence_starts=[0, 281, 402], selected_sent={'start': 0, 'end': 281, 'string': 'ISTJ ( By functions ; Introverted Sensing ( Si ) , Extroverted Thinking ( Te ) , Introverted Feeling ( Fi ) and Extroverted Intuition ( Ne ) ) is an abbreviation used in the publications of the Myers -- Briggs Type Indicator ( MBTI ) to refer to one of sixteen personality types . '}, answer=[Entity(start_offset=22, end_offset=140, type='context', text='Introverted Sensing ( Si ) , Extroverted Thinking ( Te ) , Introverted Feeling ( Fi ) and Extroverted Intuition ( Ne )', normalized_text='introverted sensing si extroverted thinking te introverted feeling fi and extroverted intuition ne')], nq_answers=[[Entity(start_offset=22, end_offset=48, type='context', text='Introverted Sensing ( Si )', normalized_text='introverted sensing si'), Entity(start_offset=51, end_offset=78, type='context', text='Extroverted Thinking ( Te )', normalized_text='extroverted thinking te'), Entity(start_offset=81, end_offset=107, type='context', text='Introverted Feeling ( Fi )', normalized_text='introverted feeling fi'), Entity(start_offset=112, end_offset=140, type='context', text='Extroverted Intuition ( Ne )', normalized_text='extroverted intuition ne')]], aligned_nps=[(Entity(start_offset=10, end_offset=14, type='question', text='istj', normalized_text='istj'), Entity(start_offset=0, end_offset=4, type='context', text='ISTJ', normalized_text='istj'))], explanation_type='single_sentence'),\n",
       " 6744148144009704081: QEDExample(example_id=6744148144009704081, title=\"Nathan's Hot Dog Eating Contest\", question=\"where is nathan's hotdog eating contest held\", passage=\"The Nathan 's Hot Dog Eating Contest is an annual American hot dog competitive eating competition . It is held each year on Independence Day at Nathan 's Famous Corporation 's original , and best - known restaurant at the corner of Surf and Stillwell Avenues in Coney Island , a neighborhood of Brooklyn , New York City .\", sentence_starts=[0, 100], selected_sent={'start': 100, 'end': 321, 'string': \"It is held each year on Independence Day at Nathan 's Famous Corporation 's original , and best - known restaurant at the corner of Surf and Stillwell Avenues in Coney Island , a neighborhood of Brooklyn , New York City .\"}, answer=[Entity(start_offset=144, end_offset=319, type='context', text=\"Nathan 's Famous Corporation 's original , and best - known restaurant at the corner of Surf and Stillwell Avenues in Coney Island , a neighborhood of Brooklyn , New York City\", normalized_text='nathan s famous corporation s original and best known restaurant at corner of surf and stillwell avenues in coney island neighborhood of brooklyn new york city')], nq_answers=[[Entity(start_offset=141, end_offset=319, type='context', text=\"at Nathan 's Famous Corporation 's original , and best - known restaurant at the corner of Surf and Stillwell Avenues in Coney Island , a neighborhood of Brooklyn , New York City\", normalized_text='at nathan s famous corporation s original and best known restaurant at corner of surf and stillwell avenues in coney island neighborhood of brooklyn new york city')]], aligned_nps=[(Entity(start_offset=9, end_offset=39, type='question', text=\"nathan's hotdog eating contest\", normalized_text='nathans hotdog eating contest'), Entity(start_offset=100, end_offset=102, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 1803248910342766083: QEDExample(example_id=1803248910342766083, title='My Country My Life', question='who wrote the book my country my life', passage=\"My Country My Life is an autobiographical book by L.K. Advani , an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004 , and was the Leader of the Opposition in the 15th Lok Sabha . The book was released on 19 March 2008 by Abdul Kalam , the eleventh President of India . The book has 1,040 pages and narrates autobiographical accounts and events in the life of Advani . It became the best seller book in the non-fiction category and Advani joined Archer as a bestseller author . The book website claims the book sold an excess of 1,000,000 copies . The book alongside mentions the event in Indian politics and India 's history from 1900 till date .\", sentence_starts=[0, 55, 215, 305, 404, 513, 583], selected_sent={'start': 0, 'end': 215, 'string': 'My Country My Life is an autobiographical book by L.K. Advani , an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004 , and was the Leader of the Opposition in the 15th Lok Sabha . '}, answer=[Entity(start_offset=50, end_offset=61, type='context', text='L.K. Advani', normalized_text='lk advani')], nq_answers=[[Entity(start_offset=50, end_offset=212, type='context', text='L.K. Advani , an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004 , and was the Leader of the Opposition in the 15th Lok Sabha', normalized_text='lk advani indian politician who served as deputy prime minister of india from 2002 to 2004 and was leader of opposition in 15th lok sabha')], [Entity(start_offset=50, end_offset=61, type='context', text='L.K. Advani', normalized_text='lk advani')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text='the book my country my life', normalized_text='book my country my life'), Entity(start_offset=0, end_offset=18, type='context', text='My Country My Life', normalized_text='my country my life'))], explanation_type='single_sentence'),\n",
       " -7769846680650238179: QEDExample(example_id=-7769846680650238179, title='Parole', question='what does it mean to be on parole', passage=\"Parole is a temporary release of a prisoner who agrees to certain conditions before the completion of the maximum sentence period , originating from the French parole ( `` voice , spoken words '' ) . The term became associated during the Middle Ages with the release of prisoners who gave their word .\", sentence_starts=[0, 200], selected_sent={'start': 0, 'end': 200, 'string': \"Parole is a temporary release of a prisoner who agrees to certain conditions before the completion of the maximum sentence period , originating from the French parole ( `` voice , spoken words '' ) . \"}, answer=[Entity(start_offset=10, end_offset=129, type='context', text='a temporary release of a prisoner who agrees to certain conditions before the completion of the maximum sentence period', normalized_text='temporary release of prisoner who agrees to certain conditions before completion of maximum sentence period')], nq_answers=[[Entity(start_offset=10, end_offset=129, type='context', text='a temporary release of a prisoner who agrees to certain conditions before the completion of the maximum sentence period', normalized_text='temporary release of prisoner who agrees to certain conditions before completion of maximum sentence period')], [Entity(start_offset=12, end_offset=129, type='context', text='temporary release of a prisoner who agrees to certain conditions before the completion of the maximum sentence period', normalized_text='temporary release of prisoner who agrees to certain conditions before completion of maximum sentence period')]], aligned_nps=[(Entity(start_offset=27, end_offset=33, type='question', text='parole', normalized_text='parole'), Entity(start_offset=0, end_offset=6, type='context', text='Parole', normalized_text='parole'))], explanation_type='single_sentence'),\n",
       " -5270061954035899369: QEDExample(example_id=-5270061954035899369, title='Stations of the Cross', question='the origins of the stations of the cross', passage='The Stations of the Cross or the Way of the Cross , also known as the Way of Sorrows or the Via Crucis , refers to a series of images depicting Jesus Christ on the day of his crucifixion and accompanying prayers . The stations grew out of imitations of Via Dolorosa in Jerusalem which is believed to be the actual path Jesus walked to Mount Calvary . The object of the stations is to help the Christians faithful to make a spiritual pilgrimage through contemplation of the Passion of Christ . It has become one of the most popular devotions and the stations can be found in many Western Christian churches , including Anglican , Lutheran , Methodist , and Roman Catholic ones .', sentence_starts=[0, 214, 351, 493], selected_sent={'start': 214, 'end': 351, 'string': 'The stations grew out of imitations of Via Dolorosa in Jerusalem which is believed to be the actual path Jesus walked to Mount Calvary . '}, answer=[Entity(start_offset=239, end_offset=348, type='context', text='imitations of Via Dolorosa in Jerusalem which is believed to be the actual path Jesus walked to Mount Calvary', normalized_text='imitations of via dolorosa in jerusalem which is believed to be actual path jesus walked to mount calvary')], nq_answers=[[Entity(start_offset=253, end_offset=348, type='context', text='Via Dolorosa in Jerusalem which is believed to be the actual path Jesus walked to Mount Calvary', normalized_text='via dolorosa in jerusalem which is believed to be actual path jesus walked to mount calvary')], [Entity(start_offset=227, end_offset=348, type='context', text='grew out of imitations of Via Dolorosa in Jerusalem which is believed to be the actual path Jesus walked to Mount Calvary', normalized_text='grew out of imitations of via dolorosa in jerusalem which is believed to be actual path jesus walked to mount calvary')]], aligned_nps=[(Entity(start_offset=15, end_offset=40, type='question', text='the stations of the cross', normalized_text='stations of cross'), Entity(start_offset=214, end_offset=231, type='context', text='The stations grew', normalized_text='stations grew'))], explanation_type='single_sentence'),\n",
       " 5557104327881436095: QEDExample(example_id=5557104327881436095, title='Google', question='who is the founder of google and when was it founded', passage=\"Google Inc. is an American multinational technology company that specializes in Internet - related services and products . These include online advertising technologies , search , cloud computing , software , and hardware . Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph. D. students at Stanford University , in California . Together , they own about 14 percent of its shares , and control 56 percent of the stockholder voting power through supervoting stock . They incorporated Google as a privately held company on September 4 , 1998 . An initial public offering ( IPO ) took place on August 19 , 2004 , and Google moved to its new headquarters in Mountain View , California , nicknamed the Googleplex . In August 2015 , Google announced plans to reorganize its various interests as a conglomerate called Alphabet Inc . Google , Alphabet 's leading subsidiary , will continue to be the umbrella company for Alphabet 's Internet interests . Upon completion of the restructure , Sundar Pichai was appointed CEO of Google ; he replaced Larry Page , who became CEO of Alphabet .\", sentence_starts=[0, 123, 224, 354, 490, 567, 735, 851, 971], selected_sent={'start': 224, 'end': 354, 'string': 'Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph. D. students at Stanford University , in California . '}, answer=[Entity(start_offset=246, end_offset=280, type='context', text='1998 by Larry Page and Sergey Brin', normalized_text='1998 by larry page and sergey brin')], nq_answers=[[Entity(start_offset=246, end_offset=250, type='context', text='1998', normalized_text='1998'), Entity(start_offset=254, end_offset=280, type='context', text='Larry Page and Sergey Brin', normalized_text='larry page and sergey brin')], [Entity(start_offset=246, end_offset=250, type='context', text='1998', normalized_text='1998'), Entity(start_offset=254, end_offset=264, type='context', text='Larry Page', normalized_text='larry page'), Entity(start_offset=269, end_offset=280, type='context', text='Sergey Brin', normalized_text='sergey brin')], [Entity(start_offset=246, end_offset=280, type='context', text='1998 by Larry Page and Sergey Brin', normalized_text='1998 by larry page and sergey brin')]], aligned_nps=[(Entity(start_offset=22, end_offset=28, type='question', text='google', normalized_text='google'), Entity(start_offset=224, end_offset=230, type='context', text='Google', normalized_text='google'))], explanation_type='single_sentence'),\n",
       " -1333328812971005142: QEDExample(example_id=-1333328812971005142, title='Dominican War of Independence', question='who did the dominican republic gain its independence from', passage='The Dominican Independence War gave the Dominican Republic autonomy from Haiti on February 27 , 1844 . Before the war , the island of Hispaniola had been united under the Haitian government for a period of 22 years when the newly independent nation , then known as the Republic of Spanish Haiti , was invaded by Haiti in 1822 . Previously known as the Captaincy General of Santo Domingo , the criollo class within the country overthrew the Spanish crown in 1821 before unifying with Haiti a year later .', sentence_starts=[0, 103, 328], selected_sent={'start': 0, 'end': 103, 'string': 'The Dominican Independence War gave the Dominican Republic autonomy from Haiti on February 27 , 1844 . '}, answer=[Entity(start_offset=73, end_offset=78, type='context', text='Haiti', normalized_text='haiti')], nq_answers=[[Entity(start_offset=73, end_offset=78, type='context', text='Haiti', normalized_text='haiti')]], aligned_nps=[(Entity(start_offset=8, end_offset=30, type='question', text='the dominican republic', normalized_text='dominican republic'), Entity(start_offset=36, end_offset=58, type='context', text='the Dominican Republic', normalized_text='dominican republic'))], explanation_type='single_sentence'),\n",
       " 1122605495295045742: QEDExample(example_id=1122605495295045742, title='Prehistoric technology', question='how did early humans make use of stones during the prehistoric period', passage='Prehistoric technology is technology that predates recorded history . History is the study of the past using written records . Anything prior to the first written accounts of history is prehistoric , including earlier technologies . About 2.5 million years before writing was developed , technology began with the earliest hominids who used stone tools , which they may have used to start fires , hunt , and bury their dead .', sentence_starts=[0, 70, 127, 233], selected_sent={'start': 233, 'end': 425, 'string': 'About 2.5 million years before writing was developed , technology began with the earliest hominids who used stone tools , which they may have used to start fires , hunt , and bury their dead .'}, answer=[Entity(start_offset=383, end_offset=423, type='context', text='start fires , hunt , and bury their dead', normalized_text='start fires hunt and bury their dead')], nq_answers=[[Entity(start_offset=383, end_offset=394, type='context', text='start fires', normalized_text='start fires'), Entity(start_offset=397, end_offset=401, type='context', text='hunt', normalized_text='hunt'), Entity(start_offset=408, end_offset=423, type='context', text='bury their dead', normalized_text='bury their dead')], [Entity(start_offset=380, end_offset=423, type='context', text='to start fires , hunt , and bury their dead', normalized_text='to start fires hunt and bury their dead')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 7402184777947527945: QEDExample(example_id=7402184777947527945, title='Jeanie with the Light Brown Hair', question='who wrote the text for jeanie with the light brown hair', passage=\"`` Jeanie with the Light Brown Hair '' is a parlor song by Stephen Foster ( 1826 -- 1864 ) . It was published by Firth , Pond & Co. of New York in 1854 . Foster wrote the song with his estranged wife Jane McDowell in mind . The lyrics allude to a permanent separation .\", sentence_starts=[0, 93, 154, 224], selected_sent={'start': 0, 'end': 93, 'string': \"`` Jeanie with the Light Brown Hair '' is a parlor song by Stephen Foster ( 1826 -- 1864 ) . \"}, answer=[Entity(start_offset=59, end_offset=73, type='context', text='Stephen Foster', normalized_text='stephen foster')], nq_answers=[[Entity(start_offset=59, end_offset=73, type='context', text='Stephen Foster', normalized_text='stephen foster')]], aligned_nps=[(Entity(start_offset=23, end_offset=55, type='question', text='jeanie with the light brown hair', normalized_text='jeanie with light brown hair'), Entity(start_offset=3, end_offset=35, type='context', text='Jeanie with the Light Brown Hair', normalized_text='jeanie with light brown hair'))], explanation_type='single_sentence'),\n",
       " 250542332339248886: QEDExample(example_id=250542332339248886, title='The Bob & Tom Show', question='where does the bob and tom show broadcast from', passage='The Bob & Tom Show is a syndicated US radio program established by Bob Kevoian and Tom Griswold at radio station WFBQ in Indianapolis , Indiana , March 7 , 1983 , and syndicated nationally since January 6 , 1995 . Originally syndicated by Premiere Networks , the show moved to Cumulus Media Networks ( now Westwood One ) at the beginning of 2014 .', sentence_starts=[0, 214], selected_sent={'start': 0, 'end': 214, 'string': 'The Bob & Tom Show is a syndicated US radio program established by Bob Kevoian and Tom Griswold at radio station WFBQ in Indianapolis , Indiana , March 7 , 1983 , and syndicated nationally since January 6 , 1995 . '}, answer=[Entity(start_offset=99, end_offset=143, type='context', text='radio station WFBQ in Indianapolis , Indiana', normalized_text='radio station wfbq in indianapolis indiana')], nq_answers=[[Entity(start_offset=113, end_offset=143, type='context', text='WFBQ in Indianapolis , Indiana', normalized_text='wfbq in indianapolis indiana')], [Entity(start_offset=99, end_offset=143, type='context', text='radio station WFBQ in Indianapolis , Indiana', normalized_text='radio station wfbq in indianapolis indiana')], [Entity(start_offset=121, end_offset=143, type='context', text='Indianapolis , Indiana', normalized_text='indianapolis indiana')]], aligned_nps=[(Entity(start_offset=11, end_offset=31, type='question', text='the bob and tom show', normalized_text='bob and tom show'), Entity(start_offset=0, end_offset=18, type='context', text='The Bob & Tom Show', normalized_text='bob tom show'))], explanation_type='single_sentence'),\n",
       " 2997223939033016160: QEDExample(example_id=2997223939033016160, title='Frontal lobe', question='what part of brain is responsible for complex thinking', passage='The function of the frontal lobe involves the ability to project future consequences resulting from current actions , the choice between good and bad actions ( or better and best ) ( also known as conscience ) , the override and suppression of socially unacceptable responses , and the determination of similarities and differences between things or events .', sentence_starts=[0], selected_sent={'start': 0, 'end': 358, 'string': 'The function of the frontal lobe involves the ability to project future consequences resulting from current actions , the choice between good and bad actions ( or better and best ) ( also known as conscience ) , the override and suppression of socially unacceptable responses , and the determination of similarities and differences between things or events .'}, answer=[Entity(start_offset=20, end_offset=32, type='context', text='frontal lobe', normalized_text='frontal lobe')], nq_answers=[[Entity(start_offset=16, end_offset=32, type='context', text='the frontal lobe', normalized_text='frontal lobe')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2680196226239522881: QEDExample(example_id=2680196226239522881, title='2016 UEFA Champions League Final', question='who won the champions league final in 2016', passage=\"The 2016 UEFA Champions League Final was the final match of the 2015 -- 16 UEFA Champions League , the 61st season of Europe 's premier club football tournament organised by UEFA , and the 24th season since it was renamed from the European Champion Clubs ' Cup to the UEFA Champions League . It was played at the San Siro stadium in Milan , Italy , on 28 May 2016 , between Spanish teams Real Madrid and Atlético Madrid , in a repeat of the 2014 final . It was the second time in the tournament 's history that both finalists were from the same city . Real Madrid won 5 -- 3 on a penalty shoot - out after a 1 -- 1 draw at the end of extra time , securing a record - extending 11th title in the competition .\", sentence_starts=[0, 292, 454, 552], selected_sent={'start': 552, 'end': 708, 'string': 'Real Madrid won 5 -- 3 on a penalty shoot - out after a 1 -- 1 draw at the end of extra time , securing a record - extending 11th title in the competition .'}, answer=[Entity(start_offset=552, end_offset=563, type='context', text='Real Madrid', normalized_text='real madrid')], nq_answers=[[Entity(start_offset=552, end_offset=563, type='context', text='Real Madrid', normalized_text='real madrid')], [Entity(start_offset=388, end_offset=399, type='context', text='Real Madrid', normalized_text='real madrid')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text='the champions league final', normalized_text='champions league final'), Entity(start_offset=564, end_offset=567, type='context', text='won', normalized_text='won')), (Entity(start_offset=38, end_offset=42, type='question', text='2016', normalized_text='2016'), Entity(start_offset=564, end_offset=567, type='context', text='won', normalized_text='won'))], explanation_type='single_sentence'),\n",
       " -1556250178028205681: QEDExample(example_id=-1556250178028205681, title='The Strangers: Prey at Night', question='where was the movie strangers prey at night filmed', passage='Filming began in June 2017 in Covington , Kentucky , and concluded on July 10 , 2017 .', sentence_starts=[0], selected_sent={'start': 0, 'end': 86, 'string': 'Filming began in June 2017 in Covington , Kentucky , and concluded on July 10 , 2017 .'}, answer=[Entity(start_offset=30, end_offset=50, type='context', text='Covington , Kentucky', normalized_text='covington kentucky')], nq_answers=[[Entity(start_offset=30, end_offset=50, type='context', text='Covington , Kentucky', normalized_text='covington kentucky')]], aligned_nps=[(Entity(start_offset=10, end_offset=43, type='question', text='the movie strangers prey at night', normalized_text='movie strangers prey at night'), Entity(start_offset=0, end_offset=7, type='context', text='Filming', normalized_text='filming'))], explanation_type='single_sentence'),\n",
       " 6023159022192897262: QEDExample(example_id=6023159022192897262, title='Limit of a function', question='when does a limit of a function not exist', passage='Formal definitions , first devised in the early 19th century , are given below . Informally , a function f assigns an output f ( x ) to every input x . We say the function has a limit L at an input p : this means f ( x ) gets closer and closer to L as x moves closer and closer to p . More specifically , when f is applied to any input sufficiently close to p , the output value is forced arbitrarily close to L. On the other hand , if some inputs very close to p are taken to outputs that stay a fixed distance apart , we say the limit does not exist .', sentence_starts=[0, 81, 152, 285], selected_sent={'start': 285, 'end': 553, 'string': 'More specifically , when f is applied to any input sufficiently close to p , the output value is forced arbitrarily close to L. On the other hand , if some inputs very close to p are taken to outputs that stay a fixed distance apart , we say the limit does not exist .'}, answer=[Entity(start_offset=433, end_offset=517, type='context', text='if some inputs very close to p are taken to outputs that stay a fixed distance apart', normalized_text='if some inputs very close to p are taken to outputs that stay fixed distance apart')], nq_answers=[[Entity(start_offset=433, end_offset=517, type='context', text='if some inputs very close to p are taken to outputs that stay a fixed distance apart', normalized_text='if some inputs very close to p are taken to outputs that stay fixed distance apart')]], aligned_nps=[(Entity(start_offset=10, end_offset=31, type='question', text='a limit of a function', normalized_text='limit of function'), Entity(start_offset=527, end_offset=536, type='context', text='the limit', normalized_text='limit'))], explanation_type='single_sentence'),\n",
       " -1602885085222027775: QEDExample(example_id=-1602885085222027775, title='Flag of Uruguay', question='what does the sun represent on the uruguay flag', passage='The horizontal stripes on the flag represent the nine original departments of Uruguay , based on the U.S flag , where the stripes represent the original 13 colonies . The first flag designed in 1828 had 9 light blue stripes ; this number was reduced to 4 in 1830 due to visibility problems from distance . The Sun of May represents the May Revolution of 1810 ; according to the historian Diego Abad de Santillán , the Sun of May is a figurative sun that represents Inti , the sun god of the Inca religion . It also appears in the Flag of Argentina and the Coat of Arms of Bolivia .', sentence_starts=[0, 167, 306, 507], selected_sent={'start': 306, 'end': 507, 'string': 'The Sun of May represents the May Revolution of 1810 ; according to the historian Diego Abad de Santillán , the Sun of May is a figurative sun that represents Inti , the sun god of the Inca religion . '}, answer=[Entity(start_offset=332, end_offset=504, type='context', text='the May Revolution of 1810 ; according to the historian Diego Abad de Santillán , the Sun of May is a figurative sun that represents Inti , the sun god of the Inca religion', normalized_text='may revolution of 1810 according to historian diego abad de santillán sun of may is figurative sun that represents inti sun god of inca religion')], nq_answers=[[Entity(start_offset=321, end_offset=358, type='context', text='represents the May Revolution of 1810', normalized_text='represents may revolution of 1810'), Entity(start_offset=432, end_offset=504, type='context', text='a figurative sun that represents Inti , the sun god of the Inca religion', normalized_text='figurative sun that represents inti sun god of inca religion')], [Entity(start_offset=332, end_offset=358, type='context', text='the May Revolution of 1810', normalized_text='may revolution of 1810')], [Entity(start_offset=332, end_offset=358, type='context', text='the May Revolution of 1810', normalized_text='may revolution of 1810'), Entity(start_offset=465, end_offset=504, type='context', text='Inti , the sun god of the Inca religion', normalized_text='inti sun god of inca religion')]], aligned_nps=[(Entity(start_offset=10, end_offset=17, type='question', text='the sun', normalized_text='sun'), Entity(start_offset=306, end_offset=320, type='context', text='The Sun of May', normalized_text='sun of may'))], explanation_type='single_sentence'),\n",
       " 8282063117132135457: QEDExample(example_id=8282063117132135457, title='Brant Daugherty', question='who does brant daugherty play in pretty little liars', passage='Brant David Daugherty ( born August 20 , 1985 ) is an American actor , known for his recurring role as Noel Kahn on the teen drama television series , Pretty Little Liars . In 2013 , he had a recurring role as Brian in the long - running NBC daytime drama Days of Our Lives .', sentence_starts=[0, 173], selected_sent={'start': 0, 'end': 173, 'string': 'Brant David Daugherty ( born August 20 , 1985 ) is an American actor , known for his recurring role as Noel Kahn on the teen drama television series , Pretty Little Liars . '}, answer=[Entity(start_offset=103, end_offset=112, type='context', text='Noel Kahn', normalized_text='noel kahn')], nq_answers=[[Entity(start_offset=103, end_offset=112, type='context', text='Noel Kahn', normalized_text='noel kahn')]], aligned_nps=[(Entity(start_offset=9, end_offset=24, type='question', text='brant daugherty', normalized_text='brant daugherty'), Entity(start_offset=0, end_offset=21, type='context', text='Brant David Daugherty', normalized_text='brant david daugherty')), (Entity(start_offset=33, end_offset=52, type='question', text='pretty little liars', normalized_text='pretty little liars'), Entity(start_offset=116, end_offset=170, type='context', text='the teen drama television series , Pretty Little Liars', normalized_text='teen drama television series pretty little liars'))], explanation_type='single_sentence'),\n",
       " -8684010845103539435: QEDExample(example_id=-8684010845103539435, title='Judicial review', question='how does the power of judicial review check the legislative and executive branches', passage='Judicial review is a process under which executive and ( in some countries ) legislative actions are subject to review by the judiciary . A court with judicial review power may invalidate laws and decisions that are incompatible with a higher authority ; an executive decision may be invalidated for being unlawful or a statute may be invalidated for violating the terms of a written constitution . Judicial review is one of the checks and balances in the separation of powers : the power of the judiciary to supervise the legislative and executive branches when the latter exceed their authority . The doctrine varies between jurisdictions , so the procedure and scope of judicial review may differ between and within countries .', sentence_starts=[0, 138, 399, 599], selected_sent={'start': 138, 'end': 399, 'string': 'A court with judicial review power may invalidate laws and decisions that are incompatible with a higher authority ; an executive decision may be invalidated for being unlawful or a statute may be invalidated for violating the terms of a written constitution . '}, answer=[Entity(start_offset=177, end_offset=396, type='context', text='invalidate laws and decisions that are incompatible with a higher authority ; an executive decision may be invalidated for being unlawful or a statute may be invalidated for violating the terms of a written constitution', normalized_text='invalidate laws and decisions that are incompatible with higher authority executive decision may be invalidated for being unlawful or statute may be invalidated for violating terms of written constitution')], nq_answers=[[Entity(start_offset=506, end_offset=596, type='context', text='to supervise the legislative and executive branches when the latter exceed their authority', normalized_text='to supervise legislative and executive branches when latter exceed their authority')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the power of judicial review', normalized_text='power of judicial review'), Entity(start_offset=151, end_offset=172, type='context', text='judicial review power', normalized_text='judicial review power'))], explanation_type='single_sentence'),\n",
       " 5306741314520007646: QEDExample(example_id=5306741314520007646, title='From Under the Cork Tree', question='when did under the cork tree come out', passage=\"From Under the Cork Tree is the second studio album by American rock band Fall Out Boy . It was released on May 3 , 2005 , through Island Records as the band 's major label debut . The music was composed by lead vocalist and guitarist Patrick Stump , with all lyrics penned by bassist Pete Wentz , continuing the band 's songwriting approach they took for some songs on their prior 2003 effort Take This to Your Grave . Neal Avron handled production duties . Commenting on the record 's lyrical themes , Wentz said the lyrics were about `` the anxiety and depression that goes along with looking at your own life . '' In support of their release the group headlined tours worldwide and played at various music festivals . For their Black Clouds and Underdogs tour the album was re-released as From Under the Cork Tree ( Limited `` Black Clouds and Underdogs '' Edition ) , featuring new songs and remixes .\", sentence_starts=[0, 89, 181, 420, 459, 618, 722], selected_sent={'start': 89, 'end': 181, 'string': \"It was released on May 3 , 2005 , through Island Records as the band 's major label debut . \"}, answer=[Entity(start_offset=108, end_offset=120, type='context', text='May 3 , 2005', normalized_text='may 3 2005')], nq_answers=[[Entity(start_offset=108, end_offset=120, type='context', text='May 3 , 2005', normalized_text='may 3 2005')]], aligned_nps=[(Entity(start_offset=9, end_offset=28, type='question', text='under the cork tree', normalized_text='under cork tree'), Entity(start_offset=89, end_offset=91, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 7732521529054562311: QEDExample(example_id=7732521529054562311, title='Division of Korea', question='when did korea separate into north and south', passage=\"The division of Korea between North and South Korea occurred after World War II , ending the Empire of Japan 's 35 - year rule over Korea in 1945 . The United States and the Soviet Union occupied two parts of the country , with the boundary between their zones of control along the 38th parallel .\", sentence_starts=[0, 148], selected_sent={'start': 0, 'end': 148, 'string': \"The division of Korea between North and South Korea occurred after World War II , ending the Empire of Japan 's 35 - year rule over Korea in 1945 . \"}, answer=[Entity(start_offset=61, end_offset=145, type='context', text=\"after World War II , ending the Empire of Japan 's 35 - year rule over Korea in 1945\", normalized_text='after world war ii ending empire of japan s 35 year rule over korea in 1945')], nq_answers=[[Entity(start_offset=141, end_offset=145, type='context', text='1945', normalized_text='1945')]], aligned_nps=[(Entity(start_offset=9, end_offset=14, type='question', text='korea', normalized_text='korea'), Entity(start_offset=16, end_offset=21, type='context', text='Korea', normalized_text='korea')), (Entity(start_offset=29, end_offset=34, type='question', text='north', normalized_text='north'), Entity(start_offset=40, end_offset=51, type='context', text='South Korea', normalized_text='south korea'))], explanation_type='single_sentence'),\n",
       " -2930493607495363881: QEDExample(example_id=-2930493607495363881, title='Esophagus', question='what is the purpose of the muscles that line the esophagus', passage='Food is ingested through the mouth and when swallowed passes first into the pharynx and then into the esophagus . The esophagus is thus one of the first components of the digestive system and the gastrointestinal tract . After food passes through the esophagus , it enters the stomach . When food is being swallowed , the epiglottis moves backward to cover the larynx , preventing food from entering the trachea . At the same time , the upper esophageal sphincter relaxes , allowing a bolus of food to enter . Peristaltic contractions of the esophageal muscle push the food down the esophagus . These rhythmic contractions occur both as a reflex response to food that is in the mouth , and also as a response to the sensation of food within the esophagus itself . Along with peristalsis , the lower esophageal sphincter relaxes .', sentence_starts=[0, 114, 221, 287, 414, 510, 595, 764], selected_sent={'start': 510, 'end': 595, 'string': 'Peristaltic contractions of the esophageal muscle push the food down the esophagus . '}, answer=[Entity(start_offset=560, end_offset=592, type='context', text='push the food down the esophagus', normalized_text='push food down esophagus')], nq_answers=[[Entity(start_offset=560, end_offset=592, type='context', text='push the food down the esophagus', normalized_text='push food down esophagus')], [Entity(start_offset=560, end_offset=594, type='context', text='push the food down the esophagus .', normalized_text='push food down esophagus')]], aligned_nps=[(Entity(start_offset=23, end_offset=58, type='question', text='the muscles that line the esophagus', normalized_text='muscles that line esophagus'), Entity(start_offset=538, end_offset=559, type='context', text='the esophageal muscle', normalized_text='esophageal muscle'))], explanation_type='single_sentence'),\n",
       " 7566216024156722346: QEDExample(example_id=7566216024156722346, title='Wonder (film)', question='who is the movie wonder based off of', passage='Wonder is a 2017 American drama film directed by Stephen Chbosky and written by Jack Thorne , Steve Conrad , and Chbosky , based on the 2012 novel of the same name by R.J. Palacio . The film stars Julia Roberts , Owen Wilson , and Jacob Tremblay . The film follows a child with Treacher Collins syndrome trying to fit in . Wonder was released in the United States on November 17 , 2017 , by Lionsgate and has grossed over $218 million worldwide on a $20 million budget .', sentence_starts=[0, 172, 182, 248, 323], selected_sent={'start': 0, 'end': 182, 'string': 'Wonder is a 2017 American drama film directed by Stephen Chbosky and written by Jack Thorne , Steve Conrad , and Chbosky , based on the 2012 novel of the same name by R.J. Palacio . '}, answer=[Entity(start_offset=132, end_offset=179, type='context', text='the 2012 novel of the same name by R.J. Palacio', normalized_text='2012 novel of same name by rj palacio')], nq_answers=[[Entity(start_offset=129, end_offset=179, type='context', text='on the 2012 novel of the same name by R.J. Palacio', normalized_text='on 2012 novel of same name by rj palacio')]], aligned_nps=[(Entity(start_offset=7, end_offset=23, type='question', text='the movie wonder', normalized_text='movie wonder'), Entity(start_offset=0, end_offset=6, type='context', text='Wonder', normalized_text='wonder'))], explanation_type='single_sentence'),\n",
       " 307455002465526783: QEDExample(example_id=307455002465526783, title='List of Lost Girl episodes', question='how many seasons are there for lost girl', passage='Lost Girl is a Canadian supernatural drama television series that aired on Showcase for five seasons , from September 12 , 2010 , to October 25 , 2015 . It follows the life of a bisexual succubus named Bo , played by Anna Silk , as she learns to control her superhuman abilities , help those in need , and discover the truth about her origins .', sentence_starts=[0, 153], selected_sent={'start': 0, 'end': 153, 'string': 'Lost Girl is a Canadian supernatural drama television series that aired on Showcase for five seasons , from September 12 , 2010 , to October 25 , 2015 . '}, answer=[Entity(start_offset=88, end_offset=92, type='context', text='five', normalized_text='five')], nq_answers=[[Entity(start_offset=88, end_offset=92, type='context', text='five', normalized_text='five')]], aligned_nps=[(Entity(start_offset=31, end_offset=40, type='question', text='lost girl', normalized_text='lost girl'), Entity(start_offset=0, end_offset=9, type='context', text='Lost Girl', normalized_text='lost girl'))], explanation_type='single_sentence'),\n",
       " -5069924657217440985: QEDExample(example_id=-5069924657217440985, title='1917–18 NHL season', question='where was the first nhl hockey game played', passage=\"The first game of the season , and in league history , featured the visiting Montreal Canadiens defeat the Ottawa Senators 7 - 4 , with Joe Malone scoring five of Montreal 's seven goals . On the same night a game featured the unnamed Toronto team versus the Wanderers . Montreal 's Dave Ritchie scored the first goal in NHL history and Harry Hyland had four goals ( the league 's first hat trick ) in the Wanderers ' 10 -- 9 victory , which would be their only one in the NHL ; Player - coach Art Ross earned the league 's first penalty . The game in Montreal was played in front of only 700 fans .\", sentence_starts=[0, 189, 271, 540], selected_sent={'start': 0, 'end': 189, 'string': \"The first game of the season , and in league history , featured the visiting Montreal Canadiens defeat the Ottawa Senators 7 - 4 , with Joe Malone scoring five of Montreal 's seven goals . \"}, answer=[Entity(start_offset=107, end_offset=113, type='context', text='Ottawa', normalized_text='ottawa')], nq_answers=[[Entity(start_offset=552, end_offset=560, type='context', text='Montreal', normalized_text='montreal')], [Entity(start_offset=107, end_offset=113, type='context', text='Ottawa', normalized_text='ottawa')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='the first nhl hockey game', normalized_text='first nhl hockey game'), Entity(start_offset=0, end_offset=52, type='context', text='The first game of the season , and in league history', normalized_text='first game of season and in league history'))], explanation_type='single_sentence'),\n",
       " -222467023790836304: QEDExample(example_id=-222467023790836304, title='iPhone 5S', question='how many inches is the iphone 5s screen', passage=\"The iPhone 5S maintains a similar design to the iPhone 5 , with a 4 in ( 10 cm ) LCD multi-touch Retina display and a screen resolution of 640 × 1136 at 326 ppi . Its home button has been updated with a new flat design using a laser - cut sapphire cover surrounded by a metallic ring ; the button is no longer concave , nor does it contain the familiar squircle icon seen on previous models . The phone itself is 0.30 in ( 7.6 mm ) thick and weighs 112 grams ( 4.0 oz ) . The phone uses an aluminum composite frame . The device is available in three color finishes ; `` space - gray '' ( replacing black with slate trim on the iPhone 5 ) , white with silver trim , and white with gold trim . The iPhone 5S was the first iPhone to be available in gold color ; this decision was influenced by the fact that gold is seen as a popular sign of a luxury product among Chinese customers .\", sentence_starts=[0, 163, 393, 472, 517, 692], selected_sent={'start': 0, 'end': 163, 'string': 'The iPhone 5S maintains a similar design to the iPhone 5 , with a 4 in ( 10 cm ) LCD multi-touch Retina display and a screen resolution of 640 × 1136 at 326 ppi . '}, answer=[Entity(start_offset=66, end_offset=80, type='context', text='4 in ( 10 cm )', normalized_text='4 in 10 cm'), Entity(start_offset=64, end_offset=111, type='context', text='a 4 in ( 10 cm ) LCD multi-touch Retina display', normalized_text='4 in 10 cm lcd multitouch retina display')], nq_answers=[[Entity(start_offset=66, end_offset=70, type='context', text='4 in', normalized_text='4 in')], [Entity(start_offset=66, end_offset=80, type='context', text='4 in ( 10 cm )', normalized_text='4 in 10 cm')]], aligned_nps=[(Entity(start_offset=19, end_offset=39, type='question', text='the iphone 5s screen', normalized_text='iphone 5s screen'), Entity(start_offset=64, end_offset=111, type='context', text='a 4 in ( 10 cm ) LCD multi-touch Retina display', normalized_text='4 in 10 cm lcd multitouch retina display'))], explanation_type='single_sentence'),\n",
       " 3330471965726271015: QEDExample(example_id=3330471965726271015, title='History of Delhi', question='who made delhi as capital for the first time', passage=\"According to Indian folklore , Delhi was the site of the magnificent and opulent Indraprastha , capital of the Pandavas in the Indian epic Mahabharata , founded around 3500 BC . It was , one of the five prasthas or ` plains ' , which included Sonepat , Panipat , Tilpat ( near Faridabad ) , and Baghpat . 16th - century , Persian historian , Firishta , recorded a tradition that Delhi or Dilli was founded by a Raja Dhilu before the Yavana ( Greek ) invasions . However , it should be noted that the kings then referred to the initial Muslim invaders as Yavanas .\", sentence_starts=[0, 178, 305, 462], selected_sent={'start': 0, 'end': 178, 'string': 'According to Indian folklore , Delhi was the site of the magnificent and opulent Indraprastha , capital of the Pandavas in the Indian epic Mahabharata , founded around 3500 BC . '}, answer=[Entity(start_offset=111, end_offset=119, type='context', text='Pandavas', normalized_text='pandavas')], nq_answers=[[Entity(start_offset=107, end_offset=119, type='context', text='the Pandavas', normalized_text='pandavas')]], aligned_nps=[(Entity(start_offset=9, end_offset=14, type='question', text='delhi', normalized_text='delhi'), Entity(start_offset=31, end_offset=36, type='context', text='Delhi', normalized_text='delhi'))], explanation_type='single_sentence'),\n",
       " 4344803622779505142: QEDExample(example_id=4344803622779505142, title='List of Australian capital cities', question='what was the first capital city of australia', passage='There are eight capital cities in Australia , each of which functions as the seat of government for the state or territory in which it is located . Melbourne was the initial capital following the 1901 Federation of Australia . In 1927 , the seat of national government was moved to the newly created city of Canberra , which continues to serve as the national capital .', sentence_starts=[0, 148, 227], selected_sent={'start': 148, 'end': 227, 'string': 'Melbourne was the initial capital following the 1901 Federation of Australia . '}, answer=[Entity(start_offset=148, end_offset=157, type='context', text='Melbourne', normalized_text='melbourne')], nq_answers=[[Entity(start_offset=148, end_offset=157, type='context', text='Melbourne', normalized_text='melbourne')]], aligned_nps=[(Entity(start_offset=9, end_offset=44, type='question', text='the first capital city of australia', normalized_text='first capital city of australia'), Entity(start_offset=162, end_offset=181, type='context', text='the initial capital', normalized_text='initial capital'))], explanation_type='single_sentence'),\n",
       " -6651263409055988535: QEDExample(example_id=-6651263409055988535, title=\"2017 NCAA Division I Women's Basketball Tournament\", question='who won the womens 2017 ncaa basketball tournament', passage=\"The 2017 NCAA Women 's Division I Basketball Tournament was played from Friday , March 17 to Sunday , April 2 , 2017 , with the Final Four played at the American Airlines Center in Dallas , Texas on March 31 and April 2 . This was the first time that the women 's Final Four was played in Dallas and the first time since 2002 that the Final Four games were played on Friday and Sunday , rather than Sunday and Tuesday . South Carolina defeated Mississippi State to win the championship .\", sentence_starts=[0, 222, 420], selected_sent={'start': 420, 'end': 487, 'string': 'South Carolina defeated Mississippi State to win the championship .'}, answer=[Entity(start_offset=420, end_offset=434, type='context', text='South Carolina', normalized_text='south carolina')], nq_answers=[[Entity(start_offset=420, end_offset=434, type='context', text='South Carolina', normalized_text='south carolina')]], aligned_nps=[(Entity(start_offset=8, end_offset=50, type='question', text='the womens 2017 ncaa basketball tournament', normalized_text='womens 2017 ncaa basketball tournament'), Entity(start_offset=469, end_offset=485, type='context', text='the championship', normalized_text='championship'))], explanation_type='single_sentence'),\n",
       " -6992125597790283273: QEDExample(example_id=-6992125597790283273, title='Daylight saving time in Canada', question='when does canada switch to daylight savings time', passage='In regions where daylight saving time is used , it commences on the second Sunday of March , and standard time restarts on the first Sunday in November .', sentence_starts=[0], selected_sent={'start': 0, 'end': 153, 'string': 'In regions where daylight saving time is used , it commences on the second Sunday of March , and standard time restarts on the first Sunday in November .'}, answer=[Entity(start_offset=64, end_offset=90, type='context', text='the second Sunday of March', normalized_text='second sunday of march')], nq_answers=[[Entity(start_offset=64, end_offset=90, type='context', text='the second Sunday of March', normalized_text='second sunday of march')]], aligned_nps=[(Entity(start_offset=27, end_offset=48, type='question', text='daylight savings time', normalized_text='daylight savings time'), Entity(start_offset=17, end_offset=37, type='context', text='daylight saving time', normalized_text='daylight saving time')), (Entity(start_offset=10, end_offset=16, type='question', text='canada', normalized_text='canada'), Entity(start_offset=3, end_offset=10, type='context', text='regions', normalized_text='regions'))], explanation_type='single_sentence'),\n",
       " -24536083689082297: QEDExample(example_id=-24536083689082297, title='Paleomagnetism', question=\"paleomagnetism is a dating method based on changes in the earth's polarity as demonstrated by\", passage=\"Paleomagnetism ( or palaeomagnetism in the United Kingdom ) is the study of the record of the Earth 's magnetic field in rocks , sediment , or archeological materials . Certain minerals in rocks lock - in a record of the direction and intensity of the magnetic field when they form . This record provides information on the past behavior of Earth 's magnetic field and the past location of tectonic plates . The record of geomagnetic reversals preserved in volcanic and sedimentary rock sequences ( magnetostratigraphy ) provides a time - scale that is used as a geochronologic tool . Geophysicists who specialize in paleomagnetism are called paleomagnetists .\", sentence_starts=[0, 169, 284, 408, 585], selected_sent={'start': 408, 'end': 585, 'string': 'The record of geomagnetic reversals preserved in volcanic and sedimentary rock sequences ( magnetostratigraphy ) provides a time - scale that is used as a geochronologic tool . '}, answer=[Entity(start_offset=457, end_offset=496, type='context', text='volcanic and sedimentary rock sequences', normalized_text='volcanic and sedimentary rock sequences')], nq_answers=[[Entity(start_offset=457, end_offset=520, type='context', text='volcanic and sedimentary rock sequences ( magnetostratigraphy )', normalized_text='volcanic and sedimentary rock sequences magnetostratigraphy')]], aligned_nps=[(Entity(start_offset=43, end_offset=74, type='question', text=\"changes in the earth's polarity\", normalized_text='changes in earths polarity'), Entity(start_offset=422, end_offset=443, type='context', text='geomagnetic reversals', normalized_text='geomagnetic reversals')), (Entity(start_offset=0, end_offset=14, type='question', text='paleomagnetism', normalized_text='paleomagnetism'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2134883146809278499: QEDExample(example_id=-2134883146809278499, title='Celebratory gunfire', question='where do bullets go when fired in the air', passage='Bullets fired into the air usually fall back with terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm . Nevertheless , people can be injured , sometimes fatally , when bullets discharged into the air fall back down to the ground . Bullets fired at angles less than vertical are more dangerous as the bullet maintains its angular ballistic trajectory and is far less likely to engage in tumbling motion ; it therefore travels at speeds much higher than a bullet in free fall .', sentence_starts=[0, 150, 277], selected_sent={'start': 0, 'end': 150, 'string': 'Bullets fired into the air usually fall back with terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm . '}, answer=[Entity(start_offset=35, end_offset=44, type='context', text='fall back', normalized_text='fall back')], nq_answers=[[Entity(start_offset=214, end_offset=274, type='context', text='bullets discharged into the air fall back down to the ground', normalized_text='bullets discharged into air fall back down to ground')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6786628352189444013: QEDExample(example_id=-6786628352189444013, title='Keep Calm and Carry On', question='where did the keep calm thing come from', passage='Keep Calm and Carry On was a motivational poster produced by the British government in 1939 in preparation for World War II . The poster was intended to raise the morale of the British public , threatened with widely predicted mass air attacks on major cities . Although 2.45 million copies were printed , and although the Blitz did in fact take place , the poster was hardly ever publicly displayed and was little known until a copy was rediscovered in 2000 at Barter Books , a bookshop in Alnwick . It has since been re-issued by a number of private companies , and has been used as the decorative theme for a range of products .', sentence_starts=[0, 126, 262, 501], selected_sent={'start': 0, 'end': 126, 'string': 'Keep Calm and Carry On was a motivational poster produced by the British government in 1939 in preparation for World War II . '}, answer=[Entity(start_offset=27, end_offset=123, type='context', text='a motivational poster produced by the British government in 1939 in preparation for World War II', normalized_text='motivational poster produced by british government in 1939 in preparation for world war ii')], nq_answers=[[Entity(start_offset=27, end_offset=123, type='context', text='a motivational poster produced by the British government in 1939 in preparation for World War II', normalized_text='motivational poster produced by british government in 1939 in preparation for world war ii')], [Entity(start_offset=29, end_offset=123, type='context', text='motivational poster produced by the British government in 1939 in preparation for World War II', normalized_text='motivational poster produced by british government in 1939 in preparation for world war ii')]], aligned_nps=[(Entity(start_offset=10, end_offset=29, type='question', text='the keep calm thing', normalized_text='keep calm thing'), Entity(start_offset=0, end_offset=22, type='context', text='Keep Calm and Carry On', normalized_text='keep calm and carry on'))], explanation_type='single_sentence'),\n",
       " 9106027670550350214: QEDExample(example_id=9106027670550350214, title='Domain (biology)', question='which domain of life are humans members of', passage=\"In biological taxonomy , a domain ( Latin : regio ) , also superkingdom or empire , is the highest taxonomic rank of organisms in the three - domain system of taxonomy designed by Carl Woese , an American microbiologist and biophysicist . According to the Woese system , introduced in 1990 , the tree of life consists of three domains : Archaea , Bacteria , and Eukarya . The first two are all prokaryotic microorganisms , or single - celled organisms whose cells have no nucleus . All life that has a nucleus and membrane - bound organelles , and multicellular organisms , is included in the Eukarya . Stefan Luketa in 2012 proposed a five `` dominion '' system , adding two more to the above .\", sentence_starts=[0, 239, 372, 482, 603], selected_sent={'start': 482, 'end': 603, 'string': 'All life that has a nucleus and membrane - bound organelles , and multicellular organisms , is included in the Eukarya . '}, answer=[Entity(start_offset=593, end_offset=600, type='context', text='Eukarya', normalized_text='eukarya')], nq_answers=[[Entity(start_offset=593, end_offset=600, type='context', text='Eukarya', normalized_text='eukarya')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 221756811657202124: QEDExample(example_id=221756811657202124, title='NFL Game Pass', question='when do replays become available on nfl game pass', passage='NFL Game Pass is a subscription based audio and video service which allows users to hear and watch live and archived National Football League ( NFL ) games via a Internet connection . For users in North America , only out - of - market preseason games can be viewed live ; full replays of all the games become available on demand after their original live broadcasts end . Live preseason , regular season , and postseason games are available to international users .', sentence_starts=[0, 184, 373], selected_sent={'start': 184, 'end': 373, 'string': 'For users in North America , only out - of - market preseason games can be viewed live ; full replays of all the games become available on demand after their original live broadcasts end . '}, answer=[Entity(start_offset=330, end_offset=370, type='context', text='after their original live broadcasts end', normalized_text='after their original live broadcasts end')], nq_answers=[[Entity(start_offset=330, end_offset=370, type='context', text='after their original live broadcasts end', normalized_text='after their original live broadcasts end')], [Entity(start_offset=273, end_offset=370, type='context', text='full replays of all the games become available on demand after their original live broadcasts end', normalized_text='full replays of all games become available on demand after their original live broadcasts end')]], aligned_nps=[(Entity(start_offset=36, end_offset=49, type='question', text='nfl game pass', normalized_text='nfl game pass'), Entity(start_offset=188, end_offset=193, type='context', text='users', normalized_text='users'))], explanation_type='single_sentence'),\n",
       " -6342434059921001640: QEDExample(example_id=-6342434059921001640, title='Jurassic World Evolution', question='when is the new jurassic world game coming out', passage='Jurassic World Evolution is an upcoming business simulation video game developed and published by Frontier Developments . The game is based on the 2015 film Jurassic World , and is scheduled for release on June 12 , 2018 , for Microsoft Windows , PlayStation 4 and Xbox One .', sentence_starts=[0, 122], selected_sent={'start': 122, 'end': 275, 'string': 'The game is based on the 2015 film Jurassic World , and is scheduled for release on June 12 , 2018 , for Microsoft Windows , PlayStation 4 and Xbox One .'}, answer=[Entity(start_offset=206, end_offset=220, type='context', text='June 12 , 2018', normalized_text='june 12 2018')], nq_answers=[[Entity(start_offset=206, end_offset=220, type='context', text='June 12 , 2018', normalized_text='june 12 2018')]], aligned_nps=[(Entity(start_offset=8, end_offset=35, type='question', text='the new jurassic world game', normalized_text='new jurassic world game'), Entity(start_offset=122, end_offset=130, type='context', text='The game', normalized_text='game'))], explanation_type='single_sentence'),\n",
       " 7808442793714993461: QEDExample(example_id=7808442793714993461, title='Triple Entente', question='what was the alliance between great britian russia and france known as', passage=\"The Triple Entente ( from French entente ( ɑ̃tɑ̃t ) `` friendship , understanding , agreement '' ) refers to the understanding linking the Russian Empire , the French Third Republic , and the United Kingdom of Great Britain and Ireland after the signing of the Anglo - Russian Entente on 31 August 1907 . The understanding between the three powers , supplemented by agreements with Japan and Portugal , was a powerful counterweight to the Triple Alliance of Germany , Austria - Hungary , and Italy .\", sentence_starts=[0, 305], selected_sent={'start': 0, 'end': 305, 'string': \"The Triple Entente ( from French entente ( ɑ̃tɑ̃t ) `` friendship , understanding , agreement '' ) refers to the understanding linking the Russian Empire , the French Third Republic , and the United Kingdom of Great Britain and Ireland after the signing of the Anglo - Russian Entente on 31 August 1907 . \"}, answer=[Entity(start_offset=0, end_offset=18, type='context', text='The Triple Entente', normalized_text='triple entente'), Entity(start_offset=109, end_offset=302, type='context', text='the understanding linking the Russian Empire , the French Third Republic , and the United Kingdom of Great Britain and Ireland after the signing of the Anglo - Russian Entente on 31 August 1907', normalized_text='understanding linking russian empire french third republic and united kingdom of great britain and ireland after signing of anglo russian entente on 31 august 1907')], nq_answers=[[Entity(start_offset=0, end_offset=18, type='context', text='The Triple Entente', normalized_text='triple entente')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6924600758326460563: QEDExample(example_id=-6924600758326460563, title='Capital punishment in Oregon', question='when was the death penalty reinstated in oregon', passage='In 1984 , Measure 6 amended the state constitution to once more make the death penalty legal . Measure 7 , a statutory measure passed in the same year , required a separate sentencing hearing before a jury in cases of aggravated murder .', sentence_starts=[0, 95], selected_sent={'start': 0, 'end': 95, 'string': 'In 1984 , Measure 6 amended the state constitution to once more make the death penalty legal . '}, answer=[Entity(start_offset=3, end_offset=7, type='context', text='1984', normalized_text='1984')], nq_answers=[[Entity(start_offset=3, end_offset=7, type='context', text='1984', normalized_text='1984')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='the death penalty', normalized_text='death penalty'), Entity(start_offset=69, end_offset=86, type='context', text='the death penalty', normalized_text='death penalty')), (Entity(start_offset=41, end_offset=47, type='question', text='oregon', normalized_text='oregon'), Entity(start_offset=28, end_offset=50, type='context', text='the state constitution', normalized_text='state constitution'))], explanation_type='single_sentence'),\n",
       " 2862391704407185252: QEDExample(example_id=2862391704407185252, title='ICQ', question='what was icq as related to instant messaging', passage=\"ICQ is an instant messaging client that was first developed and popularized by the Israeli company Mirabilis in 1996 . The name ICQ derives from the English phrase `` I Seek You '' . Ownership of ICQ passed from Mirabilis to AOL in 1998 , and from AOL to Mail.Ru Group in 2010 .\", sentence_starts=[0, 119, 183], selected_sent={'start': 0, 'end': 119, 'string': 'ICQ is an instant messaging client that was first developed and popularized by the Israeli company Mirabilis in 1996 . '}, answer=[Entity(start_offset=7, end_offset=116, type='context', text='an instant messaging client that was first developed and popularized by the Israeli company Mirabilis in 1996', normalized_text='instant messaging client that was first developed and popularized by israeli company mirabilis in 1996')], nq_answers=[[Entity(start_offset=7, end_offset=116, type='context', text='an instant messaging client that was first developed and popularized by the Israeli company Mirabilis in 1996', normalized_text='instant messaging client that was first developed and popularized by israeli company mirabilis in 1996')], [Entity(start_offset=7, end_offset=34, type='context', text='an instant messaging client', normalized_text='instant messaging client')]], aligned_nps=[(Entity(start_offset=9, end_offset=12, type='question', text='icq', normalized_text='icq'), Entity(start_offset=0, end_offset=3, type='context', text='ICQ', normalized_text='icq'))], explanation_type='single_sentence'),\n",
       " -7186555013910059700: QEDExample(example_id=-7186555013910059700, title='Rivers in Himachal Pradesh', question='chandra and bhaga river meets at the place', passage='The Chandrabhaga or Chenab ( Vedic name Askni ) , the largest river ( in terms of volume of water ) is formed after the meeting of two streams namely , Chandra and Bhaga at Tandi , in Lahaul . It flows 122 kilometres ( 76 mi ) and covers an area of 7,500 square kilometres ( 2,900 sq mi ) . in Himachal , before entering Kashmir . The Chandra passes through the barren tribal land .', sentence_starts=[0, 193, 291, 331], selected_sent={'start': 0, 'end': 193, 'string': 'The Chandrabhaga or Chenab ( Vedic name Askni ) , the largest river ( in terms of volume of water ) is formed after the meeting of two streams namely , Chandra and Bhaga at Tandi , in Lahaul . '}, answer=[Entity(start_offset=173, end_offset=190, type='context', text='Tandi , in Lahaul', normalized_text='tandi in lahaul')], nq_answers=[[Entity(start_offset=173, end_offset=190, type='context', text='Tandi , in Lahaul', normalized_text='tandi in lahaul')], [Entity(start_offset=170, end_offset=190, type='context', text='at Tandi , in Lahaul', normalized_text='at tandi in lahaul')]], aligned_nps=[(Entity(start_offset=0, end_offset=23, type='question', text='chandra and bhaga river', normalized_text='chandra and bhaga river'), Entity(start_offset=152, end_offset=169, type='context', text='Chandra and Bhaga', normalized_text='chandra and bhaga'))], explanation_type='single_sentence'),\n",
       " 8299743299185740312: QEDExample(example_id=8299743299185740312, title='Flag of India', question='when was the national flag of india adopted', passage=\"The National Flag of India is a horizontal rectangular tricolour of India saffron , white and India green ; with the Ashoka Chakra , a 24 - spoke wheel , in navy blue at its centre . It was adopted in its present form during a meeting of the Constituent Assembly held on 22 July 1947 , and it became the official flag of the Dominion of India on 15 August 1947 . The flag was subsequently retained as that of the Republic of India . In India , the term `` tricolour '' ( Hindi : तिरंगा , translit . Tiraṅgā ) almost always refers to the Indian national flag . The flag is based on the Swaraj flag , a flag of the Indian National Congress designed by Pingali Venkayya .\", sentence_starts=[0, 183, 363, 433, 499, 560], selected_sent={'start': 183, 'end': 363, 'string': 'It was adopted in its present form during a meeting of the Constituent Assembly held on 22 July 1947 , and it became the official flag of the Dominion of India on 15 August 1947 . '}, answer=[Entity(start_offset=218, end_offset=283, type='context', text='during a meeting of the Constituent Assembly held on 22 July 1947', normalized_text='during meeting of constituent assembly held on 22 july 1947')], nq_answers=[[Entity(start_offset=218, end_offset=283, type='context', text='during a meeting of the Constituent Assembly held on 22 July 1947', normalized_text='during meeting of constituent assembly held on 22 july 1947')], [Entity(start_offset=271, end_offset=283, type='context', text='22 July 1947', normalized_text='22 july 1947')], [Entity(start_offset=346, end_offset=360, type='context', text='15 August 1947', normalized_text='15 august 1947')]], aligned_nps=[(Entity(start_offset=9, end_offset=35, type='question', text='the national flag of india', normalized_text='national flag of india'), Entity(start_offset=183, end_offset=185, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 3475968917821630324: QEDExample(example_id=3475968917821630324, title='New Kingdom of Egypt', question='what was the most important new religious figure of the new kingdom of ancient egypt', passage=\"One of the best - known 18th Dynasty pharaohs is Amenhotep IV , who changed his name to Akhenaten in honor of the Aten , a representation of the Egyptian god , Ra . His exclusive worship of the Aten is often interpreted as history 's first instance of monotheism . Akhenaten 's wife , Nefertiti , contributed a great deal to his new take on the Egyptian religion . Nefertiti was bold enough to perform rituals to Aten . Akhenaten 's religious fervor is cited as the reason why he and his wife were subsequently written out of Egyptian history . Under his reign , in the 14th century BC , Egyptian art flourished under a distinctive style . ( See Amarna Period . )\", sentence_starts=[0, 165, 265, 365, 420, 545, 640], selected_sent={'start': 0, 'end': 165, 'string': 'One of the best - known 18th Dynasty pharaohs is Amenhotep IV , who changed his name to Akhenaten in honor of the Aten , a representation of the Egyptian god , Ra . '}, answer=[Entity(start_offset=110, end_offset=162, type='context', text='the Aten , a representation of the Egyptian god , Ra', normalized_text='aten representation of egyptian god ra')], nq_answers=[[Entity(start_offset=110, end_offset=162, type='context', text='the Aten , a representation of the Egyptian god , Ra', normalized_text='aten representation of egyptian god ra')], [Entity(start_offset=114, end_offset=118, type='context', text='Aten', normalized_text='aten')]], aligned_nps=[(Entity(start_offset=52, end_offset=84, type='question', text='the new kingdom of ancient egypt', normalized_text='new kingdom of ancient egypt'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2382302837416986186: QEDExample(example_id=-2382302837416986186, title='Traveling Wilburys', question='who are the artists in the traveling wilburys', passage='The Traveling Wilburys ( sometimes shortened to the Wilburys ) were a British - American supergroup consisting of Bob Dylan , George Harrison , Jeff Lynne , Roy Orbison , and Tom Petty . The band recorded two albums , the first in 1988 and the second in 1990 , though Orbison died before the second was recorded .', sentence_starts=[0, 187], selected_sent={'start': 0, 'end': 187, 'string': 'The Traveling Wilburys ( sometimes shortened to the Wilburys ) were a British - American supergroup consisting of Bob Dylan , George Harrison , Jeff Lynne , Roy Orbison , and Tom Petty . '}, answer=[Entity(start_offset=114, end_offset=184, type='context', text='Bob Dylan , George Harrison , Jeff Lynne , Roy Orbison , and Tom Petty', normalized_text='bob dylan george harrison jeff lynne roy orbison and tom petty')], nq_answers=[[Entity(start_offset=114, end_offset=123, type='context', text='Bob Dylan', normalized_text='bob dylan'), Entity(start_offset=126, end_offset=141, type='context', text='George Harrison', normalized_text='george harrison'), Entity(start_offset=144, end_offset=154, type='context', text='Jeff Lynne', normalized_text='jeff lynne'), Entity(start_offset=157, end_offset=168, type='context', text='Roy Orbison', normalized_text='roy orbison'), Entity(start_offset=175, end_offset=184, type='context', text='Tom Petty', normalized_text='tom petty')]], aligned_nps=[(Entity(start_offset=23, end_offset=45, type='question', text='the traveling wilburys', normalized_text='traveling wilburys'), Entity(start_offset=0, end_offset=22, type='context', text='The Traveling Wilburys', normalized_text='traveling wilburys'))], explanation_type='single_sentence'),\n",
       " 7084829719647229622: QEDExample(example_id=7084829719647229622, title='Cell damage', question='which term describes the replacement of damaged cells to mend a tissue', passage='When a cell can not be regenerated the body will replace it with stromal connective tissue to maintain tissue / organ function . Stromal cells are the cells that support the parenchymal cells in any organ . Fibroblasts , immune cells , pericytes , and inflammatory cells are the most common types of stromal cells .', sentence_starts=[0, 129, 207], selected_sent={'start': 0, 'end': 129, 'string': 'When a cell can not be regenerated the body will replace it with stromal connective tissue to maintain tissue / organ function . '}, answer=[Entity(start_offset=65, end_offset=90, type='context', text='stromal connective tissue', normalized_text='stromal connective tissue')], nq_answers=[[Entity(start_offset=129, end_offset=142, type='context', text='Stromal cells', normalized_text='stromal cells')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -7521086178060626112: QEDExample(example_id=-7521086178060626112, title='Ploidy', question='where are haploid cells found in the human body', passage='The number of chromosomes found in a single complete set of chromosomes is called the monoploid number ( x ) . The haploid number ( n ) is unique to gametes ( sperm or egg cells ) , and refers to the total number of chromosomes found in a gamete , which under normal conditions is half the total number of chromosomes in a somatic cell .', sentence_starts=[0, 111], selected_sent={'start': 111, 'end': 337, 'string': 'The haploid number ( n ) is unique to gametes ( sperm or egg cells ) , and refers to the total number of chromosomes found in a gamete , which under normal conditions is half the total number of chromosomes in a somatic cell .'}, answer=[Entity(start_offset=149, end_offset=179, type='context', text='gametes ( sperm or egg cells )', normalized_text='gametes sperm or egg cells')], nq_answers=[[Entity(start_offset=159, end_offset=177, type='context', text='sperm or egg cells', normalized_text='sperm or egg cells')], [Entity(start_offset=149, end_offset=179, type='context', text='gametes ( sperm or egg cells )', normalized_text='gametes sperm or egg cells')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 3718565919673293381: QEDExample(example_id=3718565919673293381, title='Earth', question='form from material that has accumulated on the earths surface', passage=\"The continental crust consists of lower density material such as the igneous rocks granite and andesite . Less common is basalt , a denser volcanic rock that is the primary constituent of the ocean floors . Sedimentary rock is formed from the accumulation of sediment that becomes buried and compacted together . Nearly 75 % of the continental surfaces are covered by sedimentary rocks , although they form about 5 % of the crust . The third form of rock material found on Earth is metamorphic rock , which is created from the transformation of pre-existing rock types through high pressures , high temperatures , or both . The most abundant silicate minerals on Earth 's surface include quartz , feldspars , amphibole , mica , pyroxene and olivine . Common carbonate minerals include calcite ( found in limestone ) and dolomite .\", sentence_starts=[0, 106, 207, 313, 432, 624, 751], selected_sent={'start': 207, 'end': 313, 'string': 'Sedimentary rock is formed from the accumulation of sediment that becomes buried and compacted together . '}, answer=[Entity(start_offset=207, end_offset=223, type='context', text='Sedimentary rock', normalized_text='sedimentary rock')], nq_answers=[[Entity(start_offset=207, end_offset=223, type='context', text='Sedimentary rock', normalized_text='sedimentary rock')]], aligned_nps=[(Entity(start_offset=43, end_offset=61, type='question', text='the earths surface', normalized_text='earths surface'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -3609099329397965026: QEDExample(example_id=-3609099329397965026, title='New York Giants', question='when is the last time the new york giants won the super bowl', passage=\"The Giants were one of five teams that joined the NFL in 1925 , and is the only one of that group still existing , as well as the league 's longest - established team in the Northeastern United States . The team ranks third among all NFL franchises with eight NFL championship titles : four in the pre -- Super Bowl era ( 1927 , 1934 , 1938 , 1956 ) and four since the advent of the Super Bowl ( Super Bowls XXI ( 1986 ) , XXV ( 1990 ) , XLII ( 2007 ) , and XLVI ( 2011 ) ) , along with more championship appearances than any other team , with 19 overall appearances . Their championship tally is surpassed only by the Green Bay Packers ( 13 ) and Chicago Bears ( 9 ) . Throughout their history , the Giants have featured 28 Hall of Fame players , including NFL Most Valuable Player ( MVP ) award winners Mel Hein , Frank Gifford , Y.A. Tittle , and Lawrence Taylor .\", sentence_starts=[0, 203, 569, 670, 837], selected_sent={'start': 203, 'end': 569, 'string': 'The team ranks third among all NFL franchises with eight NFL championship titles : four in the pre -- Super Bowl era ( 1927 , 1934 , 1938 , 1956 ) and four since the advent of the Super Bowl ( Super Bowls XXI ( 1986 ) , XXV ( 1990 ) , XLII ( 2007 ) , and XLVI ( 2011 ) ) , along with more championship appearances than any other team , with 19 overall appearances . '}, answer=[Entity(start_offset=465, end_offset=469, type='context', text='2011', normalized_text='2011')], nq_answers=[[Entity(start_offset=463, end_offset=469, type='context', text='( 2011', normalized_text='2011')]], aligned_nps=[(Entity(start_offset=22, end_offset=41, type='question', text='the new york giants', normalized_text='new york giants'), Entity(start_offset=203, end_offset=211, type='context', text='The team', normalized_text='team')), (Entity(start_offset=46, end_offset=60, type='question', text='the super bowl', normalized_text='super bowl'), Entity(start_offset=379, end_offset=393, type='context', text='the Super Bowl', normalized_text='super bowl'))], explanation_type='single_sentence'),\n",
       " 867176429412490099: QEDExample(example_id=867176429412490099, title='Robber baron (industrialist)', question='nickname given to railroad executives due to shady practices of their businesses', passage=\"`` Robber baron '' is a derogatory metaphor of social criticism originally applied to certain late 19th - century American businessmen who used unscrupulous methods to get rich .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 178, 'string': \"`` Robber baron '' is a derogatory metaphor of social criticism originally applied to certain late 19th - century American businessmen who used unscrupulous methods to get rich .\"}, answer=[Entity(start_offset=3, end_offset=15, type='context', text='Robber baron', normalized_text='robber baron')], nq_answers=[[Entity(start_offset=3, end_offset=15, type='context', text='Robber baron', normalized_text='robber baron')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 390660943990140780: QEDExample(example_id=390660943990140780, title='Bobby Anderson (actor)', question=\"who is young george bailey in it's a wonderful life\", passage=\"Robert James Anderson ( March 6 , 1933 -- June 6 , 2008 ) was an American actor and television producer , most famous for his role as the young George Bailey in It 's a Wonderful Life .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 185, 'string': \"Robert James Anderson ( March 6 , 1933 -- June 6 , 2008 ) was an American actor and television producer , most famous for his role as the young George Bailey in It 's a Wonderful Life .\"}, answer=[Entity(start_offset=0, end_offset=21, type='context', text='Robert James Anderson', normalized_text='robert james anderson')], nq_answers=[[Entity(start_offset=0, end_offset=21, type='context', text='Robert James Anderson', normalized_text='robert james anderson')]], aligned_nps=[(Entity(start_offset=7, end_offset=26, type='question', text='young george bailey', normalized_text='young george bailey'), Entity(start_offset=134, end_offset=157, type='context', text='the young George Bailey', normalized_text='young george bailey')), (Entity(start_offset=30, end_offset=51, type='question', text=\"it's a wonderful life\", normalized_text='its wonderful life'), Entity(start_offset=161, end_offset=183, type='context', text=\"It 's a Wonderful Life\", normalized_text='it s wonderful life'))], explanation_type='single_sentence'),\n",
       " -4481086743458136206: QEDExample(example_id=-4481086743458136206, title='Tablets of Stone', question='where is the tablet of the ten commandments', passage='According to the bible , both the first shattered set and the second unbroken set were stored in the Ark of the Covenant ( the Aron Habrit in Hebrew ) .', sentence_starts=[0], selected_sent={'start': 0, 'end': 152, 'string': 'According to the bible , both the first shattered set and the second unbroken set were stored in the Ark of the Covenant ( the Aron Habrit in Hebrew ) .'}, answer=[Entity(start_offset=97, end_offset=150, type='context', text='the Ark of the Covenant ( the Aron Habrit in Hebrew )', normalized_text='ark of covenant aron habrit in hebrew')], nq_answers=[[Entity(start_offset=94, end_offset=120, type='context', text='in the Ark of the Covenant', normalized_text='in ark of covenant')], [Entity(start_offset=101, end_offset=120, type='context', text='Ark of the Covenant', normalized_text='ark of covenant')]], aligned_nps=[(Entity(start_offset=9, end_offset=43, type='question', text='the tablet of the ten commandments', normalized_text='tablet of ten commandments'), Entity(start_offset=30, end_offset=81, type='context', text='the first shattered set and the second unbroken set', normalized_text='first shattered set and second unbroken set'))], explanation_type='single_sentence'),\n",
       " 3581703127157842174: QEDExample(example_id=3581703127157842174, title='Right to Buy', question='when did the right to buy scheme start', passage='The Right to Buy scheme is a policy in the United Kingdom ( with the exception of Scotland since August 1 , 2016 ) which gives secure tenants of councils and some housing associations the legal right to buy , at a large discount , the council house they are living in . There is also a Right to Acquire for assured tenants of housing association homes built with public subsidy after 1997 , at a smaller discount . About 1,500,000 homes in the UK have been sold in this manner since the introduction of the scheme in 1980 .', sentence_starts=[0, 270, 415], selected_sent={'start': 415, 'end': 523, 'string': 'About 1,500,000 homes in the UK have been sold in this manner since the introduction of the scheme in 1980 .'}, answer=[Entity(start_offset=517, end_offset=521, type='context', text='1980', normalized_text='1980')], nq_answers=[[Entity(start_offset=517, end_offset=521, type='context', text='1980', normalized_text='1980')]], aligned_nps=[(Entity(start_offset=9, end_offset=32, type='question', text='the right to buy scheme', normalized_text='right to buy scheme'), Entity(start_offset=503, end_offset=513, type='context', text='the scheme', normalized_text='scheme'))], explanation_type='single_sentence'),\n",
       " -4463524755977549691: QEDExample(example_id=-4463524755977549691, title='Card security code', question='what is a cvv code on a visa gift card', passage=\"A card security code ( CSC ; also called card verification data ( CVD ) , card verification number , card verification value ( CVV ) , card verification value code , card verification code ( CVC ) , verification code ( V - code or V code ) , or signature panel code ( SPC ) ) is a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 408, 'string': \"A card security code ( CSC ; also called card verification data ( CVD ) , card verification number , card verification value ( CVV ) , card verification value code , card verification code ( CVC ) , verification code ( V - code or V code ) , or signature panel code ( SPC ) ) is a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud .\"}, answer=[Entity(start_offset=101, end_offset=132, type='context', text='card verification value ( CVV )', normalized_text='card verification value cvv'), Entity(start_offset=279, end_offset=406, type='context', text=\"a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud\", normalized_text='security feature for card not present payment card transactions instituted to reduce incidence of credit card fraud')], nq_answers=[[Entity(start_offset=279, end_offset=406, type='context', text=\"a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud\", normalized_text='security feature for card not present payment card transactions instituted to reduce incidence of credit card fraud')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 3329484920776215448: QEDExample(example_id=3329484920776215448, title='List of players who have scored 10,000 or more runs in One Day International cricket', question='how many players have scored 10000 runs in odi', passage=\"Scoring over 10,000 runs across a playing career in any format of cricket is considered a significant achievement . In the year 2001 , Sachin Tendulkar became the first player to score 10,000 runs in ODIs , while playing a match during the bi-lateral series against Australia at home . In the chase for achieving top scores , West Indies ' Desmond Haynes retired as the most prolific run - scorer in One Day Internationals ( ODIs ) , with a total of 8,648 runs in 1994 . The record stood for four years until it was broken by India 's Mohammed Azharuddin . Azharuddin remained the top - scorer in the format until his compatriot Sachin Tendulkar passed him in October 2000 . As of August 2016 , eleven players -- from six teams that are Full members of the International Cricket Council -- have scored more than 10,000 runs in ODIs . Four of these are from Sri Lanka and three from India . The rest are one player each from Pakistan , Australia , West Indies , and South Africa . Bangladesh , England , New Zealand , and Zimbabwe are yet to have a player reach the 10,000 - run mark in this format .\", sentence_starts=[0, 116, 286, 471, 557, 675, 834, 890, 980], selected_sent={'start': 675, 'end': 834, 'string': 'As of August 2016 , eleven players -- from six teams that are Full members of the International Cricket Council -- have scored more than 10,000 runs in ODIs . '}, answer=[Entity(start_offset=695, end_offset=701, type='context', text='eleven', normalized_text='eleven')], nq_answers=[[Entity(start_offset=695, end_offset=701, type='context', text='eleven', normalized_text='eleven')]], aligned_nps=[(Entity(start_offset=43, end_offset=46, type='question', text='odi', normalized_text='odi'), Entity(start_offset=827, end_offset=831, type='context', text='ODIs', normalized_text='odis'))], explanation_type='single_sentence'),\n",
       " 2936402326207785693: QEDExample(example_id=2936402326207785693, title='New Jersey Drive', question='what is the movie new jersey drive about', passage=\"New Jersey Drive is a 1995 crime drama film about joy riding black teenagers in 1990s Newark , New Jersey , then known as the `` car theft capital of the world '' .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 164, 'string': \"New Jersey Drive is a 1995 crime drama film about joy riding black teenagers in 1990s Newark , New Jersey , then known as the `` car theft capital of the world '' .\"}, answer=[Entity(start_offset=50, end_offset=162, type='context', text=\"joy riding black teenagers in 1990s Newark , New Jersey , then known as the `` car theft capital of the world ''\", normalized_text='joy riding black teenagers in 1990s newark new jersey then known as car theft capital of world')], nq_answers=[[Entity(start_offset=50, end_offset=105, type='context', text='joy riding black teenagers in 1990s Newark , New Jersey', normalized_text='joy riding black teenagers in 1990s newark new jersey')], [Entity(start_offset=50, end_offset=162, type='context', text=\"joy riding black teenagers in 1990s Newark , New Jersey , then known as the `` car theft capital of the world ''\", normalized_text='joy riding black teenagers in 1990s newark new jersey then known as car theft capital of world')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text='the movie new jersey drive', normalized_text='movie new jersey drive'), Entity(start_offset=0, end_offset=16, type='context', text='New Jersey Drive', normalized_text='new jersey drive'))], explanation_type='single_sentence'),\n",
       " -928229760699185795: QEDExample(example_id=-928229760699185795, title='Telephone numbers in the United Kingdom', question='what do mobile numbers start with in the uk', passage=\"Since 28 April 2001 , almost all geographic numbers and most non-geographic numbers have 9 or 10 national ( significant ) numbers after the `` 0 '' trunk code . All mobile telephone numbers have 10 national ( significant ) numbers after the `` 0 '' trunk code . The overall structure of the UK 's National Numbering Plan is :\", sentence_starts=[0, 161, 262], selected_sent={'start': 161, 'end': 262, 'string': \"All mobile telephone numbers have 10 national ( significant ) numbers after the `` 0 '' trunk code . \"}, answer=[Entity(start_offset=237, end_offset=259, type='context', text=\"the `` 0 '' trunk code\", normalized_text='0 trunk code')], nq_answers=[[Entity(start_offset=244, end_offset=245, type='context', text='0', normalized_text='0')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 3022939638183417538: QEDExample(example_id=3022939638183417538, title='List of Formula One Grand Prix winners', question='who has won the most f1 grand prix', passage='Michael Schumacher holds the record for the most Grand Prix victories , having won 91 times . Lewis Hamilton is second with 62 wins and Alain Prost is third with 51 wins . Michael Schumacher holds the distinction of having the longest time between his first win and his last . He won his first Grand Prix in 1992 at the Belgian Grand Prix , and his last in 2006 at the Chinese Grand Prix , a span of 14 years , 1 month and 1 day . Riccardo Patrese holds the record for the longest period of time between two race wins -- more than six - and - a-half years between the 1983 South African Grand Prix and the 1990 San Marino Grand Prix . Mario Andretti had to wait the longest time between his maiden victory at the 1971 South African Grand Prix and his second win -- coming five years , seven months and 18 days later at the 1976 Japanese Grand Prix . Sebastian Vettel holds the record for the most consecutive wins , having won nine Grands Prix in a row from the 2013 Belgian Grand Prix to the 2013 Brazilian Grand Prix . Max Verstappen is the youngest winner of a Grand Prix ; he was 18 years and 227 days old when he won the 2016 Spanish Grand Prix . Luigi Fagioli is the oldest winner of a Formula One Grand Prix ; he was 53 years and 22 days old when he won the 1951 French Grand Prix .', sentence_starts=[0, 94, 172, 277, 431, 635, 850, 1021, 1152], selected_sent={'start': 0, 'end': 94, 'string': 'Michael Schumacher holds the record for the most Grand Prix victories , having won 91 times . '}, answer=[Entity(start_offset=0, end_offset=18, type='context', text='Michael Schumacher', normalized_text='michael schumacher')], nq_answers=[[Entity(start_offset=0, end_offset=18, type='context', text='Michael Schumacher', normalized_text='michael schumacher')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -4645318265748668766: QEDExample(example_id=-4645318265748668766, title='Keeping up with the Joneses', question='where does the saying keeping up with the jones come from', passage=\"The phrase originates with the comic strip Keeping Up with the Joneses , created by Arthur R. `` Pop '' Momand in 1913 . The strip ran until 1940 in The New York World and various other newspapers . The strip depicts the social climbing McGinis family , who struggle to `` keep up '' with their neighbors , the Joneses of the title . The Joneses were unseen characters throughout the strip 's run , often spoken of but never shown . The idiom keeping up with the Joneses has remained popular long after the strip 's end .\", sentence_starts=[0, 121, 199, 334, 433], selected_sent={'start': 0, 'end': 121, 'string': \"The phrase originates with the comic strip Keeping Up with the Joneses , created by Arthur R. `` Pop '' Momand in 1913 . \"}, answer=[Entity(start_offset=27, end_offset=118, type='context', text=\"the comic strip Keeping Up with the Joneses , created by Arthur R. `` Pop '' Momand in 1913\", normalized_text='comic strip keeping up with joneses created by arthur r pop momand in 1913')], nq_answers=[[Entity(start_offset=27, end_offset=70, type='context', text='the comic strip Keeping Up with the Joneses', normalized_text='comic strip keeping up with joneses')]], aligned_nps=[(Entity(start_offset=11, end_offset=47, type='question', text='the saying keeping up with the jones', normalized_text='saying keeping up with jones'), Entity(start_offset=0, end_offset=10, type='context', text='The phrase', normalized_text='phrase'))], explanation_type='single_sentence'),\n",
       " 2642993931001870696: QEDExample(example_id=2642993931001870696, title='Laura Haddock', question='who plays meredith quill in guardians of the galaxy 2', passage=\"Laura Jane Haddock ( born 21 August 1985 ) is an English actress . She is best known for portraying Kacie Carter in Honest , Lucrezia in Da Vinci 's Demons , Meredith Quill in Guardians of the Galaxy and its sequel Guardians of the Galaxy Vol. 2 , Alison in The Inbetweeners Movie and Viviane Wembly in Transformers : The Last Knight .\", sentence_starts=[0, 67], selected_sent={'start': 67, 'end': 335, 'string': \"She is best known for portraying Kacie Carter in Honest , Lucrezia in Da Vinci 's Demons , Meredith Quill in Guardians of the Galaxy and its sequel Guardians of the Galaxy Vol. 2 , Alison in The Inbetweeners Movie and Viviane Wembly in Transformers : The Last Knight .\"}, answer=[Entity(start_offset=0, end_offset=18, type='context', text='Laura Jane Haddock', normalized_text='laura jane haddock')], nq_answers=[[Entity(start_offset=0, end_offset=18, type='context', text='Laura Jane Haddock', normalized_text='laura jane haddock')]], aligned_nps=[(Entity(start_offset=10, end_offset=24, type='question', text='meredith quill', normalized_text='meredith quill'), Entity(start_offset=158, end_offset=172, type='context', text='Meredith Quill', normalized_text='meredith quill')), (Entity(start_offset=28, end_offset=53, type='question', text='guardians of the galaxy 2', normalized_text='guardians of galaxy 2'), Entity(start_offset=176, end_offset=199, type='context', text='Guardians of the Galaxy', normalized_text='guardians of galaxy'))], explanation_type='single_sentence'),\n",
       " 9027116721747088541: QEDExample(example_id=9027116721747088541, title='Jonathan Cheban', question='who is the guy on keeping up with the kardashians', passage='Jonathan Cheban ( born c. 1974 ) is a reality - television star and entrepreneur . He is noted for his recurring role on the show Keeping Up with the Kardashians and its spinoffs .', sentence_starts=[0, 83], selected_sent={'start': 83, 'end': 180, 'string': 'He is noted for his recurring role on the show Keeping Up with the Kardashians and its spinoffs .'}, answer=[Entity(start_offset=0, end_offset=15, type='context', text='Jonathan Cheban', normalized_text='jonathan cheban')], nq_answers=[[Entity(start_offset=0, end_offset=15, type='context', text='Jonathan Cheban', normalized_text='jonathan cheban')]], aligned_nps=[(Entity(start_offset=18, end_offset=49, type='question', text='keeping up with the kardashians', normalized_text='keeping up with kardashians'), Entity(start_offset=121, end_offset=161, type='context', text='the show Keeping Up with the Kardashians', normalized_text='show keeping up with kardashians'))], explanation_type='single_sentence'),\n",
       " -2321556715412254267: QEDExample(example_id=-2321556715412254267, title='The Englishman who Went up a Hill but Came down a Mountain', question='locations for the film an englishman who went up a hill', passage=\"The film is based on a story heard by Christopher Monger from his grandfather about the real village of Taff 's Well , in the old county of Glamorgan , and its neighbouring Garth Hill . Due to 20th century urbanisation of the area , it was filmed in the more rural Llanrhaeadr - ym - Mochnant and Llansilin in Powys . The Welsh Male Voice Choir used to provide background music throughout the film was , in fact , the London - based Gwalia Male Choir .\", sentence_starts=[0, 186, 318], selected_sent={'start': 186, 'end': 318, 'string': 'Due to 20th century urbanisation of the area , it was filmed in the more rural Llanrhaeadr - ym - Mochnant and Llansilin in Powys . '}, answer=[Entity(start_offset=265, end_offset=315, type='context', text='Llanrhaeadr - ym - Mochnant and Llansilin in Powys', normalized_text='llanrhaeadr ym mochnant and llansilin in powys')], nq_answers=[[Entity(start_offset=265, end_offset=315, type='context', text='Llanrhaeadr - ym - Mochnant and Llansilin in Powys', normalized_text='llanrhaeadr ym mochnant and llansilin in powys')], [Entity(start_offset=265, end_offset=292, type='context', text='Llanrhaeadr - ym - Mochnant', normalized_text='llanrhaeadr ym mochnant'), Entity(start_offset=297, end_offset=315, type='context', text='Llansilin in Powys', normalized_text='llansilin in powys')]], aligned_nps=[(Entity(start_offset=14, end_offset=55, type='question', text='the film an englishman who went up a hill', normalized_text='film englishman who went up hill'), Entity(start_offset=233, end_offset=235, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6787462403220370958: QEDExample(example_id=6787462403220370958, title='Game seven', question='where is the 7th game of the world series played', passage='The game is generally played at the site of the team holding the home advantage across the series .', sentence_starts=[0], selected_sent={'start': 0, 'end': 99, 'string': 'The game is generally played at the site of the team holding the home advantage across the series .'}, answer=[Entity(start_offset=29, end_offset=97, type='context', text='at the site of the team holding the home advantage across the series', normalized_text='at site of team holding home advantage across series')], nq_answers=[[Entity(start_offset=29, end_offset=97, type='context', text='at the site of the team holding the home advantage across the series', normalized_text='at site of team holding home advantage across series')], [Entity(start_offset=12, end_offset=97, type='context', text='generally played at the site of the team holding the home advantage across the series', normalized_text='generally played at site of team holding home advantage across series')], [Entity(start_offset=32, end_offset=97, type='context', text='the site of the team holding the home advantage across the series', normalized_text='site of team holding home advantage across series')]], aligned_nps=[(Entity(start_offset=9, end_offset=41, type='question', text='the 7th game of the world series', normalized_text='7th game of world series'), Entity(start_offset=0, end_offset=8, type='context', text='The game', normalized_text='game'))], explanation_type='single_sentence'),\n",
       " -3655952387338820756: QEDExample(example_id=-3655952387338820756, title='Valley of the Dolls', question='who is the valley of the dolls based on', passage=\"Valley of the Dolls is widely considered to be a roman a clef , with its characters based on such famous figures as Judy Garland , Carole Landis , Dean Martin , and Ethel Merman . In 1973 , after publication of her third novel , Susann said , `` They can keep calling it that ( roman a clef ) . It 'll only make my books sell , I do n't care . '' Susann insisted that she began each book with a theme : `` Then I start asking , what kind of a personality ? And because I have a good ear , I unconsciously pick up certain people . ''\", sentence_starts=[0, 180, 295, 347, 457], selected_sent={'start': 0, 'end': 180, 'string': 'Valley of the Dolls is widely considered to be a roman a clef , with its characters based on such famous figures as Judy Garland , Carole Landis , Dean Martin , and Ethel Merman . '}, answer=[Entity(start_offset=116, end_offset=177, type='context', text='Judy Garland , Carole Landis , Dean Martin , and Ethel Merman', normalized_text='judy garland carole landis dean martin and ethel merman')], nq_answers=[[Entity(start_offset=116, end_offset=128, type='context', text='Judy Garland', normalized_text='judy garland'), Entity(start_offset=131, end_offset=144, type='context', text='Carole Landis', normalized_text='carole landis'), Entity(start_offset=147, end_offset=158, type='context', text='Dean Martin', normalized_text='dean martin'), Entity(start_offset=165, end_offset=177, type='context', text='Ethel Merman', normalized_text='ethel merman')]], aligned_nps=[(Entity(start_offset=7, end_offset=30, type='question', text='the valley of the dolls', normalized_text='valley of dolls'), Entity(start_offset=0, end_offset=19, type='context', text='Valley of the Dolls', normalized_text='valley of dolls'))], explanation_type='single_sentence'),\n",
       " -6733068299815020054: QEDExample(example_id=-6733068299815020054, title='Widget (beer)', question='why is there a ball in guinness beer', passage=\"A widget is a device placed in a container of beer to manage the characteristics of the beer 's head . The original widget was patented in Ireland by Guinness . The `` floating widget '' is found in cans of beer as a hollow plastic sphere , approximately 3 cm in diameter ( similar in appearance to table tennis ball , but smaller ) with at least one small hole and a seam . The `` rocket widget '' is found in bottles , 7 cm in length with the small hole at the bottom .\", sentence_starts=[0, 103, 161, 375], selected_sent={'start': 0, 'end': 103, 'string': \"A widget is a device placed in a container of beer to manage the characteristics of the beer 's head . \"}, answer=[Entity(start_offset=51, end_offset=100, type='context', text=\"to manage the characteristics of the beer 's head\", normalized_text='to manage characteristics of beer s head')], nq_answers=[[Entity(start_offset=51, end_offset=100, type='context', text=\"to manage the characteristics of the beer 's head\", normalized_text='to manage characteristics of beer s head')]], aligned_nps=[(Entity(start_offset=13, end_offset=19, type='question', text='a ball', normalized_text='ball'), Entity(start_offset=0, end_offset=8, type='context', text='A widget', normalized_text='widget'))], explanation_type='single_sentence'),\n",
       " 5772493760731282819: QEDExample(example_id=5772493760731282819, title='Transfer RNA', question='what is the function of trnas in protein synthesis', passage='A transfer RNA ( abbreviated tRNA and formerly referred to as sRNA , for soluble RNA ) is an adaptor molecule composed of RNA , typically 76 to 90 nucleotides in length , that serves as the physical link between the mRNA and the amino acid sequence of proteins . tRNA does this by carrying an amino acid to the protein synthetic machinery of a cell ( ribosome ) as directed by a three - nucleotide sequence ( codon ) in a messenger RNA ( mRNA ) . As such , tRNAs are a necessary component of translation , the biological synthesis of new proteins in accordance with the genetic code .', sentence_starts=[0, 263, 447], selected_sent={'start': 0, 'end': 263, 'string': 'A transfer RNA ( abbreviated tRNA and formerly referred to as sRNA , for soluble RNA ) is an adaptor molecule composed of RNA , typically 76 to 90 nucleotides in length , that serves as the physical link between the mRNA and the amino acid sequence of proteins . '}, answer=[Entity(start_offset=176, end_offset=260, type='context', text='serves as the physical link between the mRNA and the amino acid sequence of proteins', normalized_text='serves as physical link between mrna and amino acid sequence of proteins')], nq_answers=[[Entity(start_offset=176, end_offset=260, type='context', text='serves as the physical link between the mRNA and the amino acid sequence of proteins', normalized_text='serves as physical link between mrna and amino acid sequence of proteins')], [Entity(start_offset=281, end_offset=442, type='context', text='carrying an amino acid to the protein synthetic machinery of a cell ( ribosome ) as directed by a three - nucleotide sequence ( codon ) in a messenger RNA ( mRNA', normalized_text='carrying amino acid to protein synthetic machinery of cell ribosome as directed by three nucleotide sequence codon in messenger rna mrna')]], aligned_nps=[(Entity(start_offset=24, end_offset=29, type='question', text='trnas', normalized_text='trnas'), Entity(start_offset=0, end_offset=14, type='context', text='A transfer RNA', normalized_text='transfer rna'))], explanation_type='single_sentence'),\n",
       " -4879672631592131847: QEDExample(example_id=-4879672631592131847, title='Paul Hogan', question='who was the actor who played crocodile dundee', passage=\"Paul Hogan , AM ( born 8 October 1939 ) is an Australian comedian , actor and television presenter . He was nominated for the Academy Award for Best Original Screenplay and won the Golden Globe Award for Best Actor -- Motion Picture Musical or Comedy for his performance as outback adventurer Michael `` Crocodile '' Dundee in Crocodile Dundee ( 1986 ) , the first in the Dundee film franchise .\", sentence_starts=[0, 101], selected_sent={'start': 101, 'end': 395, 'string': \"He was nominated for the Academy Award for Best Original Screenplay and won the Golden Globe Award for Best Actor -- Motion Picture Musical or Comedy for his performance as outback adventurer Michael `` Crocodile '' Dundee in Crocodile Dundee ( 1986 ) , the first in the Dundee film franchise .\"}, answer=[Entity(start_offset=0, end_offset=10, type='context', text='Paul Hogan', normalized_text='paul hogan')], nq_answers=[[Entity(start_offset=0, end_offset=10, type='context', text='Paul Hogan', normalized_text='paul hogan')], [Entity(start_offset=0, end_offset=15, type='context', text='Paul Hogan , AM', normalized_text='paul hogan am')]], aligned_nps=[(Entity(start_offset=29, end_offset=45, type='question', text='crocodile dundee', normalized_text='crocodile dundee'), Entity(start_offset=293, end_offset=323, type='context', text=\"Michael `` Crocodile '' Dundee\", normalized_text='michael crocodile dundee'))], explanation_type='single_sentence'),\n",
       " -8199145431277346508: QEDExample(example_id=-8199145431277346508, title='Myofascial trigger point', question='where are trigger points located in the body', passage=\"Myofascial trigger points , also known as trigger points , are described as hyperirritable spots in the fascia surrounding skeletal muscle . They are associated with palpable nodules in taut bands of muscle fibers . They are a topic of ongoing controversy , as there is limited data to inform a scientific understanding of the phenomenon . Accordingly , a formal acceptance of myofascial `` knots '' as an identifiable source of pain is more common among bodyworkers , physical therapists , chiropractors , and osteopathic practitioners . Nonetheless , the concept of trigger points provides a framework which may be used to help address certain musculoskeletal pain .\", sentence_starts=[0, 141, 216, 340, 539], selected_sent={'start': 0, 'end': 141, 'string': 'Myofascial trigger points , also known as trigger points , are described as hyperirritable spots in the fascia surrounding skeletal muscle . '}, answer=[Entity(start_offset=97, end_offset=138, type='context', text='in the fascia surrounding skeletal muscle', normalized_text='in fascia surrounding skeletal muscle')], nq_answers=[[Entity(start_offset=97, end_offset=138, type='context', text='in the fascia surrounding skeletal muscle', normalized_text='in fascia surrounding skeletal muscle')], [Entity(start_offset=76, end_offset=138, type='context', text='hyperirritable spots in the fascia surrounding skeletal muscle', normalized_text='hyperirritable spots in fascia surrounding skeletal muscle')]], aligned_nps=[(Entity(start_offset=10, end_offset=24, type='question', text='trigger points', normalized_text='trigger points'), Entity(start_offset=0, end_offset=56, type='context', text='Myofascial trigger points , also known as trigger points', normalized_text='myofascial trigger points also known as trigger points'))], explanation_type='single_sentence'),\n",
       " 8451264603946634151: QEDExample(example_id=8451264603946634151, title='Ambulatory care', question='ambulatory is a term used in health care to describe', passage='Ambulatory care or outpatient care is medical care provided on an outpatient basis , including diagnosis , observation , consultation , treatment , intervention , and rehabilitation services . This care can include advanced medical technology and procedures even when provided outside of hospitals .', sentence_starts=[0, 193], selected_sent={'start': 0, 'end': 193, 'string': 'Ambulatory care or outpatient care is medical care provided on an outpatient basis , including diagnosis , observation , consultation , treatment , intervention , and rehabilitation services . '}, answer=[Entity(start_offset=38, end_offset=190, type='context', text='medical care provided on an outpatient basis , including diagnosis , observation , consultation , treatment , intervention , and rehabilitation services', normalized_text='medical care provided on outpatient basis including diagnosis observation consultation treatment intervention and rehabilitation services')], nq_answers=[[Entity(start_offset=38, end_offset=190, type='context', text='medical care provided on an outpatient basis , including diagnosis , observation , consultation , treatment , intervention , and rehabilitation services', normalized_text='medical care provided on outpatient basis including diagnosis observation consultation treatment intervention and rehabilitation services')]], aligned_nps=[(Entity(start_offset=0, end_offset=10, type='question', text='ambulatory', normalized_text='ambulatory'), Entity(start_offset=0, end_offset=15, type='context', text='Ambulatory care', normalized_text='ambulatory care'))], explanation_type='single_sentence'),\n",
       " 6419419776853227880: QEDExample(example_id=6419419776853227880, title='History of the Philadelphia Eagles', question='how long has it been since eagles went to super bowl', passage='The history of the Philadelphia Eagles begins in 1933 . In their history , the Eagles have appeared in the Super Bowl three times , losing in their first two appearances but winning the third , in 2018 . They won three NFL Championships , the precursor to the Super Bowl , in four appearances .', sentence_starts=[0, 56, 204], selected_sent={'start': 56, 'end': 204, 'string': 'In their history , the Eagles have appeared in the Super Bowl three times , losing in their first two appearances but winning the third , in 2018 . '}, answer=[Entity(start_offset=197, end_offset=201, type='context', text='2018', normalized_text='2018')], nq_answers=[[Entity(start_offset=197, end_offset=201, type='context', text='2018', normalized_text='2018')]], aligned_nps=[(Entity(start_offset=27, end_offset=33, type='question', text='eagles', normalized_text='eagles'), Entity(start_offset=75, end_offset=85, type='context', text='the Eagles', normalized_text='eagles')), (Entity(start_offset=42, end_offset=52, type='question', text='super bowl', normalized_text='super bowl'), Entity(start_offset=103, end_offset=117, type='context', text='the Super Bowl', normalized_text='super bowl'))], explanation_type='single_sentence'),\n",
       " 4075061692712596480: QEDExample(example_id=4075061692712596480, title='Independence Day (United States)', question='who did the united states win its independence from', passage='Independence Day , also referred to as the Fourth of July or July Fourth , is a federal holiday in the United States commemorating the adoption of the Declaration of Independence on July 4 , 1776 . The Continental Congress declared that the thirteen American colonies regarded themselves as a new nation , the United States of America , and were no longer part of the British Empire . The Congress actually voted to declare independence two days earlier , on July 2 .', sentence_starts=[0, 198, 385], selected_sent={'start': 198, 'end': 385, 'string': 'The Continental Congress declared that the thirteen American colonies regarded themselves as a new nation , the United States of America , and were no longer part of the British Empire . '}, answer=[Entity(start_offset=364, end_offset=382, type='context', text='the British Empire', normalized_text='british empire')], nq_answers=[[Entity(start_offset=364, end_offset=382, type='context', text='the British Empire', normalized_text='british empire')]], aligned_nps=[(Entity(start_offset=8, end_offset=25, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=306, end_offset=334, type='context', text='the United States of America', normalized_text='united states of america'))], explanation_type='single_sentence'),\n",
       " -9097447514182117784: QEDExample(example_id=-9097447514182117784, title=\"America's Next Top Model (cycle 8)\", question=\"who won season 8 of america's next top model\", passage='The winner was 20 - year - old Jaslene Gonzalez from Chicago , Illinois , who notably had made it to the semi-finals of cycle 7 , but was not cast . Gonzalez became the first winner without any bottom two appearance .', sentence_starts=[0, 149], selected_sent={'start': 0, 'end': 149, 'string': 'The winner was 20 - year - old Jaslene Gonzalez from Chicago , Illinois , who notably had made it to the semi-finals of cycle 7 , but was not cast . '}, answer=[Entity(start_offset=31, end_offset=47, type='context', text='Jaslene Gonzalez', normalized_text='jaslene gonzalez')], nq_answers=[[Entity(start_offset=15, end_offset=71, type='context', text='20 - year - old Jaslene Gonzalez from Chicago , Illinois', normalized_text='20 year old jaslene gonzalez from chicago illinois')], [Entity(start_offset=31, end_offset=47, type='context', text='Jaslene Gonzalez', normalized_text='jaslene gonzalez')]], aligned_nps=[(Entity(start_offset=8, end_offset=44, type='question', text=\"season 8 of america's next top model\", normalized_text='season 8 of americas next top model'), Entity(start_offset=0, end_offset=10, type='context', text='The winner', normalized_text='winner'))], explanation_type='single_sentence'),\n",
       " 6750542872001190782: QEDExample(example_id=6750542872001190782, title='History of scientific method', question='who was an early advocate for using scientific methods based on inductive reasoning', passage='Some of the most important debates in the history of scientific method center on : rationalism , especially as advocated by René Descartes ; inductivism , which rose to particular prominence with Isaac Newton and his followers ; and hypothetico - deductivism , which came to the fore in the early 19th century . In the late 19th and early 20th centuries , a debate over realism vs. antirealism was central to discussions of scientific method as powerful scientific theories extended beyond the realm of the observable , while in the mid-20th century some prominent philosophers argued against any universal rules of science at all .', sentence_starts=[0, 312], selected_sent={'start': 0, 'end': 312, 'string': 'Some of the most important debates in the history of scientific method center on : rationalism , especially as advocated by René Descartes ; inductivism , which rose to particular prominence with Isaac Newton and his followers ; and hypothetico - deductivism , which came to the fore in the early 19th century . '}, answer=[Entity(start_offset=196, end_offset=226, type='context', text='Isaac Newton and his followers', normalized_text='isaac newton and his followers')], nq_answers=[[Entity(start_offset=124, end_offset=138, type='context', text='René Descartes', normalized_text='rené descartes')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3933162766009466595: QEDExample(example_id=-3933162766009466595, title='Pop music', question='where does the term pop music come from', passage=\"According to the website of The New Grove Dictionary of Music and Musicians , called Grove Music Online , the term `` pop music '' `` originated in Britain in the mid-1950s as a description for rock and roll and the new youth music styles that it influenced '' . The Oxford Dictionary of Music states that while pop 's `` earlier meaning meant concerts appealing to a wide audience ... since the late 1950s , however , pop has had the special meaning of non-classical mus ( ic ) , usually in the form of songs , performed by such artists as the Beatles , the Rolling Stones , ABBA , etc '' . Grove Music Online also states that `` ... in the early 1960s , ( the term ) ' pop music ' competed terminologically with beat music ( in England ) , while in the USA its coverage overlapped ( as it still does ) with that of ' rock and roll ' '' .\", sentence_starts=[0, 263, 386, 592], selected_sent={'start': 0, 'end': 263, 'string': \"According to the website of The New Grove Dictionary of Music and Musicians , called Grove Music Online , the term `` pop music '' `` originated in Britain in the mid-1950s as a description for rock and roll and the new youth music styles that it influenced '' . \"}, answer=[Entity(start_offset=148, end_offset=257, type='context', text='Britain in the mid-1950s as a description for rock and roll and the new youth music styles that it influenced', normalized_text='britain in mid1950s as description for rock and roll and new youth music styles that it influenced')], nq_answers=[[Entity(start_offset=131, end_offset=207, type='context', text='`` originated in Britain in the mid-1950s as a description for rock and roll', normalized_text='originated in britain in mid1950s as description for rock and roll')], [Entity(start_offset=148, end_offset=155, type='context', text='Britain', normalized_text='britain')], [Entity(start_offset=148, end_offset=257, type='context', text='Britain in the mid-1950s as a description for rock and roll and the new youth music styles that it influenced', normalized_text='britain in mid1950s as description for rock and roll and new youth music styles that it influenced')]], aligned_nps=[(Entity(start_offset=11, end_offset=29, type='question', text='the term pop music', normalized_text='term pop music'), Entity(start_offset=106, end_offset=130, type='context', text=\"the term `` pop music ''\", normalized_text='term pop music'))], explanation_type='single_sentence'),\n",
       " 3465345421885406629: QEDExample(example_id=3465345421885406629, title='Albatross (metaphor)', question='the rime of the ancient mariner albatross symbolism', passage=\"It is an allusion to Samuel Taylor Coleridge 's poem The Rime of the Ancient Mariner ( 1798 ) . In the poem , an albatross starts to follow a ship -- being followed by an albatross was generally considered a sign of good luck . However , the titular mariner shoots the albatross with a crossbow , which is regarded as an act that will curse the ship ( which indeed suffers terrible mishaps ) . Even when they are too thirsty to speak , the ship 's crew let the mariner know through their glances that they blame his action for the curse . The albatross is then literally hung around the mariner 's neck by the crew to symbolize his guilt in killing the bird . Thus , the albatross can be both an omen of good or bad luck , as well as a metaphor for a burden to be carried as penance .\", sentence_starts=[0, 96, 228, 394, 539, 660], selected_sent={'start': 660, 'end': 784, 'string': 'Thus , the albatross can be both an omen of good or bad luck , as well as a metaphor for a burden to be carried as penance .'}, answer=[Entity(start_offset=693, end_offset=782, type='context', text='an omen of good or bad luck , as well as a metaphor for a burden to be carried as penance', normalized_text='omen of good or bad luck as well as metaphor for burden to be carried as penance')], nq_answers=[[Entity(start_offset=749, end_offset=782, type='context', text='a burden to be carried as penance', normalized_text='burden to be carried as penance')], [Entity(start_offset=696, end_offset=720, type='context', text='omen of good or bad luck', normalized_text='omen of good or bad luck'), Entity(start_offset=734, end_offset=782, type='context', text='a metaphor for a burden to be carried as penance', normalized_text='metaphor for burden to be carried as penance')]], aligned_nps=[(Entity(start_offset=32, end_offset=41, type='question', text='albatross', normalized_text='albatross'), Entity(start_offset=667, end_offset=680, type='context', text='the albatross', normalized_text='albatross')), (Entity(start_offset=0, end_offset=31, type='question', text='the rime of the ancient mariner', normalized_text='rime of ancient mariner'), Entity(start_offset=660, end_offset=664, type='context', text='Thus', normalized_text='thus'))], explanation_type='single_sentence'),\n",
       " 14177645587273144: QEDExample(example_id=14177645587273144, title='Evolution of the horse', question='when did equus first appear in fossil record', passage='The first Old World equid fossil was found in the gypsum quarries in Montmartre , Paris , in the 1820s . The tooth was sent to the Paris Conservatory , where it was identified by Georges Cuvier , who identified it as a browsing equine related to the tapir . His sketch of the entire animal matched later skeletons found at the site .', sentence_starts=[0, 105, 258], selected_sent={'start': 0, 'end': 105, 'string': 'The first Old World equid fossil was found in the gypsum quarries in Montmartre , Paris , in the 1820s . '}, answer=[Entity(start_offset=97, end_offset=102, type='context', text='1820s', normalized_text='1820s')], nq_answers=[[Entity(start_offset=97, end_offset=102, type='context', text='1820s', normalized_text='1820s')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3563945110717053326: QEDExample(example_id=-3563945110717053326, title='Remittance', question='sending money home to the native country is an example of', passage=\"A remittance is a transfer of money by a foreign worker to an individual in his or her home country . Money sent home by migrants competes with international aid as one of the largest financial inflows to developing countries . Workers ' remittances are a significant part of international capital flows , especially with regard to labour - exporting countries . In 2014 , $436 billion went to developing countries , setting a new record . Overall global remittances totaled $582 billion in 2015 . Some countries , such as India and China , receive tens of billions of US dollars in remittances each year from their expatriates and diaspora . In 2014 , India received an estimated $70 billion and China an estimated $64 billion .\", sentence_starts=[0, 102, 228, 363, 440, 498, 643], selected_sent={'start': 0, 'end': 102, 'string': 'A remittance is a transfer of money by a foreign worker to an individual in his or her home country . '}, answer=[Entity(start_offset=0, end_offset=12, type='context', text='A remittance', normalized_text='remittance')], nq_answers=[[Entity(start_offset=2, end_offset=12, type='context', text='remittance', normalized_text='remittance')], [Entity(start_offset=276, end_offset=303, type='context', text='international capital flows', normalized_text='international capital flows')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -6037882677543157353: QEDExample(example_id=-6037882677543157353, title='Foreign Account Tax Compliance Act', question='what is foreign account tax compliance act (fatca)', passage=\"The Foreign Account Tax Compliance Act ( FATCA ) is a 2010 United States federal law requiring all non-U.S. ( ' foreign ' ) financial institutions ( FFIs ) to search their records for customers with indicia of ' U.S. - person ' status , such as a U.S. place of birth , and to report the assets and identities of such persons to the U.S. Department of the Treasury . FATCA also requires such persons to self - report their non-U.S. financial assets annually to the Internal Revenue Service ( IRS ) on form 8938 , which is in addition to the older and further redundant requirement to self - report them annually to the Financial Crimes Enforcement Network ( FinCEN ) on form 114 ( also known as ' FBAR ' ) . Like U.S. income tax law , FATCA applies to U.S. residents and also to U.S. citizens and green card holders residing in other countries .\", sentence_starts=[0, 366, 707], selected_sent={'start': 0, 'end': 366, 'string': \"The Foreign Account Tax Compliance Act ( FATCA ) is a 2010 United States federal law requiring all non-U.S. ( ' foreign ' ) financial institutions ( FFIs ) to search their records for customers with indicia of ' U.S. - person ' status , such as a U.S. place of birth , and to report the assets and identities of such persons to the U.S. Department of the Treasury . \"}, answer=[Entity(start_offset=52, end_offset=363, type='context', text=\"a 2010 United States federal law requiring all non-U.S. ( ' foreign ' ) financial institutions ( FFIs ) to search their records for customers with indicia of ' U.S. - person ' status , such as a U.S. place of birth , and to report the assets and identities of such persons to the U.S. Department of the Treasury\", normalized_text='2010 united states federal law requiring all nonus foreign financial institutions ffis to search their records for customers with indicia of us person status such as us place of birth and to report assets and identities of such persons to us department of treasury')], nq_answers=[[Entity(start_offset=52, end_offset=363, type='context', text=\"a 2010 United States federal law requiring all non-U.S. ( ' foreign ' ) financial institutions ( FFIs ) to search their records for customers with indicia of ' U.S. - person ' status , such as a U.S. place of birth , and to report the assets and identities of such persons to the U.S. Department of the Treasury\", normalized_text='2010 united states federal law requiring all nonus foreign financial institutions ffis to search their records for customers with indicia of us person status such as us place of birth and to report assets and identities of such persons to us department of treasury')]], aligned_nps=[(Entity(start_offset=8, end_offset=50, type='question', text='foreign account tax compliance act (fatca)', normalized_text='foreign account tax compliance act fatca'), Entity(start_offset=0, end_offset=48, type='context', text='The Foreign Account Tax Compliance Act ( FATCA )', normalized_text='foreign account tax compliance act fatca'))], explanation_type='single_sentence'),\n",
       " 27330048533872728: QEDExample(example_id=27330048533872728, title='The Perks of Being a Wallflower', question='who was charlie writing to in perks of being a wallflower movie', passage='The story begins with a quiet , sensitive 15 - year - old boy named Charlie writing letters about his life to an unknown recipient . Charlie chooses that person because he said that he heard the person was nice and thought that this person would not be judgmental . He discusses his first year at high school , grappling with two traumatic experiences from his past : the suicide of his only middle - school friend , Michael Dobson , a year before , and the death of his favorite aunt , Helen , during his early childhood .', sentence_starts=[0, 133, 266], selected_sent={'start': 0, 'end': 133, 'string': 'The story begins with a quiet , sensitive 15 - year - old boy named Charlie writing letters about his life to an unknown recipient . '}, answer=[Entity(start_offset=110, end_offset=130, type='context', text='an unknown recipient', normalized_text='unknown recipient')], nq_answers=[[Entity(start_offset=110, end_offset=130, type='context', text='an unknown recipient', normalized_text='unknown recipient')]], aligned_nps=[(Entity(start_offset=8, end_offset=15, type='question', text='charlie', normalized_text='charlie'), Entity(start_offset=22, end_offset=75, type='context', text='a quiet , sensitive 15 - year - old boy named Charlie', normalized_text='quiet sensitive 15 year old boy named charlie')), (Entity(start_offset=27, end_offset=63, type='question', text='in perks of being a wallflower movie', normalized_text='in perks of being wallflower movie'), Entity(start_offset=0, end_offset=9, type='context', text='The story', normalized_text='story'))], explanation_type='single_sentence'),\n",
       " 3630480194417653112: QEDExample(example_id=3630480194417653112, title='The Real Thing (story)', question='what is henry james the real thing about', passage=\"`` The Real Thing '' is a short story by Henry James , first syndicated by S.S. McClure in multiple American newspapers and then published in the British publication Black and White in April 1892 and the following year as the title story in the collection , The Real Thing and Other Stories published by Macmillan . This story , often read as a parable , plays with the reality - illusion dichotomy that fascinated James , especially in the later stages of his career . For the illustrator who narrates the story , the genuine article proves all too useless for his commercial purposes . The story portrays the unfortunate victims of a society in which reality and representation are closely intertwined in ways that make art a difficult project to untangle the two .\", sentence_starts=[0, 80, 316, 470, 588], selected_sent={'start': 588, 'end': 767, 'string': 'The story portrays the unfortunate victims of a society in which reality and representation are closely intertwined in ways that make art a difficult project to untangle the two .'}, answer=[Entity(start_offset=607, end_offset=765, type='context', text='the unfortunate victims of a society in which reality and representation are closely intertwined in ways that make art a difficult project to untangle the two', normalized_text='unfortunate victims of society in which reality and representation are closely intertwined in ways that make art difficult project to untangle two')], nq_answers=[[Entity(start_offset=607, end_offset=765, type='context', text='the unfortunate victims of a society in which reality and representation are closely intertwined in ways that make art a difficult project to untangle the two', normalized_text='unfortunate victims of society in which reality and representation are closely intertwined in ways that make art difficult project to untangle two')]], aligned_nps=[(Entity(start_offset=8, end_offset=40, type='question', text='henry james the real thing about', normalized_text='henry james real thing about'), Entity(start_offset=588, end_offset=597, type='context', text='The story', normalized_text='story'))], explanation_type='single_sentence'),\n",
       " -6618900434743562612: QEDExample(example_id=-6618900434743562612, title='Greg Wise', question='who played mr. willoughby in sense and sensibility', passage='Matthew Gregory Wise ( born 15 May 1966 ) is an English actor and producer . He has appeared in many British television works , as well as several feature films ( notably the role of John Willoughby in Sense and Sensibility ) .', sentence_starts=[0, 77], selected_sent={'start': 77, 'end': 227, 'string': 'He has appeared in many British television works , as well as several feature films ( notably the role of John Willoughby in Sense and Sensibility ) .'}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='Matthew Gregory Wise', normalized_text='matthew gregory wise')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='Matthew Gregory Wise', normalized_text='matthew gregory wise')]], aligned_nps=[(Entity(start_offset=11, end_offset=25, type='question', text='mr. willoughby', normalized_text='mr willoughby'), Entity(start_offset=183, end_offset=198, type='context', text='John Willoughby', normalized_text='john willoughby')), (Entity(start_offset=29, end_offset=50, type='question', text='sense and sensibility', normalized_text='sense and sensibility'), Entity(start_offset=202, end_offset=223, type='context', text='Sense and Sensibility', normalized_text='sense and sensibility'))], explanation_type='single_sentence'),\n",
       " 4305916235259203400: QEDExample(example_id=4305916235259203400, title='Soviet Union', question='when did the soviet union start and end', passage='The Soviet Union ( Russian : Сове́тский Сою́з , tr . Sovetsky Soyuz , IPA : ( sɐˈvjɛt͡skjɪj sɐˈjus ) ( listen ) ) , officially the Union of Soviet Socialist Republics ( Russian : Сою́з Сове́тских Социалисти́ческих Респу́блик , tr . Soyuz Sovetskikh Sotsialisticheskikh Respublik , IPA : ( sɐˈjus sɐˈvjɛtskjɪx sətsɨəljɪsˈtjitɕɪskjɪx rjɪˈspubljɪk ) ( listen ) ) , abbreviated as USSR ( Russian : СССР , tr . SSSR ) , was a socialist state in Eurasia that existed from 1922 to 1991 . Nominally a union of multiple national Soviet republics , its government and economy were highly centralized . The country was a one - party state , governed by the Communist Party with Moscow as its capital in its largest republic , the Russian Soviet Federative Socialist Republic . The Russian nation had constitutionally equal status among the many nations of the union but exerted de facto dominance in various respects . Other major urban centres were Leningrad , Kiev , Minsk , Alma - Ata and Novosibirsk . The Soviet Union was one of the five recognized nuclear weapons states and possessed the largest stockpile of weapons of mass destruction . It was a founding permanent member of the United Nations Security Council , as well as a member of the Organization for Security and Co-operation in Europe ( OSCE ) and the leading member of the Council for Mutual Economic Assistance ( CMEA ) and the Warsaw Pact .', sentence_starts=[0, 53, 232, 406, 481, 592, 766, 908, 995, 1135], selected_sent={'start': 0, 'end': 481, 'string': 'The Soviet Union ( Russian : Сове́тский Сою́з , tr . Sovetsky Soyuz , IPA : ( sɐˈvjɛt͡skjɪj sɐˈjus ) ( listen ) ) , officially the Union of Soviet Socialist Republics ( Russian : Сою́з Сове́тских Социалисти́ческих Респу́блик , tr . Soyuz Sovetskikh Sotsialisticheskikh Respublik , IPA : ( sɐˈjus sɐˈvjɛtskjɪx sətsɨəljɪsˈtjitɕɪskjɪx rjɪˈspubljɪk ) ( listen ) ) , abbreviated as USSR ( Russian : СССР , tr . SSSR ) , was a socialist state in Eurasia that existed from 1922 to 1991 . '}, answer=[Entity(start_offset=461, end_offset=478, type='context', text='from 1922 to 1991', normalized_text='from 1922 to 1991')], nq_answers=[[Entity(start_offset=437, end_offset=447, type='context', text='in Eurasia', normalized_text='in eurasia')]], aligned_nps=[(Entity(start_offset=9, end_offset=25, type='question', text='the soviet union', normalized_text='soviet union'), Entity(start_offset=0, end_offset=16, type='context', text='The Soviet Union', normalized_text='soviet union'))], explanation_type='single_sentence'),\n",
       " 5035306782925064813: QEDExample(example_id=5035306782925064813, title='What Makes You Beautiful', question='where was one direction what makes you beautiful filmed', passage=\"The accompanying music video , directed by John Urbano , depicts One Direction spending time on a beach in Malibu , California . The music video was uploaded to YouTube on August 19 , 2011 and has accumulated more than 940 million views since it premiered . The clip garnered the group three MTV Video Music Awards at the 2012 ceremony . One Direction performed the song live on televised shows , at awards ceremonies , and on four of their major concert tours : Up All Night Tour ( 2011 -- 12 ) , Take Me Home Tour ( 2013 ) , Where We Are Tour ( 2014 ) and On the Road Again Tour ( 2015 ) . Harry performed the song his 2017 solo tour . Artists including the Piano Guys have covered `` What Makes You Beautiful '' .\", sentence_starts=[0, 129, 258, 338, 592, 638], selected_sent={'start': 0, 'end': 129, 'string': 'The accompanying music video , directed by John Urbano , depicts One Direction spending time on a beach in Malibu , California . '}, answer=[Entity(start_offset=107, end_offset=126, type='context', text='Malibu , California', normalized_text='malibu california')], nq_answers=[[Entity(start_offset=107, end_offset=126, type='context', text='Malibu , California', normalized_text='malibu california')]], aligned_nps=[(Entity(start_offset=10, end_offset=48, type='question', text='one direction what makes you beautiful', normalized_text='one direction what makes you beautiful'), Entity(start_offset=0, end_offset=28, type='context', text='The accompanying music video', normalized_text='accompanying music video'))], explanation_type='single_sentence'),\n",
       " -5083423407995797659: QEDExample(example_id=-5083423407995797659, title='Pertussis', question='when did they start vaccinating for whooping cough', passage='An estimated 16.3 million people worldwide were infected in 2015 . Most cases occur in the developing world , and people of all ages may be affected . In 2015 , it resulted in 58,700 deaths -- down from 138,000 deaths in 1990 . Nearly 0.5 % of infected children less than one year of age die . Outbreaks of the disease were first described in the 16th century . The bacterium that causes the infection was discovered in 1906 . The pertussis vaccine became available in the 1940s .', sentence_starts=[0, 67, 151, 228, 294, 362, 427], selected_sent={'start': 427, 'end': 480, 'string': 'The pertussis vaccine became available in the 1940s .'}, answer=[Entity(start_offset=469, end_offset=478, type='context', text='the 1940s', normalized_text='1940s')], nq_answers=[[Entity(start_offset=469, end_offset=478, type='context', text='the 1940s', normalized_text='1940s')]], aligned_nps=[(Entity(start_offset=36, end_offset=50, type='question', text='whooping cough', normalized_text='whooping cough'), Entity(start_offset=427, end_offset=448, type='context', text='The pertussis vaccine', normalized_text='pertussis vaccine'))], explanation_type='single_sentence'),\n",
       " -5269403993925950076: QEDExample(example_id=-5269403993925950076, title='Majority Leader of the New York State Senate', question='who is the new york state senate majority leader', passage=\"There was a lengthy dispute over the leadership of the Senate during June and July 2009 . On June 8 , 2009 , Democrats Hiram Monserrate and Pedro Espada , Jr. , joined the 30 Republican members of the State Senate to attempt to issue a motion to replace current Majority Leader Malcolm Smith with Minority Leader Dean Skelos . Following the precedent of 1913 , the temporary presidency and the majority leadership would have been separated again under this scenario . Since the office of Lieutenant Governor fell vacant after Lt. Gov. David Paterson succeeded to the governorship upon Gov. Eliot Spitzer 's resignation , the majority leaders ( Bruno , Skelos and Smith ) have acted as lieutenant governors . The motions put forward on June 8 also sought to select Pedro Espada as Temporary President of the State Senate , which would have installed him as acting lieutenant governor . The Democrats have disputed the legitimacy of the motions put forward on June 8 . The New York State Senate has been providing a running update of the legal proceedings since June 11 , 2009 . The dispute ended July 9 , 2009 , when Senator Espada announced he would return to the Democratic caucus and take on the position of majority leader , while it was also announced that former majority leader Malcolm Smith had assumed the title of president pro tempore , and John Sampson would serve as Democratic conference leader with the understanding he would assume the presidency at an undetermined future date . Following the 2010 election and the Republican victory in the Senate , Senator Dean Skelos from Long Island served as both Temporary President and Majority Leader , but resigned in May 2015 in the midst of corruption charges . The current majority leader , or president , is John J. Flanagan .\", sentence_starts=[0, 90, 327, 468, 708, 885, 967, 1077, 1495, 1722], selected_sent={'start': 1722, 'end': 1788, 'string': 'The current majority leader , or president , is John J. Flanagan .'}, answer=[Entity(start_offset=1770, end_offset=1786, type='context', text='John J. Flanagan', normalized_text='john j flanagan')], nq_answers=[[Entity(start_offset=1770, end_offset=1786, type='context', text='John J. Flanagan', normalized_text='john j flanagan')]], aligned_nps=[(Entity(start_offset=7, end_offset=48, type='question', text='the new york state senate majority leader', normalized_text='new york state senate majority leader'), Entity(start_offset=1722, end_offset=1749, type='context', text='The current majority leader', normalized_text='current majority leader'))], explanation_type='single_sentence'),\n",
       " 8308557182013290945: QEDExample(example_id=8308557182013290945, title='Core (optical fiber)', question='the core of an optical fiber has a', passage=\"The core of a conventional optical fiber is a cylinder of glass or plastic that runs along the fiber 's length . The core is surrounded by a medium with a lower index of refraction , typically a cladding of a different glass , or plastic . Light travelling in the core reflects from the core - cladding boundary due to total internal reflection , as long as the angle between the light and the boundary is less than the critical angle . As a result , the fiber transmits all rays that enter the fiber with a sufficiently small angle to the fiber 's axis . The limiting angle is called the acceptance angle , and the rays that are confined by the core / cladding boundary are called guided rays .\", sentence_starts=[0, 113, 240, 437, 556], selected_sent={'start': 0, 'end': 113, 'string': \"The core of a conventional optical fiber is a cylinder of glass or plastic that runs along the fiber 's length . \"}, answer=[Entity(start_offset=44, end_offset=110, type='context', text=\"a cylinder of glass or plastic that runs along the fiber 's length\", normalized_text='cylinder of glass or plastic that runs along fiber s length')], nq_answers=[[Entity(start_offset=46, end_offset=110, type='context', text=\"cylinder of glass or plastic that runs along the fiber 's length\", normalized_text='cylinder of glass or plastic that runs along fiber s length')]], aligned_nps=[(Entity(start_offset=0, end_offset=28, type='question', text='the core of an optical fiber', normalized_text='core of optical fiber'), Entity(start_offset=0, end_offset=40, type='context', text='The core of a conventional optical fiber', normalized_text='core of conventional optical fiber'))], explanation_type='single_sentence'),\n",
       " 8196940260721089488: QEDExample(example_id=8196940260721089488, title='Boy Scouts of America', question='which president of the united states was a boy scout', passage='Eagle Scout is the highest rank one can receive in BSA . A Scout who attains this rank is called an Eagle Scout . Since its introduction in 1911 , the Eagle Scout rank has been earned by more than two million young men . Requirements include earning at least 21 merit badges and demonstrating Scout Spirit through the Boy Scout Oath and Law , service , and leadership all before or by age 18 . This includes an extensive service project that the Scout plans , organizes , leads , and manages . Eagle Scouts are presented with a medal and a badge that visibly recognizes the accomplishments of the Scout . Additional recognition can be earned through Eagle Palms , awarded for completing additional tenure , leadership , and merit badge requirements . Many famous Americans are Eagle Scouts : astronaut Neil Armstrong , film director Michael Moore , TV host Mike Rowe , Steven Spielberg , Mayor Michael Bloomberg , Secretary of Defense Robert Gates , and President Gerald Ford are just a small sample of Eagle Scouts .', sentence_starts=[0, 57, 114, 221, 394, 494, 605, 751], selected_sent={'start': 751, 'end': 1017, 'string': 'Many famous Americans are Eagle Scouts : astronaut Neil Armstrong , film director Michael Moore , TV host Mike Rowe , Steven Spielberg , Mayor Michael Bloomberg , Secretary of Defense Robert Gates , and President Gerald Ford are just a small sample of Eagle Scouts .'}, answer=[Entity(start_offset=964, end_offset=975, type='context', text='Gerald Ford', normalized_text='gerald ford')], nq_answers=[[Entity(start_offset=964, end_offset=975, type='context', text='Gerald Ford', normalized_text='gerald ford')], [Entity(start_offset=954, end_offset=975, type='context', text='President Gerald Ford', normalized_text='president gerald ford')]], aligned_nps=[(Entity(start_offset=19, end_offset=36, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=751, end_offset=789, type='context', text='Many famous Americans are Eagle Scouts', normalized_text='many famous americans are eagle scouts'))], explanation_type='single_sentence'),\n",
       " 8553713904242169921: QEDExample(example_id=8553713904242169921, title='Orozco', question='where does the last name orozco originate from', passage='Orozco is of Spanish / Basque origin . Notable people with the surname include :', sentence_starts=[0, 39], selected_sent={'start': 0, 'end': 39, 'string': 'Orozco is of Spanish / Basque origin . '}, answer=[Entity(start_offset=13, end_offset=29, type='context', text='Spanish / Basque', normalized_text='spanish basque')], nq_answers=[[Entity(start_offset=13, end_offset=36, type='context', text='Spanish / Basque origin', normalized_text='spanish basque origin')]], aligned_nps=[(Entity(start_offset=11, end_offset=31, type='question', text='the last name orozco', normalized_text='last name orozco'), Entity(start_offset=0, end_offset=6, type='context', text='Orozco', normalized_text='orozco'))], explanation_type='single_sentence'),\n",
       " 8624898251093284247: QEDExample(example_id=8624898251093284247, title='The Bronx', question='which river separates the bronx in new york city from manhattan island', passage='The Bronx ( / brɒŋks / ) is the northernmost of the five boroughs of New York City , in the U.S. state of New York . It is south of Westchester County ; north and east of Manhattan , across the Harlem River ; and north of Queens , across the East River . Since 1914 , the borough has had the same boundaries as Bronx County , the third-most densely populated county in the United States .', sentence_starts=[0, 117, 255], selected_sent={'start': 117, 'end': 255, 'string': 'It is south of Westchester County ; north and east of Manhattan , across the Harlem River ; and north of Queens , across the East River . '}, answer=[Entity(start_offset=190, end_offset=206, type='context', text='the Harlem River', normalized_text='harlem river')], nq_answers=[[Entity(start_offset=194, end_offset=206, type='context', text='Harlem River', normalized_text='harlem river')], [Entity(start_offset=190, end_offset=206, type='context', text='the Harlem River', normalized_text='harlem river')]], aligned_nps=[(Entity(start_offset=22, end_offset=48, type='question', text='the bronx in new york city', normalized_text='bronx in new york city'), Entity(start_offset=117, end_offset=119, type='context', text='It', normalized_text='it')), (Entity(start_offset=54, end_offset=70, type='question', text='manhattan island', normalized_text='manhattan island'), Entity(start_offset=171, end_offset=180, type='context', text='Manhattan', normalized_text='manhattan'))], explanation_type='single_sentence'),\n",
       " -5061926765893337070: QEDExample(example_id=-5061926765893337070, title='Red wolf', question='where does the red wolf live in the world', passage='The red wolf ( Canis rufus or Canis lupus rufus ) , also known as the Florida black wolf or Mississippi Valley wolf , is a canid native to the southeastern United States of unresolved taxonomic identity . Morphologically it is intermediate between the coyote and gray wolf , and is of a reddish , tawny color . The Red Wolf is a federally listed endangered species of the United States and is protected by law . It has been listed by IUCN as a critically endangered species since 1996 . It is considered the rarest species of wolf and is one of the five most endangered species of wolf in the world .', sentence_starts=[0, 205, 311, 412, 487], selected_sent={'start': 0, 'end': 205, 'string': 'The red wolf ( Canis rufus or Canis lupus rufus ) , also known as the Florida black wolf or Mississippi Valley wolf , is a canid native to the southeastern United States of unresolved taxonomic identity . '}, answer=[Entity(start_offset=139, end_offset=169, type='context', text='the southeastern United States', normalized_text='southeastern united states')], nq_answers=[[Entity(start_offset=139, end_offset=169, type='context', text='the southeastern United States', normalized_text='southeastern united states')], [Entity(start_offset=143, end_offset=169, type='context', text='southeastern United States', normalized_text='southeastern united states')]], aligned_nps=[(Entity(start_offset=11, end_offset=23, type='question', text='the red wolf', normalized_text='red wolf'), Entity(start_offset=0, end_offset=49, type='context', text='The red wolf ( Canis rufus or Canis lupus rufus )', normalized_text='red wolf canis rufus or canis lupus rufus'))], explanation_type='single_sentence'),\n",
       " -7066978684275822190: QEDExample(example_id=-7066978684275822190, title='Escherichia coli', question='what is the full scientific name for the e. coli bacteria', passage='Escherichia coli ( / ˌɛʃɪˈrɪkiə ˈkoʊlaɪ / ; also known as E. coli ) is a Gram - negative , facultatively anaerobic , rod - shaped , coliform bacterium of the genus Escherichia that is commonly found in the lower intestine of warm - blooded organisms ( endotherms ) . Most E. coli strains are harmless , but some serotypes can cause serious food poisoning in their hosts , and are occasionally responsible for product recalls due to food contamination . The harmless strains are part of the normal flora of the gut , and can benefit their hosts by producing vitamin K , and preventing colonization of the intestine with pathogenic bacteria , having a symbiotic relationship . E. coli is expelled into the environment within fecal matter . The bacterium grows massively in fresh fecal matter under aerobic conditions for 3 days , but its numbers decline slowly afterwards .', sentence_starts=[0, 267, 453, 675, 738], selected_sent={'start': 0, 'end': 267, 'string': 'Escherichia coli ( / ˌɛʃɪˈrɪkiə ˈkoʊlaɪ / ; also known as E. coli ) is a Gram - negative , facultatively anaerobic , rod - shaped , coliform bacterium of the genus Escherichia that is commonly found in the lower intestine of warm - blooded organisms ( endotherms ) . '}, answer=[Entity(start_offset=0, end_offset=16, type='context', text='Escherichia coli', normalized_text='escherichia coli')], nq_answers=[[Entity(start_offset=0, end_offset=16, type='context', text='Escherichia coli', normalized_text='escherichia coli')]], aligned_nps=[(Entity(start_offset=37, end_offset=57, type='question', text='the e. coli bacteria', normalized_text='e coli bacteria'), Entity(start_offset=58, end_offset=65, type='context', text='E. coli', normalized_text='e coli'))], explanation_type='single_sentence'),\n",
       " -7729388021714760854: QEDExample(example_id=-7729388021714760854, title='Rock and Roll Hall of Fame', question='when was the rock and roll hall of fame built in cleveland', passage=\"The Rock and Roll Hall of Fame , located on the shore of Lake Erie in downtown Cleveland , Ohio , recognizes and archives the history of the best - known and most influential artists , producers , engineers , and other notable figures who have had some major influence on the development of rock and roll . The Rock and Roll Hall of Fame Foundation was established on April 20 , 1983 , by Atlantic Records founder and chairman Ahmet Ertegun . In 1986 , Cleveland was chosen as the Hall of Fame 's permanent home . Since opening in September 1995 , the `` Rock Hall '' -- part of the city 's redeveloped North Coast Harbor -- has hosted more than 10 million visitors and had a cumulative economic impact estimated at more than $1.8 billion .\", sentence_starts=[0, 307, 443, 514], selected_sent={'start': 514, 'end': 740, 'string': \"Since opening in September 1995 , the `` Rock Hall '' -- part of the city 's redeveloped North Coast Harbor -- has hosted more than 10 million visitors and had a cumulative economic impact estimated at more than $1.8 billion .\"}, answer=[Entity(start_offset=531, end_offset=545, type='context', text='September 1995', normalized_text='september 1995')], nq_answers=[[Entity(start_offset=531, end_offset=545, type='context', text='September 1995', normalized_text='september 1995')], [Entity(start_offset=41, end_offset=78, type='context', text='on the shore of Lake Erie in downtown', normalized_text='on shore of lake erie in downtown')], [Entity(start_offset=541, end_offset=545, type='context', text='1995', normalized_text='1995')]], aligned_nps=[(Entity(start_offset=9, end_offset=39, type='question', text='the rock and roll hall of fame', normalized_text='rock and roll hall of fame'), Entity(start_offset=548, end_offset=567, type='context', text=\"the `` Rock Hall ''\", normalized_text='rock hall')), (Entity(start_offset=49, end_offset=58, type='question', text='cleveland', normalized_text='cleveland'), Entity(start_offset=520, end_offset=527, type='context', text='opening', normalized_text='opening'))], explanation_type='single_sentence'),\n",
       " -1367137361753059601: QEDExample(example_id=-1367137361753059601, title='Doreen Mantle', question='who played mrs warboys in one foot in the grave', passage='Doreen Mantle ( born 1926 ) is a South African - born English actress who is probably best known for her role as Jean Warboys in One Foot in the Grave ( 1990 -- 2000 ) .', sentence_starts=[0], selected_sent={'start': 0, 'end': 169, 'string': 'Doreen Mantle ( born 1926 ) is a South African - born English actress who is probably best known for her role as Jean Warboys in One Foot in the Grave ( 1990 -- 2000 ) .'}, answer=[Entity(start_offset=0, end_offset=13, type='context', text='Doreen Mantle', normalized_text='doreen mantle')], nq_answers=[[Entity(start_offset=0, end_offset=13, type='context', text='Doreen Mantle', normalized_text='doreen mantle')]], aligned_nps=[(Entity(start_offset=11, end_offset=22, type='question', text='mrs warboys', normalized_text='mrs warboys'), Entity(start_offset=113, end_offset=125, type='context', text='Jean Warboys', normalized_text='jean warboys')), (Entity(start_offset=26, end_offset=47, type='question', text='one foot in the grave', normalized_text='one foot in grave'), Entity(start_offset=129, end_offset=150, type='context', text='One Foot in the Grave', normalized_text='one foot in grave'))], explanation_type='single_sentence'),\n",
       " -1285885938956879930: QEDExample(example_id=-1285885938956879930, title='Game of Thrones', question='what is the time setting of game of thrones', passage=\"The series is generally praised for what is perceived as a sort of medieval realism . George R.R. Martin set out to make the story feel more like historical fiction than contemporary fantasy , with less emphasis on magic and sorcery and more on battles , political intrigue , and the characters , believing that magic should be used moderately in the epic fantasy genre . Martin has stated that `` the true horrors of human history derive not from orcs and Dark Lords , but from ourselves . ''\", sentence_starts=[0, 86, 98, 372], selected_sent={'start': 0, 'end': 86, 'string': 'The series is generally praised for what is perceived as a sort of medieval realism . '}, answer=[Entity(start_offset=59, end_offset=75, type='context', text='sort of medieval', normalized_text='sort of medieval')], nq_answers=[[Entity(start_offset=67, end_offset=75, type='context', text='medieval', normalized_text='medieval')]], aligned_nps=[(Entity(start_offset=28, end_offset=43, type='question', text='game of thrones', normalized_text='game of thrones'), Entity(start_offset=0, end_offset=10, type='context', text='The series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " -2281675922136458544: QEDExample(example_id=-2281675922136458544, title='Arsenic and Old Lace (play)', question='where does arsenic and old lace take place', passage='The play is a farcical black comedy revolving around the Brewster family , descended from the Mayflower , but now composed of insane homicidal maniacs . The hero , Mortimer Brewster , is a drama critic who must deal with his crazy , homicidal family and local police in Brooklyn , New York , as he debates whether to go through with his recent promise to marry the woman he loves .', sentence_starts=[0, 153], selected_sent={'start': 153, 'end': 381, 'string': 'The hero , Mortimer Brewster , is a drama critic who must deal with his crazy , homicidal family and local police in Brooklyn , New York , as he debates whether to go through with his recent promise to marry the woman he loves .'}, answer=[Entity(start_offset=270, end_offset=289, type='context', text='Brooklyn , New York', normalized_text='brooklyn new york')], nq_answers=[[Entity(start_offset=270, end_offset=289, type='context', text='Brooklyn , New York', normalized_text='brooklyn new york')]], aligned_nps=[(Entity(start_offset=11, end_offset=31, type='question', text='arsenic and old lace', normalized_text='arsenic and old lace'), Entity(start_offset=153, end_offset=161, type='context', text='The hero', normalized_text='hero'))], explanation_type='single_sentence'),\n",
       " 6605227747829720945: QEDExample(example_id=6605227747829720945, title='Cricket bat', question='what is the width of a cricket bat', passage='A cricket bat is a specialised piece of equipment used by batsmen in the sport of cricket to hit the ball , typically consisting of a cane handle attached to a flat - fronted willow - wood blade . The length of the bat may be no more than 38 inches ( 965 mm ) and the width no more than 4.25 inches ( 108 mm ) . Its use is first mentioned in 1624 . Since 1979 , a rule change stipulated that bats can only be made from wood .', sentence_starts=[0, 197, 312, 349], selected_sent={'start': 197, 'end': 312, 'string': 'The length of the bat may be no more than 38 inches ( 965 mm ) and the width no more than 4.25 inches ( 108 mm ) . '}, answer=[Entity(start_offset=274, end_offset=309, type='context', text='no more than 4.25 inches ( 108 mm )', normalized_text='no more than 425 inches 108 mm')], nq_answers=[[Entity(start_offset=274, end_offset=309, type='context', text='no more than 4.25 inches ( 108 mm )', normalized_text='no more than 425 inches 108 mm')], [Entity(start_offset=274, end_offset=298, type='context', text='no more than 4.25 inches', normalized_text='no more than 425 inches')], [Entity(start_offset=287, end_offset=309, type='context', text='4.25 inches ( 108 mm )', normalized_text='425 inches 108 mm')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text='the width of a cricket bat', normalized_text='width of cricket bat'), Entity(start_offset=264, end_offset=273, type='context', text='the width', normalized_text='width'))], explanation_type='single_sentence'),\n",
       " -1373652773107850061: QEDExample(example_id=-1373652773107850061, title='Along Came a Spider (film)', question='who played alex cross in along came a spider', passage='Along Came a Spider is a 2001 American neo noir psychological thriller film directed by Lee Tamahori . It is a sequel to the 1997 film Kiss the Girls , with Morgan Freeman reprising his role as detective Alex Cross . The screenplay by Marc Moss was adapted from the 1993 novel of the same title by James Patterson , but many of the key plot elements of the book were controversially eliminated . The movie received negative to mixed critical reviews , although it became a box office success .', sentence_starts=[0, 103, 217, 396], selected_sent={'start': 103, 'end': 217, 'string': 'It is a sequel to the 1997 film Kiss the Girls , with Morgan Freeman reprising his role as detective Alex Cross . '}, answer=[Entity(start_offset=157, end_offset=171, type='context', text='Morgan Freeman', normalized_text='morgan freeman')], nq_answers=[[Entity(start_offset=157, end_offset=171, type='context', text='Morgan Freeman', normalized_text='morgan freeman')]], aligned_nps=[(Entity(start_offset=25, end_offset=44, type='question', text='along came a spider', normalized_text='along came spider'), Entity(start_offset=103, end_offset=105, type='context', text='It', normalized_text='it')), (Entity(start_offset=11, end_offset=21, type='question', text='alex cross', normalized_text='alex cross'), Entity(start_offset=194, end_offset=214, type='context', text='detective Alex Cross', normalized_text='detective alex cross'))], explanation_type='single_sentence'),\n",
       " 6486446244503815045: QEDExample(example_id=6486446244503815045, title='Israeli Declaration of Independence', question='who was the first signatory of the israeli declaration of independence', passage=\"As leader of the Yishuv , David Ben - Gurion was the first person to sign . The declaration was due to be signed by all 37 members of Moetzet HaAm . However , twelve members could not attend , eleven of them trapped in besieged Jerusalem and one abroad . The remaining 25 signatories present were called up in alphabetical order to sign , leaving spaces for those absent . Although a space was left for him between the signatures of Eliyahu Dobkin and Meir Vilner , Zerach Warhaftig signed at the top of the next column , leading to speculation that Vilner 's name had been left alone to isolate him , or to stress that even a communist agreed with the declaration . However , Warhaftig later denied this , stating that a space had been left for him ( as he was one of the signatories trapped in Jerusalem ) where a Hebraicised form of his name would have fitted alphabetically , but he insisted on signing under his actual name so as to honour his father 's memory and so moved down two spaces . He and Vilner would be the last surviving signatories , and remained close for the rest of their lives . Of the signatories , two were women ( Golda Meir ( Meyerson / Myerson ) and Rachel Cohen - Kagan ) .\", sentence_starts=[0, 76, 149, 255, 373, 667, 997, 1102], selected_sent={'start': 0, 'end': 76, 'string': 'As leader of the Yishuv , David Ben - Gurion was the first person to sign . '}, answer=[Entity(start_offset=26, end_offset=44, type='context', text='David Ben - Gurion', normalized_text='david ben gurion')], nq_answers=[[Entity(start_offset=26, end_offset=44, type='context', text='David Ben - Gurion', normalized_text='david ben gurion')]], aligned_nps=[(Entity(start_offset=31, end_offset=70, type='question', text='the israeli declaration of independence', normalized_text='israeli declaration of independence'), Entity(start_offset=69, end_offset=73, type='context', text='sign', normalized_text='sign'))], explanation_type='single_sentence'),\n",
       " 1023450971555923009: QEDExample(example_id=1023450971555923009, title='History of the periodic table', question='who came up with the first working periodic table', passage='The history of the periodic table reflects over a century of growth in the understanding of chemical properties . The most important event in its history occurred in 1869 , when the table was published by Dmitri Mendeleev , who built upon earlier discoveries by scientists such as Antoine - Laurent de Lavoisier and John Newlands , but who is nevertheless generally given sole credit for its development .', sentence_starts=[0, 114], selected_sent={'start': 114, 'end': 405, 'string': 'The most important event in its history occurred in 1869 , when the table was published by Dmitri Mendeleev , who built upon earlier discoveries by scientists such as Antoine - Laurent de Lavoisier and John Newlands , but who is nevertheless generally given sole credit for its development .'}, answer=[Entity(start_offset=205, end_offset=221, type='context', text='Dmitri Mendeleev', normalized_text='dmitri mendeleev')], nq_answers=[[Entity(start_offset=205, end_offset=221, type='context', text='Dmitri Mendeleev', normalized_text='dmitri mendeleev')]], aligned_nps=[(Entity(start_offset=17, end_offset=49, type='question', text='the first working periodic table', normalized_text='first working periodic table'), Entity(start_offset=178, end_offset=187, type='context', text='the table', normalized_text='table'))], explanation_type='single_sentence'),\n",
       " -2495593332815009891: QEDExample(example_id=-2495593332815009891, title='Thumb twiddling', question='what does it mean when you roll your thumbs', passage=\"While it is an expression of at least a moderate amount of manual dexterity , thumb twiddling is frequently used as an example of a useless , time - wasting activity . It has even been proposed as `` the ultimate exercise for the bored and lazy '' .\", sentence_starts=[0, 168], selected_sent={'start': 0, 'end': 168, 'string': 'While it is an expression of at least a moderate amount of manual dexterity , thumb twiddling is frequently used as an example of a useless , time - wasting activity . '}, answer=[Entity(start_offset=97, end_offset=165, type='context', text='frequently used as an example of a useless , time - wasting activity', normalized_text='frequently used as example of useless time wasting activity')], nq_answers=[[Entity(start_offset=116, end_offset=165, type='context', text='an example of a useless , time - wasting activity', normalized_text='example of useless time wasting activity')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2885278237105070353: QEDExample(example_id=2885278237105070353, title='Freedom of the City', question='what does the keys to the city mean', passage=\"In some countries , such as the United States , an ornamental key -- the `` Key to the City '' -- is presented to esteemed visitors , residents , or others whom the city wishes to honour . This practice is a variation on the Freedom of the City tradition , and has a similar symbolic meaning ; evoking medieval walled cities , the gates of which would be guarded during the day and locked at night , the key symbolises the freedom of the recipient to enter and leave the city at will , as a trusted friend of city residents .\", sentence_starts=[0, 189], selected_sent={'start': 189, 'end': 525, 'string': 'This practice is a variation on the Freedom of the City tradition , and has a similar symbolic meaning ; evoking medieval walled cities , the gates of which would be guarded during the day and locked at night , the key symbolises the freedom of the recipient to enter and leave the city at will , as a trusted friend of city residents .'}, answer=[Entity(start_offset=408, end_offset=523, type='context', text='symbolises the freedom of the recipient to enter and leave the city at will , as a trusted friend of city residents', normalized_text='symbolises freedom of recipient to enter and leave city at will as trusted friend of city residents')], nq_answers=[[Entity(start_offset=408, end_offset=523, type='context', text='symbolises the freedom of the recipient to enter and leave the city at will , as a trusted friend of city residents', normalized_text='symbolises freedom of recipient to enter and leave city at will as trusted friend of city residents')], [Entity(start_offset=294, end_offset=523, type='context', text='evoking medieval walled cities , the gates of which would be guarded during the day and locked at night , the key symbolises the freedom of the recipient to enter and leave the city at will , as a trusted friend of city residents', normalized_text='evoking medieval walled cities gates of which would be guarded during day and locked at night key symbolises freedom of recipient to enter and leave city at will as trusted friend of city residents')]], aligned_nps=[(Entity(start_offset=10, end_offset=30, type='question', text='the keys to the city', normalized_text='keys to city'), Entity(start_offset=400, end_offset=407, type='context', text='the key', normalized_text='key'))], explanation_type='single_sentence'),\n",
       " 1615626468308135253: QEDExample(example_id=1615626468308135253, title='Topographic map', question='what is one element a topographic map shows', passage='In modern mapping , a topographic map is a type of map characterized by large - scale detail and quantitative representation of relief , usually using contour lines , but historically using a variety of methods . Traditional definitions require a topographic map to show both natural and man - made features . A topographic map is typically published as a map series , made up of two or more map sheets that combine to form the whole map . A contour line is a line connecting places of equal elevation .', sentence_starts=[0, 213, 310, 440], selected_sent={'start': 0, 'end': 213, 'string': 'In modern mapping , a topographic map is a type of map characterized by large - scale detail and quantitative representation of relief , usually using contour lines , but historically using a variety of methods . '}, answer=[Entity(start_offset=128, end_offset=134, type='context', text='relief', normalized_text='relief')], nq_answers=[[Entity(start_offset=128, end_offset=134, type='context', text='relief', normalized_text='relief')]], aligned_nps=[(Entity(start_offset=20, end_offset=37, type='question', text='a topographic map', normalized_text='topographic map'), Entity(start_offset=20, end_offset=37, type='context', text='a topographic map', normalized_text='topographic map'))], explanation_type='single_sentence'),\n",
       " 8848582210866367992: QEDExample(example_id=8848582210866367992, title='2017 Nobel Peace Prize', question='who won the nobel peace prize for 2017', passage=\"The 2017 Nobel Peace Prize was awarded to the International Campaign to Abolish Nuclear Weapons ( ICAN ) `` for its work to draw attention to the catastrophic humanitarian consequences of any use of nuclear weapons and for its ground - breaking efforts to achieve a treaty - based prohibition on such weapons , '' according to the Norwegian Nobel Committee announcement on October 6 , 2017 . The award announcement acknowledged the fact that `` the world 's nine nuclear - armed powers and their allies '' neither signed nor supported the treaty - based prohibition known as the Treaty on the Prohibition of Nuclear Weapons or nuclear ban treaty , yet in an interview Committee Chair Berit Reiss - Andersen told reporters that the award was intended to give `` encouragement to all players in the field '' to disarm . The award was hailed by civil society as well as governmental and intergovernmental representatives who support the nuclear ban treaty , but drew criticism from those opposed . At the Nobel Peace Prize award ceremony held in Oslo City Hall on December 10 , 2017 , Setsuko Thurlow , an 85 - year - old survivor of the 1945 atomic bombing of Hiroshima , and ICAN Executive Director Beatrice Fihn jointly received a medal and diploma of the award on behalf of ICAN and delivered the Nobel lecture .\", sentence_starts=[0, 392, 818, 995], selected_sent={'start': 0, 'end': 392, 'string': \"The 2017 Nobel Peace Prize was awarded to the International Campaign to Abolish Nuclear Weapons ( ICAN ) `` for its work to draw attention to the catastrophic humanitarian consequences of any use of nuclear weapons and for its ground - breaking efforts to achieve a treaty - based prohibition on such weapons , '' according to the Norwegian Nobel Committee announcement on October 6 , 2017 . \"}, answer=[Entity(start_offset=42, end_offset=104, type='context', text='the International Campaign to Abolish Nuclear Weapons ( ICAN )', normalized_text='international campaign to abolish nuclear weapons ican')], nq_answers=[[Entity(start_offset=42, end_offset=104, type='context', text='the International Campaign to Abolish Nuclear Weapons ( ICAN )', normalized_text='international campaign to abolish nuclear weapons ican')], [Entity(start_offset=46, end_offset=104, type='context', text='International Campaign to Abolish Nuclear Weapons ( ICAN )', normalized_text='international campaign to abolish nuclear weapons ican')]], aligned_nps=[(Entity(start_offset=8, end_offset=38, type='question', text='the nobel peace prize for 2017', normalized_text='nobel peace prize for 2017'), Entity(start_offset=0, end_offset=26, type='context', text='The 2017 Nobel Peace Prize', normalized_text='2017 nobel peace prize'))], explanation_type='single_sentence'),\n",
       " 6077371157930183398: QEDExample(example_id=6077371157930183398, title='Justice League (Smallville)', question='when does clark meet the flash in smallville', passage=\"Although the Justice League first appeared in season six 's `` Justice '' , each member had their own introduction and recurring storylines in the series prior to the formation of the team . The first member to appear on Smallville , other than Clark Kent ( Tom Welling ) , was Bart Allen ( Kyle Gallner ) , who was introduced in the season four episode `` Run '' . In the episode , Bart is the first person Clark discovers to have a superhuman ability -- being able to run at supersonic speeds -- that was not created from exposure to kryptonite . When Clark and Bart first meet , Bart is a pickpocket who saves Jonathan Kent ( John Schneider ) from being hit by a truck . Eventually , Clark convinces Bart to give up his life of crime . Arthur Curry ( Alan Ritchson ) , who has the ability to swim at superhuman speeds and create energy blasts through the water , is next to appear in the season five episode `` Aqua '' . Arthur arrives in Smallville to stop an underwater weapon developed by Lex Luthor ( Michael Rosenbaum ) , which is killing the surrounding ocean life . Arthur and Clark initially clash on Arthur 's tactics ; Arthur tries to blow up Lex 's lab , while Clark insists that they should simply talk to Lex face - to - face and ask him to stop . Eventually , Arthur and Clark locate and destroy the weapon outright . Season five also introduced Victor Stone ( Lee Thompson Young ) in the episode `` Cyborg '' . Here , it is revealed that Victor was mortally wounded in a car accident that also took the lives of his family , but Lex 's company , LuthorCorp , took Victor 's body to a research lab where they experimented on him -- ultimately replacing his bone skeleton with a metal one . Clark attempts to provide Victor with a safe haven after Victor escapes from Lex 's facility . Clark manages to convince Lex to stop hunting Victor , who eventually leaves Smallville with his girlfriend .\", sentence_starts=[0, 191, 366, 549, 674, 739, 924, 1076, 1264, 1335, 1429, 1707, 1802], selected_sent={'start': 366, 'end': 549, 'string': 'In the episode , Bart is the first person Clark discovers to have a superhuman ability -- being able to run at supersonic speeds -- that was not created from exposure to kryptonite . '}, answer=[Entity(start_offset=330, end_offset=363, type='context', text=\"the season four episode `` Run ''\", normalized_text='season four episode run')], nq_answers=[[Entity(start_offset=330, end_offset=363, type='context', text=\"the season four episode `` Run ''\", normalized_text='season four episode run')]], aligned_nps=[(Entity(start_offset=21, end_offset=30, type='question', text='the flash', normalized_text='flash'), Entity(start_offset=383, end_offset=387, type='context', text='Bart', normalized_text='bart')), (Entity(start_offset=10, end_offset=15, type='question', text='clark', normalized_text='clark'), Entity(start_offset=408, end_offset=413, type='context', text='Clark', normalized_text='clark')), (Entity(start_offset=34, end_offset=44, type='question', text='smallville', normalized_text='smallville'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2723133941683365826: QEDExample(example_id=-2723133941683365826, title='Boston Tea Party', question='why did the colonists have a problem with the tea act of 1773', passage=\"The Tea Party was the culmination of a resistance movement throughout British America against the Tea Act , which had been passed by the British Parliament in 1773 . Colonists objected to the Tea Act because they believed that it violated their rights as Englishmen to `` No taxation without representation '' , that is , to be taxed only by their own elected representatives and not by a British parliament in which they were not represented . In addition , the well - connected East India Company had been granted competitive advantages over colonial tea importers , who resented the move and feared additional infringement on their business . Protesters had successfully prevented the unloading of taxed tea in three other colonies , but in Boston , embattled Royal Governor Thomas Hutchinson refused to allow the tea to be returned to Britain .\", sentence_starts=[0, 166, 445, 646], selected_sent={'start': 166, 'end': 445, 'string': \"Colonists objected to the Tea Act because they believed that it violated their rights as Englishmen to `` No taxation without representation '' , that is , to be taxed only by their own elected representatives and not by a British parliament in which they were not represented . \"}, answer=[Entity(start_offset=208, end_offset=442, type='context', text=\"they believed that it violated their rights as Englishmen to `` No taxation without representation '' , that is , to be taxed only by their own elected representatives and not by a British parliament in which they were not represented\", normalized_text='they believed that it violated their rights as englishmen to no taxation without representation that is to be taxed only by their own elected representatives and not by british parliament in which they were not represented')], nq_answers=[[Entity(start_offset=200, end_offset=442, type='context', text=\"because they believed that it violated their rights as Englishmen to `` No taxation without representation '' , that is , to be taxed only by their own elected representatives and not by a British parliament in which they were not represented\", normalized_text='because they believed that it violated their rights as englishmen to no taxation without representation that is to be taxed only by their own elected representatives and not by british parliament in which they were not represented')]], aligned_nps=[(Entity(start_offset=8, end_offset=21, type='question', text='the colonists', normalized_text='colonists'), Entity(start_offset=166, end_offset=175, type='context', text='Colonists', normalized_text='colonists')), (Entity(start_offset=42, end_offset=61, type='question', text='the tea act of 1773', normalized_text='tea act of 1773'), Entity(start_offset=188, end_offset=199, type='context', text='the Tea Act', normalized_text='tea act'))], explanation_type='single_sentence'),\n",
       " -3343520513831734535: QEDExample(example_id=-3343520513831734535, title='Easter egg', question='who started the tradition of coloring easter eggs', passage=\"Easter eggs , also called Paschal eggs , are decorated eggs that are usually used as gifts on the occasion of Easter . As such , Easter eggs are common during the season of Eastertide ( Easter season ) . The oldest tradition is to use dyed and painted chicken eggs , but a modern custom is to substitute chocolate eggs wrapped in colourful foil , hand - carved wooden eggs , or plastic eggs filled with confectionery such as chocolate . However , real eggs continue to be used in Eastern European tradition . Although eggs , in general , were a traditional symbol of fertility and rebirth , in Christianity , for the celebration of Eastertide , Easter eggs symbolize the empty tomb of Jesus , from which Jesus resurrected . In addition , one ancient tradition was the staining of Easter eggs with the colour red `` in memory of the blood of Christ , shed as at that time of his crucifixion . '' This custom of the Easter egg can be traced to early Christians of Mesopotamia , and from there it spread into Russia and Siberia through the Orthodox Churches , and later into Europe through the Catholic and Protestant Churches . This Christian use of eggs may have been influenced by practices in `` pre-dynastic period in Egypt , as well as amid the early cultures of Mesopotamia and Crete '' .\", sentence_starts=[0, 119, 204, 437, 509, 724, 895, 1126], selected_sent={'start': 895, 'end': 1126, 'string': 'This custom of the Easter egg can be traced to early Christians of Mesopotamia , and from there it spread into Russia and Siberia through the Orthodox Churches , and later into Europe through the Catholic and Protestant Churches . '}, answer=[Entity(start_offset=942, end_offset=973, type='context', text='early Christians of Mesopotamia', normalized_text='early christians of mesopotamia')], nq_answers=[[Entity(start_offset=942, end_offset=973, type='context', text='early Christians of Mesopotamia', normalized_text='early christians of mesopotamia')]], aligned_nps=[(Entity(start_offset=12, end_offset=49, type='question', text='the tradition of coloring easter eggs', normalized_text='tradition of coloring easter eggs'), Entity(start_offset=895, end_offset=924, type='context', text='This custom of the Easter egg', normalized_text='this custom of easter egg'))], explanation_type='single_sentence'),\n",
       " 4941105400369114094: QEDExample(example_id=4941105400369114094, title='British Hong Kong', question='why was hong kong important to the british empire', passage=\"The stability , security , and predictability of British law and government enabled Hong Kong to flourish as a centre for international trade . In the colony 's first decade , the revenue from the opium trade was a key source of government funds . The importance of opium reduced over time , but the colonial government was dependent on its revenues until the Japanese occupation in 1941 . Although the largest businesses in the early colony were operated by British , American , and other expatriates , Chinese workers provided the bulk of the manpower to build a new port city .\", sentence_starts=[0, 144, 248, 390], selected_sent={'start': 144, 'end': 248, 'string': \"In the colony 's first decade , the revenue from the opium trade was a key source of government funds . \"}, answer=[Entity(start_offset=176, end_offset=245, type='context', text='the revenue from the opium trade was a key source of government funds', normalized_text='revenue from opium trade was key source of government funds')], nq_answers=[[Entity(start_offset=109, end_offset=141, type='context', text='a centre for international trade', normalized_text='centre for international trade')]], aligned_nps=[(Entity(start_offset=8, end_offset=17, type='question', text='hong kong', normalized_text='hong kong'), Entity(start_offset=147, end_offset=157, type='context', text='the colony', normalized_text='colony')), (Entity(start_offset=31, end_offset=49, type='question', text='the british empire', normalized_text='british empire'), Entity(start_offset=229, end_offset=245, type='context', text='government funds', normalized_text='government funds'))], explanation_type='single_sentence'),\n",
       " 3116877022765338485: QEDExample(example_id=3116877022765338485, title='Chymotrypsin', question='where does cleavage of the peptide bond by chymotrypsin occur', passage=\"Chymotrypsin ( EC 3.4. 21.1 , chymotrypsins A and B , alpha - chymar ophth , avazyme , chymar , chymotest , enzeon , quimar , quimotrase , alpha - chymar , alpha - chymotrypsin A , alpha - chymotrypsin ) is a digestive enzyme component of pancreatic juice acting in the duodenum where it performs proteolysis , the breakdown of proteins and polypeptides . Chymotrypsin preferentially cleaves peptide amide bonds where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid ( tyrosine , tryptophan , and phenylalanine ) . These amino acids contain an aromatic ring in their sidechain that fits into a ' hydrophobic pocket ' ( the S position ) of the enzyme . It is activated in the presence of trypsin . The hydrophobic and shape complementarity between the peptide substrate P sidechain and the enzyme S binding cavity accounts for the substrate specificity of this enzyme . Chymotrypsin also hydrolyzes other amide bonds in peptides at slower rates , particularly those containing leucine and methionine at the P position .\", sentence_starts=[0, 356, 594, 731, 776, 948], selected_sent={'start': 356, 'end': 594, 'string': 'Chymotrypsin preferentially cleaves peptide amide bonds where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid ( tyrosine , tryptophan , and phenylalanine ) . '}, answer=[Entity(start_offset=412, end_offset=591, type='context', text='where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid ( tyrosine , tryptophan , and phenylalanine )', normalized_text='where side chain of amino acid n terminal to scissile amide bond p position is large hydrophobic amino acid tyrosine tryptophan and phenylalanine')], nq_answers=[[Entity(start_offset=412, end_offset=591, type='context', text='where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid ( tyrosine , tryptophan , and phenylalanine )', normalized_text='where side chain of amino acid n terminal to scissile amide bond p position is large hydrophobic amino acid tyrosine tryptophan and phenylalanine')]], aligned_nps=[(Entity(start_offset=43, end_offset=55, type='question', text='chymotrypsin', normalized_text='chymotrypsin'), Entity(start_offset=356, end_offset=368, type='context', text='Chymotrypsin', normalized_text='chymotrypsin')), (Entity(start_offset=23, end_offset=39, type='question', text='the peptide bond', normalized_text='peptide bond'), Entity(start_offset=392, end_offset=411, type='context', text='peptide amide bonds', normalized_text='peptide amide bonds'))], explanation_type='single_sentence'),\n",
       " 1129148751656372803: QEDExample(example_id=1129148751656372803, title='Great Pyramid of Giza', question='how long did it take to build the great pyramid of egypt', passage=\"Based on a mark in an interior chamber naming the work gang and a reference to the fourth dynasty Egyptian Pharaoh Khufu , Egyptologists believe that the pyramid was built as a tomb over a 10 - to 20 - year period concluding around 2560 BC . Initially at 146.5 metres ( 481 feet ) , the Great Pyramid was the tallest man - made structure in the world for more than 3,800 years . Originally , the Great Pyramid was covered by limestone casing stones that formed a smooth outer surface ; what is seen today is the underlying core structure . Some of the casing stones that once covered the structure can still be seen around the base . There have been varying scientific and alternative theories about the Great Pyramid 's construction techniques . Most accepted construction hypotheses are based on the idea that it was built by moving huge stones from a quarry and dragging and lifting them into place .\", sentence_starts=[0, 242, 379, 540, 634, 747], selected_sent={'start': 0, 'end': 242, 'string': 'Based on a mark in an interior chamber naming the work gang and a reference to the fourth dynasty Egyptian Pharaoh Khufu , Egyptologists believe that the pyramid was built as a tomb over a 10 - to 20 - year period concluding around 2560 BC . '}, answer=[Entity(start_offset=187, end_offset=213, type='context', text='a 10 - to 20 - year period', normalized_text='10 to 20 year period')], nq_answers=[[Entity(start_offset=182, end_offset=213, type='context', text='over a 10 - to 20 - year period', normalized_text='over 10 to 20 year period')], [Entity(start_offset=187, end_offset=213, type='context', text='a 10 - to 20 - year period', normalized_text='10 to 20 year period')]], aligned_nps=[(Entity(start_offset=30, end_offset=56, type='question', text='the great pyramid of egypt', normalized_text='great pyramid of egypt'), Entity(start_offset=150, end_offset=161, type='context', text='the pyramid', normalized_text='pyramid'))], explanation_type='single_sentence'),\n",
       " 6288059070998153819: QEDExample(example_id=6288059070998153819, title='NBC Sports Northwest', question='what channel is nbc sports northwest on directv', passage=\"As of August 2013 , the network is not available on satellite providers DirecTV and Dish Network , which both maintain that Comcast has negotiated in bad faith during carriage discussions engaged between the parties . Particularly , Comcast demands the network be carried on more widely subscribed basic programming tiers , while contradictorily arguing that sports networks not owned by the company be carried only on a dedicated sports tier . The Trail Blazers are said to be frustrated and disappointed with Comcast 's conduct over their contract with CSN Northwest in this regard .\", sentence_starts=[0, 218, 445], selected_sent={'start': 0, 'end': 218, 'string': 'As of August 2013 , the network is not available on satellite providers DirecTV and Dish Network , which both maintain that Comcast has negotiated in bad faith during carriage discussions engaged between the parties . '}, answer=[Entity(start_offset=35, end_offset=48, type='context', text='not available', normalized_text='not available')], nq_answers=[[Entity(start_offset=35, end_offset=79, type='context', text='not available on satellite providers DirecTV', normalized_text='not available on satellite providers directv')]], aligned_nps=[(Entity(start_offset=16, end_offset=36, type='question', text='nbc sports northwest', normalized_text='nbc sports northwest'), Entity(start_offset=20, end_offset=31, type='context', text='the network', normalized_text='network')), (Entity(start_offset=40, end_offset=47, type='question', text='directv', normalized_text='directv'), Entity(start_offset=72, end_offset=79, type='context', text='DirecTV', normalized_text='directv'))], explanation_type='single_sentence'),\n",
       " 6243386362552941358: QEDExample(example_id=6243386362552941358, title='Exocrine gland', question='where do the secretory cells of endocrine glands secrete their products', passage='Exocrine glands are glands that produce and secrete substances onto an epithelial surface by way of a duct . Examples of exocrine glands include sweat , salivary , mammary , ceruminous , lacrimal , sebaceous , and mucous . Exocrine glands are one of two types of glands in the human body , the other being endocrine glands , which secrete their products directly into the bloodstream . The liver and pancreas are both exocrine and endocrine glands ; they are exocrine glands because they secrete products -- bile and pancreatic juice -- into the gastrointestinal tract through a series of ducts , and endocrine because they secrete other substances directly into the bloodstream .', sentence_starts=[0, 109, 223, 386], selected_sent={'start': 223, 'end': 386, 'string': 'Exocrine glands are one of two types of glands in the human body , the other being endocrine glands , which secrete their products directly into the bloodstream . '}, answer=[Entity(start_offset=354, end_offset=383, type='context', text='directly into the bloodstream', normalized_text='directly into bloodstream')], nq_answers=[[Entity(start_offset=71, end_offset=89, type='context', text='epithelial surface', normalized_text='epithelial surface')], [Entity(start_offset=372, end_offset=383, type='context', text='bloodstream', normalized_text='bloodstream')], [Entity(start_offset=354, end_offset=383, type='context', text='directly into the bloodstream', normalized_text='directly into bloodstream')]], aligned_nps=[(Entity(start_offset=32, end_offset=48, type='question', text='endocrine glands', normalized_text='endocrine glands'), Entity(start_offset=306, end_offset=322, type='context', text='endocrine glands', normalized_text='endocrine glands')), (Entity(start_offset=57, end_offset=71, type='question', text='their products', normalized_text='their products'), Entity(start_offset=339, end_offset=353, type='context', text='their products', normalized_text='their products'))], explanation_type='single_sentence'),\n",
       " 7439208340888264395: QEDExample(example_id=7439208340888264395, title='The Cosby Show', question='where did the cosbys live in new york', passage='The Cosby Show is an American television sitcom starring Bill Cosby , which aired for eight seasons on NBC from September 20 , 1984 , until April 30 , 1992 . The show focuses on the Huxtable family , an upper middle - class African - American family living in Brooklyn , New York .', sentence_starts=[0, 158], selected_sent={'start': 158, 'end': 281, 'string': 'The show focuses on the Huxtable family , an upper middle - class African - American family living in Brooklyn , New York .'}, answer=[Entity(start_offset=260, end_offset=268, type='context', text='Brooklyn', normalized_text='brooklyn')], nq_answers=[[Entity(start_offset=260, end_offset=279, type='context', text='Brooklyn , New York', normalized_text='brooklyn new york')], [Entity(start_offset=257, end_offset=268, type='context', text='in Brooklyn', normalized_text='in brooklyn')]], aligned_nps=[(Entity(start_offset=10, end_offset=20, type='question', text='the cosbys', normalized_text='cosbys'), Entity(start_offset=178, end_offset=197, type='context', text='the Huxtable family', normalized_text='huxtable family')), (Entity(start_offset=29, end_offset=37, type='question', text='new york', normalized_text='new york'), Entity(start_offset=271, end_offset=279, type='context', text='New York', normalized_text='new york'))], explanation_type='single_sentence'),\n",
       " 5101639460405472653: QEDExample(example_id=5101639460405472653, title='Christmas', question='christmas though a christian holiday began as a celebration of', passage=\"Many popular customs associated with Christmas developed independently of the commemoration of Jesus ' birth , with certain elements having origins in pre-Christian festivals that were celebrated around the winter solstice by pagan populations who were later converted to Christianity . These elements , including the Yule log from Yule and gift giving from Saturnalia , became syncretized into Christmas over the centuries . The prevailing atmosphere of Christmas has also continually evolved since the holiday 's inception , ranging from a sometimes raucous , drunken , carnival - like state in the Middle Ages , to a tamer family - oriented and children - centered theme introduced in a 19th - century transformation . In fact , the celebration of Christmas was banned on more than one occasion within certain Protestant groups , such as the Puritans , due to concerns that it was too pagan or unbiblical . Jehovah 's Witnesses also reject the celebration of Christmas .\", sentence_starts=[0, 287, 426, 722, 910], selected_sent={'start': 0, 'end': 287, 'string': \"Many popular customs associated with Christmas developed independently of the commemoration of Jesus ' birth , with certain elements having origins in pre-Christian festivals that were celebrated around the winter solstice by pagan populations who were later converted to Christianity . \"}, answer=[Entity(start_offset=203, end_offset=222, type='context', text='the winter solstice', normalized_text='winter solstice')], nq_answers=[[Entity(start_offset=151, end_offset=222, type='context', text='pre-Christian festivals that were celebrated around the winter solstice', normalized_text='prechristian festivals that were celebrated around winter solstice')]], aligned_nps=[(Entity(start_offset=0, end_offset=9, type='question', text='christmas', normalized_text='christmas'), Entity(start_offset=37, end_offset=46, type='context', text='Christmas', normalized_text='christmas'))], explanation_type='single_sentence'),\n",
       " -8811644368342820787: QEDExample(example_id=-8811644368342820787, title='Beer Hall Putsch', question='where did the beer hall putsch take place', passage='The Beer Hall Putsch , also known as the Munich Putsch , and , in German , as the Hitlerputsch , Hitler - Ludendorff - Putsch , Bürgerbräu - Putsch or mostly Marsch auf die Feldherrnhalle , was a failed coup attempt by the Nazi Party ( NSDAP ) leader Adolf Hitler -- along with Generalquartiermeister Erich Ludendorff and other Kampfbund leaders -- to seize power in Munich , Bavaria , during 8 -- 9 November 1923 . About two thousand Nazis marched to the centre of Munich , where they confronted the police , which resulted in the death of 16 Nazis and four police officers . Hitler was not wounded during the clash , although he locked his left arm with the right arm of Max Erwin von Scheubner - Richter who , when he was shot and killed , pulled Hitler to the pavement with him . Hitler escaped immediate arrest and was spirited off to safety in the countryside . After two days , Hitler was arrested and charged with treason .', sentence_starts=[0, 416, 577, 784, 868], selected_sent={'start': 0, 'end': 416, 'string': 'The Beer Hall Putsch , also known as the Munich Putsch , and , in German , as the Hitlerputsch , Hitler - Ludendorff - Putsch , Bürgerbräu - Putsch or mostly Marsch auf die Feldherrnhalle , was a failed coup attempt by the Nazi Party ( NSDAP ) leader Adolf Hitler -- along with Generalquartiermeister Erich Ludendorff and other Kampfbund leaders -- to seize power in Munich , Bavaria , during 8 -- 9 November 1923 . '}, answer=[Entity(start_offset=367, end_offset=383, type='context', text='Munich , Bavaria', normalized_text='munich bavaria')], nq_answers=[[Entity(start_offset=367, end_offset=383, type='context', text='Munich , Bavaria', normalized_text='munich bavaria')]], aligned_nps=[(Entity(start_offset=10, end_offset=30, type='question', text='the beer hall putsch', normalized_text='beer hall putsch'), Entity(start_offset=0, end_offset=20, type='context', text='The Beer Hall Putsch', normalized_text='beer hall putsch'))], explanation_type='single_sentence'),\n",
       " -6655692357261534837: QEDExample(example_id=-6655692357261534837, title='List of The Next Step episodes', question='when does season 6 of the next step start', passage='On March 21 , 2016 , Frank van Keeken announced on Instagram that The Next Step would return for a fifth season , which premiered on May 26 , 2017 . The series has been renewed for a sixth season of 26 episodes which will premiere in 2018 .', sentence_starts=[0, 149], selected_sent={'start': 149, 'end': 240, 'string': 'The series has been renewed for a sixth season of 26 episodes which will premiere in 2018 .'}, answer=[Entity(start_offset=234, end_offset=238, type='context', text='2018', normalized_text='2018')], nq_answers=[[Entity(start_offset=234, end_offset=238, type='context', text='2018', normalized_text='2018')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='season 6 of the next step', normalized_text='season 6 of next step'), Entity(start_offset=181, end_offset=210, type='context', text='a sixth season of 26 episodes', normalized_text='sixth season of 26 episodes'))], explanation_type='single_sentence'),\n",
       " 2125482171201889012: QEDExample(example_id=2125482171201889012, title='Total Drama', question='what is the third season of total drama', passage='The Total Drama series is the original series of the greater Total Drama franchise , which consists of five seasons that have aired during a timeframe of seven years : the first season , Total Drama Island , the second season , Total Drama Action , the third season , Total Drama World Tour , the fourth season , Total Drama : Revenge of the Island , and the fifth season , titled as both Total Drama All - Stars and Total Drama : Pahkitew Island . The latest installment premiered on July 7 , 2014 , in the United States and September 4 , 2014 , in Canada . A spin - off series based on the main series , The Ridonculous Race , was produced shortly after the fifth season was aired . A prequel series , titled Total Drama Daycare is currently in production which is scheduled to be released in 2018 .', sentence_starts=[0, 449, 559, 685], selected_sent={'start': 0, 'end': 449, 'string': 'The Total Drama series is the original series of the greater Total Drama franchise , which consists of five seasons that have aired during a timeframe of seven years : the first season , Total Drama Island , the second season , Total Drama Action , the third season , Total Drama World Tour , the fourth season , Total Drama : Revenge of the Island , and the fifth season , titled as both Total Drama All - Stars and Total Drama : Pahkitew Island . '}, answer=[Entity(start_offset=268, end_offset=290, type='context', text='Total Drama World Tour', normalized_text='total drama world tour')], nq_answers=[[Entity(start_offset=268, end_offset=290, type='context', text='Total Drama World Tour', normalized_text='total drama world tour')]], aligned_nps=[(Entity(start_offset=8, end_offset=39, type='question', text='the third season of total drama', normalized_text='third season of total drama'), Entity(start_offset=249, end_offset=265, type='context', text='the third season', normalized_text='third season'))], explanation_type='single_sentence'),\n",
       " 5209333152825126410: QEDExample(example_id=5209333152825126410, title=\"Can't Change Me\", question=\"chris cornell she's going to change the world\", passage=\"Greg Tate of Rolling Stone said this about the song `` Ca n't Change Me , '' is as rhapsodically gorgeous as pop gets , putting a spin on true love that any reprobate slacker can relate to : `` She 's going to change the world / But she ca n't change me / Suddenly I can see everything that 's wrong with me / But what can I do ? / I 'm the only thing I really have at all . '' Cornell unveils a desire to be reckoned with as an openly wounded and unabashedly portentous rock balladeer . ''\", sentence_starts=[0, 378], selected_sent={'start': 0, 'end': 378, 'string': \"Greg Tate of Rolling Stone said this about the song `` Ca n't Change Me , '' is as rhapsodically gorgeous as pop gets , putting a spin on true love that any reprobate slacker can relate to : `` She 's going to change the world / But she ca n't change me / Suddenly I can see everything that 's wrong with me / But what can I do ? / I 'm the only thing I really have at all . '' \"}, answer=[Entity(start_offset=43, end_offset=76, type='context', text=\"the song `` Ca n't Change Me , ''\", normalized_text='song ca nt change me')], nq_answers=[[Entity(start_offset=55, end_offset=71, type='context', text=\"Ca n't Change Me\", normalized_text='ca nt change me')]], aligned_nps=[(Entity(start_offset=0, end_offset=45, type='question', text=\"chris cornell she's going to change the world\", normalized_text='chris cornell shes going to change world'), Entity(start_offset=194, end_offset=226, type='context', text=\"She 's going to change the world\", normalized_text='she s going to change world'))], explanation_type='single_sentence'),\n",
       " -7292727871491736887: QEDExample(example_id=-7292727871491736887, title='List of tallest buildings in Las Vegas', question='how tall is the tallest building in las vegas', passage='The city of Las Vegas , Nevada and its surrounding unincorporated communities in the Las Vegas Valley are the sites of more than 160 high - rises , 42 of which stand taller than 400 feet ( 122 m ) . The tallest structure in the city is the Stratosphere Tower , which rises 1,149 feet ( 350 m ) just north of the Las Vegas Strip . The tower is also the tallest observation tower in the United States . Since the Stratosphere Tower is not fully habitable , however , it is not considered a building . The tallest building in Las Vegas is The Drew Las Vegas , which rises 735 feet ( 224 m ) and was topped out in November 2008 . This building , however , is currently on hold . The tallest completed building in the city is the 52 - story Palazzo , which rises 642 feet ( 196 m ) and was completed in 2007 .', sentence_starts=[0, 199, 330, 401, 499, 626, 675], selected_sent={'start': 199, 'end': 330, 'string': 'The tallest structure in the city is the Stratosphere Tower , which rises 1,149 feet ( 350 m ) just north of the Las Vegas Strip . '}, answer=[Entity(start_offset=273, end_offset=293, type='context', text='1,149 feet ( 350 m )', normalized_text='1149 feet 350 m')], nq_answers=[[Entity(start_offset=536, end_offset=554, type='context', text='The Drew Las Vegas', normalized_text='drew las vegas')], [Entity(start_offset=569, end_offset=587, type='context', text='735 feet ( 224 m )', normalized_text='735 feet 224 m')], [Entity(start_offset=273, end_offset=283, type='context', text='1,149 feet', normalized_text='1149 feet')], [Entity(start_offset=758, end_offset=776, type='context', text='642 feet ( 196 m )', normalized_text='642 feet 196 m')]], aligned_nps=[(Entity(start_offset=12, end_offset=45, type='question', text='the tallest building in las vegas', normalized_text='tallest building in las vegas'), Entity(start_offset=199, end_offset=232, type='context', text='The tallest structure in the city', normalized_text='tallest structure in city'))], explanation_type='single_sentence'),\n",
       " 386193802683148237: QEDExample(example_id=386193802683148237, title='Dome of the Rock', question='when was the dome of the rock completed', passage='It was initially completed in 691 CE at the order of Umayyad Caliph Abd al - Malik during the Second Fitna , built on the site of the Roman temple of Jupiter Capitolinus , which had in turn been built on the site of the Second Jewish Temple , destroyed during the Roman Siege of Jerusalem in 70 CE . The original dome collapsed in 1015 and was rebuilt in 1022 -- 23 . The Dome of the Rock is in its core one of the oldest extant works of Islamic architecture .', sentence_starts=[0, 300, 368], selected_sent={'start': 0, 'end': 300, 'string': 'It was initially completed in 691 CE at the order of Umayyad Caliph Abd al - Malik during the Second Fitna , built on the site of the Roman temple of Jupiter Capitolinus , which had in turn been built on the site of the Second Jewish Temple , destroyed during the Roman Siege of Jerusalem in 70 CE . '}, answer=[Entity(start_offset=30, end_offset=36, type='context', text='691 CE', normalized_text='691 ce')], nq_answers=[[Entity(start_offset=30, end_offset=36, type='context', text='691 CE', normalized_text='691 ce')], [Entity(start_offset=27, end_offset=36, type='context', text='in 691 CE', normalized_text='in 691 ce')]], aligned_nps=[(Entity(start_offset=9, end_offset=29, type='question', text='the dome of the rock', normalized_text='dome of rock'), Entity(start_offset=0, end_offset=2, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -4222264770799630551: QEDExample(example_id=-4222264770799630551, title='History of the Bahamas', question='who explored waters of cuba the bahamas and hispaniola', passage=\"In 1492 Christopher Columbus sailed from Spain on his first voyage with three ships , the Niña , the Pinta , and the flagship , Santa Maria , seeking a direct route to Asia . On 12 October 1492 Columbus reached an island in the Bahamas and claimed it for Spain , an event long regarded by Europeans as the ' discovery ' of America . This island was called Guanahani by the Lucayan , and San Salvador by the Spanish . The identity of the first American landfall by Columbus remains controversial , but many authors accept Samuel E. Morison 's identification of Columbus ' San Salvador as what was later called Watling ( or Watling 's ) Island . Its name has been officially changed to San Salvador . Columbus visited several other islands in the Bahamas before sailing to present - day Cuba and afterwards to Hispaniola .\", sentence_starts=[0, 175, 333, 417, 644, 699], selected_sent={'start': 699, 'end': 820, 'string': 'Columbus visited several other islands in the Bahamas before sailing to present - day Cuba and afterwards to Hispaniola .'}, answer=[Entity(start_offset=8, end_offset=28, type='context', text='Christopher Columbus', normalized_text='christopher columbus')], nq_answers=[[Entity(start_offset=8, end_offset=28, type='context', text='Christopher Columbus', normalized_text='christopher columbus')]], aligned_nps=[(Entity(start_offset=28, end_offset=39, type='question', text='the bahamas', normalized_text='bahamas'), Entity(start_offset=741, end_offset=752, type='context', text='the Bahamas', normalized_text='bahamas')), (Entity(start_offset=23, end_offset=27, type='question', text='cuba', normalized_text='cuba'), Entity(start_offset=771, end_offset=789, type='context', text='present - day Cuba', normalized_text='present day cuba')), (Entity(start_offset=44, end_offset=54, type='question', text='hispaniola', normalized_text='hispaniola'), Entity(start_offset=808, end_offset=818, type='context', text='Hispaniola', normalized_text='hispaniola'))], explanation_type='single_sentence'),\n",
       " -4283464153717448291: QEDExample(example_id=-4283464153717448291, title='Elizabeth Patterson (actress)', question='who played mrs. trumbull on i love lucy', passage='Mary Elizabeth Patterson ( November 22 , 1874 -- January 31 , 1966 ) was an American theatre , film , and television character actress who gained popular recognition late in her career playing the elderly neighbor Matilda Trumbull on the television comedy series I Love Lucy .', sentence_starts=[0], selected_sent={'start': 0, 'end': 276, 'string': 'Mary Elizabeth Patterson ( November 22 , 1874 -- January 31 , 1966 ) was an American theatre , film , and television character actress who gained popular recognition late in her career playing the elderly neighbor Matilda Trumbull on the television comedy series I Love Lucy .'}, answer=[Entity(start_offset=0, end_offset=24, type='context', text='Mary Elizabeth Patterson', normalized_text='mary elizabeth patterson')], nq_answers=[[Entity(start_offset=0, end_offset=24, type='context', text='Mary Elizabeth Patterson', normalized_text='mary elizabeth patterson')]], aligned_nps=[(Entity(start_offset=11, end_offset=24, type='question', text='mrs. trumbull', normalized_text='mrs trumbull'), Entity(start_offset=193, end_offset=230, type='context', text='the elderly neighbor Matilda Trumbull', normalized_text='elderly neighbor matilda trumbull')), (Entity(start_offset=28, end_offset=39, type='question', text='i love lucy', normalized_text='i love lucy'), Entity(start_offset=234, end_offset=274, type='context', text='the television comedy series I Love Lucy', normalized_text='television comedy series i love lucy'))], explanation_type='single_sentence'),\n",
       " 6788437746271264652: QEDExample(example_id=6788437746271264652, title='Peripheral nervous system', question='explain the function of the peripheral nervous system', passage='The peripheral nervous system ( PNS ) is one of the two components of the nervous system , the other part is the central nervous system ( CNS ) . The PNS consists of the nerves and ganglia outside the brain and spinal cord . The main function of the PNS is to connect the CNS to the limbs and organs , essentially serving as a relay between the brain and spinal cord and the rest of the body . Unlike the CNS , the PNS is not protected by the vertebral column and skull , or by the blood -- brain barrier , which leaves it exposed to toxins and mechanical injuries . The peripheral nervous system is divided into the somatic nervous system and the autonomic nervous system . In the somatic nervous system , the cranial nerves are part of the PNS with the exception of the optic nerve ( cranial nerve II ) , along with the retina . The second cranial nerve is not a true peripheral nerve but a tract of the diencephalon . Cranial nerve ganglia originated in the CNS . However , the remaining ten cranial nerve axons extend beyond the brain and are therefore considered part of the PNS . The autonomic nervous system is an involuntary control of smooth muscle and glands . The connection between CNS and organs allows the system to be in two different functional states : sympathetic and parasympathetic .', sentence_starts=[0, 146, 225, 394, 567, 675, 831, 921, 967, 1086, 1171], selected_sent={'start': 225, 'end': 394, 'string': 'The main function of the PNS is to connect the CNS to the limbs and organs , essentially serving as a relay between the brain and spinal cord and the rest of the body . '}, answer=[Entity(start_offset=260, end_offset=391, type='context', text='connect the CNS to the limbs and organs , essentially serving as a relay between the brain and spinal cord and the rest of the body', normalized_text='connect cns to limbs and organs essentially serving as relay between brain and spinal cord and rest of body')], nq_answers=[[Entity(start_offset=257, end_offset=391, type='context', text='to connect the CNS to the limbs and organs , essentially serving as a relay between the brain and spinal cord and the rest of the body', normalized_text='to connect cns to limbs and organs essentially serving as relay between brain and spinal cord and rest of body')]], aligned_nps=[(Entity(start_offset=8, end_offset=53, type='question', text='the function of the peripheral nervous system', normalized_text='function of peripheral nervous system'), Entity(start_offset=225, end_offset=253, type='context', text='The main function of the PNS', normalized_text='main function of pns'))], explanation_type='single_sentence'),\n",
       " -6838591751616736870: QEDExample(example_id=-6838591751616736870, title=\"There's a Riot Going On\", question='yo la tengo theres a riot going on release date', passage=\"There 's a Riot Going On is the fifteenth full - length studio album by the American band Yo La Tengo , and was released through Matador Records on March 16 , 2018 .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 165, 'string': \"There 's a Riot Going On is the fifteenth full - length studio album by the American band Yo La Tengo , and was released through Matador Records on March 16 , 2018 .\"}, answer=[Entity(start_offset=148, end_offset=163, type='context', text='March 16 , 2018', normalized_text='march 16 2018')], nq_answers=[[Entity(start_offset=148, end_offset=163, type='context', text='March 16 , 2018', normalized_text='march 16 2018')]], aligned_nps=[(Entity(start_offset=0, end_offset=31, type='question', text='yo la tengo theres a riot going', normalized_text='yo la tengo theres riot going'), Entity(start_offset=0, end_offset=24, type='context', text=\"There 's a Riot Going On\", normalized_text='there s riot going on'))], explanation_type='single_sentence'),\n",
       " -4196407015282160487: QEDExample(example_id=-4196407015282160487, title='Pattern hair loss', question='where do you get male pattern baldness from', passage='Male pattern hair loss is believed to be due to a combination of genetics and the male hormone dihydrotestosterone . The cause in female pattern hair loss remains unclear .', sentence_starts=[0, 117], selected_sent={'start': 0, 'end': 117, 'string': 'Male pattern hair loss is believed to be due to a combination of genetics and the male hormone dihydrotestosterone . '}, answer=[Entity(start_offset=48, end_offset=114, type='context', text='a combination of genetics and the male hormone dihydrotestosterone', normalized_text='combination of genetics and male hormone dihydrotestosterone')], nq_answers=[[Entity(start_offset=48, end_offset=114, type='context', text='a combination of genetics and the male hormone dihydrotestosterone', normalized_text='combination of genetics and male hormone dihydrotestosterone')], [Entity(start_offset=50, end_offset=114, type='context', text='combination of genetics and the male hormone dihydrotestosterone', normalized_text='combination of genetics and male hormone dihydrotestosterone')]], aligned_nps=[(Entity(start_offset=17, end_offset=38, type='question', text='male pattern baldness', normalized_text='male pattern baldness'), Entity(start_offset=0, end_offset=22, type='context', text='Male pattern hair loss', normalized_text='male pattern hair loss'))], explanation_type='single_sentence'),\n",
       " 5482109430613356344: QEDExample(example_id=5482109430613356344, title='Qing dynasty', question='where did the rulers of the qing dynasty originate', passage=\"The dynasty was founded by the Jurchen Aisin Gioro clan in Manchuria . In the late sixteenth century , Nurhaci , originally a Ming vassal , began organizing `` Banners '' , military - social units that included Jurchen , Han Chinese , and Mongol elements . Nurhaci formed the Jurchen clans into a unified entity , which he renamed as the Manchus . By 1636 , his son Hong Taiji began driving Ming forces out of Liaodong and declared a new dynasty , the Qing . In 1644 , peasant rebels led by Li Zicheng conquered the Ming capital , Beijing . Rather than serve them , Ming general Wu Sangui made an alliance with the Manchus and opened the Shanhai Pass to the Banner Armies led by the regent Prince Dorgon , who defeated the rebels and seized the capital . Resistance from the Southern Ming and the Revolt of the Three Feudatories led by Wu Sangui extended the conquest of China proper for nearly four decades and was not completed until 1683 under the Kangxi Emperor ( r . 1661 -- 1722 ) . The Ten Great Campaigns of the Qianlong Emperor from the 1750s to the 1790s extended Qing control into Inner Asia . The early rulers maintained their Manchu ways , and while their title was Emperor , they used `` Bogd khaan '' to the Mongols and they were patrons of Tibetan Buddhism . They governed using Confucian styles and institutions of bureaucratic government and retained the imperial examinations to recruit Han Chinese to work under or in parallel with Manchus . They also adapted the ideals of the tributary system in dealing with neighboring territories .\", sentence_starts=[0, 71, 257, 348, 459, 541, 755, 972, 989, 1105, 1275, 1462], selected_sent={'start': 0, 'end': 71, 'string': 'The dynasty was founded by the Jurchen Aisin Gioro clan in Manchuria . '}, answer=[Entity(start_offset=59, end_offset=68, type='context', text='Manchuria', normalized_text='manchuria')], nq_answers=[[Entity(start_offset=59, end_offset=68, type='context', text='Manchuria', normalized_text='manchuria')], [Entity(start_offset=31, end_offset=68, type='context', text='Jurchen Aisin Gioro clan in Manchuria', normalized_text='jurchen aisin gioro clan in manchuria')]], aligned_nps=[(Entity(start_offset=24, end_offset=40, type='question', text='the qing dynasty', normalized_text='qing dynasty'), Entity(start_offset=0, end_offset=11, type='context', text='The dynasty', normalized_text='dynasty'))], explanation_type='single_sentence'),\n",
       " 6603574027721863645: QEDExample(example_id=6603574027721863645, title='Empiricism', question='what word is used to describe knowledge about the universe and method of obtaining that knowledge', passage='Empiricism is a theory that states that knowledge comes only or primarily from sensory experience . It is one of several views of epistemology , the study of human knowledge , along with rationalism and skepticism . Empiricism emphasizes the role of empirical evidence in the formation of ideas , over the idea of innate ideas or traditions ; empiricists may argue however that traditions ( or customs ) arise due to relations of previous sense experiences .', sentence_starts=[0, 100, 216], selected_sent={'start': 100, 'end': 216, 'string': 'It is one of several views of epistemology , the study of human knowledge , along with rationalism and skepticism . '}, answer=[Entity(start_offset=130, end_offset=142, type='context', text='epistemology', normalized_text='epistemology')], nq_answers=[[Entity(start_offset=130, end_offset=142, type='context', text='epistemology', normalized_text='epistemology')], [Entity(start_offset=0, end_offset=10, type='context', text='Empiricism', normalized_text='empiricism')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -1932118074616697613: QEDExample(example_id=-1932118074616697613, title='Central India', question='which state is located in the centre of india', passage='Central India is a loosely defined region of India consisting of the states of Chhattisgarh and Madhya Pradesh . Indore , the commercial capital of Madhya Pradesh is the largest city in the region . Other major cities include Bhopal and Raipur . The states share many linguistic and cultural characteristics with the Northern Region including the predominance of Hindi . The states of Madhya Pradesh and Chhattisgarh have been grouped along with the states of Uttar Pradesh and Uttarakhand as the Northern Zonal Council for cooperation .', sentence_starts=[0, 113, 199, 246, 371], selected_sent={'start': 0, 'end': 113, 'string': 'Central India is a loosely defined region of India consisting of the states of Chhattisgarh and Madhya Pradesh . '}, answer=[Entity(start_offset=79, end_offset=110, type='context', text='Chhattisgarh and Madhya Pradesh', normalized_text='chhattisgarh and madhya pradesh')], nq_answers=[[Entity(start_offset=79, end_offset=91, type='context', text='Chhattisgarh', normalized_text='chhattisgarh'), Entity(start_offset=96, end_offset=110, type='context', text='Madhya Pradesh', normalized_text='madhya pradesh')]], aligned_nps=[(Entity(start_offset=40, end_offset=45, type='question', text='india', normalized_text='india'), Entity(start_offset=45, end_offset=50, type='context', text='India', normalized_text='india'))], explanation_type='single_sentence'),\n",
       " -7475618662654372287: QEDExample(example_id=-7475618662654372287, title='Scythe', question='what is the name of the weapon the grim reaper carries', passage=\"The Dictionary of Greek and Roman Antiquities of Sir William Smith claims that the scythe , known in Latin as the falx foenaria as opposed to the sickle , the falx messoria , was used by the ancient Romans. According to ancient Greek mythology it was believed that Gaea the Greek goddess mother of Titans gave ' a sickle was made out of the strongest metal ' to her youngest son ' Kronos ' who is also youngest of Titans ( also known as God of Harvest ) to seek vengeance against her Husband Ouranos for Torturing their oldest sons . To illustrate this , Smith cites an image of Saturn holding a scythe , from an ancient Italian cameo . The Grim Reaper and the Greek Titan Cronus were often depicted carrying or wielding a scythe . According to Jack Herer and `` Flesh of The Gods '' ( Emboden , W.A. , Jr. , Praeger Press , NY , 1974 . ) ; the ancient Scythians grew hemp and harvested it with a hand reaper that we still call a scythe .\", sentence_starts=[0, 534, 637, 732], selected_sent={'start': 637, 'end': 732, 'string': 'The Grim Reaper and the Greek Titan Cronus were often depicted carrying or wielding a scythe . '}, answer=[Entity(start_offset=721, end_offset=729, type='context', text='a scythe', normalized_text='scythe')], nq_answers=[[Entity(start_offset=723, end_offset=729, type='context', text='scythe', normalized_text='scythe')]], aligned_nps=[(Entity(start_offset=31, end_offset=46, type='question', text='the grim reaper', normalized_text='grim reaper'), Entity(start_offset=637, end_offset=652, type='context', text='The Grim Reaper', normalized_text='grim reaper'))], explanation_type='single_sentence'),\n",
       " 6969539427365218166: QEDExample(example_id=6969539427365218166, title='2014 FIFA World Cup statistics', question='who was the top scorer in 2014 world cup', passage='The winner of the Golden Boot was James Rodríguez .', sentence_starts=[0], selected_sent={'start': 0, 'end': 51, 'string': 'The winner of the Golden Boot was James Rodríguez .'}, answer=[Entity(start_offset=34, end_offset=49, type='context', text='James Rodríguez', normalized_text='james rodríguez')], nq_answers=[[Entity(start_offset=34, end_offset=49, type='context', text='James Rodríguez', normalized_text='james rodríguez')]], aligned_nps=[(Entity(start_offset=26, end_offset=40, type='question', text='2014 world cup', normalized_text='2014 world cup'), Entity(start_offset=0, end_offset=29, type='context', text='The winner of the Golden Boot', normalized_text='winner of golden boot'))], explanation_type='single_sentence'),\n",
       " 3370121445039290406: QEDExample(example_id=3370121445039290406, title='Captain Phasma', question='who plays captain phasma in star wars the force awakens', passage=\"Captain Phasma is a fictional character in the Star Wars franchise , portrayed by Gwendoline Christie . Introduced in Star Wars : The Force Awakens ( 2015 ) , the first film in the Star Wars sequel trilogy , Phasma is the commander of the First Order 's force of stormtroopers . Christie returned to the role in the next of the trilogy 's films , Star Wars : The Last Jedi ( 2017 ) . The character also made an additional appearance in Before the Awakening , an anthology book set before the events of The Force Awakens .\", sentence_starts=[0, 104, 279, 384], selected_sent={'start': 0, 'end': 104, 'string': 'Captain Phasma is a fictional character in the Star Wars franchise , portrayed by Gwendoline Christie . '}, answer=[Entity(start_offset=82, end_offset=101, type='context', text='Gwendoline Christie', normalized_text='gwendoline christie')], nq_answers=[[Entity(start_offset=82, end_offset=101, type='context', text='Gwendoline Christie', normalized_text='gwendoline christie')]], aligned_nps=[(Entity(start_offset=10, end_offset=17, type='question', text='captain', normalized_text='captain'), Entity(start_offset=0, end_offset=14, type='context', text='Captain Phasma', normalized_text='captain phasma'))], explanation_type='single_sentence'),\n",
       " 1735050411816900715: QEDExample(example_id=1735050411816900715, title='Overshoot (population)', question='when does a dieback or population crash occur', passage=\"In population dynamics and population ecology , overshoot occurs when a population temporarily exceeds the long term carrying capacity of its environment . The environment usually has mechanisms in place to prevent overshoot . For example , plants are only able to regenerate and regrow a few times after being consumed before completely dying off . The consequence of overshoot is called a collapse , a crash or a die - off in which there is a decline in population density . The entire sequence or trajectory undergone by the population and its environment together is often termed ' overshoot - and - collapse ' .\", sentence_starts=[0, 156, 227, 350, 477], selected_sent={'start': 350, 'end': 477, 'string': 'The consequence of overshoot is called a collapse , a crash or a die - off in which there is a decline in population density . '}, answer=[Entity(start_offset=65, end_offset=153, type='context', text='when a population temporarily exceeds the long term carrying capacity of its environment', normalized_text='when population temporarily exceeds long term carrying capacity of its environment')], nq_answers=[[Entity(start_offset=65, end_offset=153, type='context', text='when a population temporarily exceeds the long term carrying capacity of its environment', normalized_text='when population temporarily exceeds long term carrying capacity of its environment')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2747706330327946050: QEDExample(example_id=2747706330327946050, title='Salisbury steak', question=\"what's the difference between salisbury steak and hamburger steak\", passage='Salisbury steak is a dish made from a blend of ground beef and other ingredients and is usually served with gravy or brown sauce . Hamburg steak is a similar product but differs in ingredients .', sentence_starts=[0, 131], selected_sent={'start': 131, 'end': 194, 'string': 'Hamburg steak is a similar product but differs in ingredients .'}, answer=[Entity(start_offset=181, end_offset=192, type='context', text='ingredients', normalized_text='ingredients')], nq_answers=[[Entity(start_offset=181, end_offset=192, type='context', text='ingredients', normalized_text='ingredients')]], aligned_nps=[(Entity(start_offset=50, end_offset=65, type='question', text='hamburger steak', normalized_text='hamburger steak'), Entity(start_offset=131, end_offset=144, type='context', text='Hamburg steak', normalized_text='hamburg steak')), (Entity(start_offset=30, end_offset=45, type='question', text='salisbury steak', normalized_text='salisbury steak'), Entity(start_offset=148, end_offset=165, type='context', text='a similar product', normalized_text='similar product'))], explanation_type='single_sentence'),\n",
       " -5299749370232228058: QEDExample(example_id=-5299749370232228058, title='Meninges', question='what are the 3 layers of the meninges', passage=\"The meninges ( / məˈnɪndʒiːz / , singular : meninx ( / ˈmiːnɪŋks / or / ˈmɛnɪŋks / ) , from Ancient Greek : μῆνιγξ , translit . mēninx , lit . ' membrane ' , adjectival : meningeal / məˈnɪndʒəl / ) are the three membranes that envelop the brain and spinal cord . In mammals , the meninges are the dura mater , the arachnoid mater , and the pia mater . Cerebrospinal fluid is located in the subarachnoid space between the arachnoid mater and the pia mater . The primary function of the meninges is to protect the central nervous system .\", sentence_starts=[0, 128, 143, 263, 352, 457], selected_sent={'start': 263, 'end': 352, 'string': 'In mammals , the meninges are the dura mater , the arachnoid mater , and the pia mater . '}, answer=[Entity(start_offset=293, end_offset=349, type='context', text='the dura mater , the arachnoid mater , and the pia mater', normalized_text='dura mater arachnoid mater and pia mater')], nq_answers=[[Entity(start_offset=297, end_offset=307, type='context', text='dura mater', normalized_text='dura mater'), Entity(start_offset=314, end_offset=329, type='context', text='arachnoid mater', normalized_text='arachnoid mater'), Entity(start_offset=340, end_offset=349, type='context', text='pia mater', normalized_text='pia mater')], [Entity(start_offset=297, end_offset=307, type='context', text='dura mater', normalized_text='dura mater'), Entity(start_offset=310, end_offset=329, type='context', text='the arachnoid mater', normalized_text='arachnoid mater'), Entity(start_offset=336, end_offset=349, type='context', text='the pia mater', normalized_text='pia mater')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the 3 layers of the meninges', normalized_text='3 layers of meninges'), Entity(start_offset=276, end_offset=288, type='context', text='the meninges', normalized_text='meninges'))], explanation_type='single_sentence'),\n",
       " 8816667823188176068: QEDExample(example_id=8816667823188176068, title='Daylight saving time in the United States', question='what states do not allow daylight savings time', passage='Daylight saving time in the United States is the practice of setting the clock forward by one hour during the warmer part of the year , so that evenings have more daylight and mornings have less . Most areas of the United States observe daylight saving time ( DST ) , the exceptions being Arizona ( except for the Navajo , who do observe daylight saving time on tribal lands ) , Hawaii , and the overseas territories of American Samoa , Guam , the Northern Mariana Islands , Puerto Rico , and the United States Virgin Islands . The Uniform Time Act of 1966 established the system of uniform Daylight Saving Time throughout the US .', sentence_starts=[0, 197, 528], selected_sent={'start': 197, 'end': 528, 'string': 'Most areas of the United States observe daylight saving time ( DST ) , the exceptions being Arizona ( except for the Navajo , who do observe daylight saving time on tribal lands ) , Hawaii , and the overseas territories of American Samoa , Guam , the Northern Mariana Islands , Puerto Rico , and the United States Virgin Islands . '}, answer=[Entity(start_offset=289, end_offset=525, type='context', text='Arizona ( except for the Navajo , who do observe daylight saving time on tribal lands ) , Hawaii , and the overseas territories of American Samoa , Guam , the Northern Mariana Islands , Puerto Rico , and the United States Virgin Islands', normalized_text='arizona except for navajo who do observe daylight saving time on tribal lands hawaii and overseas territories of american samoa guam northern mariana islands puerto rico and united states virgin islands')], nq_answers=[[Entity(start_offset=289, end_offset=296, type='context', text='Arizona', normalized_text='arizona'), Entity(start_offset=314, end_offset=320, type='context', text='Navajo', normalized_text='navajo')], [Entity(start_offset=289, end_offset=376, type='context', text='Arizona ( except for the Navajo , who do observe daylight saving time on tribal lands )', normalized_text='arizona except for navajo who do observe daylight saving time on tribal lands'), Entity(start_offset=379, end_offset=385, type='context', text='Hawaii', normalized_text='hawaii')], [Entity(start_offset=289, end_offset=296, type='context', text='Arizona', normalized_text='arizona'), Entity(start_offset=379, end_offset=385, type='context', text='Hawaii', normalized_text='hawaii')]], aligned_nps=[(Entity(start_offset=25, end_offset=46, type='question', text='daylight savings time', normalized_text='daylight savings time'), Entity(start_offset=237, end_offset=265, type='context', text='daylight saving time ( DST )', normalized_text='daylight saving time dst'))], explanation_type='single_sentence'),\n",
       " 3616632103136384232: QEDExample(example_id=3616632103136384232, title='Subdural hematoma', question='which type of hematoma is a result of torn bridging meningeal veins', passage='A subdural hematoma ( SDH ) , is a type of hematoma , usually associated with traumatic brain injury . Blood gathers between the inner layer of the dura mater and the arachnoid mater . Usually resulting from tears in bridging veins which cross the subdural space , subdural hemorrhages may cause an increase in intracranial pressure ( ICP ) , which can cause compression of and damage to delicate brain tissue . Subdural hematomas are often life - threatening when acute . Chronic subdural hematomas , however , have a better prognosis if properly managed .', sentence_starts=[0, 103, 185, 412, 473], selected_sent={'start': 185, 'end': 412, 'string': 'Usually resulting from tears in bridging veins which cross the subdural space , subdural hemorrhages may cause an increase in intracranial pressure ( ICP ) , which can cause compression of and damage to delicate brain tissue . '}, answer=[Entity(start_offset=2, end_offset=27, type='context', text='subdural hematoma ( SDH )', normalized_text='subdural hematoma sdh')], nq_answers=[[Entity(start_offset=2, end_offset=27, type='context', text='subdural hematoma ( SDH )', normalized_text='subdural hematoma sdh')], [Entity(start_offset=0, end_offset=27, type='context', text='A subdural hematoma ( SDH )', normalized_text='subdural hematoma sdh')], [Entity(start_offset=0, end_offset=19, type='context', text='A subdural hematoma', normalized_text='subdural hematoma')], [Entity(start_offset=2, end_offset=19, type='context', text='subdural hematoma', normalized_text='subdural hematoma')]], aligned_nps=[(Entity(start_offset=43, end_offset=67, type='question', text='bridging meningeal veins', normalized_text='bridging meningeal veins'), Entity(start_offset=217, end_offset=262, type='context', text='bridging veins which cross the subdural space', normalized_text='bridging veins which cross subdural space'))], explanation_type='single_sentence'),\n",
       " -2337443782475108766: QEDExample(example_id=-2337443782475108766, title=\"Bobby's Girl (song)\", question='who sang i want to be bobbys girl', passage=\"`` Bobby 's Girl '' is a song and single written by Gary Klein and Henry Hoffman and performed by American teenage singer , Marcie Blane .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 138, 'string': \"`` Bobby 's Girl '' is a song and single written by Gary Klein and Henry Hoffman and performed by American teenage singer , Marcie Blane .\"}, answer=[Entity(start_offset=124, end_offset=136, type='context', text='Marcie Blane', normalized_text='marcie blane')], nq_answers=[[Entity(start_offset=124, end_offset=136, type='context', text='Marcie Blane', normalized_text='marcie blane')]], aligned_nps=[(Entity(start_offset=9, end_offset=33, type='question', text='i want to be bobbys girl', normalized_text='i want to be bobbys girl'), Entity(start_offset=3, end_offset=16, type='context', text=\"Bobby 's Girl\", normalized_text='bobby s girl'))], explanation_type='single_sentence'),\n",
       " 8650209400315075977: QEDExample(example_id=8650209400315075977, title='Three-point field goal', question='when did the nba add the three point line', passage='In the 1979 -- 80 season , after having tested it in the previous pre-season , the NBA adopted the three - point line despite the view of many that it was a gimmick . Chris Ford of the Boston Celtics is widely credited with making the first three - point shot in NBA history on October 12 , 1979 . Kevin Grevey of the Washington Bullets also made one on the same day .', sentence_starts=[0, 167, 298], selected_sent={'start': 0, 'end': 167, 'string': 'In the 1979 -- 80 season , after having tested it in the previous pre-season , the NBA adopted the three - point line despite the view of many that it was a gimmick . '}, answer=[Entity(start_offset=3, end_offset=24, type='context', text='the 1979 -- 80 season', normalized_text='1979 80 season')], nq_answers=[[Entity(start_offset=7, end_offset=24, type='context', text='1979 -- 80 season', normalized_text='1979 80 season')], [Entity(start_offset=7, end_offset=17, type='context', text='1979 -- 80', normalized_text='1979 80')], [Entity(start_offset=3, end_offset=24, type='context', text='the 1979 -- 80 season', normalized_text='1979 80 season')], [Entity(start_offset=0, end_offset=24, type='context', text='In the 1979 -- 80 season', normalized_text='in 1979 80 season')]], aligned_nps=[(Entity(start_offset=9, end_offset=16, type='question', text='the nba', normalized_text='nba'), Entity(start_offset=79, end_offset=86, type='context', text='the NBA', normalized_text='nba')), (Entity(start_offset=21, end_offset=41, type='question', text='the three point line', normalized_text='three point line'), Entity(start_offset=95, end_offset=117, type='context', text='the three - point line', normalized_text='three point line'))], explanation_type='single_sentence'),\n",
       " 8730028009751947933: QEDExample(example_id=8730028009751947933, title='Cone cell', question='where are the cones in the eye located', passage=\"Cone cells , or cones , are one of three types of photoreceptor cells in the retina of mammalian eyes ( e.g. the human eye ) . They are responsible for color vision and function best in relatively bright light , as opposed to rod cells , which work better in dim light . Cone cells are densely packed in the fovea centralis , a 0.3 mm diameter rod - free area with very thin , densely packed cones which quickly reduce in number towards the periphery of the retina . There are about six to seven million cones in a human eye and are most concentrated towards the macula . The commonly cited figure of six million cone cells in the human eye was found by Osterberg in 1935 . Oyster 's textbook ( 1999 ) cites work by Curcio et al. ( 1990 ) indicating an average close to 4.5 million cone cells and 90 million rod cells in the human retina .\", sentence_starts=[0, 127, 271, 467, 572, 674], selected_sent={'start': 0, 'end': 127, 'string': 'Cone cells , or cones , are one of three types of photoreceptor cells in the retina of mammalian eyes ( e.g. the human eye ) . '}, answer=[Entity(start_offset=73, end_offset=83, type='context', text='the retina', normalized_text='retina')], nq_answers=[[Entity(start_offset=70, end_offset=83, type='context', text='in the retina', normalized_text='in retina')], [Entity(start_offset=301, end_offset=323, type='context', text='in the fovea centralis', normalized_text='in fovea centralis')], [Entity(start_offset=301, end_offset=359, type='context', text='in the fovea centralis , a 0.3 mm diameter rod - free area', normalized_text='in fovea centralis 03 mm diameter rod free area')], [Entity(start_offset=73, end_offset=83, type='context', text='the retina', normalized_text='retina')]], aligned_nps=[(Entity(start_offset=10, end_offset=30, type='question', text='the cones in the eye', normalized_text='cones in eye'), Entity(start_offset=0, end_offset=21, type='context', text='Cone cells , or cones', normalized_text='cone cells or cones'))], explanation_type='single_sentence'),\n",
       " -918571312056093750: QEDExample(example_id=-918571312056093750, title='Puerto Rico Electric Power Authority', question=\"where does puerto rico's power come from\", passage='The Puerto Rico Electric Power Authority ( PREPA ) -- Spanish : Autoridad de Energía Eléctrica ( AEE ) -- is an electric power company and the government - owned corporation of Puerto Rico responsible for electricity generation , power distribution , and power transmission on the island . PREPA is the only entity authorized to conduct such business in Puerto Rico , making it a government monopoly . The authority is ruled by a board of directors appointed by the governor with the advice and consent of the Senate . Since 2014 , PREPA is subject to the Puerto Rico Energy Commission , another government agency whose board of directors is also appointed by the governor .', sentence_starts=[0, 290, 402, 519], selected_sent={'start': 0, 'end': 290, 'string': 'The Puerto Rico Electric Power Authority ( PREPA ) -- Spanish : Autoridad de Energía Eléctrica ( AEE ) -- is an electric power company and the government - owned corporation of Puerto Rico responsible for electricity generation , power distribution , and power transmission on the island . '}, answer=[Entity(start_offset=0, end_offset=50, type='context', text='The Puerto Rico Electric Power Authority ( PREPA )', normalized_text='puerto rico electric power authority prepa')], nq_answers=[[Entity(start_offset=4, end_offset=50, type='context', text='Puerto Rico Electric Power Authority ( PREPA )', normalized_text='puerto rico electric power authority prepa')], [Entity(start_offset=4, end_offset=40, type='context', text='Puerto Rico Electric Power Authority', normalized_text='puerto rico electric power authority')]], aligned_nps=[(Entity(start_offset=11, end_offset=22, type='question', text='puerto rico', normalized_text='puerto rico'), Entity(start_offset=177, end_offset=188, type='context', text='Puerto Rico', normalized_text='puerto rico'))], explanation_type='single_sentence'),\n",
       " 6174719789292441458: QEDExample(example_id=6174719789292441458, title=\"Bacon's Rebellion\", question=\"what were the some of the causes for bacon's rebellion\", passage=\"Bacon 's Rebellion was an armed rebellion in 1676 by Virginia settlers led by Nathaniel Bacon against the rule of Governor William Berkeley . The colony 's dismissive policy as it related to the political challenges of its western frontier , along with other challenges including leaving Bacon out of his inner circle , refusing to allow Bacon to be a part of his fur trade with the Indians , and Doeg American Indian attacks , helped to motivate a popular uprising against Berkeley , who had failed to address the demands of the colonists regarding their safety .\", sentence_starts=[0, 142], selected_sent={'start': 142, 'end': 564, 'string': \"The colony 's dismissive policy as it related to the political challenges of its western frontier , along with other challenges including leaving Bacon out of his inner circle , refusing to allow Bacon to be a part of his fur trade with the Indians , and Doeg American Indian attacks , helped to motivate a popular uprising against Berkeley , who had failed to address the demands of the colonists regarding their safety .\"}, answer=[Entity(start_offset=142, end_offset=425, type='context', text=\"The colony 's dismissive policy as it related to the political challenges of its western frontier , along with other challenges including leaving Bacon out of his inner circle , refusing to allow Bacon to be a part of his fur trade with the Indians , and Doeg American Indian attacks\", normalized_text='colony s dismissive policy as it related to political challenges of its western frontier along with other challenges including leaving bacon out of his inner circle refusing to allow bacon to be part of his fur trade with indians and doeg american indian attacks')], nq_answers=[[Entity(start_offset=142, end_offset=425, type='context', text=\"The colony 's dismissive policy as it related to the political challenges of its western frontier , along with other challenges including leaving Bacon out of his inner circle , refusing to allow Bacon to be a part of his fur trade with the Indians , and Doeg American Indian attacks\", normalized_text='colony s dismissive policy as it related to political challenges of its western frontier along with other challenges including leaving bacon out of his inner circle refusing to allow bacon to be part of his fur trade with indians and doeg american indian attacks')]], aligned_nps=[(Entity(start_offset=37, end_offset=54, type='question', text=\"bacon's rebellion\", normalized_text='bacons rebellion'), Entity(start_offset=447, end_offset=562, type='context', text='a popular uprising against Berkeley , who had failed to address the demands of the colonists regarding their safety', normalized_text='popular uprising against berkeley who had failed to address demands of colonists regarding their safety'))], explanation_type='single_sentence'),\n",
       " 4359809240674669371: QEDExample(example_id=4359809240674669371, title='El Pollo Loco', question='who is the founder of el pollo loco', passage='El Pollo Loco is the name of two independent restaurant chains that are controlled by different companies , El Pollo Loco , Inc. and El Pollo Loco , S.A. de C.V. Both companies specialize in Mexican - style grilled chicken and were founded by Juan Francisco Ochoa . Ochoa established the first El Pollo Loco restaurant in Guasave , Sinaloa , Mexico , in the mid-1970s , and then expanded his chain into the United States in 1980 . Ochoa then sold his U.S. restaurants in 1983 , which became El Pollo Loco , Inc. , while keeping the ones in Mexico , which became El Pollo Loco , S.A. de C.V. Both companies have since occupied non-overlapping global territories , and have offered different fare .', sentence_starts=[0, 162, 266, 431, 591], selected_sent={'start': 162, 'end': 266, 'string': 'Both companies specialize in Mexican - style grilled chicken and were founded by Juan Francisco Ochoa . '}, answer=[Entity(start_offset=243, end_offset=263, type='context', text='Juan Francisco Ochoa', normalized_text='juan francisco ochoa')], nq_answers=[[Entity(start_offset=243, end_offset=263, type='context', text='Juan Francisco Ochoa', normalized_text='juan francisco ochoa')]], aligned_nps=[(Entity(start_offset=22, end_offset=35, type='question', text='el pollo loco', normalized_text='el pollo loco'), Entity(start_offset=162, end_offset=176, type='context', text='Both companies', normalized_text='both companies'))], explanation_type='single_sentence'),\n",
       " -4199405438415986663: QEDExample(example_id=-4199405438415986663, title='Vikings (season 5)', question='when does the second half of vikings season 5 air', passage=\"The fifth season consists of a double order of twenty episodes , split into two parts of ten episodes ; the second half will premiere in 2018 . The premise of the fifth season differs from the previous four after the departure of Travis Fimmel as Ragnar , and it now follows the adventures of his sons . Jonathan Rhys Meyers is introduced as a major character , after his initial appearance in the fourth season 's finale .\", sentence_starts=[0, 144, 304], selected_sent={'start': 0, 'end': 144, 'string': 'The fifth season consists of a double order of twenty episodes , split into two parts of ten episodes ; the second half will premiere in 2018 . '}, answer=[Entity(start_offset=134, end_offset=141, type='context', text='in 2018', normalized_text='in 2018')], nq_answers=[[Entity(start_offset=134, end_offset=141, type='context', text='in 2018', normalized_text='in 2018')], [Entity(start_offset=137, end_offset=141, type='context', text='2018', normalized_text='2018')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='the second half of vikings season 5', normalized_text='second half of vikings season 5'), Entity(start_offset=104, end_offset=119, type='context', text='the second half', normalized_text='second half'))], explanation_type='single_sentence'),\n",
       " -8476469032627307723: QEDExample(example_id=-8476469032627307723, title='Connective tissue', question='where is connective tissue found in the body', passage='Connective tissue ( CT ) is one of the four basic types of animal tissue , along with epithelial tissue , muscle tissue , and nervous tissue . It develops from the mesoderm . Connective tissue is found in between other tissues everywhere in the body , including the nervous system . In the central nervous system , the three outer membranes ( the meninges ) that envelop the brain and spinal cord are composed of connective tissue . They support and protect the body . All connective tissue consists of three main components : fibers ( elastic and collagenous fibers ) , ground substance and cells . Not all authorities include blood or lymph as connective tissue because they lack the fiber component . All are immersed in the body water .', sentence_starts=[0, 143, 175, 283, 433, 469, 600, 704], selected_sent={'start': 175, 'end': 283, 'string': 'Connective tissue is found in between other tissues everywhere in the body , including the nervous system . '}, answer=[Entity(start_offset=202, end_offset=280, type='context', text='in between other tissues everywhere in the body , including the nervous system', normalized_text='in between other tissues everywhere in body including nervous system')], nq_answers=[[Entity(start_offset=205, end_offset=249, type='context', text='between other tissues everywhere in the body', normalized_text='between other tissues everywhere in body')], [Entity(start_offset=202, end_offset=280, type='context', text='in between other tissues everywhere in the body , including the nervous system', normalized_text='in between other tissues everywhere in body including nervous system')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='connective tissue', normalized_text='connective tissue'), Entity(start_offset=175, end_offset=192, type='context', text='Connective tissue', normalized_text='connective tissue')), (Entity(start_offset=36, end_offset=44, type='question', text='the body', normalized_text='body'), Entity(start_offset=241, end_offset=249, type='context', text='the body', normalized_text='body'))], explanation_type='single_sentence'),\n",
       " -8288621808951627468: QEDExample(example_id=-8288621808951627468, title='Pineapple', question='where do pineapples come from in the world', passage=\"Pineapples may be cultivated from a crown cutting of the fruit , possibly flowering in five to ten months and fruiting in the following six months . Pineapples do not ripen significantly after harvest . In 2016 , Costa Rica , Brazil , and the Philippines accounted for nearly one - third of the world 's production of pineapples .\", sentence_starts=[0, 149, 203], selected_sent={'start': 203, 'end': 330, 'string': \"In 2016 , Costa Rica , Brazil , and the Philippines accounted for nearly one - third of the world 's production of pineapples .\"}, answer=[Entity(start_offset=213, end_offset=254, type='context', text='Costa Rica , Brazil , and the Philippines', normalized_text='costa rica brazil and philippines')], nq_answers=[[Entity(start_offset=213, end_offset=254, type='context', text='Costa Rica , Brazil , and the Philippines', normalized_text='costa rica brazil and philippines')], [Entity(start_offset=213, end_offset=223, type='context', text='Costa Rica', normalized_text='costa rica'), Entity(start_offset=226, end_offset=232, type='context', text='Brazil', normalized_text='brazil'), Entity(start_offset=239, end_offset=254, type='context', text='the Philippines', normalized_text='philippines')]], aligned_nps=[(Entity(start_offset=9, end_offset=19, type='question', text='pineapples', normalized_text='pineapples'), Entity(start_offset=318, end_offset=328, type='context', text='pineapples', normalized_text='pineapples'))], explanation_type='single_sentence'),\n",
       " -8151116444308374539: QEDExample(example_id=-8151116444308374539, title=\"April Fools' Day\", question='when does april fools day end at noon', passage=\"In Poland , prima aprilis ( `` 1 April '' in Latin ) as a day of jokes is a centuries - long tradition . It is a day in which many jokes are told ; various hoaxes -- sometimes very sophisticated -- are prepared by people , media ( which often cooperate to make the `` information '' more credible ) and even public institutions . Serious activities are usually avoided , and generally every word said on April 1st can be a lie , or a joke . The conviction for this is so strong that the Polish anti-Turkish alliance with Leopold I signed on April 1 , 1683 , was backdated to March 31 . However , for some in Poland prima aprilis ends at noon of April 1st , and prima aprilis jokes after that hour are considered inappropriate and not classy .\", sentence_starts=[0, 105, 330, 441, 586], selected_sent={'start': 586, 'end': 742, 'string': 'However , for some in Poland prima aprilis ends at noon of April 1st , and prima aprilis jokes after that hour are considered inappropriate and not classy .'}, answer=[Entity(start_offset=608, end_offset=614, type='context', text='Poland', normalized_text='poland')], nq_answers=[[Entity(start_offset=645, end_offset=654, type='context', text='April 1st', normalized_text='april 1st')]], aligned_nps=[(Entity(start_offset=10, end_offset=25, type='question', text='april fools day', normalized_text='april fools day'), Entity(start_offset=615, end_offset=628, type='context', text='prima aprilis', normalized_text='prima aprilis')), (Entity(start_offset=33, end_offset=37, type='question', text='noon', normalized_text='noon'), Entity(start_offset=637, end_offset=654, type='context', text='noon of April 1st', normalized_text='noon of april 1st'))], explanation_type='single_sentence'),\n",
       " -2709461925297014430: QEDExample(example_id=-2709461925297014430, title='Action Jackson (2014 film)', question='new movie of ajay devgan and sonakshi sinha', passage='Action Jackson is a 2014 Indian action comedy film directed by Prabhu Deva and produced by Gordhan Tanwani and Sunil Lulla . It features Ajay Devgn in dual roles , alongside Sonakshi Sinha , Yami Gautam and Manasvi Mamgai as the female leads . Kunaal Roy Kapur appears in a supporting role with Anandaraj portraying the main antagonist . Prabhu Deva and Ajay Devgn have paired for the first time with this film . Action Jackson released on 5 December 2014 .', sentence_starts=[0, 125, 244, 338, 413], selected_sent={'start': 125, 'end': 244, 'string': 'It features Ajay Devgn in dual roles , alongside Sonakshi Sinha , Yami Gautam and Manasvi Mamgai as the female leads . '}, answer=[Entity(start_offset=0, end_offset=14, type='context', text='Action Jackson', normalized_text='action jackson')], nq_answers=[[Entity(start_offset=0, end_offset=14, type='context', text='Action Jackson', normalized_text='action jackson')]], aligned_nps=[(Entity(start_offset=13, end_offset=24, type='question', text='ajay devgan', normalized_text='ajay devgan'), Entity(start_offset=137, end_offset=147, type='context', text='Ajay Devgn', normalized_text='ajay devgn')), (Entity(start_offset=29, end_offset=43, type='question', text='sonakshi sinha', normalized_text='sonakshi sinha'), Entity(start_offset=174, end_offset=188, type='context', text='Sonakshi Sinha', normalized_text='sonakshi sinha'))], explanation_type='single_sentence'),\n",
       " -8247901781841476685: QEDExample(example_id=-8247901781841476685, title='Winter Olympic Games', question='how many times have the winter olympics been in the usa since 1924', passage='The Winter Olympics has been hosted on three continents by twelve different countries . The Games have been held four times in the United States ( in 1932 , 1960 , 1980 and 2002 ) ; three times in France ( in 1924 , 1968 and 1992 ) ; and twice each in Austria ( 1964 , 1976 ) , Canada ( 1988 , 2010 ) , Japan ( 1972 , 1998 ) , Italy ( 1956 , 2006 ) , Norway ( 1952 , 1994 ) , and Switzerland ( 1928 , 1948 ) . Also , the Games have been held just once each in Germany ( 1936 ) , Yugoslavia ( 1984 ) , Russia ( 2014 ) and South Korea ( 2018 ) . The IOC has selected Beijing , China , to host the 2022 Winter Olympics and the host of the 2026 Winter Olympics will be selected in September 2019 . As of 2018 , no city in the southern hemisphere has applied to host the cold - weather - dependent Winter Olympics , which are held in February at the height of the southern hemisphere summer .', sentence_starts=[0, 88, 410, 544, 694], selected_sent={'start': 88, 'end': 410, 'string': 'The Games have been held four times in the United States ( in 1932 , 1960 , 1980 and 2002 ) ; three times in France ( in 1924 , 1968 and 1992 ) ; and twice each in Austria ( 1964 , 1976 ) , Canada ( 1988 , 2010 ) , Japan ( 1972 , 1998 ) , Italy ( 1956 , 2006 ) , Norway ( 1952 , 1994 ) , and Switzerland ( 1928 , 1948 ) . '}, answer=[Entity(start_offset=113, end_offset=117, type='context', text='four', normalized_text='four')], nq_answers=[[Entity(start_offset=113, end_offset=117, type='context', text='four', normalized_text='four')], [Entity(start_offset=150, end_offset=154, type='context', text='1932', normalized_text='1932'), Entity(start_offset=157, end_offset=161, type='context', text='1960', normalized_text='1960'), Entity(start_offset=164, end_offset=168, type='context', text='1980', normalized_text='1980'), Entity(start_offset=173, end_offset=177, type='context', text='2002', normalized_text='2002')], [Entity(start_offset=113, end_offset=123, type='context', text='four times', normalized_text='four times')]], aligned_nps=[(Entity(start_offset=20, end_offset=39, type='question', text='the winter olympics', normalized_text='winter olympics'), Entity(start_offset=88, end_offset=97, type='context', text='The Games', normalized_text='games')), (Entity(start_offset=48, end_offset=55, type='question', text='the usa', normalized_text='usa'), Entity(start_offset=127, end_offset=144, type='context', text='the United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " -6649599371685719288: QEDExample(example_id=-6649599371685719288, title='City and Guilds of London Institute', question='what level is a city and guilds qualification', passage='City & Guilds is an awarding body offering a large number of accredited qualifications mapped onto the Regulated Qualifications Framework ( RQF ) , Credit and Qualifications Framework for Wales ( CQFW ) and Scottish Credit and Qualifications Framework ( SCQF ) . As of November 2016 , City & Guilds offers 2312 different regulated qualifications , more than any other awarding body . These cover entry level to level 7 on the RQF , with most qualifications falling in the entry level to level 3 range .', sentence_starts=[0, 263, 384], selected_sent={'start': 384, 'end': 502, 'string': 'These cover entry level to level 7 on the RQF , with most qualifications falling in the entry level to level 3 range .'}, answer=[Entity(start_offset=396, end_offset=500, type='context', text='entry level to level 7 on the RQF , with most qualifications falling in the entry level to level 3 range', normalized_text='entry level to level 7 on rqf with most qualifications falling in entry level to level 3 range')], nq_answers=[[Entity(start_offset=396, end_offset=418, type='context', text='entry level to level 7', normalized_text='entry level to level 7')]], aligned_nps=[(Entity(start_offset=14, end_offset=45, type='question', text='a city and guilds qualification', normalized_text='city and guilds qualification'), Entity(start_offset=384, end_offset=389, type='context', text='These', normalized_text='these'))], explanation_type='single_sentence'),\n",
       " -2531986732227033629: QEDExample(example_id=-2531986732227033629, title='Intermountain West', question='where is the intermountain region located on a map', passage='The Intermountain West , or Intermountain Region , is a geographic and geological region of the Western United States . It is located between the front ranges of the Rocky Mountains on the east and the Cascade Range and Sierra Nevada on the west .', sentence_starts=[0, 120], selected_sent={'start': 120, 'end': 247, 'string': 'It is located between the front ranges of the Rocky Mountains on the east and the Cascade Range and Sierra Nevada on the west .'}, answer=[Entity(start_offset=134, end_offset=245, type='context', text='between the front ranges of the Rocky Mountains on the east and the Cascade Range and Sierra Nevada on the west', normalized_text='between front ranges of rocky mountains on east and cascade range and sierra nevada on west')], nq_answers=[[Entity(start_offset=134, end_offset=245, type='context', text='between the front ranges of the Rocky Mountains on the east and the Cascade Range and Sierra Nevada on the west', normalized_text='between front ranges of rocky mountains on east and cascade range and sierra nevada on west')]], aligned_nps=[(Entity(start_offset=9, end_offset=33, type='question', text='the intermountain region', normalized_text='intermountain region'), Entity(start_offset=120, end_offset=122, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6680511654068483210: QEDExample(example_id=6680511654068483210, title=\"A Doll's House\", question='what is the setting of a dolls house', passage=\"A Doll 's House ( Bokmål : Et dukkehjem ; also translated as A Doll House ) is a three - act play written by Norway 's Henrik Ibsen . It premiered at the Royal Theatre in Copenhagen , Denmark , on 21 December 1879 , having been published earlier that month . The play is set in a Norwegian town circa 1879 .\", sentence_starts=[0, 134, 259], selected_sent={'start': 259, 'end': 307, 'string': 'The play is set in a Norwegian town circa 1879 .'}, answer=[Entity(start_offset=278, end_offset=305, type='context', text='a Norwegian town circa 1879', normalized_text='norwegian town circa 1879')], nq_answers=[[Entity(start_offset=278, end_offset=305, type='context', text='a Norwegian town circa 1879', normalized_text='norwegian town circa 1879')], [Entity(start_offset=278, end_offset=294, type='context', text='a Norwegian town', normalized_text='norwegian town')]], aligned_nps=[(Entity(start_offset=23, end_offset=36, type='question', text='a dolls house', normalized_text='dolls house'), Entity(start_offset=259, end_offset=267, type='context', text='The play', normalized_text='play'))], explanation_type='single_sentence'),\n",
       " -1145193137828819774: QEDExample(example_id=-1145193137828819774, title='Diana Rigg', question='who plays the grandmother in game of thrones', passage=\"The same year , Rigg secured a recurring role in the third season of the HBO series Game of Thrones , portraying Lady Olenna Tyrell , a witty and sarcastic political mastermind popularly known as the Queen of Thorns , the grandmother of regular character Margaery Tyrell . Her performance was well received by critics and audiences alike , and earned her an Emmy nomination for Outstanding Guest Actress in a Drama Series for the 65th Primetime Emmy Awards in 2013 . She reprised her role in season four of Game of Thrones , and in July 2014 received another Guest Actress Emmy nomination . In 2015 and 2016 , she again reprised the role in seasons five and six in an expanded role from the books . The character was finally killed off in the seventh season , with Rigg 's final performance receiving critical acclaim .\", sentence_starts=[0, 273, 467, 591, 699], selected_sent={'start': 0, 'end': 273, 'string': 'The same year , Rigg secured a recurring role in the third season of the HBO series Game of Thrones , portraying Lady Olenna Tyrell , a witty and sarcastic political mastermind popularly known as the Queen of Thorns , the grandmother of regular character Margaery Tyrell . '}, answer=[Entity(start_offset=16, end_offset=20, type='context', text='Rigg', normalized_text='rigg')], nq_answers=[[Entity(start_offset=16, end_offset=20, type='context', text='Rigg', normalized_text='rigg')]], aligned_nps=[(Entity(start_offset=29, end_offset=44, type='question', text='game of thrones', normalized_text='game of thrones'), Entity(start_offset=69, end_offset=99, type='context', text='the HBO series Game of Thrones', normalized_text='hbo series game of thrones')), (Entity(start_offset=10, end_offset=25, type='question', text='the grandmother', normalized_text='grandmother'), Entity(start_offset=113, end_offset=270, type='context', text='Lady Olenna Tyrell , a witty and sarcastic political mastermind popularly known as the Queen of Thorns , the grandmother of regular character Margaery Tyrell', normalized_text='lady olenna tyrell witty and sarcastic political mastermind popularly known as queen of thorns grandmother of regular character margaery tyrell'))], explanation_type='single_sentence'),\n",
       " -7370925457649269027: QEDExample(example_id=-7370925457649269027, title='The Ten Commandments (1956 film)', question='who played the king in the ten commandments', passage=\"The Ten Commandments is a 1956 American biblical epic film produced , directed , and narrated by Cecil B. DeMille , shot in VistaVision ( color by Technicolor ) , and released by Paramount Pictures . The film is based on Prince of Egypt by Dorothy Clarke Wilson , Pillar of Fire by J.H. Ingraham , On Eagle 's Wings by A.E. Southon , and the Book of Exodus . The Ten Commandments dramatizes the biblical story of the life of Moses , an adopted Egyptian prince who becomes the deliverer of his real brethren , the enslaved Hebrews , and therefore leads the Exodus to Mount Sinai , where he receives , from God , the Ten Commandments . The film stars Charlton Heston in the lead role , Yul Brynner as Rameses , Anne Baxter as Nefretiri , Edward G. Robinson as Dathan , Yvonne De Carlo as Sephora , Debra Paget as Lilia , and John Derek as Joshua ; and features Sir Cedric Hardwicke as Sethi , Nina Foch as Bithiah , Martha Scott as Yoshebel , Judith Anderson as Memnet , and Vincent Price as Baka , among others .\", sentence_starts=[0, 200, 287, 324, 359, 634], selected_sent={'start': 634, 'end': 1011, 'string': 'The film stars Charlton Heston in the lead role , Yul Brynner as Rameses , Anne Baxter as Nefretiri , Edward G. Robinson as Dathan , Yvonne De Carlo as Sephora , Debra Paget as Lilia , and John Derek as Joshua ; and features Sir Cedric Hardwicke as Sethi , Nina Foch as Bithiah , Martha Scott as Yoshebel , Judith Anderson as Memnet , and Vincent Price as Baka , among others .'}, answer=[Entity(start_offset=684, end_offset=695, type='context', text='Yul Brynner', normalized_text='yul brynner')], nq_answers=[[Entity(start_offset=684, end_offset=695, type='context', text='Yul Brynner', normalized_text='yul brynner')]], aligned_nps=[(Entity(start_offset=23, end_offset=43, type='question', text='the ten commandments', normalized_text='ten commandments'), Entity(start_offset=699, end_offset=706, type='context', text='Rameses', normalized_text='rameses'))], explanation_type='single_sentence'),\n",
       " 8994603957493774314: QEDExample(example_id=8994603957493774314, title='I Write Sins Not Tragedies', question='who is the original singer of i write sins not tragedies', passage=\"`` I Write Sins Not Tragedies '' is a song by American rock band Panic ! at the Disco , and is the second single from their debut studio album , A Fever You Ca n't Sweat Out ( 2005 ) . It was released on April 27 , 2006 on both CD and 7 '' vinyl . The pizzicato cello motif that the song is built upon was played by session musician Heather Stebbins . The song reached No. 7 on the United States Billboard Hot 100 . This was the band 's only top forty hit until the release of `` Hallelujah '' in 2015 . While the song failed to hit the top 10 on the Alternative Songs chart peaking at No. 12 which was lower than their prior single , `` The Only Difference Between Martyrdom and Suicide Is Press Coverage '' which peaked at No. 5 , the song 's success on the Hot 100 and Mainstream Top 40 ( at No. 2 ) charts was what made the song one of the biggest modern rock hits of 2006 and is still one of the band 's most played songs on alternative radio stations to this day .\", sentence_starts=[0, 73, 185, 248, 352, 416, 504], selected_sent={'start': 0, 'end': 185, 'string': \"`` I Write Sins Not Tragedies '' is a song by American rock band Panic ! at the Disco , and is the second single from their debut studio album , A Fever You Ca n't Sweat Out ( 2005 ) . \"}, answer=[Entity(start_offset=65, end_offset=85, type='context', text='Panic ! at the Disco', normalized_text='panic at disco')], nq_answers=[[Entity(start_offset=65, end_offset=85, type='context', text='Panic ! at the Disco', normalized_text='panic at disco')], [Entity(start_offset=46, end_offset=85, type='context', text='American rock band Panic ! at the Disco', normalized_text='american rock band panic at disco')]], aligned_nps=[(Entity(start_offset=30, end_offset=56, type='question', text='i write sins not tragedies', normalized_text='i write sins not tragedies'), Entity(start_offset=3, end_offset=29, type='context', text='I Write Sins Not Tragedies', normalized_text='i write sins not tragedies'))], explanation_type='single_sentence'),\n",
       " 6984338270146750184: QEDExample(example_id=6984338270146750184, title='Las Vegas Stadium', question='where is the new stadium being built in las vegas', passage='Las Vegas Stadium is the working name for a domed stadium under construction in Paradise , Nevada for the Las Vegas Raiders of the National Football League ( NFL ) and the UNLV Rebels football team of the University of Nevada , Las Vegas ( UNLV ) . It is located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive , just west of Interstate 15 . Construction of the $1.8 billion stadium began in September 2017 and is expected to be completed in time for the 2020 NFL season .', sentence_starts=[0, 249, 418], selected_sent={'start': 249, 'end': 418, 'string': 'It is located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive , just west of Interstate 15 . '}, answer=[Entity(start_offset=263, end_offset=415, type='context', text='on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive , just west of Interstate 15', normalized_text='on about 62 acres west of mandalay bay at russell road and hacienda avenue and between polaris avenue and dean martin drive just west of interstate 15')], nq_answers=[[Entity(start_offset=263, end_offset=415, type='context', text='on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive , just west of Interstate 15', normalized_text='on about 62 acres west of mandalay bay at russell road and hacienda avenue and between polaris avenue and dean martin drive just west of interstate 15')], [Entity(start_offset=281, end_offset=415, type='context', text='west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive , just west of Interstate 15', normalized_text='west of mandalay bay at russell road and hacienda avenue and between polaris avenue and dean martin drive just west of interstate 15')], [Entity(start_offset=80, end_offset=97, type='context', text='Paradise , Nevada', normalized_text='paradise nevada')], [Entity(start_offset=266, end_offset=415, type='context', text='about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive , just west of Interstate 15', normalized_text='about 62 acres west of mandalay bay at russell road and hacienda avenue and between polaris avenue and dean martin drive just west of interstate 15')], [Entity(start_offset=77, end_offset=97, type='context', text='in Paradise , Nevada', normalized_text='in paradise nevada')]], aligned_nps=[(Entity(start_offset=9, end_offset=24, type='question', text='the new stadium', normalized_text='new stadium'), Entity(start_offset=249, end_offset=251, type='context', text='It', normalized_text='it')), (Entity(start_offset=40, end_offset=49, type='question', text='las vegas', normalized_text='las vegas'), Entity(start_offset=255, end_offset=262, type='context', text='located', normalized_text='located'))], explanation_type='single_sentence'),\n",
       " -2609190921911067088: QEDExample(example_id=-2609190921911067088, title='List of To Kill a Mockingbird characters', question='name of black man in to kill a mockingbird', passage=\"Atticus Finch is the middle - aged father of Jem and Scout Finch . He is a lawyer and was once known as `` the deadliest shot in Maycomb County '' . Although he was a good shot , he does not like to mention the fact as he does not like the thought of having an advantage over people . He appears to support racial equality and was appointed to represent Tom Robinson , a black man who has been accused of raping a young white woman , Mayella Ewell . The town disapproves of him defending Tom especially when he makes clear his intent to defend Tom Robinson to the best of his abilities . He is portrayed by Gregory Peck in the film adaptation of To Kill a Mockingbird .\", sentence_starts=[0, 67, 149, 285, 450, 588], selected_sent={'start': 285, 'end': 450, 'string': 'He appears to support racial equality and was appointed to represent Tom Robinson , a black man who has been accused of raping a young white woman , Mayella Ewell . '}, answer=[Entity(start_offset=354, end_offset=366, type='context', text='Tom Robinson', normalized_text='tom robinson')], nq_answers=[[Entity(start_offset=354, end_offset=366, type='context', text='Tom Robinson', normalized_text='tom robinson')]], aligned_nps=[(Entity(start_offset=8, end_offset=42, type='question', text='black man in to kill a mockingbird', normalized_text='black man in to kill mockingbird'), Entity(start_offset=354, end_offset=447, type='context', text='Tom Robinson , a black man who has been accused of raping a young white woman , Mayella Ewell', normalized_text='tom robinson black man who has been accused of raping young white woman mayella ewell'))], explanation_type='single_sentence'),\n",
       " -4262241418874240439: QEDExample(example_id=-4262241418874240439, title='Santa Fe Trail', question='where did the santa fe trail take emigrants', passage='The Santa Fe Trail was a 19th - century transportation route through central North America that connected Independence , Missouri with Santa Fe , New Mexico . Pioneered in 1821 by William Becknell , it served as a vital commercial highway until the introduction of the railroad to Santa Fe in 1880 . Santa Fe was near the end of the El Camino Real de Tierra Adentro which carried trade from Mexico City .', sentence_starts=[0, 159, 300], selected_sent={'start': 0, 'end': 159, 'string': 'The Santa Fe Trail was a 19th - century transportation route through central North America that connected Independence , Missouri with Santa Fe , New Mexico . '}, answer=[Entity(start_offset=69, end_offset=156, type='context', text='central North America that connected Independence , Missouri with Santa Fe , New Mexico', normalized_text='central north america that connected independence missouri with santa fe new mexico')], nq_answers=[[Entity(start_offset=96, end_offset=156, type='context', text='connected Independence , Missouri with Santa Fe , New Mexico', normalized_text='connected independence missouri with santa fe new mexico')]], aligned_nps=[(Entity(start_offset=10, end_offset=28, type='question', text='the santa fe trail', normalized_text='santa fe trail'), Entity(start_offset=0, end_offset=18, type='context', text='The Santa Fe Trail', normalized_text='santa fe trail'))], explanation_type='single_sentence'),\n",
       " 7596628080391120719: QEDExample(example_id=7596628080391120719, title=\"It Happened at the World's Fair\", question='where was it happened at the world fair filmed', passage=\"It Happened at the World 's Fair is a 1963 American musical film starring Elvis Presley as a cropdusting pilot . It was filmed in Seattle , Washington , site of the Century 21 Exposition , the 1962 World 's Fair . The governor of Washington at the time , Albert Rosellini , suggested the setting to Metro - Goldwyn - Mayer executives . The film made $2.25 million at the box office .\", sentence_starts=[0, 113, 214, 336], selected_sent={'start': 113, 'end': 214, 'string': \"It was filmed in Seattle , Washington , site of the Century 21 Exposition , the 1962 World 's Fair . \"}, answer=[Entity(start_offset=130, end_offset=150, type='context', text='Seattle , Washington', normalized_text='seattle washington')], nq_answers=[[Entity(start_offset=130, end_offset=150, type='context', text='Seattle , Washington', normalized_text='seattle washington')], [Entity(start_offset=130, end_offset=211, type='context', text=\"Seattle , Washington , site of the Century 21 Exposition , the 1962 World 's Fair\", normalized_text='seattle washington site of century 21 exposition 1962 world s fair')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text='it happened at the world fair', normalized_text='it happened at world fair'), Entity(start_offset=113, end_offset=115, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 8164301669866012157: QEDExample(example_id=8164301669866012157, title='Charleston, West Virginia', question='what river flows through charleston west virginia’s capital', passage='Charleston is the state capital and the most populous city in the U.S. state of West Virginia , and the county seat of Kanawha County . It is located at the confluence of the Elk and Kanawha Rivers . As of the 2013 Census Estimate , it had a population of 50,821 , while its metropolitan area had 224,743 . It is a center of government , commerce , and industry .', sentence_starts=[0, 136, 200, 307], selected_sent={'start': 136, 'end': 200, 'string': 'It is located at the confluence of the Elk and Kanawha Rivers . '}, answer=[Entity(start_offset=171, end_offset=197, type='context', text='the Elk and Kanawha Rivers', normalized_text='elk and kanawha rivers')], nq_answers=[[Entity(start_offset=153, end_offset=197, type='context', text='the confluence of the Elk and Kanawha Rivers', normalized_text='confluence of elk and kanawha rivers')], [Entity(start_offset=175, end_offset=178, type='context', text='Elk', normalized_text='elk'), Entity(start_offset=183, end_offset=190, type='context', text='Kanawha', normalized_text='kanawha')], [Entity(start_offset=171, end_offset=197, type='context', text='the Elk and Kanawha Rivers', normalized_text='elk and kanawha rivers')]], aligned_nps=[(Entity(start_offset=25, end_offset=59, type='question', text='charleston west virginia’s capital', normalized_text='charleston west virginia’s capital'), Entity(start_offset=136, end_offset=138, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6013074568970466569: QEDExample(example_id=6013074568970466569, title='History of chocolate in Spain', question='where did chocolate originate the americas spain asia', passage='The history of chocolate in Spain is part of the culinary history of Spain as understood since the 16th century , when the colonization of the Americas began and the cocoa plant was discovered in regions of Mesoamerica , until the present . After the conquest of Mexico , cocoa as a commodity travelled by boat from the port of Nueva España to the Spanish coast . The first such voyage to Europe occurred at an unknown date in the 1520s . However it was only in the 17th century that regular trade began from the port of Veracruz , opening a maritime trade route that would supply the new demand from Spain , and later from other European countries .', sentence_starts=[0, 241, 364, 439], selected_sent={'start': 0, 'end': 241, 'string': 'The history of chocolate in Spain is part of the culinary history of Spain as understood since the 16th century , when the colonization of the Americas began and the cocoa plant was discovered in regions of Mesoamerica , until the present . '}, answer=[Entity(start_offset=139, end_offset=151, type='context', text='the Americas', normalized_text='americas')], nq_answers=[[Entity(start_offset=143, end_offset=151, type='context', text='Americas', normalized_text='americas')], [Entity(start_offset=139, end_offset=151, type='context', text='the Americas', normalized_text='americas')], [Entity(start_offset=207, end_offset=218, type='context', text='Mesoamerica', normalized_text='mesoamerica')]], aligned_nps=[(Entity(start_offset=10, end_offset=19, type='question', text='chocolate', normalized_text='chocolate'), Entity(start_offset=15, end_offset=24, type='context', text='chocolate', normalized_text='chocolate'))], explanation_type='single_sentence'),\n",
       " 7539197459439257235: QEDExample(example_id=7539197459439257235, title='Jai Ho (song)', question='who sings so come and dance with me jai ho', passage=\"`` Jai Ho '' is a song composed by A.R. Rahman for the 2008 film , Slumdog Millionaire . When Danny Boyle , the director of Slumdog Millionaire , approached Rahman to compose its soundtrack , he included the song . `` Jai Ho '' accompanies a choreographed dance sequence at the end credits of Slumdog Millionaire . The song features vocals from Sukhvinder Singh , Mahalaxmi Iyer and Vijay Prakash in Hindi , Urdu and Punjabi . Indian singer Tanvi Shah wrote and provided vocals for a Spanish section of the song . `` Jai Ho '' is a Hindi phrase which can be roughly translated as `` Let ( the ) victory prevail '' , `` Let there be victory '' , or `` May there always be victory '' .\", sentence_starts=[0, 40, 89, 215, 315, 427, 514], selected_sent={'start': 315, 'end': 427, 'string': 'The song features vocals from Sukhvinder Singh , Mahalaxmi Iyer and Vijay Prakash in Hindi , Urdu and Punjabi . '}, answer=[Entity(start_offset=345, end_offset=396, type='context', text='Sukhvinder Singh , Mahalaxmi Iyer and Vijay Prakash', normalized_text='sukhvinder singh mahalaxmi iyer and vijay prakash')], nq_answers=[[Entity(start_offset=345, end_offset=361, type='context', text='Sukhvinder Singh', normalized_text='sukhvinder singh'), Entity(start_offset=364, end_offset=378, type='context', text='Mahalaxmi Iyer', normalized_text='mahalaxmi iyer'), Entity(start_offset=383, end_offset=396, type='context', text='Vijay Prakash', normalized_text='vijay prakash'), Entity(start_offset=441, end_offset=451, type='context', text='Tanvi Shah', normalized_text='tanvi shah')]], aligned_nps=[(Entity(start_offset=10, end_offset=42, type='question', text='so come and dance with me jai ho', normalized_text='so come and dance with me jai ho'), Entity(start_offset=315, end_offset=323, type='context', text='The song', normalized_text='song'))], explanation_type='single_sentence'),\n",
       " -3708167573543567001: QEDExample(example_id=-3708167573543567001, title='Sex and the City (season 5)', question='why only 8 episodes in satc season 5', passage=\"The 5th season , airing on Sunday nights at 9 : 00 PM from July 21 , 2002 ( 2002 - 07 - 21 ) to September 8 , 2002 ( 2002 - 09 - 08 ) , comprised eight episodes as opposed to the original 18 episode order due to Parker 's pregnancy at the time of filming . In the United Kingdom , the season was broadcast on Wednesday nights between January 1 and February 19 , 2003 . The season received mixed to positive critical responses while receiving several awards and nominations , including winning the Golden Globe Award for Best Supporting Actress -- Series , Miniseries or Television Film for Cattrall . The season averaged over 7 million viewers .\", sentence_starts=[0, 257, 369, 601], selected_sent={'start': 0, 'end': 257, 'string': \"The 5th season , airing on Sunday nights at 9 : 00 PM from July 21 , 2002 ( 2002 - 07 - 21 ) to September 8 , 2002 ( 2002 - 09 - 08 ) , comprised eight episodes as opposed to the original 18 episode order due to Parker 's pregnancy at the time of filming . \"}, answer=[Entity(start_offset=205, end_offset=254, type='context', text=\"due to Parker 's pregnancy at the time of filming\", normalized_text='due to parker s pregnancy at time of filming')], nq_answers=[[Entity(start_offset=205, end_offset=254, type='context', text=\"due to Parker 's pregnancy at the time of filming\", normalized_text='due to parker s pregnancy at time of filming')], [Entity(start_offset=212, end_offset=254, type='context', text=\"Parker 's pregnancy at the time of filming\", normalized_text='parker s pregnancy at time of filming')]], aligned_nps=[(Entity(start_offset=23, end_offset=36, type='question', text='satc season 5', normalized_text='satc season 5'), Entity(start_offset=0, end_offset=14, type='context', text='The 5th season', normalized_text='5th season'))], explanation_type='single_sentence'),\n",
       " 8281535833205122078: QEDExample(example_id=8281535833205122078, title='Sofia', question='of which country is sofia the capital city', passage='Sofia ( / ˈsoʊfiə , ˈsɒf - , soʊˈfiːə / SOH - fee - ə , SOF - , soh - FEE - ə ; Bulgarian : Со́фия , tr . Sofiya , pronounced ( ˈsɔfijə ) ( listen ) ) is the capital and largest city of Bulgaria . 1.3 million people live in the city and 1.7 million people live in its metropolitan area . The city is at the foot of Vitosha Mountain in the western part of the country . Being in the centre of the Balkan peninsula , it is midway between the Black Sea and the Adriatic Sea , and closest to the Aegean Sea .', sentence_starts=[0, 106, 197, 288, 369], selected_sent={'start': 0, 'end': 197, 'string': 'Sofia ( / ˈsoʊfiə , ˈsɒf - , soʊˈfiːə / SOH - fee - ə , SOF - , soh - FEE - ə ; Bulgarian : Со́фия , tr . Sofiya , pronounced ( ˈsɔfijə ) ( listen ) ) is the capital and largest city of Bulgaria . '}, answer=[Entity(start_offset=186, end_offset=194, type='context', text='Bulgaria', normalized_text='bulgaria')], nq_answers=[[Entity(start_offset=186, end_offset=194, type='context', text='Bulgaria', normalized_text='bulgaria')]], aligned_nps=[(Entity(start_offset=20, end_offset=25, type='question', text='sofia', normalized_text='sofia'), Entity(start_offset=0, end_offset=150, type='context', text='Sofia ( / ˈsoʊfiə , ˈsɒf - , soʊˈfiːə / SOH - fee - ə , SOF - , soh - FEE - ə ; Bulgarian : Со́фия , tr . Sofiya , pronounced ( ˈsɔfijə ) ( listen ) )', normalized_text='sofia ˈsoʊfiə ˈsɒf soʊˈfiːə soh fee ə sof soh fee ə bulgarian со́фия tr sofiya pronounced ˈsɔfijə listen'))], explanation_type='single_sentence'),\n",
       " -4253887715222554102: QEDExample(example_id=-4253887715222554102, title='Heart development', question='when does the heart develop and begin pumping blood', passage='Heart development refers to the prenatal development of the human heart . This begins with the formation of two endocardial tubes which merge to form the tubular heart , also called the primitive heart tube , that loops and septates into the four chambers and paired arterial trunks that form the adult heart . The heart is the first functional organ in vertebrate embryos , and in the human , beats spontaneously by week 4 of development .', sentence_starts=[0, 74, 311], selected_sent={'start': 311, 'end': 440, 'string': 'The heart is the first functional organ in vertebrate embryos , and in the human , beats spontaneously by week 4 of development .'}, answer=[Entity(start_offset=379, end_offset=438, type='context', text='in the human , beats spontaneously by week 4 of development', normalized_text='in human beats spontaneously by week 4 of development')], nq_answers=[[Entity(start_offset=379, end_offset=438, type='context', text='in the human , beats spontaneously by week 4 of development', normalized_text='in human beats spontaneously by week 4 of development')], [Entity(start_offset=414, end_offset=438, type='context', text='by week 4 of development', normalized_text='by week 4 of development')], [Entity(start_offset=417, end_offset=438, type='context', text='week 4 of development', normalized_text='week 4 of development')]], aligned_nps=[(Entity(start_offset=10, end_offset=19, type='question', text='the heart', normalized_text='heart'), Entity(start_offset=311, end_offset=320, type='context', text='The heart', normalized_text='heart'))], explanation_type='single_sentence'),\n",
       " 7131905053479064171: QEDExample(example_id=7131905053479064171, title='The Big Texan Steak Ranch', question='how much is a 72 oz steak at the big texan', passage=\"The Big Texan is best known for its 72 ounce ( 4.5 pounds or 2.04 kg ) steak , nicknamed `` The Texas King . '' The steak is free to anyone who , in one hour or less , can eat the entire meal , consisting of the steak itself , a bread roll with butter , a baked potato , shrimp cocktail , and a salad ; otherwise , the meal costs $72 . Those who have successfully consumed the Texas King meal have their names recorded and posted at the restaurant . As of February 2018 , over 9,500 people out of about 62,000 have accomplished this feat .\", sentence_starts=[0, 112, 336, 450], selected_sent={'start': 112, 'end': 336, 'string': 'The steak is free to anyone who , in one hour or less , can eat the entire meal , consisting of the steak itself , a bread roll with butter , a baked potato , shrimp cocktail , and a salad ; otherwise , the meal costs $72 . '}, answer=[Entity(start_offset=125, end_offset=333, type='context', text='free to anyone who , in one hour or less , can eat the entire meal , consisting of the steak itself , a bread roll with butter , a baked potato , shrimp cocktail , and a salad ; otherwise , the meal costs $72', normalized_text='free to anyone who in one hour or less can eat entire meal consisting of steak itself bread roll with butter baked potato shrimp cocktail and salad otherwise meal costs 72')], nq_answers=[[Entity(start_offset=330, end_offset=333, type='context', text='$72', normalized_text='72')]], aligned_nps=[(Entity(start_offset=12, end_offset=42, type='question', text='a 72 oz steak at the big texan', normalized_text='72 oz steak at big texan'), Entity(start_offset=112, end_offset=121, type='context', text='The steak', normalized_text='steak'))], explanation_type='single_sentence'),\n",
       " -2416336019123591997: QEDExample(example_id=-2416336019123591997, title='Spinothalamic tract', question='where does decussation occur in the spinothalamic pathway', passage='The axons of the tract cells cross over ( decussate ) to the other side of the spinal cord via the anterior white commissure , and to the anterolateral corner of the spinal cord ( hence the spinothalamic tract being part of the anterolateral system ) . Decussation usually occurs 1 - 2 spinal nerve segments above the point of entry . The axons travel up the length of the spinal cord into the brainstem , specifically the rostral ventromedial medulla .', sentence_starts=[0, 253, 335], selected_sent={'start': 253, 'end': 335, 'string': 'Decussation usually occurs 1 - 2 spinal nerve segments above the point of entry . '}, answer=[Entity(start_offset=280, end_offset=332, type='context', text='1 - 2 spinal nerve segments above the point of entry', normalized_text='1 2 spinal nerve segments above point of entry')], nq_answers=[[Entity(start_offset=265, end_offset=332, type='context', text='usually occurs 1 - 2 spinal nerve segments above the point of entry', normalized_text='usually occurs 1 2 spinal nerve segments above point of entry')], [Entity(start_offset=280, end_offset=332, type='context', text='1 - 2 spinal nerve segments above the point of entry', normalized_text='1 2 spinal nerve segments above point of entry')]], aligned_nps=[(Entity(start_offset=11, end_offset=22, type='question', text='decussation', normalized_text='decussation'), Entity(start_offset=253, end_offset=264, type='context', text='Decussation', normalized_text='decussation')), (Entity(start_offset=32, end_offset=57, type='question', text='the spinothalamic pathway', normalized_text='spinothalamic pathway'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 1586691717504133123: QEDExample(example_id=1586691717504133123, title='Basic education', question='who propounded the idea of basic education in india', passage='The pedagogic goals of Basic Education by Mahatma Gandhi are general and complex pedagogic targets and conrete pedagogic targets . The general targets are lifelong education , social education and integral education . The conrete pedagogic targets are craftwork , native language , co-education , the village community , hygiene - the Programme of safai - and reading and writing .', sentence_starts=[0, 131, 218], selected_sent={'start': 0, 'end': 131, 'string': 'The pedagogic goals of Basic Education by Mahatma Gandhi are general and complex pedagogic targets and conrete pedagogic targets . '}, answer=[Entity(start_offset=42, end_offset=56, type='context', text='Mahatma Gandhi', normalized_text='mahatma gandhi')], nq_answers=[[Entity(start_offset=42, end_offset=56, type='context', text='Mahatma Gandhi', normalized_text='mahatma gandhi')]], aligned_nps=[(Entity(start_offset=27, end_offset=42, type='question', text='basic education', normalized_text='basic education'), Entity(start_offset=23, end_offset=38, type='context', text='Basic Education', normalized_text='basic education'))], explanation_type='single_sentence'),\n",
       " 4728901131999035522: QEDExample(example_id=4728901131999035522, title='Capital punishment in New York', question='when did new york stop using the electric chair', passage=\"Capital punishment is not in force in the State of New York . The last execution took place in 1963 , when Eddie Mays was electrocuted at Sing Sing Prison . The state was the first to adopt the electric chair as a method of execution , which replaced hanging . Following the U.S. Supreme Court 's ruling declaring existing capital punishment statutes unconstitutional in Furman v. Georgia ( 1972 ) , New York was without a death penalty until 1995 , when then - Governor George Pataki signed a new statute into law , which provided for execution by lethal injection .\", sentence_starts=[0, 62, 157, 261], selected_sent={'start': 62, 'end': 157, 'string': 'The last execution took place in 1963 , when Eddie Mays was electrocuted at Sing Sing Prison . '}, answer=[Entity(start_offset=95, end_offset=99, type='context', text='1963', normalized_text='1963')], nq_answers=[[Entity(start_offset=95, end_offset=99, type='context', text='1963', normalized_text='1963')], [Entity(start_offset=391, end_offset=395, type='context', text='1972', normalized_text='1972')]], aligned_nps=[(Entity(start_offset=9, end_offset=17, type='question', text='new york', normalized_text='new york'), Entity(start_offset=62, end_offset=80, type='context', text='The last execution', normalized_text='last execution'))], explanation_type='single_sentence'),\n",
       " -3654809363614635590: QEDExample(example_id=-3654809363614635590, title='Howard Rollins', question='who played tibbs on in the heat of the night', passage=\"Howard Ellsworth Rollins Jr . ( October 17 , 1950 -- December 8 , 1996 ) was an American stage , film and television actor . Howard Rollins was best known for his role as Andrew Young in 1978 's King , George Haley in the 1979 miniseries Roots : The Next Generations , Coalhouse Walker Jr. in the 1981 film Ragtime , Captain Davenport in the 1984 film A Soldier 's Story , and as Virgil Tibbs on the crime drama In the Heat of the Night .\", sentence_starts=[0, 30, 125], selected_sent={'start': 125, 'end': 438, 'string': \"Howard Rollins was best known for his role as Andrew Young in 1978 's King , George Haley in the 1979 miniseries Roots : The Next Generations , Coalhouse Walker Jr. in the 1981 film Ragtime , Captain Davenport in the 1984 film A Soldier 's Story , and as Virgil Tibbs on the crime drama In the Heat of the Night .\"}, answer=[Entity(start_offset=0, end_offset=29, type='context', text='Howard Ellsworth Rollins Jr .', normalized_text='howard ellsworth rollins jr')], nq_answers=[[Entity(start_offset=0, end_offset=29, type='context', text='Howard Ellsworth Rollins Jr .', normalized_text='howard ellsworth rollins jr')]], aligned_nps=[(Entity(start_offset=11, end_offset=16, type='question', text='tibbs', normalized_text='tibbs'), Entity(start_offset=380, end_offset=392, type='context', text='Virgil Tibbs', normalized_text='virgil tibbs')), (Entity(start_offset=23, end_offset=44, type='question', text='the heat of the night', normalized_text='heat of night'), Entity(start_offset=396, end_offset=436, type='context', text='the crime drama In the Heat of the Night', normalized_text='crime drama in heat of night'))], explanation_type='single_sentence'),\n",
       " 1184676958861396405: QEDExample(example_id=1184676958861396405, title='The Book of Eli', question='where did they film the book of eli', passage=\"The Book of Eli is a 2010 American post-apocalyptic neo-Western action film directed by the Hughes brothers , written by Gary Whitta , and starring Denzel Washington , Gary Oldman , Mila Kunis , Ray Stevenson , and Jennifer Beals . The story revolves around Eli , a nomad in a post-apocalyptic world , who is told by a voice to deliver his copy of a mysterious book to a safe location on the West Coast of the United States . The history of the post-war world is explained along the way , as is the importance of Eli 's task . Filming began in February 2009 and took place in New Mexico .\", sentence_starts=[0, 232, 426, 527], selected_sent={'start': 527, 'end': 588, 'string': 'Filming began in February 2009 and took place in New Mexico .'}, answer=[Entity(start_offset=576, end_offset=586, type='context', text='New Mexico', normalized_text='new mexico')], nq_answers=[[Entity(start_offset=576, end_offset=586, type='context', text='New Mexico', normalized_text='new mexico')]], aligned_nps=[(Entity(start_offset=20, end_offset=35, type='question', text='the book of eli', normalized_text='book of eli'), Entity(start_offset=527, end_offset=534, type='context', text='Filming', normalized_text='filming'))], explanation_type='single_sentence'),\n",
       " -6223025678147948803: QEDExample(example_id=-6223025678147948803, title='San Juan Mountains', question='where are the san juan mountains in new mexico', passage='The San Juan Mountains are a high and rugged mountain range in the Rocky Mountains in southwestern Colorado and northwestern New Mexico . The area is highly mineralized ( the Colorado Mineral Belt ) and figured in the gold and silver mining industry of early Colorado . Major towns , all old mining camps , include Creede , Lake City , Silverton , Ouray , and Telluride . Large scale mining has ended in the region , although independent prospectors still work claims throughout the range . The last large scale mines were the Sunnyside Mine near Silverton , which operated until late in the 20th century and the Idarado Mine on Red Mountain Pass that closed down in the 1970s . Famous old San Juan mines include the Camp Bird and Smuggler Union mines , both located between Telluride and Ouray .', sentence_starts=[0, 138, 270, 372, 491, 679], selected_sent={'start': 0, 'end': 138, 'string': 'The San Juan Mountains are a high and rugged mountain range in the Rocky Mountains in southwestern Colorado and northwestern New Mexico . '}, answer=[Entity(start_offset=112, end_offset=135, type='context', text='northwestern New Mexico', normalized_text='northwestern new mexico')], nq_answers=[[Entity(start_offset=112, end_offset=135, type='context', text='northwestern New Mexico', normalized_text='northwestern new mexico')], [Entity(start_offset=83, end_offset=135, type='context', text='in southwestern Colorado and northwestern New Mexico', normalized_text='in southwestern colorado and northwestern new mexico')]], aligned_nps=[(Entity(start_offset=10, end_offset=32, type='question', text='the san juan mountains', normalized_text='san juan mountains'), Entity(start_offset=0, end_offset=22, type='context', text='The San Juan Mountains', normalized_text='san juan mountains')), (Entity(start_offset=36, end_offset=46, type='question', text='new mexico', normalized_text='new mexico'), Entity(start_offset=125, end_offset=135, type='context', text='New Mexico', normalized_text='new mexico'))], explanation_type='single_sentence'),\n",
       " 2722525402856944570: QEDExample(example_id=2722525402856944570, title='Religion in early Virginia', question='what was the religion in the virginia colony', passage='The history of religion in early Virginia begins with the commencing of Anglican services in Jamestown 1607 , which became the established church in 1619 , and culminates with the Virginia Statute for Religious Freedom in 1786 .', sentence_starts=[0], selected_sent={'start': 0, 'end': 228, 'string': 'The history of religion in early Virginia begins with the commencing of Anglican services in Jamestown 1607 , which became the established church in 1619 , and culminates with the Virginia Statute for Religious Freedom in 1786 .'}, answer=[Entity(start_offset=72, end_offset=80, type='context', text='Anglican', normalized_text='anglican')], nq_answers=[[Entity(start_offset=72, end_offset=80, type='context', text='Anglican', normalized_text='anglican')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -4924316288481476246: QEDExample(example_id=-4924316288481476246, title='Dazed and Confused (film)', question='what is the movie dazed and confused about', passage='Dazed and Confused is a 1993 American coming - of - age comedy film written and directed by Richard Linklater . The film features a large ensemble cast of actors who would later become stars , including Jason London , Ben Affleck , Milla Jovovich , Cole Hauser , Parker Posey , Adam Goldberg , Joey Lauren Adams , Matthew McConaughey , Nicky Katt , and Rory Cochrane . The plot follows various groups of Texas teenagers during the last day of school in 1976 .', sentence_starts=[0, 112, 369], selected_sent={'start': 369, 'end': 459, 'string': 'The plot follows various groups of Texas teenagers during the last day of school in 1976 .'}, answer=[Entity(start_offset=386, end_offset=457, type='context', text='various groups of Texas teenagers during the last day of school in 1976', normalized_text='various groups of texas teenagers during last day of school in 1976')], nq_answers=[[Entity(start_offset=378, end_offset=457, type='context', text='follows various groups of Texas teenagers during the last day of school in 1976', normalized_text='follows various groups of texas teenagers during last day of school in 1976')]], aligned_nps=[(Entity(start_offset=8, end_offset=36, type='question', text='the movie dazed and confused', normalized_text='movie dazed and confused'), Entity(start_offset=369, end_offset=377, type='context', text='The plot', normalized_text='plot'))], explanation_type='single_sentence'),\n",
       " -3156792715420337745: QEDExample(example_id=-3156792715420337745, title='List of Manchester United F.C. managers', question='who is the longest serving manager in manchester united history', passage=\"The longest - serving and most successful person to manage Manchester United is Sir Alex Ferguson , who won 13 Premier League titles , five FA Cups , four League Cups , 10 Community Shields , two UEFA Champions League titles , one UEFA Cup Winners ' Cup , one UEFA Super Cup , one Intercontinental Cup and one FIFA Club World Cup in his managerial reign of more than 26 years .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 377, 'string': \"The longest - serving and most successful person to manage Manchester United is Sir Alex Ferguson , who won 13 Premier League titles , five FA Cups , four League Cups , 10 Community Shields , two UEFA Champions League titles , one UEFA Cup Winners ' Cup , one UEFA Super Cup , one Intercontinental Cup and one FIFA Club World Cup in his managerial reign of more than 26 years .\"}, answer=[Entity(start_offset=80, end_offset=97, type='context', text='Sir Alex Ferguson', normalized_text='sir alex ferguson')], nq_answers=[[Entity(start_offset=80, end_offset=97, type='context', text='Sir Alex Ferguson', normalized_text='sir alex ferguson')]], aligned_nps=[(Entity(start_offset=38, end_offset=55, type='question', text='manchester united', normalized_text='manchester united'), Entity(start_offset=59, end_offset=76, type='context', text='Manchester United', normalized_text='manchester united'))], explanation_type='single_sentence'),\n",
       " -7056118700490851801: QEDExample(example_id=-7056118700490851801, title='Implantation (human embryo)', question='when does the implantation of the embryo occur', passage='In humans , implantation of a fertilized ovum is most likely to occur around 9 days after ovulation , however this can range between 6 and 12 days .', sentence_starts=[0], selected_sent={'start': 0, 'end': 148, 'string': 'In humans , implantation of a fertilized ovum is most likely to occur around 9 days after ovulation , however this can range between 6 and 12 days .'}, answer=[Entity(start_offset=49, end_offset=146, type='context', text='most likely to occur around 9 days after ovulation , however this can range between 6 and 12 days', normalized_text='most likely to occur around 9 days after ovulation however this can range between 6 and 12 days')], nq_answers=[[Entity(start_offset=70, end_offset=99, type='context', text='around 9 days after ovulation', normalized_text='around 9 days after ovulation')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='the implantation of the embryo', normalized_text='implantation of embryo'), Entity(start_offset=12, end_offset=45, type='context', text='implantation of a fertilized ovum', normalized_text='implantation of fertilized ovum'))], explanation_type='single_sentence'),\n",
       " -3895567339690724091: QEDExample(example_id=-3895567339690724091, title='Noli Me Tángere (novel)', question='rizal finished all the chapters of the novel noli me tangere in', passage='Originally written in Spanish , the book is more commonly published and read in the Philippines in either Tagalog or English . Together with its sequel , El Filibusterismo , the reading of Noli is obligatory for high school students throughout the country .', sentence_starts=[0, 127], selected_sent={'start': 0, 'end': 127, 'string': 'Originally written in Spanish , the book is more commonly published and read in the Philippines in either Tagalog or English . '}, answer=[Entity(start_offset=22, end_offset=29, type='context', text='Spanish', normalized_text='spanish')], nq_answers=[[Entity(start_offset=22, end_offset=29, type='context', text='Spanish', normalized_text='spanish')]], aligned_nps=[(Entity(start_offset=35, end_offset=60, type='question', text='the novel noli me tangere', normalized_text='novel noli me tangere'), Entity(start_offset=32, end_offset=40, type='context', text='the book', normalized_text='book')), (Entity(start_offset=0, end_offset=5, type='question', text='rizal', normalized_text='rizal'), Entity(start_offset=0, end_offset=18, type='context', text='Originally written', normalized_text='originally written'))], explanation_type='single_sentence'),\n",
       " -2471128667829068882: QEDExample(example_id=-2471128667829068882, title='Mexican Train', question='how many dominoes do you need for mexican train', passage='A double - twelve set of dominoes is marketed as the standard for Mexican Train , and accommodates up to 8 players . Other sets are commonly used as well . The following alternate sets are common , depending on the number of people playing :', sentence_starts=[0, 117, 156], selected_sent={'start': 0, 'end': 117, 'string': 'A double - twelve set of dominoes is marketed as the standard for Mexican Train , and accommodates up to 8 players . '}, answer=[Entity(start_offset=0, end_offset=21, type='context', text='A double - twelve set', normalized_text='double twelve set')], nq_answers=[[Entity(start_offset=0, end_offset=21, type='context', text='A double - twelve set', normalized_text='double twelve set')]], aligned_nps=[(Entity(start_offset=34, end_offset=47, type='question', text='mexican train', normalized_text='mexican train'), Entity(start_offset=66, end_offset=79, type='context', text='Mexican Train', normalized_text='mexican train'))], explanation_type='single_sentence'),\n",
       " -8587350848837910884: QEDExample(example_id=-8587350848837910884, title='Consequences of the attack on Pearl Harbor', question='who declared war on the united states four days after pearl harbor', passage='On December 11 , 1941 , Nazi Germany and Fascist Italy declared war on the United States , and the United States reciprocated , formally entering the war in Europe .', sentence_starts=[0], selected_sent={'start': 0, 'end': 165, 'string': 'On December 11 , 1941 , Nazi Germany and Fascist Italy declared war on the United States , and the United States reciprocated , formally entering the war in Europe .'}, answer=[Entity(start_offset=24, end_offset=54, type='context', text='Nazi Germany and Fascist Italy', normalized_text='nazi germany and fascist italy')], nq_answers=[[Entity(start_offset=24, end_offset=36, type='context', text='Nazi Germany', normalized_text='nazi germany'), Entity(start_offset=41, end_offset=54, type='context', text='Fascist Italy', normalized_text='fascist italy')]], aligned_nps=[(Entity(start_offset=38, end_offset=66, type='question', text='four days after pearl harbor', normalized_text='four days after pearl harbor'), Entity(start_offset=3, end_offset=21, type='context', text='December 11 , 1941', normalized_text='december 11 1941')), (Entity(start_offset=20, end_offset=37, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=71, end_offset=88, type='context', text='the United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 7416298161166363032: QEDExample(example_id=7416298161166363032, title='Red Bull', question='when did red bull come to the united states', passage='In 1992 , the product expanded to international markets : Hungary and Slovenia . It entered the United States via California in 1997 and the Middle East in 2000 . In 2008 , Forbes magazine listed both Chaleo and Mateschitz as the 250th richest people in the world with an estimated net worth of US $4 billion .', sentence_starts=[0, 81, 163], selected_sent={'start': 81, 'end': 163, 'string': 'It entered the United States via California in 1997 and the Middle East in 2000 . '}, answer=[Entity(start_offset=128, end_offset=132, type='context', text='1997', normalized_text='1997')], nq_answers=[[Entity(start_offset=128, end_offset=132, type='context', text='1997', normalized_text='1997')]], aligned_nps=[(Entity(start_offset=9, end_offset=17, type='question', text='red bull', normalized_text='red bull'), Entity(start_offset=81, end_offset=83, type='context', text='It', normalized_text='it')), (Entity(start_offset=26, end_offset=43, type='question', text='the united states', normalized_text='united states'), Entity(start_offset=92, end_offset=109, type='context', text='the United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 1331101156591334824: QEDExample(example_id=1331101156591334824, title='DD Form 214', question='when do you get a dd form 214', passage=\"The DD Form 214 , Certificate of Release or Discharge from Active Duty , generally referred to as a `` DD 214 '' , is a document of the United States Department of Defense , issued upon a military service member 's retirement , separation , or discharge from active duty in the Armed Forces of the United States , e.g. , U.S. Air Force , U.S. Army , U.S. Coast Guard , U.S. Marine Corps , or U.S. Navy .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 403, 'string': \"The DD Form 214 , Certificate of Release or Discharge from Active Duty , generally referred to as a `` DD 214 '' , is a document of the United States Department of Defense , issued upon a military service member 's retirement , separation , or discharge from active duty in the Armed Forces of the United States , e.g. , U.S. Air Force , U.S. Army , U.S. Coast Guard , U.S. Marine Corps , or U.S. Navy .\"}, answer=[Entity(start_offset=181, end_offset=311, type='context', text=\"upon a military service member 's retirement , separation , or discharge from active duty in the Armed Forces of the United States\", normalized_text='upon military service member s retirement separation or discharge from active duty in armed forces of united states')], nq_answers=[[Entity(start_offset=181, end_offset=311, type='context', text=\"upon a military service member 's retirement , separation , or discharge from active duty in the Armed Forces of the United States\", normalized_text='upon military service member s retirement separation or discharge from active duty in armed forces of united states')], [Entity(start_offset=174, end_offset=311, type='context', text=\"issued upon a military service member 's retirement , separation , or discharge from active duty in the Armed Forces of the United States\", normalized_text='issued upon military service member s retirement separation or discharge from active duty in armed forces of united states')]], aligned_nps=[(Entity(start_offset=16, end_offset=29, type='question', text='a dd form 214', normalized_text='dd form 214'), Entity(start_offset=0, end_offset=112, type='context', text=\"The DD Form 214 , Certificate of Release or Discharge from Active Duty , generally referred to as a `` DD 214 ''\", normalized_text='dd form 214 certificate of release or discharge from active duty generally referred to as dd 214'))], explanation_type='single_sentence'),\n",
       " -845091588828084337: QEDExample(example_id=-845091588828084337, title='Adelaide Football Club', question='when was the last time the crows were in the grand final', passage=\"Star midfielder for many years Patrick Dangerfield left the club at the end of the 2015 season ( a season in which he won the club 's best and fairest ) and Don Pyke , a former premiership player and assistant coach with West Coast who had also been an assistant coach at Adelaide from 2005 to 2006 , was appointed Adelaide 's senior coach for at least three years . Adelaide was widely tipped to slide out of the finals in 2016 but the Crows proved to be one of the successes of the season , comfortably qualifying for a home elimination final and defeating North Melbourne by 62 points , before being eliminated the next week by eventual beaten grand finalists , Sydney in the semi-finals . The club had a dominant 2017 season , winning their opening six games and never falling below second place for the entire season . Adelaide claimed their second McClelland Trophy as minor premiers . The Adelaide Crows entered the 2017 finals series as favourites for the premiership ; they defeated Greater Western Sydney and Geelong by 36 and 61 points respectively to qualify for the Grand Final , their first since 1998 , where they faced Richmond . Despite starting as favourites , the Crows lost the match by 48 points .\", sentence_starts=[0, 367, 693, 824, 892, 1146], selected_sent={'start': 892, 'end': 1146, 'string': 'The Adelaide Crows entered the 2017 finals series as favourites for the premiership ; they defeated Greater Western Sydney and Geelong by 36 and 61 points respectively to qualify for the Grand Final , their first since 1998 , where they faced Richmond . '}, answer=[Entity(start_offset=923, end_offset=927, type='context', text='2017', normalized_text='2017')], nq_answers=[[Entity(start_offset=923, end_offset=927, type='context', text='2017', normalized_text='2017')]], aligned_nps=[(Entity(start_offset=23, end_offset=32, type='question', text='the crows', normalized_text='crows'), Entity(start_offset=892, end_offset=910, type='context', text='The Adelaide Crows', normalized_text='adelaide crows')), (Entity(start_offset=41, end_offset=56, type='question', text='the grand final', normalized_text='grand final'), Entity(start_offset=1075, end_offset=1090, type='context', text='the Grand Final', normalized_text='grand final'))], explanation_type='single_sentence'),\n",
       " 7753793359500605772: QEDExample(example_id=7753793359500605772, title='Gastrocnemius muscle', question='what is the scientific name for the calf muscle', passage=\"In humans , the gastrocnemius muscle ( / ˌɡæstrɒkˈniːmiəs / or / ˌɡæstrəkˈniːmiəs / ; plural gastrocnemii ; Latin , from Greek γαστήρ `` stomach '' and κνήμη ( knḗmē ) `` leg '' ; meaning `` stomach of leg '' ( referring to the bulging shape of the calf ) is a very powerful superficial bipennate muscle that is in the back part of the lower leg . It runs from its two heads just above the knee to the heel , a two joint muscle .\", sentence_starts=[0, 348], selected_sent={'start': 0, 'end': 348, 'string': \"In humans , the gastrocnemius muscle ( / ˌɡæstrɒkˈniːmiəs / or / ˌɡæstrəkˈniːmiəs / ; plural gastrocnemii ; Latin , from Greek γαστήρ `` stomach '' and κνήμη ( knḗmē ) `` leg '' ; meaning `` stomach of leg '' ( referring to the bulging shape of the calf ) is a very powerful superficial bipennate muscle that is in the back part of the lower leg . \"}, answer=[Entity(start_offset=16, end_offset=36, type='context', text='gastrocnemius muscle', normalized_text='gastrocnemius muscle')], nq_answers=[[Entity(start_offset=16, end_offset=36, type='context', text='gastrocnemius muscle', normalized_text='gastrocnemius muscle')]], aligned_nps=[(Entity(start_offset=32, end_offset=47, type='question', text='the calf muscle', normalized_text='calf muscle'), Entity(start_offset=12, end_offset=255, type='context', text=\"the gastrocnemius muscle ( / ˌɡæstrɒkˈniːmiəs / or / ˌɡæstrəkˈniːmiəs / ; plural gastrocnemii ; Latin , from Greek γαστήρ `` stomach '' and κνήμη ( knḗmē ) `` leg '' ; meaning `` stomach of leg '' ( referring to the bulging shape of the calf )\", normalized_text='gastrocnemius muscle ˌɡæstrɒkˈniːmiəs or ˌɡæstrəkˈniːmiəs plural gastrocnemii latin from greek γαστήρ stomach and κνήμη knḗmē leg meaning stomach of leg referring to bulging shape of calf'))], explanation_type='single_sentence'),\n",
       " -557956134937901493: QEDExample(example_id=-557956134937901493, title='We Are the World', question='who made the song we are the world', passage=\"`` We Are the World '' is a song and charity single originally recorded by the supergroup United Support of Artists ( USA ) for Africa in 1985 . It was written by Michael Jackson and Lionel Richie ( with arrangements by Michael Omartian ) and produced by Quincy Jones for the album We Are the World . With sales in excess of 20 million copies , it is one of the fewer than 30 all - time physical singles to have sold at least 10 million copies worldwide .\", sentence_starts=[0, 145, 301], selected_sent={'start': 0, 'end': 145, 'string': \"`` We Are the World '' is a song and charity single originally recorded by the supergroup United Support of Artists ( USA ) for Africa in 1985 . \"}, answer=[Entity(start_offset=75, end_offset=123, type='context', text='the supergroup United Support of Artists ( USA )', normalized_text='supergroup united support of artists usa')], nq_answers=[[Entity(start_offset=79, end_offset=134, type='context', text='supergroup United Support of Artists ( USA ) for Africa', normalized_text='supergroup united support of artists usa for africa')], [Entity(start_offset=75, end_offset=134, type='context', text='the supergroup United Support of Artists ( USA ) for Africa', normalized_text='supergroup united support of artists usa for africa')], [Entity(start_offset=63, end_offset=134, type='context', text='recorded by the supergroup United Support of Artists ( USA ) for Africa', normalized_text='recorded by supergroup united support of artists usa for africa'), Entity(start_offset=152, end_offset=238, type='context', text='written by Michael Jackson and Lionel Richie ( with arrangements by Michael Omartian )', normalized_text='written by michael jackson and lionel richie with arrangements by michael omartian'), Entity(start_offset=243, end_offset=267, type='context', text='produced by Quincy Jones', normalized_text='produced by quincy jones')]], aligned_nps=[(Entity(start_offset=9, end_offset=34, type='question', text='the song we are the world', normalized_text='song we are world'), Entity(start_offset=3, end_offset=19, type='context', text='We Are the World', normalized_text='we are world'))], explanation_type='single_sentence'),\n",
       " 4963150476526458181: QEDExample(example_id=4963150476526458181, title='Biltmore Estate', question='when was the biltmore house opened to the public', passage=\"In an attempt to bolster the estate 's financial situation during the Great Depression , Cornelia and her husband opened Biltmore to the public in March 1930 at the request of the City of Asheville , which hoped the attraction would revitalize the area with tourism . Biltmore closed during World War II and in 1942 , 62 paintings and 17 sculptures were moved to the estate by train from the National Gallery of Art in Washington , D.C. to protect them in the event of an attack on the United States . The Music Room on the first floor was never finished , so it was used for storage until 1944 , when the possibility of an attack became more remote . Among the works stored were the Gilbert Stuart portrait of George Washington and works by Rembrandt , Raphael , and Anthony van Dyck . David Finley , the gallery director , was a friend of Edith Vanderbilt and had stayed at the estate .\", sentence_starts=[0, 268, 502, 652, 787], selected_sent={'start': 0, 'end': 268, 'string': \"In an attempt to bolster the estate 's financial situation during the Great Depression , Cornelia and her husband opened Biltmore to the public in March 1930 at the request of the City of Asheville , which hoped the attraction would revitalize the area with tourism . \"}, answer=[Entity(start_offset=147, end_offset=157, type='context', text='March 1930', normalized_text='march 1930')], nq_answers=[[Entity(start_offset=147, end_offset=157, type='context', text='March 1930', normalized_text='march 1930')]], aligned_nps=[(Entity(start_offset=9, end_offset=27, type='question', text='the biltmore house', normalized_text='biltmore house'), Entity(start_offset=121, end_offset=129, type='context', text='Biltmore', normalized_text='biltmore'))], explanation_type='single_sentence'),\n",
       " -4726363016166772094: QEDExample(example_id=-4726363016166772094, title='Dodgers–Yankees rivalry', question='when was the last time the dodgers played yankees in the world series', passage=\"The Dodgers -- Yankees rivalry is a Major League Baseball ( MLB ) rivalry between the Los Angeles Dodgers and the New York Yankees . The Dodgers are a member club of the National League ( NL ) West division , and the Yankees are a member club of the American League ( AL ) East division . The rivalry between the Dodgers and Yankees is one of the most well - known rivalries in Major League Baseball . The two teams have met 11 times in the World Series , more times than any other pair of teams from the American and National Leagues . The initial significance was embodied in the two teams ' proximity in New York City , when the Dodgers initially played in Brooklyn . After the Dodgers moved to Los Angeles in 1958 , the rivalry retained its significance as the two teams represented the dominant cities on each coast of the United States , and since the 1980s , the two largest cities in the United States . The Dodgers currently lead the regular season series 7 - 6 . Although the rivalry 's significance arose from the two teams ' numerous World Series meetings , the Yankees and Dodgers have not met in the World Series since 1981 . They would not play each other in a non-exhibition game until 2004 , when they played a 3 - game interleague series . Nevertheless , games between the two teams have become quite popular and draw sellout crowds .\", sentence_starts=[0, 133, 289, 402, 537, 671, 912, 973, 1140, 1258], selected_sent={'start': 973, 'end': 1140, 'string': \"Although the rivalry 's significance arose from the two teams ' numerous World Series meetings , the Yankees and Dodgers have not met in the World Series since 1981 . \"}, answer=[Entity(start_offset=1133, end_offset=1137, type='context', text='1981', normalized_text='1981')], nq_answers=[[Entity(start_offset=1133, end_offset=1137, type='context', text='1981', normalized_text='1981')]], aligned_nps=[(Entity(start_offset=42, end_offset=49, type='question', text='yankees', normalized_text='yankees'), Entity(start_offset=1086, end_offset=1093, type='context', text='Dodgers', normalized_text='dodgers')), (Entity(start_offset=53, end_offset=69, type='question', text='the world series', normalized_text='world series'), Entity(start_offset=1110, end_offset=1126, type='context', text='the World Series', normalized_text='world series'))], explanation_type='single_sentence'),\n",
       " -6600651124515937323: QEDExample(example_id=-6600651124515937323, title='List of Olympic Games host cities', question='where will be the next olympics be held', passage=\"This is a list of host cities of the Olympic Games , both summer and winter , since the modern Olympics began in 1896 . Since then , summer games have usually -- but not always -- celebrated a four - year period known as an Olympiad . There have been 28 Summer Olympic Games held in 23 cities , and 23 Winter Olympic Games held in 20 cities . In addition , three summer and two winter editions of the Games were scheduled to take place but later cancelled due to war : Berlin ( summer ) in 1916 ; Tokyo / Helsinki ( summer ) and Sapporo / Garmisch - Partenkirchen ( winter ) in 1940 ; and London ( summer ) and Cortina d'Ampezzo , Italy ( winter ) in 1944 . The 1906 Summer Olympics were officially sanctioned and held in Athens . However , in 1949 , the International Olympic Committee ( IOC ) , decided to unrecognize the 1906 Games . Four cities have been chosen by the IOC to host upcoming Olympic Games : Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics , Paris for the 2024 Summer Olympics , and Los Angeles for the 2028 Summer Olympics .\", sentence_starts=[0, 120, 235, 343, 658, 731, 837], selected_sent={'start': 837, 'end': 1069, 'string': 'Four cities have been chosen by the IOC to host upcoming Olympic Games : Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics , Paris for the 2024 Summer Olympics , and Los Angeles for the 2028 Summer Olympics .'}, answer=[Entity(start_offset=910, end_offset=915, type='context', text='Tokyo', normalized_text='tokyo')], nq_answers=[[Entity(start_offset=910, end_offset=915, type='context', text='Tokyo', normalized_text='tokyo')]], aligned_nps=[(Entity(start_offset=14, end_offset=31, type='question', text='the next olympics', normalized_text='next olympics'), Entity(start_offset=920, end_offset=944, type='context', text='the 2020 Summer Olympics', normalized_text='2020 summer olympics'))], explanation_type='single_sentence'),\n",
       " 1555896205825422569: QEDExample(example_id=1555896205825422569, title='Tinker Air Force Base', question='who is tinker air force base named after', passage='The base , originally known as Midwest Air Depot , is named in honor of Oklahoma native Major General Clarence L. Tinker , the first Native American Major General .', sentence_starts=[0], selected_sent={'start': 0, 'end': 164, 'string': 'The base , originally known as Midwest Air Depot , is named in honor of Oklahoma native Major General Clarence L. Tinker , the first Native American Major General .'}, answer=[Entity(start_offset=72, end_offset=162, type='context', text='Oklahoma native Major General Clarence L. Tinker , the first Native American Major General', normalized_text='oklahoma native major general clarence l tinker first native american major general')], nq_answers=[[Entity(start_offset=88, end_offset=162, type='context', text='Major General Clarence L. Tinker , the first Native American Major General', normalized_text='major general clarence l tinker first native american major general')], [Entity(start_offset=88, end_offset=120, type='context', text='Major General Clarence L. Tinker', normalized_text='major general clarence l tinker')]], aligned_nps=[(Entity(start_offset=7, end_offset=28, type='question', text='tinker air force base', normalized_text='tinker air force base'), Entity(start_offset=0, end_offset=8, type='context', text='The base', normalized_text='base'))], explanation_type='single_sentence'),\n",
       " -6306988093164932974: QEDExample(example_id=-6306988093164932974, title=\"Mother's Day (2016 film)\", question='where does the movie mothers day take place', passage=\"As Mother 's Day draws close , a group of seemingly unconnected people in Atlanta come to terms with the relationships they have with their mothers . Sandy ( Jennifer Aniston ) is a divorced mother of two boys whose ex-husband has recently remarried a younger woman named Tina ( Shay Mitchell ) . Miranda ( Julia Roberts ) is an accomplished writer who gave up her only child , Kristin ( Britt Robertson ) , for adoption at birth . But as a grown - up Kristin prepares herself for marriage , she begins to contemplate the missing part in her life and is encouraged by her friend , Jesse ( Kate Hudson ) , to go out and find her mother . Meanwhile , Jesse and her sister Gabi , who never see their mother , are surprised by their parents when they come to visit and must come to terms with their failing relationship .\", sentence_starts=[0, 150, 297, 432, 637], selected_sent={'start': 0, 'end': 150, 'string': \"As Mother 's Day draws close , a group of seemingly unconnected people in Atlanta come to terms with the relationships they have with their mothers . \"}, answer=[Entity(start_offset=74, end_offset=81, type='context', text='Atlanta', normalized_text='atlanta')], nq_answers=[[Entity(start_offset=74, end_offset=81, type='context', text='Atlanta', normalized_text='atlanta')]], aligned_nps=[(Entity(start_offset=11, end_offset=32, type='question', text='the movie mothers day', normalized_text='movie mothers day'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -971333942462495445: QEDExample(example_id=-971333942462495445, title='Dome of the Rock', question='what is the big gold dome in jerusalem', passage='The Dome of the Rock ( Arabic : قبة الصخرة \\u200e Qubbat al - Sakhrah , Hebrew : כיפת הסלע \\u200e Kippat ha - Sela ) is an Islamic shrine located on the Temple Mount in the Old City of Jerusalem .', sentence_starts=[0], selected_sent={'start': 0, 'end': 186, 'string': 'The Dome of the Rock ( Arabic : قبة الصخرة \\u200e Qubbat al - Sakhrah , Hebrew : כיפת הסלע \\u200e Kippat ha - Sela ) is an Islamic shrine located on the Temple Mount in the Old City of Jerusalem .'}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='The Dome of the Rock', normalized_text='dome of rock')], nq_answers=[[Entity(start_offset=4, end_offset=20, type='context', text='Dome of the Rock', normalized_text='dome of rock')]], aligned_nps=[(Entity(start_offset=8, end_offset=38, type='question', text='the big gold dome in jerusalem', normalized_text='big gold dome in jerusalem'), Entity(start_offset=110, end_offset=184, type='context', text='an Islamic shrine located on the Temple Mount in the Old City of Jerusalem', normalized_text='islamic shrine located on temple mount in old city of jerusalem'))], explanation_type='single_sentence'),\n",
       " -752729428506071643: QEDExample(example_id=-752729428506071643, title='Group of Eight', question='when did russia join the world economic forum', passage=\"The forum originated with a 1975 summit hosted by France that brought together representatives of six governments : France , Germany , Italy , Japan , the United Kingdom , and the United States , thus leading to the name Group of Six or G6 . The summit came to be known as the Group of Seven , or G7 , in 1976 with the addition of Canada . Russia was added to the political forum from 1997 , which the following year became known as the G8 . In March 2014 Russia was suspended following the annexation of Crimea , whereupon the group 's name reverted to the G7 . Certain representatives of G7 countries stated that they would be interested in Russia 's return to the group . However in 2017 Russia announced that it would permanently leave the political forum G8 . The European Union was represented at the G8 since the 1980s as a `` nonenumerated '' participant , but originally could not host or chair summits . The 40th summit was the first time the European Union was able to host and chair a summit . Collectively , in 2012 the G8 nations comprised 50.1 percent of 2012 global nominal GDP and 40.9 percent of global GDP ( PPP ) .\", sentence_starts=[0, 242, 340, 442, 563, 675, 765, 914, 1006], selected_sent={'start': 340, 'end': 442, 'string': 'Russia was added to the political forum from 1997 , which the following year became known as the G8 . '}, answer=[Entity(start_offset=385, end_offset=389, type='context', text='1997', normalized_text='1997')], nq_answers=[[Entity(start_offset=385, end_offset=389, type='context', text='1997', normalized_text='1997')]], aligned_nps=[(Entity(start_offset=9, end_offset=15, type='question', text='russia', normalized_text='russia'), Entity(start_offset=340, end_offset=346, type='context', text='Russia', normalized_text='russia')), (Entity(start_offset=21, end_offset=45, type='question', text='the world economic forum', normalized_text='world economic forum'), Entity(start_offset=360, end_offset=379, type='context', text='the political forum', normalized_text='political forum'))], explanation_type='single_sentence'),\n",
       " 4258621144767286597: QEDExample(example_id=4258621144767286597, title='Once Upon a Dream (Sleeping Beauty song)', question='who sang once upon a dream at the end of maleficent', passage=\"The song was covered by the American girl group No Secrets in 2003 for the two - disc DVD release , and by Emily Osment in October 2008 for the Platinum Edition release of the film , and also included on the compilation album Princess Disneymania . Lana Del Rey covered it in a `` somber and sinister '' mood for the 2014 film Maleficent .\", sentence_starts=[0, 249], selected_sent={'start': 249, 'end': 339, 'string': \"Lana Del Rey covered it in a `` somber and sinister '' mood for the 2014 film Maleficent .\"}, answer=[Entity(start_offset=249, end_offset=261, type='context', text='Lana Del Rey', normalized_text='lana del rey')], nq_answers=[[Entity(start_offset=249, end_offset=261, type='context', text='Lana Del Rey', normalized_text='lana del rey')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='once upon a dream', normalized_text='once upon dream'), Entity(start_offset=270, end_offset=272, type='context', text='it', normalized_text='it')), (Entity(start_offset=41, end_offset=51, type='question', text='maleficent', normalized_text='maleficent'), Entity(start_offset=313, end_offset=337, type='context', text='the 2014 film Maleficent', normalized_text='2014 film maleficent'))], explanation_type='single_sentence'),\n",
       " 3413977600585971868: QEDExample(example_id=3413977600585971868, title='John Connor', question='who played john connor in the original terminator', passage=\"John Connor is a fictional character of the Terminator franchise . Created by writer and director James Cameron , the character is first referred to in the 1984 film The Terminator and first appears in its 1991 sequel Terminator 2 : Judgment Day initially portrayed by Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film ; in addition , Linda Hamilton 's real - life son Dalton Abbot played John as a toddler in a dream sequence . The character is subsequently portrayed in the films , Nick Stahl in Terminator 3 : Rise of the Machines ( 2003 ) , Christian Bale in Terminator Salvation ( 2009 ) and Jason Clarke in Terminator Genisys ( 2015 ) and from the television series Thomas Dekker and John De Vito in Terminator : The Sarah Connor Chronicles ( 2008 -- 2009 ) as the teenager and little John respectively . In the fifth film , where John Connor who becomes the T - 3000 and serves as the antagonist of the series .\", sentence_starts=[0, 67, 505, 887], selected_sent={'start': 67, 'end': 505, 'string': \"Created by writer and director James Cameron , the character is first referred to in the 1984 film The Terminator and first appears in its 1991 sequel Terminator 2 : Judgment Day initially portrayed by Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film ; in addition , Linda Hamilton 's real - life son Dalton Abbot played John as a toddler in a dream sequence . \"}, answer=[Entity(start_offset=269, end_offset=394, type='context', text='Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film', normalized_text='michael edwards briefly as older connor and then by teenage actor edward furlong throughout remainder of film')], nq_answers=[[Entity(start_offset=269, end_offset=284, type='context', text='Michael Edwards', normalized_text='michael edwards'), Entity(start_offset=343, end_offset=357, type='context', text='Edward Furlong', normalized_text='edward furlong')], [Entity(start_offset=269, end_offset=284, type='context', text='Michael Edwards', normalized_text='michael edwards')], [Entity(start_offset=269, end_offset=316, type='context', text='Michael Edwards ( briefly as the older Connor )', normalized_text='michael edwards briefly as older connor'), Entity(start_offset=343, end_offset=394, type='context', text='Edward Furlong throughout the remainder of the film', normalized_text='edward furlong throughout remainder of film')]], aligned_nps=[(Entity(start_offset=11, end_offset=22, type='question', text='john connor', normalized_text='john connor'), Entity(start_offset=114, end_offset=127, type='context', text='the character', normalized_text='character')), (Entity(start_offset=26, end_offset=49, type='question', text='the original terminator', normalized_text='original terminator'), Entity(start_offset=202, end_offset=245, type='context', text='its 1991 sequel Terminator 2 : Judgment Day', normalized_text='its 1991 sequel terminator 2 judgment day'))], explanation_type='single_sentence'),\n",
       " 6391410727834544867: QEDExample(example_id=6391410727834544867, title='Octet rule', question='the octet rule states that in chemical compounds atoms tend to have the electron configuration of a', passage='The octet rule is a chemical rule of thumb that reflects observation that atoms of main - group elements tend to combine in such a way that each atom has eight electrons in its valence shell , giving it the same electron configuration as a noble gas . The rule is especially applicable to carbon , nitrogen , oxygen , and the halogens , but also to metals such as sodium or magnesium .', sentence_starts=[0, 252], selected_sent={'start': 0, 'end': 252, 'string': 'The octet rule is a chemical rule of thumb that reflects observation that atoms of main - group elements tend to combine in such a way that each atom has eight electrons in its valence shell , giving it the same electron configuration as a noble gas . '}, answer=[Entity(start_offset=238, end_offset=249, type='context', text='a noble gas', normalized_text='noble gas')], nq_answers=[[Entity(start_offset=240, end_offset=249, type='context', text='noble gas', normalized_text='noble gas')]], aligned_nps=[(Entity(start_offset=0, end_offset=14, type='question', text='the octet rule', normalized_text='octet rule'), Entity(start_offset=0, end_offset=9, type='context', text='The octet', normalized_text='octet'))], explanation_type='single_sentence'),\n",
       " 4042125617485022148: QEDExample(example_id=4042125617485022148, title='Days Gone Bye (The Walking Dead)', question='who was the walker rick killed in the first episode', passage='The episode opens in medias res as former Sheriff Deputy Rick Grimes ( Andrew Lincoln ) scavenges for gas and supplies at an abandoned convenience store in rural Georgia on a deserted highway . He spots a little girl ( Addy Miller ) , but she turns out to be a zombie . When she charges towards him , Rick shoots her in the head .', sentence_starts=[0, 194, 270], selected_sent={'start': 270, 'end': 330, 'string': 'When she charges towards him , Rick shoots her in the head .'}, answer=[Entity(start_offset=275, end_offset=278, type='context', text='she', normalized_text='she')], nq_answers=[[Entity(start_offset=203, end_offset=232, type='context', text='a little girl ( Addy Miller )', normalized_text='little girl addy miller')], [Entity(start_offset=219, end_offset=230, type='context', text='Addy Miller', normalized_text='addy miller')]], aligned_nps=[(Entity(start_offset=8, end_offset=18, type='question', text='the walker', normalized_text='walker'), Entity(start_offset=275, end_offset=278, type='context', text='she', normalized_text='she')), (Entity(start_offset=19, end_offset=23, type='question', text='rick', normalized_text='rick'), Entity(start_offset=301, end_offset=305, type='context', text='Rick', normalized_text='rick')), (Entity(start_offset=34, end_offset=51, type='question', text='the first episode', normalized_text='first episode'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -6171145136739461013: QEDExample(example_id=-6171145136739461013, title='Baby (Justin Bieber song)', question='who sings the rap in baby by justin bieber', passage=\"The song is predominantly upbeat , featuring Bieber 's R&B vocals over a backdrop containing a dance infused beat , full of keyboard and `` disco string '' synths . The song is composed in the key of E ♭ major with Bieber 's vocal range spanning from the low - note of G to the high - note of C. According to Jody Rosen of Rolling Stone , the song `` blends winks at Fifties doo - wop with hip - hop chants '' , comparing the style and the lyrics `` My first love broke my heart for the first time / And I was like / Baby , baby , baby , ooooh / I thought you 'd always be mine '' to fifties ballads like `` Tears on My Pillow '' , `` Why Do Fools Fall in Love '' and `` Earth Angel '' . Lyrically , Bieber 's lines explain his distress over his lost love , and promise to get it back , featured in lines like , `` And I wan na play it cool / But I 'm losin ' you ... / I 'm in pieces / So come and fix me ... '' . The chorus features the distinct and repetitive `` baby , baby , baby , ohhhh ( nooooo ) '' hook . After the second verse , Ludacris comes in with the verse - rap , an anecdote of young love when he was thirteen , as it runs `` When I was 13 / I had my first love / She had me going crazy / Oh , I was star - struck / She woke me up daily / Do n't need no Starbucks ... '' .\", sentence_starts=[0, 165, 688, 915, 1014], selected_sent={'start': 1014, 'end': 1289, 'string': \"After the second verse , Ludacris comes in with the verse - rap , an anecdote of young love when he was thirteen , as it runs `` When I was 13 / I had my first love / She had me going crazy / Oh , I was star - struck / She woke me up daily / Do n't need no Starbucks ... '' .\"}, answer=[Entity(start_offset=1039, end_offset=1047, type='context', text='Ludacris', normalized_text='ludacris')], nq_answers=[[Entity(start_offset=1039, end_offset=1047, type='context', text='Ludacris', normalized_text='ludacris')]], aligned_nps=[(Entity(start_offset=10, end_offset=42, type='question', text='the rap in baby by justin bieber', normalized_text='rap in baby by justin bieber'), Entity(start_offset=1062, end_offset=1126, type='context', text='the verse - rap , an anecdote of young love when he was thirteen', normalized_text='verse rap anecdote of young love when he was thirteen'))], explanation_type='single_sentence'),\n",
       " -8209058272420680202: QEDExample(example_id=-8209058272420680202, title='Beauty and the Beast (2017 film)', question='who plays the beast on the new beauty and the beast', passage=\"Beauty and the Beast is a 2017 American musical romantic fantasy film directed by Bill Condon from a screenplay written by Stephen Chbosky and Evan Spiliotopoulos , and co-produced by Walt Disney Pictures and Mandeville Films . The film is based on Disney 's 1991 animated film of the same name , itself an adaptation of Jeanne - Marie Leprince de Beaumont 's eighteenth - century fairy tale . The film features an ensemble cast that includes Emma Watson and Dan Stevens as the eponymous characters with Luke Evans , Kevin Kline , Josh Gad , Ewan McGregor , Stanley Tucci , Audra McDonald , Gugu Mbatha - Raw , Ian McKellen , and Emma Thompson in supporting roles .\", sentence_starts=[0, 228, 394], selected_sent={'start': 394, 'end': 665, 'string': 'The film features an ensemble cast that includes Emma Watson and Dan Stevens as the eponymous characters with Luke Evans , Kevin Kline , Josh Gad , Ewan McGregor , Stanley Tucci , Audra McDonald , Gugu Mbatha - Raw , Ian McKellen , and Emma Thompson in supporting roles .'}, answer=[Entity(start_offset=459, end_offset=470, type='context', text='Dan Stevens', normalized_text='dan stevens')], nq_answers=[[Entity(start_offset=459, end_offset=470, type='context', text='Dan Stevens', normalized_text='dan stevens')]], aligned_nps=[(Entity(start_offset=23, end_offset=51, type='question', text='the new beauty and the beast', normalized_text='new beauty and beast'), Entity(start_offset=394, end_offset=402, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " -7994495557308141403: QEDExample(example_id=-7994495557308141403, title='Brave New World', question='what inspired huxley to write brave new world', passage=\"Huxley said that Brave New World was inspired by the utopian novels of H.G. Wells , including A Modern Utopia ( 1905 ) and Men Like Gods ( 1923 ) . Wells 's hopeful vision of the future 's possibilities gave Huxley the idea to begin writing a parody of the novel , which became Brave New World . He wrote in a letter to Mrs. Arthur Goldsmith , an American acquaintance , that he had `` been having a little fun pulling the leg of H.G. Wells , '' but then he `` got caught up in the excitement of ( his ) own ideas . '' Unlike the most popular optimist utopian novels of the time , Huxley sought to provide a frightening vision of the future . Huxley referred to Brave New World as a `` negative utopia '' , somewhat influenced by Wells 's own The Sleeper Awakes ( dealing with subjects like corporate tyranny and behavioural conditioning ) and the works of D.H. Lawrence .\", sentence_starts=[0, 148, 296, 519, 643], selected_sent={'start': 0, 'end': 148, 'string': 'Huxley said that Brave New World was inspired by the utopian novels of H.G. Wells , including A Modern Utopia ( 1905 ) and Men Like Gods ( 1923 ) . '}, answer=[Entity(start_offset=49, end_offset=145, type='context', text='the utopian novels of H.G. Wells , including A Modern Utopia ( 1905 ) and Men Like Gods ( 1923 )', normalized_text='utopian novels of hg wells including modern utopia 1905 and men like gods 1923')], nq_answers=[[Entity(start_offset=49, end_offset=81, type='context', text='the utopian novels of H.G. Wells', normalized_text='utopian novels of hg wells')], [Entity(start_offset=49, end_offset=145, type='context', text='the utopian novels of H.G. Wells , including A Modern Utopia ( 1905 ) and Men Like Gods ( 1923 )', normalized_text='utopian novels of hg wells including modern utopia 1905 and men like gods 1923')]], aligned_nps=[(Entity(start_offset=14, end_offset=20, type='question', text='huxley', normalized_text='huxley'), Entity(start_offset=0, end_offset=6, type='context', text='Huxley', normalized_text='huxley')), (Entity(start_offset=30, end_offset=45, type='question', text='brave new world', normalized_text='brave new world'), Entity(start_offset=17, end_offset=32, type='context', text='Brave New World', normalized_text='brave new world'))], explanation_type='single_sentence'),\n",
       " -8411218336314702052: QEDExample(example_id=-8411218336314702052, title='Arachidonic acid', question='where is arachidonic acid found in the body', passage=\"Arachidonic acid is a polyunsaturated fatty acid present in the phospholipids ( especially phosphatidylethanolamine , phosphatidylcholine , and phosphatidylinositides ) of membranes of the body 's cells , and is abundant in the brain , muscles , and liver . Skeletal muscle is an especially active site of arachidonic acid retention , accounting for roughly 10 - 20 % of the phospholipid fatty acid content on average .\", sentence_starts=[0, 258], selected_sent={'start': 0, 'end': 258, 'string': \"Arachidonic acid is a polyunsaturated fatty acid present in the phospholipids ( especially phosphatidylethanolamine , phosphatidylcholine , and phosphatidylinositides ) of membranes of the body 's cells , and is abundant in the brain , muscles , and liver . \"}, answer=[Entity(start_offset=224, end_offset=255, type='context', text='the brain , muscles , and liver', normalized_text='brain muscles and liver')], nq_answers=[[Entity(start_offset=228, end_offset=233, type='context', text='brain', normalized_text='brain'), Entity(start_offset=236, end_offset=243, type='context', text='muscles', normalized_text='muscles'), Entity(start_offset=250, end_offset=255, type='context', text='liver', normalized_text='liver')]], aligned_nps=[(Entity(start_offset=9, end_offset=25, type='question', text='arachidonic acid', normalized_text='arachidonic acid'), Entity(start_offset=0, end_offset=16, type='context', text='Arachidonic acid', normalized_text='arachidonic acid'))], explanation_type='single_sentence'),\n",
       " -7235273497959781617: QEDExample(example_id=-7235273497959781617, title='Chair of the Federal Reserve', question='who appoints the chair of the federal reserve system', passage='The chair is chosen by the President of the United States from among the members of the Board of Governors ; and serves for four - year - terms after appointment . A chair may be appointed for several consecutive terms . William Martin was the longest serving chair , holding the position from 1951 to 1970 .', sentence_starts=[0, 164, 221], selected_sent={'start': 0, 'end': 164, 'string': 'The chair is chosen by the President of the United States from among the members of the Board of Governors ; and serves for four - year - terms after appointment . '}, answer=[Entity(start_offset=23, end_offset=57, type='context', text='the President of the United States', normalized_text='president of united states')], nq_answers=[[Entity(start_offset=23, end_offset=57, type='context', text='the President of the United States', normalized_text='president of united states')], [Entity(start_offset=27, end_offset=57, type='context', text='President of the United States', normalized_text='president of united states')]], aligned_nps=[(Entity(start_offset=13, end_offset=52, type='question', text='the chair of the federal reserve system', normalized_text='chair of federal reserve system'), Entity(start_offset=0, end_offset=9, type='context', text='The chair', normalized_text='chair'))], explanation_type='single_sentence'),\n",
       " -2288554954984872130: QEDExample(example_id=-2288554954984872130, title=\"Australia's Got Talent\", question=\"who are the australia's got talent judges\", passage=\"Australia 's Got Talent is an Australian reality television talent show which premiered on 18 February 2007 on the Seven Network . The show is based on the Got Talent series format that originated in the United Kingdom with Simon Cowell . The original judges were Tom Burlinson , Red Symons and Dannii Minogue . Burlinson and Symons did not return for season four and were replaced by Brian McFadden and Kyle Sandilands . Dawn French , Timomatic and Geri Halliwell joined the panel in season seven as replacements for McFadden and Minogue . All four judges from season seven will be replaced by Kelly Osbourne , Ian `` Dicko '' Dickson , Sophie Monk and Eddie Perfect in season eight .\", sentence_starts=[0, 131, 239, 312, 422, 541], selected_sent={'start': 541, 'end': 685, 'string': \"All four judges from season seven will be replaced by Kelly Osbourne , Ian `` Dicko '' Dickson , Sophie Monk and Eddie Perfect in season eight .\"}, answer=[Entity(start_offset=595, end_offset=667, type='context', text=\"Kelly Osbourne , Ian `` Dicko '' Dickson , Sophie Monk and Eddie Perfect\", normalized_text='kelly osbourne ian dicko dickson sophie monk and eddie perfect')], nq_answers=[[Entity(start_offset=595, end_offset=609, type='context', text='Kelly Osbourne', normalized_text='kelly osbourne'), Entity(start_offset=612, end_offset=635, type='context', text=\"Ian `` Dicko '' Dickson\", normalized_text='ian dicko dickson'), Entity(start_offset=638, end_offset=649, type='context', text='Sophie Monk', normalized_text='sophie monk'), Entity(start_offset=654, end_offset=667, type='context', text='Eddie Perfect', normalized_text='eddie perfect')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text=\"the australia's got talent\", normalized_text='australias got talent'), Entity(start_offset=562, end_offset=574, type='context', text='season seven', normalized_text='season seven'))], explanation_type='single_sentence'),\n",
       " -5720002001068693478: QEDExample(example_id=-5720002001068693478, title='General election', question='when are general elections held in the us', passage=\"In U.S. politics , general elections are elections held at any level ( e.g. city , county , congressional district , state ) that involve competition between at least two parties . General elections occur every two to six years ( depending on the positions being filled with most positions good for four years ) and include the presidential election , but unlike parliamentary systems the term can also refer to special elections that fill out positions prematurely vacated by the previous office holder ( e.g. through death , resignation , etc . ) . Some parallels can be drawn between the general election in parliamentary systems and the biennial elections determining all House seats , although there is no analogue to `` calling early elections '' in the U.S. , and the members of the elected U.S. Senate face elections of only one - third at a time at two - year intervals including during a general election .\", sentence_starts=[0, 181, 551], selected_sent={'start': 181, 'end': 551, 'string': 'General elections occur every two to six years ( depending on the positions being filled with most positions good for four years ) and include the presidential election , but unlike parliamentary systems the term can also refer to special elections that fill out positions prematurely vacated by the previous office holder ( e.g. through death , resignation , etc . ) . '}, answer=[Entity(start_offset=205, end_offset=227, type='context', text='every two to six years', normalized_text='every two to six years')], nq_answers=[[Entity(start_offset=205, end_offset=227, type='context', text='every two to six years', normalized_text='every two to six years')]], aligned_nps=[(Entity(start_offset=9, end_offset=26, type='question', text='general elections', normalized_text='general elections'), Entity(start_offset=181, end_offset=198, type='context', text='General elections', normalized_text='general elections')), (Entity(start_offset=35, end_offset=41, type='question', text='the us', normalized_text='us'), Entity(start_offset=199, end_offset=204, type='context', text='occur', normalized_text='occur'))], explanation_type='single_sentence'),\n",
       " -5907316762189930025: QEDExample(example_id=-5907316762189930025, title='2017 Stanley Cup Finals', question='who played in the stanley cup finals last year', passage=\"The 2017 Stanley Cup Finals was the championship series of the National Hockey League 's ( NHL ) 2016 -- 17 season , and the culmination of the 2017 Stanley Cup playoffs . The Eastern Conference champion and defending Stanley Cup champion Pittsburgh Penguins defeated the Western Conference champion Nashville Predators , four games to two . Penguins captain Sidney Crosby was awarded the Conn Smythe Trophy as most valuable player of the playoffs for the second consecutive year . The Penguins won the Stanley Cup in their opponent 's rink , just like they did the previous four times\", sentence_starts=[0, 172, 342, 482], selected_sent={'start': 172, 'end': 342, 'string': 'The Eastern Conference champion and defending Stanley Cup champion Pittsburgh Penguins defeated the Western Conference champion Nashville Predators , four games to two . '}, answer=[Entity(start_offset=239, end_offset=319, type='context', text='Pittsburgh Penguins defeated the Western Conference champion Nashville Predators', normalized_text='pittsburgh penguins defeated western conference champion nashville predators')], nq_answers=[[Entity(start_offset=239, end_offset=258, type='context', text='Pittsburgh Penguins', normalized_text='pittsburgh penguins'), Entity(start_offset=300, end_offset=319, type='context', text='Nashville Predators', normalized_text='nashville predators')], [Entity(start_offset=172, end_offset=258, type='context', text='The Eastern Conference champion and defending Stanley Cup champion Pittsburgh Penguins', normalized_text='eastern conference champion and defending stanley cup champion pittsburgh penguins'), Entity(start_offset=268, end_offset=319, type='context', text='the Western Conference champion Nashville Predators', normalized_text='western conference champion nashville predators')]], aligned_nps=[(Entity(start_offset=14, end_offset=36, type='question', text='the stanley cup finals', normalized_text='stanley cup finals'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text='')), (Entity(start_offset=37, end_offset=46, type='question', text='last year', normalized_text='last year'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -4219221292631893667: QEDExample(example_id=-4219221292631893667, title='Conan the Destroyer', question='who played the virgin in conan the destroyer', passage=\"Conan ( Schwarzenegger ) and his companion , the thief Malak ( Walter ) , are confronted by Queen Taramis ( Sarah Douglas ) of Shadizar . She tests their combat ability with several of her guards . Satisfied , she tells Conan that she has a quest for him . He refuses her , but when she promises to resurrect his lost love , Valeria , Conan agrees to the quest . He is to escort the Queen 's niece , Jehnna ( Olivia d'Abo ) , a virgin , who is destined to restore the jeweled horn of the dreaming god Dagoth ; a magic gem must first be retrieved that will locate the horn . Conan and Malak are joined by Bombaata ( Chamberlain ) , the captain of Taramis 's guard . Bombaata has secret orders to kill Conan once the gem is obtained .\", sentence_starts=[0, 138, 198, 257, 363, 574, 665], selected_sent={'start': 363, 'end': 574, 'string': \"He is to escort the Queen 's niece , Jehnna ( Olivia d'Abo ) , a virgin , who is destined to restore the jeweled horn of the dreaming god Dagoth ; a magic gem must first be retrieved that will locate the horn . \"}, answer=[Entity(start_offset=409, end_offset=421, type='context', text=\"Olivia d'Abo\", normalized_text='olivia dabo')], nq_answers=[[Entity(start_offset=409, end_offset=421, type='context', text=\"Olivia d'Abo\", normalized_text='olivia dabo')]], aligned_nps=[(Entity(start_offset=11, end_offset=21, type='question', text='the virgin', normalized_text='virgin'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -403334692092268805: QEDExample(example_id=-403334692092268805, title='Limited government', question='the main idea of limited government is that', passage='In political philosophy , limited government is where the government is empowered by law from a starting point of having no power , or where governmental power is restricted by law , usually in a written constitution . It is a key concept in the history of liberalism . The United States Constitution presents an example of the federal government not possessing any power except what is delegated to it by the Constitution - with the Tenth Amendment to the United States Constitution specifically stating that powers not specifically delegated to the federal government is reserved for the people and the states . The Magna Carta and the United States Constitution also represents important milestones in the limiting of governmental power . The earliest use of the term limited government dates back to King James VI and I in the late 16th century . Limited government put into practice often involves the protection of individual liberty from government intrusion .', sentence_starts=[0, 219, 270, 614, 742, 851], selected_sent={'start': 0, 'end': 219, 'string': 'In political philosophy , limited government is where the government is empowered by law from a starting point of having no power , or where governmental power is restricted by law , usually in a written constitution . '}, answer=[Entity(start_offset=54, end_offset=216, type='context', text='the government is empowered by law from a starting point of having no power , or where governmental power is restricted by law , usually in a written constitution', normalized_text='government is empowered by law from starting point of having no power or where governmental power is restricted by law usually in written constitution')], nq_answers=[[Entity(start_offset=54, end_offset=216, type='context', text='the government is empowered by law from a starting point of having no power , or where governmental power is restricted by law , usually in a written constitution', normalized_text='government is empowered by law from starting point of having no power or where governmental power is restricted by law usually in written constitution')], [Entity(start_offset=141, end_offset=180, type='context', text='governmental power is restricted by law', normalized_text='governmental power is restricted by law')], [Entity(start_offset=907, end_offset=965, type='context', text='protection of individual liberty from government intrusion', normalized_text='protection of individual liberty from government intrusion')], [Entity(start_offset=58, end_offset=216, type='context', text='government is empowered by law from a starting point of having no power , or where governmental power is restricted by law , usually in a written constitution', normalized_text='government is empowered by law from starting point of having no power or where governmental power is restricted by law usually in written constitution')]], aligned_nps=[(Entity(start_offset=17, end_offset=35, type='question', text='limited government', normalized_text='limited government'), Entity(start_offset=26, end_offset=44, type='context', text='limited government', normalized_text='limited government'))], explanation_type='single_sentence'),\n",
       " 8202542199325451106: QEDExample(example_id=8202542199325451106, title='Sweet Caroline', question='when did sweet caroline start at red sox games', passage=\"The song has been played at Fenway Park , home of Major League Baseball 's Boston Red Sox , since at least 1997 , and in the middle of the eighth inning at every game since 2002 . On opening night of the 2010 season at Fenway Park , the song was performed by Diamond himself . `` Sweet Caroline '' was played at Penn State Nittany Lions football games at Beaver Stadium until August 2012 , halting after the Penn State child sex abuse scandal . Performances at Beaver Stadium resumed in September 2013 , however . The song is played at the start of the fourth quarter of Pittsburgh Panthers Football games at Heinz Field . In response , West Virginia University students and fans will yell `` eat shit , Pitt '' during the refrain if heard played . It is also an unofficial song of the University of North Carolina at Chapel Hill , being played at athletic events and pep rallies .\", sentence_starts=[0, 180, 277, 445, 514, 623, 749], selected_sent={'start': 0, 'end': 180, 'string': \"The song has been played at Fenway Park , home of Major League Baseball 's Boston Red Sox , since at least 1997 , and in the middle of the eighth inning at every game since 2002 . \"}, answer=[Entity(start_offset=92, end_offset=111, type='context', text='since at least 1997', normalized_text='since at least 1997')], nq_answers=[[Entity(start_offset=98, end_offset=111, type='context', text='at least 1997', normalized_text='at least 1997')], [Entity(start_offset=107, end_offset=111, type='context', text='1997', normalized_text='1997')], [Entity(start_offset=92, end_offset=177, type='context', text='since at least 1997 , and in the middle of the eighth inning at every game since 2002', normalized_text='since at least 1997 and in middle of eighth inning at every game since 2002')]], aligned_nps=[(Entity(start_offset=9, end_offset=23, type='question', text='sweet caroline', normalized_text='sweet caroline'), Entity(start_offset=0, end_offset=8, type='context', text='The song', normalized_text='song'))], explanation_type='single_sentence'),\n",
       " -5127759950686598566: QEDExample(example_id=-5127759950686598566, title='Epistle to the Philippians', question='who was the book of philippians written to', passage=\"The Epistle of Paul to the Philippians , often referred to simply as Philippians , is the eleventh book in the New Testament . Paul and Timothy first visited Philippi in Greece during Paul 's second missionary journey , which occurred between approximately 49 and 51 AD . Philippi was the location of the first Christian community established in Europe .\", sentence_starts=[0, 127, 272], selected_sent={'start': 0, 'end': 127, 'string': 'The Epistle of Paul to the Philippians , often referred to simply as Philippians , is the eleventh book in the New Testament . '}, answer=[Entity(start_offset=23, end_offset=38, type='context', text='the Philippians', normalized_text='philippians')], nq_answers=[[Entity(start_offset=27, end_offset=38, type='context', text='Philippians', normalized_text='philippians')]], aligned_nps=[(Entity(start_offset=8, end_offset=31, type='question', text='the book of philippians', normalized_text='book of philippians'), Entity(start_offset=0, end_offset=80, type='context', text='The Epistle of Paul to the Philippians , often referred to simply as Philippians', normalized_text='epistle of paul to philippians often referred to simply as philippians'))], explanation_type='single_sentence'),\n",
       " 2429975703499991137: QEDExample(example_id=2429975703499991137, title='Sinus rhythm', question='what is the meaning of sinus rhythm in ecg', passage='A sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node . It is characterised by the presence of correctly oriented P waves on the electrocardiogram ( ECG ) . Sinus rhythm is necessary , but not sufficient , for normal electrical activity within the heart .', sentence_starts=[0, 107, 208], selected_sent={'start': 0, 'end': 107, 'string': 'A sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node . '}, answer=[Entity(start_offset=18, end_offset=104, type='context', text='any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node', normalized_text='any cardiac rhythm where depolarization of cardiac muscle begins at sinus node')], nq_answers=[[Entity(start_offset=22, end_offset=104, type='context', text='cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node', normalized_text='cardiac rhythm where depolarization of cardiac muscle begins at sinus node')], [Entity(start_offset=18, end_offset=104, type='context', text='any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node', normalized_text='any cardiac rhythm where depolarization of cardiac muscle begins at sinus node')], [Entity(start_offset=130, end_offset=172, type='context', text='the presence of correctly oriented P waves', normalized_text='presence of correctly oriented p waves')], [Entity(start_offset=18, end_offset=104, type='context', text='any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node', normalized_text='any cardiac rhythm where depolarization of cardiac muscle begins at sinus node'), Entity(start_offset=113, end_offset=205, type='context', text='characterised by the presence of correctly oriented P waves on the electrocardiogram ( ECG )', normalized_text='characterised by presence of correctly oriented p waves on electrocardiogram ecg')]], aligned_nps=[(Entity(start_offset=23, end_offset=35, type='question', text='sinus rhythm', normalized_text='sinus rhythm'), Entity(start_offset=0, end_offset=14, type='context', text='A sinus rhythm', normalized_text='sinus rhythm'))], explanation_type='single_sentence'),\n",
       " 4209478290770938677: QEDExample(example_id=4209478290770938677, title='Habib', question='what is the meaning of the name habib', passage=\"Habib ( Arabic : حبيب \\u200e , translit . ḥabīb ; Arabic pronunciation : ( ħabiːb ) ) , sometimes written as Habeeb , is an Arabic masculine given name and occasional surname with the meaning `` beloved '' . The name is popular throughout the Muslim World , though particularly in the Middle East and Africa . In other countries , especially in Yemen and Southeast Asian countries such as Brunei , Singapore , Indonesia and Malaysia , it is an honorific to address a Muslim scholar of Sayyid ( a descendant of Muhammad ) families . It is important to note that the name , as is the case with other Arabic names , is not confined to Muslims . Notable examples of Christian individuals named Habib include ' Habib the Deacon ' and Gabriel Habib and the Philosopher Habib .\", sentence_starts=[0, 37, 203, 305, 527, 637], selected_sent={'start': 0, 'end': 203, 'string': \"Habib ( Arabic : حبيب \\u200e , translit . ḥabīb ; Arabic pronunciation : ( ħabiːb ) ) , sometimes written as Habeeb , is an Arabic masculine given name and occasional surname with the meaning `` beloved '' . \"}, answer=[Entity(start_offset=190, end_offset=197, type='context', text='beloved', normalized_text='beloved')], nq_answers=[[Entity(start_offset=190, end_offset=197, type='context', text='beloved', normalized_text='beloved')], [Entity(start_offset=187, end_offset=200, type='context', text=\"`` beloved ''\", normalized_text='beloved')]], aligned_nps=[(Entity(start_offset=23, end_offset=37, type='question', text='the name habib', normalized_text='name habib'), Entity(start_offset=0, end_offset=110, type='context', text='Habib ( Arabic : حبيب \\u200e , translit . ḥabīb ; Arabic pronunciation : ( ħabiːb ) ) , sometimes written as Habeeb', normalized_text='habib arabic حبيب \\u200e translit ḥabīb arabic pronunciation ħabiːb sometimes written as habeeb'))], explanation_type='single_sentence'),\n",
       " -6247624090496620705: QEDExample(example_id=-6247624090496620705, title='90th Academy Awards', question='where will the oscars be held this year', passage='The 90th Academy Awards ceremony , presented by the Academy of Motion Picture Arts and Sciences ( AMPAS ) , honored the best films of 2017 and took place at the Dolby Theatre in Hollywood , Los Angeles , California . The ceremony was held on March 4 , 2018 rather than its usual late - February date to avoid conflicting with the 2018 Winter Olympics . During the ceremony , AMPAS presented Academy Awards ( commonly referred to as Oscars ) in 24 categories . The ceremony was televised in the United States by American Broadcasting Company ( ABC ) , produced by Michael De Luca and Jennifer Todd and directed by Glenn Weiss . Comedian Jimmy Kimmel hosted for the second consecutive year , making him the first person to host back - to - back ceremonies since Billy Crystal in 1997 and 1998 .', sentence_starts=[0, 217, 353, 460, 627], selected_sent={'start': 0, 'end': 217, 'string': 'The 90th Academy Awards ceremony , presented by the Academy of Motion Picture Arts and Sciences ( AMPAS ) , honored the best films of 2017 and took place at the Dolby Theatre in Hollywood , Los Angeles , California . '}, answer=[Entity(start_offset=157, end_offset=214, type='context', text='the Dolby Theatre in Hollywood , Los Angeles , California', normalized_text='dolby theatre in hollywood los angeles california')], nq_answers=[[Entity(start_offset=161, end_offset=214, type='context', text='Dolby Theatre in Hollywood , Los Angeles , California', normalized_text='dolby theatre in hollywood los angeles california')], [Entity(start_offset=157, end_offset=214, type='context', text='the Dolby Theatre in Hollywood , Los Angeles , California', normalized_text='dolby theatre in hollywood los angeles california')], [Entity(start_offset=154, end_offset=214, type='context', text='at the Dolby Theatre in Hollywood , Los Angeles , California', normalized_text='at dolby theatre in hollywood los angeles california')]], aligned_nps=[(Entity(start_offset=11, end_offset=21, type='question', text='the oscars', normalized_text='oscars'), Entity(start_offset=0, end_offset=105, type='context', text='The 90th Academy Awards ceremony , presented by the Academy of Motion Picture Arts and Sciences ( AMPAS )', normalized_text='90th academy awards ceremony presented by academy of motion picture arts and sciences ampas'))], explanation_type='single_sentence'),\n",
       " 7639529212077881462: QEDExample(example_id=7639529212077881462, title='Silver Linings Playbook', question='where was the movie silver linings playbook filmed', passage=\"The locations are Upper Darby , Ridley Park , and Lansdowne small communities just outside Philadelphia , Pennsylvania . Although not mentioned by name in the film , Ridley Park is credited at the end , and a police officer can be seen wearing the initials `` RPPD '' on his collar .\", sentence_starts=[0, 121], selected_sent={'start': 0, 'end': 121, 'string': 'The locations are Upper Darby , Ridley Park , and Lansdowne small communities just outside Philadelphia , Pennsylvania . '}, answer=[Entity(start_offset=18, end_offset=118, type='context', text='Upper Darby , Ridley Park , and Lansdowne small communities just outside Philadelphia , Pennsylvania', normalized_text='upper darby ridley park and lansdowne small communities just outside philadelphia pennsylvania')], nq_answers=[[Entity(start_offset=18, end_offset=118, type='context', text='Upper Darby , Ridley Park , and Lansdowne small communities just outside Philadelphia , Pennsylvania', normalized_text='upper darby ridley park and lansdowne small communities just outside philadelphia pennsylvania')], [Entity(start_offset=18, end_offset=29, type='context', text='Upper Darby', normalized_text='upper darby'), Entity(start_offset=32, end_offset=43, type='context', text='Ridley Park', normalized_text='ridley park'), Entity(start_offset=50, end_offset=59, type='context', text='Lansdowne', normalized_text='lansdowne'), Entity(start_offset=78, end_offset=118, type='context', text='just outside Philadelphia , Pennsylvania', normalized_text='just outside philadelphia pennsylvania')], [Entity(start_offset=60, end_offset=118, type='context', text='small communities just outside Philadelphia , Pennsylvania', normalized_text='small communities just outside philadelphia pennsylvania')], [Entity(start_offset=18, end_offset=29, type='context', text='Upper Darby', normalized_text='upper darby'), Entity(start_offset=32, end_offset=43, type='context', text='Ridley Park', normalized_text='ridley park'), Entity(start_offset=50, end_offset=59, type='context', text='Lansdowne', normalized_text='lansdowne')]], aligned_nps=[(Entity(start_offset=10, end_offset=43, type='question', text='the movie silver linings playbook', normalized_text='movie silver linings playbook'), Entity(start_offset=0, end_offset=13, type='context', text='The locations', normalized_text='locations'))], explanation_type='single_sentence'),\n",
       " 1080890781259710062: QEDExample(example_id=1080890781259710062, title='List of Game of Thrones characters', question='who plays the dragon queen from game of thrones', passage=\"Daenerys Targaryen ( season 1 -- present ) portrayed by Emilia Clarke . Daenerys Targaryen is the exiled princess of the Targaryen dynasty . Also called `` the Stormborn '' , she and her brother Viserys were smuggled to Essos during the end of Robert 's Rebellion . For seventeen years , she has been under the care of Viserys , whom she fears , as he is abusive to her whenever she displeases him . In exchange for an army , Viserys marries her to the powerful Dothraki warlord Khal Drogo , making her a Khaleesi , a queen of the Dothraki . Daenerys is at first afraid of her new husband but after learning the Dothraki language , she manages to get past their barriers . She begins to understand him and genuinely falls in love with him after learning Drogo is an intelligent leader and a kind man . After embracing the Dothraki culture , she becomes stronger and rebels against her brother . She later becomes pregnant with Drogo 's son who is prophesied by the Dothraki to be the `` Stallion Who Mounts the World '' . After her brother 's death and an assassination attempt by Robert Baratheon , Drogo vows to Daenerys that he will conquer the Seven Kingdoms for her and their unborn son . However , during their journey Drogo suffers from blood poisoning due to an infected wound incurred during a fight with a Dothraki tribesman . Daenerys is forced to seek the help of healer Mirri Maz Duur to save his life using blood magic . Mirri tricks Daenerys by using her unborn son 's life as a sacrifice to heal Drogo , leaving him in a permanent catatonic state , and forcing Daenerys to end her husband 's life . Losing both her husband and son , Daenerys punishes Mirri by having her burnt at the stake . She also lays the three dragon eggs she received as a wedding gift onto Khal Drogo 's body , then steps into the burning funeral pyre . After the fire extinguishes itself , the Khaleesi and three baby dragons , named Drogon , Rhaegal , and Viserion , are found alive and unharmed . Daenerys takes the baby dragons and the remaining tribe to gather new allies and reclaim the Iron Throne . She becomes the first female Dothraki leader . In Season 2 , she is lost in the Red Waste , a stretch of barren land . She and her khalasar eventually make it to Qarth , where the nobles are more interested in her dragons than her conquering Westeros . When her dragons are stolen by Pyat Pree , she goes into the House of the Undying and retrieves them , killing Pyat Pree . In the second season 's finale , she imprisons her host Xaro Xoan Daxos for having helped Pyat Pree . Her horde loot Xaro 's mansion to buy a ship . Daenerys travels from Qarth to Astapor , a city in Slaver 's Bay , where she negotiates the purchase of elite eunuch soldiers called the Unsullied . She also meets the famed knight Ser Barristan Selmy , and accepts him into her queensguard . On her departure from the city , she frees the slaves and has Drogon torch its elders . By the end of Season 3 , although her power has not yet been tested , she has acquired the loyalty of tens of thousands of freed slaves from Astapor and Yunkai , her remaining Dothraki brethren ( and two former Westerosi soldiers whom she encountered through the Dothraki , who advise her ) 2,000 ' Second Sons ' cavalrymen , 8,000 ' Unsullied ' elite infantry , and three rapidly growing dragons . The stay in Slaver 's Bay has made her question her motives , however , and she takes up the cause of ending slavery as well , donning the honorific `` Breaker of Chains '' as the slaves hold her to the sky , praising her as their Mhysa , or `` Mother '' . Daenerys later frees the slaves from Meereen , the last of the slave cities in Slaver 's Bay , but realizes that she is slowly losing control of her dragons , especially when Drogon shows signs of aggression towards her when she tries to break up a fight between them over food . Aware that she does not have enough men to conquer Westeros just yet , Daenerys resolves to remain in Slaver 's Bay and rule as Queen for the time being . She eventually learns of Jorah 's original purpose , which was to spy on her for Robert Baratheon , and orders him to leave Meereen on threat of execution . After she receives too many complaints about her dragons , Daenerys , locks Rhaegal and Viserion of them in the catacombs beneath Meereen before searching for Drogon . Meanwhile , Daenerys faces a new threat to her rule in the form of the Sons of the Harpy , a resistance movement against her and the Unsullied . She considers freeing her dragons , but they attempt to attack her , making her realize that they are no longer loyal to her . After Daario and Grey Worm arrest a member of the Sons of the Harpy , Mossador implores Daenerys to execute their captive , but Barristan tells her of the Mad King 's actions against his enemies , which included burning them with wildfire while laughing . He asks her not to execute the captive without a fair trial , and she agrees with him . Mossador goes against her wishes , and kills the captive Son of the Harpy . Daenerys has him publicly executed , which leads a riot to break out between the old masters and the freed slaves . At night , Daenerys finds that Drogon has returned , but when she tries to touch his face , he flies away . Soon afterward , a group of Unsullied patrolling the streets of Meereen are stopped by a crying woman who points them to an alleyway . The Unsullied head in to investigate , but it is revealed that the entire affair was a set up after they are soon cornered by a group of the Sons of the Harpy . The Unsullied attempt to fight back , but the Sons of the Harpy kill many of them . Barristan Selmy sees the commotion and tries to help , killing many of the Sons of the Harpy , but gets badly wounded , and dies . Grey Worm also sustains serious but nonfatal injuries . Daenerys is furious after learning what has happened to Barristan , and rounds up the leaders of the great Meereenese houses . She takes them into the catacombs where she randomly has one of them shoved forward . The Meereenese lord is promptly killed by dragonfire from Rhaegal , and he and Viserion eat him . Daenerys then has all the lords arrested , including her former adviser Hizdahr zo Loraq , whom she decides to marry to win over the Meereenese nobles . To respect the culture of the region , she agrees to have the fighting pits reinstated ( she had previously declined due to her distaste for killing for sport ) . Hizdahr convinces Daenerys to go to one of the pits to see the contestants battling over who will go to the final competition . Daenerys is sickened by the bloodshed , and gets up to leave , but her attention is turned by one masked competitor who defeats all of the other competitors without killing any of them . This competitor turns out to be Jorah Mormont , who is trying to win over Daenerys ' favor after being banished . Daenerys orders the Unsullied to take him away , but Jorah announces that he has brought her a gift , and Tyrion Lannister reveals himself to Daenerys . After a round of questioning , Daenerys banishes Jorah once again , but takes Tyrion on as her adviser . On the great opening of Daznak 's Pit , Jorah resurfaces as a voluntary contender on the arena , but Daenerys refuses to stop the games to spare his life . Jorah eventually prevails and saves her life by impaling with his spear an attacker from the Sons of the Harpy , who appear in legions and attack Daenerys ' guards . Cornered at the midst of the arena , defeat seems immediate when Drogon returns , killing many Sons of the Harpy despite being wounded by several of their spears . Daenerys manages to rekindle their bond and climbs his back , riding off into the distance to a stunned crowd . She roams the Great Steppe north of the city , where Drogon seems reluctant to obey her commands or even hunt for food . Strolling about on her own , Daenerys is faced with an incoming Dothraki khalasar of great numbers , and after dropping a ring to the ground to leave a trail , she is surrounded . In season 6 , the Dothraki take her to Vaes Dothrak , where she identifies herself to Khal Moro as Drogo 's former wife . Out of respect for Dothraki traditions , they take Daenerys to join the Dosh Khaleen , which consisted of the wives of deceased khals . Daenerys refuses and instead burns the temple down with herself and all the khals still inside . She emerges unscathed , and the awed Dothraki accept her as their new leader . She returns to Meereen with her new army and destroys the slaver fleet assaulting the city with her dragons . In the aftermath , Daenerys meets with Theon and Yara Greyjoy , who offer their support for her claim so that they can overthrow their uncle Euron . Daenerys accepts their aid and secures help from the Reach and Dorne , names Tyrion as her hand , but breaks up with Daario , ordering him to stay behind and govern Slaver 's Bay in her absence . With her new army , Daenerys finally sets sail for Westeros . In Season 7 Daenerys finally uses her dragons in battle , annihilating a Lannister force and their baggage train with fire . Daenerys welcomes Jon Snow to Dragonstone , seeing him as a friend and ally , insisting that he bend the knee to her but exhibiting patience with his refusal . She believes his tales of white walkers and agrees to let him mine dragonglass ( obsidian ) from her land . When Jon 's expedition north of the Wall gets into trouble Daenerys takes her dragons to rescue them , and is devastated when the Night King kills one . On the ship back to Dragonstone she and Jon make love .\", sentence_starts=[0, 72, 141, 266, 400, 542, 673, 802, 895, 1022, 1194, 1337, 1435, 1615, 1708, 1844, 1990, 2097, 2144, 2216, 2350, 2473, 2575, 2622, 2771, 2864, 2952, 3351, 3608, 3888, 4043, 4200, 4368, 4513, 4640, 4896, 4984, 5060, 5176, 5284, 5419, 5580, 5664, 5795, 5851, 5978, 6064, 6162, 6315, 6478, 6606, 6793, 6907, 7060, 7165, 7321, 7487, 7651, 7763, 7884, 8064, 8186, 8322, 8419, 8498, 8608, 8757, 8953, 9015, 9140, 9300, 9408, 9561], selected_sent={'start': 0, 'end': 72, 'string': 'Daenerys Targaryen ( season 1 -- present ) portrayed by Emilia Clarke . '}, answer=[Entity(start_offset=56, end_offset=69, type='context', text='Emilia Clarke', normalized_text='emilia clarke')], nq_answers=[[Entity(start_offset=56, end_offset=69, type='context', text='Emilia Clarke', normalized_text='emilia clarke')]], aligned_nps=[(Entity(start_offset=10, end_offset=47, type='question', text='the dragon queen from game of thrones', normalized_text='dragon queen from game of thrones'), Entity(start_offset=0, end_offset=42, type='context', text='Daenerys Targaryen ( season 1 -- present )', normalized_text='daenerys targaryen season 1 present'))], explanation_type='single_sentence'),\n",
       " 8900387163847503723: QEDExample(example_id=8900387163847503723, title='Dave Madden', question='who played mr. kincaid on the partridge family', passage=\"David Joseph Madden ( December 17 , 1931 -- January 16 , 2014 ) was a Canadian - born American actor . His most famous role came on the 1970s sitcom The Partridge Family , in which he played the group 's manager , Reuben Kincaid , opposite Shirley Jones 's character . Madden later had a recurring role as diner customer Earl Hicks on the mid-1970s to mid-1980s sitcom , Alice .\", sentence_starts=[0, 103, 269], selected_sent={'start': 103, 'end': 269, 'string': \"His most famous role came on the 1970s sitcom The Partridge Family , in which he played the group 's manager , Reuben Kincaid , opposite Shirley Jones 's character . \"}, answer=[Entity(start_offset=0, end_offset=19, type='context', text='David Joseph Madden', normalized_text='david joseph madden')], nq_answers=[[Entity(start_offset=0, end_offset=19, type='context', text='David Joseph Madden', normalized_text='david joseph madden')]], aligned_nps=[(Entity(start_offset=26, end_offset=46, type='question', text='the partridge family', normalized_text='partridge family'), Entity(start_offset=132, end_offset=169, type='context', text='the 1970s sitcom The Partridge Family', normalized_text='1970s sitcom partridge family')), (Entity(start_offset=11, end_offset=22, type='question', text='mr. kincaid', normalized_text='mr kincaid'), Entity(start_offset=191, end_offset=228, type='context', text=\"the group 's manager , Reuben Kincaid\", normalized_text='group s manager reuben kincaid'))], explanation_type='single_sentence'),\n",
       " 1308354162543821630: QEDExample(example_id=1308354162543821630, title='British Empire', question='where did the british empire control an entire continent', passage=\"Since 1718 , transportation to the American colonies had been a penalty for various offences in Britain , with approximately one thousand convicts transported per year across the Atlantic . Forced to find an alternative location after the loss of the Thirteen Colonies in 1783 , the British government turned to the newly discovered lands of Australia . The western coast of Australia had been discovered for Europeans by the Dutch explorer Willem Janszoon in 1606 and was later named New Holland by the Dutch East India Company , but there was no attempt to colonise it . In 1770 James Cook discovered the eastern coast of Australia while on a scientific voyage to the South Pacific Ocean , claimed the continent for Britain , and named it New South Wales . In 1778 , Joseph Banks , Cook 's botanist on the voyage , presented evidence to the government on the suitability of Botany Bay for the establishment of a penal settlement , and in 1787 the first shipment of convicts set sail , arriving in 1788 . Britain continued to transport convicts to New South Wales until 1840 . The Australian colonies became profitable exporters of wool and gold , mainly because of gold rushes in the colony of Victoria , making its capital Melbourne for a time the richest city in the world and the second largest city ( after London ) in the British Empire .\", sentence_starts=[0, 190, 354, 573, 759, 1006, 1078], selected_sent={'start': 573, 'end': 759, 'string': 'In 1770 James Cook discovered the eastern coast of Australia while on a scientific voyage to the South Pacific Ocean , claimed the continent for Britain , and named it New South Wales . '}, answer=[Entity(start_offset=624, end_offset=633, type='context', text='Australia', normalized_text='australia')], nq_answers=[[Entity(start_offset=624, end_offset=633, type='context', text='Australia', normalized_text='australia')], [Entity(start_offset=342, end_offset=351, type='context', text='Australia', normalized_text='australia')]], aligned_nps=[(Entity(start_offset=10, end_offset=28, type='question', text='the british empire', normalized_text='british empire'), Entity(start_offset=718, end_offset=725, type='context', text='Britain', normalized_text='britain'))], explanation_type='single_sentence'),\n",
       " 7765845025759665798: QEDExample(example_id=7765845025759665798, title='Non-rebreather mask', question='when should a non rebreather mask be used', passage=\"The non-rebreather mask is utilized for patients with physical trauma , chronic airway limitation , cluster headache , smoke inhalation , and carbon monoxide poisoning , or any other patients who require high - concentration oxygen , but do not require breathing assistance . Patients uncomfortable with having a mask on their face , such as those with claustrophobia , or patients with injuries to the mouth are more likely to benefit from a nasal cannula , or passive ( `` blow - by '' ) oxygen . Patients who are unable to breathe on their own would require invasive or noninvasive mechanical ventilation .\", sentence_starts=[0, 276, 499], selected_sent={'start': 0, 'end': 276, 'string': 'The non-rebreather mask is utilized for patients with physical trauma , chronic airway limitation , cluster headache , smoke inhalation , and carbon monoxide poisoning , or any other patients who require high - concentration oxygen , but do not require breathing assistance . '}, answer=[Entity(start_offset=36, end_offset=273, type='context', text='for patients with physical trauma , chronic airway limitation , cluster headache , smoke inhalation , and carbon monoxide poisoning , or any other patients who require high - concentration oxygen , but do not require breathing assistance', normalized_text='for patients with physical trauma chronic airway limitation cluster headache smoke inhalation and carbon monoxide poisoning or any other patients who require high concentration oxygen but do not require breathing assistance')], nq_answers=[[Entity(start_offset=36, end_offset=273, type='context', text='for patients with physical trauma , chronic airway limitation , cluster headache , smoke inhalation , and carbon monoxide poisoning , or any other patients who require high - concentration oxygen , but do not require breathing assistance', normalized_text='for patients with physical trauma chronic airway limitation cluster headache smoke inhalation and carbon monoxide poisoning or any other patients who require high concentration oxygen but do not require breathing assistance')], [Entity(start_offset=40, end_offset=273, type='context', text='patients with physical trauma , chronic airway limitation , cluster headache , smoke inhalation , and carbon monoxide poisoning , or any other patients who require high - concentration oxygen , but do not require breathing assistance', normalized_text='patients with physical trauma chronic airway limitation cluster headache smoke inhalation and carbon monoxide poisoning or any other patients who require high concentration oxygen but do not require breathing assistance')]], aligned_nps=[(Entity(start_offset=12, end_offset=33, type='question', text='a non rebreather mask', normalized_text='non rebreather mask'), Entity(start_offset=0, end_offset=23, type='context', text='The non-rebreather mask', normalized_text='nonrebreather mask'))], explanation_type='single_sentence'),\n",
       " -6713067461712918177: QEDExample(example_id=-6713067461712918177, title='Bye, Felicia', question='where does the phrase good bye felicia come from', passage=\"The phrase `` Bye , Felicia '' ( actually spelled `` Felisha '' in the cast listing ) came from a scene in the American stoner buddy crime comedy film Friday ( 1995 ) . According to Ice Cube , who starred in the film and co-wrote its script , `` Bye , Felicia '' is `` the phrase ' to get anyone out of your face ' , '' and , as it was used in the Friday scene , is generally intended as a dismissive kiss - off .\", sentence_starts=[0, 169], selected_sent={'start': 0, 'end': 169, 'string': \"The phrase `` Bye , Felicia '' ( actually spelled `` Felisha '' in the cast listing ) came from a scene in the American stoner buddy crime comedy film Friday ( 1995 ) . \"}, answer=[Entity(start_offset=96, end_offset=166, type='context', text='a scene in the American stoner buddy crime comedy film Friday ( 1995 )', normalized_text='scene in american stoner buddy crime comedy film friday 1995')], nq_answers=[[Entity(start_offset=96, end_offset=166, type='context', text='a scene in the American stoner buddy crime comedy film Friday ( 1995 )', normalized_text='scene in american stoner buddy crime comedy film friday 1995')], [Entity(start_offset=376, end_offset=411, type='context', text='intended as a dismissive kiss - off', normalized_text='intended as dismissive kiss off')], [Entity(start_offset=96, end_offset=157, type='context', text='a scene in the American stoner buddy crime comedy film Friday', normalized_text='scene in american stoner buddy crime comedy film friday')], [Entity(start_offset=86, end_offset=166, type='context', text='came from a scene in the American stoner buddy crime comedy film Friday ( 1995 )', normalized_text='came from scene in american stoner buddy crime comedy film friday 1995')]], aligned_nps=[(Entity(start_offset=11, end_offset=38, type='question', text='the phrase good bye felicia', normalized_text='phrase good bye felicia'), Entity(start_offset=0, end_offset=85, type='context', text=\"The phrase `` Bye , Felicia '' ( actually spelled `` Felisha '' in the cast listing )\", normalized_text='phrase bye felicia actually spelled felisha in cast listing'))], explanation_type='single_sentence'),\n",
       " -5991572213073579162: QEDExample(example_id=-5991572213073579162, title='Fifty Shades (novel series)', question='what are the three fifty shades of grey books', passage='Fifty Shades is a series of erotic novels by E.L. James . Initially a trilogy consisting of Fifty Shades of Grey ( 2011 ) , Fifty Shades Darker , and Fifty Shades Freed ( 2012 ) , the series traces the deepening relationship between a college graduate , Anastasia Steele , and a young business magnate , Christian Grey .', sentence_starts=[0, 50, 58], selected_sent={'start': 58, 'end': 320, 'string': 'Initially a trilogy consisting of Fifty Shades of Grey ( 2011 ) , Fifty Shades Darker , and Fifty Shades Freed ( 2012 ) , the series traces the deepening relationship between a college graduate , Anastasia Steele , and a young business magnate , Christian Grey .'}, answer=[Entity(start_offset=92, end_offset=177, type='context', text='Fifty Shades of Grey ( 2011 ) , Fifty Shades Darker , and Fifty Shades Freed ( 2012 )', normalized_text='fifty shades of grey 2011 fifty shades darker and fifty shades freed 2012')], nq_answers=[[Entity(start_offset=92, end_offset=112, type='context', text='Fifty Shades of Grey', normalized_text='fifty shades of grey'), Entity(start_offset=124, end_offset=143, type='context', text='Fifty Shades Darker', normalized_text='fifty shades darker'), Entity(start_offset=150, end_offset=168, type='context', text='Fifty Shades Freed', normalized_text='fifty shades freed')]], aligned_nps=[(Entity(start_offset=9, end_offset=45, type='question', text='the three fifty shades of grey books', normalized_text='three fifty shades of grey books'), Entity(start_offset=180, end_offset=190, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " -7892904540301629325: QEDExample(example_id=-7892904540301629325, title='Kansas City (Leiber and Stoller song)', question='who wrote the song going to kansas city', passage=\"`` Kansas City '' is a rhythm and blues song written by Jerry Leiber and Mike Stoller in 1952 . First recorded by Little Willie Littlefield the same year , the song later became a # 1 hit when it was recorded by Wilbert Harrison in 1959 . `` Kansas City '' became one of Leiber and Stoller 's `` most recorded tunes , with more than three hundred versions , '' with several appearing in the R&B and pop record charts .\", sentence_starts=[0, 96, 239], selected_sent={'start': 0, 'end': 96, 'string': \"`` Kansas City '' is a rhythm and blues song written by Jerry Leiber and Mike Stoller in 1952 . \"}, answer=[Entity(start_offset=56, end_offset=85, type='context', text='Jerry Leiber and Mike Stoller', normalized_text='jerry leiber and mike stoller')], nq_answers=[[Entity(start_offset=56, end_offset=85, type='context', text='Jerry Leiber and Mike Stoller', normalized_text='jerry leiber and mike stoller')], [Entity(start_offset=56, end_offset=68, type='context', text='Jerry Leiber', normalized_text='jerry leiber'), Entity(start_offset=73, end_offset=85, type='context', text='Mike Stoller', normalized_text='mike stoller')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text='the song going to kansas city', normalized_text='song going to kansas city'), Entity(start_offset=3, end_offset=14, type='context', text='Kansas City', normalized_text='kansas city'))], explanation_type='single_sentence'),\n",
       " 5758350213523510518: QEDExample(example_id=5758350213523510518, title='Death in Paradise (TV series)', question='where is the tv series death in paradise filmed', passage=\"Death in Paradise is a British - French crime drama television series created by Robert Thorogood , starring Ben Miller ( series 1 -- 3 ) , Kris Marshall ( series 3 -- 6 ) and Ardal O'Hanlon ( series 6 -- present ) . The programme is a joint UK and French production filmed on the French Caribbean island of Guadeloupe and broadcast on BBC One in the United Kingdom and France 2 in France . Death in Paradise has enjoyed high ratings , leading to repeated renewals . A seventh series began broadcasting on 4 January 2018 , with an eighth for 2019 already commissioned , with O'Hanlon and Jobert confirmed to return . Danny John - Jules ( who plays Officer Dwayne Myers ) will not be returning for series eight and will be replaced by actress Shyko Amos playing Officer Ruby Patterson , the niece of the commissioner . John - Jules cited his reason for exiting the show as wanting to `` leave on a high ''\", sentence_starts=[0, 217, 391, 467, 617, 818], selected_sent={'start': 217, 'end': 391, 'string': 'The programme is a joint UK and French production filmed on the French Caribbean island of Guadeloupe and broadcast on BBC One in the United Kingdom and France 2 in France . '}, answer=[Entity(start_offset=277, end_offset=318, type='context', text='the French Caribbean island of Guadeloupe', normalized_text='french caribbean island of guadeloupe')], nq_answers=[[Entity(start_offset=277, end_offset=318, type='context', text='the French Caribbean island of Guadeloupe', normalized_text='french caribbean island of guadeloupe')]], aligned_nps=[(Entity(start_offset=9, end_offset=40, type='question', text='the tv series death in paradise', normalized_text='tv series death in paradise'), Entity(start_offset=217, end_offset=230, type='context', text='The programme', normalized_text='programme'))], explanation_type='single_sentence'),\n",
       " 2074005917748197063: QEDExample(example_id=2074005917748197063, title='Elections in the Philippines', question='who has the right to vote in philippines', passage=\"Every citizen 18 years old or above on Election Day who has been a resident of the Philippines for at least a year and for at least six months in the place he is registering , and is not otherwise disqualified by law , may vote . In order to actually vote , a citizen has to register . The COMELEC has a registration period for several months prior to the election . Those who are not registered will not appear on the voters ' list and are ineligible to vote despite being qualified to do so .\", sentence_starts=[0, 230, 286, 367], selected_sent={'start': 0, 'end': 230, 'string': 'Every citizen 18 years old or above on Election Day who has been a resident of the Philippines for at least a year and for at least six months in the place he is registering , and is not otherwise disqualified by law , may vote . '}, answer=[Entity(start_offset=0, end_offset=216, type='context', text='Every citizen 18 years old or above on Election Day who has been a resident of the Philippines for at least a year and for at least six months in the place he is registering , and is not otherwise disqualified by law', normalized_text='every citizen 18 years old or above on election day who has been resident of philippines for at least year and for at least six months in place he is registering and is not otherwise disqualified by law')], nq_answers=[[Entity(start_offset=0, end_offset=216, type='context', text='Every citizen 18 years old or above on Election Day who has been a resident of the Philippines for at least a year and for at least six months in the place he is registering , and is not otherwise disqualified by law', normalized_text='every citizen 18 years old or above on election day who has been resident of philippines for at least year and for at least six months in place he is registering and is not otherwise disqualified by law')]], aligned_nps=[(Entity(start_offset=29, end_offset=40, type='question', text='philippines', normalized_text='philippines'), Entity(start_offset=79, end_offset=94, type='context', text='the Philippines', normalized_text='philippines'))], explanation_type='single_sentence'),\n",
       " -1976095529069495826: QEDExample(example_id=-1976095529069495826, title='Niger Delta', question='where is the niger delta on a map', passage='The Niger Delta is the delta of the Niger River sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria . It is typically considered to be located within nine coastal southern Nigerian states , which include : all six states from the South South geopolitical zone , one state ( Ondo ) from South West geopolitical zone and two states ( Abia and Imo ) from South East geopolitical zone . Of all the states that the region covers , only Cross River is not an oil - producing state .', sentence_starts=[0, 122, 403], selected_sent={'start': 0, 'end': 122, 'string': 'The Niger Delta is the delta of the Niger River sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria . '}, answer=[Entity(start_offset=48, end_offset=119, type='context', text='sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria', normalized_text='sitting directly on gulf of guinea on atlantic ocean in nigeria')], nq_answers=[[Entity(start_offset=48, end_offset=119, type='context', text='sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria', normalized_text='sitting directly on gulf of guinea on atlantic ocean in nigeria')]], aligned_nps=[(Entity(start_offset=9, end_offset=24, type='question', text='the niger delta', normalized_text='niger delta'), Entity(start_offset=0, end_offset=15, type='context', text='The Niger Delta', normalized_text='niger delta'))], explanation_type='single_sentence'),\n",
       " 3228081808286540919: QEDExample(example_id=3228081808286540919, title='Civil Rights Act of 1964', question='who does the civil rights act of 1964 protect', passage=\"The bill was called for by President John F. Kennedy in his Report to the American People on Civil Rights of June 11 , 1963 , in which he asked for legislation `` giving all Americans the right to be served in facilities which are open to the public -- hotels , restaurants , theaters , retail stores , and similar establishments '' , as well as `` greater protection for the right to vote '' . Kennedy delivered this speech following the immediate aftermath of the Birmingham campaign and the growing number of demonstrations and protests throughout the southern United States . Kennedy was moved to action following the elevated racial tensions and wave of black riots in the spring 1963 .\", sentence_starts=[0, 395, 580], selected_sent={'start': 0, 'end': 395, 'string': \"The bill was called for by President John F. Kennedy in his Report to the American People on Civil Rights of June 11 , 1963 , in which he asked for legislation `` giving all Americans the right to be served in facilities which are open to the public -- hotels , restaurants , theaters , retail stores , and similar establishments '' , as well as `` greater protection for the right to vote '' . \"}, answer=[Entity(start_offset=170, end_offset=183, type='context', text='all Americans', normalized_text='all americans')], nq_answers=[[Entity(start_offset=170, end_offset=183, type='context', text='all Americans', normalized_text='all americans')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the civil rights act of 1964', normalized_text='civil rights act of 1964'), Entity(start_offset=0, end_offset=8, type='context', text='The bill', normalized_text='bill'))], explanation_type='single_sentence'),\n",
       " -5052975019646502623: QEDExample(example_id=-5052975019646502623, title='NFL International Series', question='when did the nfl start playing in london', passage='Starting in the 2007 season , the National Football League ( NFL ) has hosted regular season American football games outside the United States every year . Collectively officially known through 2016 as the NFL International Series , from 2017 the series currently has two sub-series , the NFL London Games in London , which has been in place since 2007 , and the NFL Mexico Game in Mexico City , which began in 2016 with a predecessor game in 2005 .', sentence_starts=[0, 156], selected_sent={'start': 156, 'end': 449, 'string': 'Collectively officially known through 2016 as the NFL International Series , from 2017 the series currently has two sub-series , the NFL London Games in London , which has been in place since 2007 , and the NFL Mexico Game in Mexico City , which began in 2016 with a predecessor game in 2005 .'}, answer=[Entity(start_offset=348, end_offset=352, type='context', text='2007', normalized_text='2007')], nq_answers=[[Entity(start_offset=16, end_offset=20, type='context', text='2007', normalized_text='2007')], [Entity(start_offset=342, end_offset=352, type='context', text='since 2007', normalized_text='since 2007')], [Entity(start_offset=348, end_offset=352, type='context', text='2007', normalized_text='2007')]], aligned_nps=[(Entity(start_offset=9, end_offset=16, type='question', text='the nfl', normalized_text='nfl'), Entity(start_offset=206, end_offset=209, type='context', text='NFL', normalized_text='nfl')), (Entity(start_offset=34, end_offset=40, type='question', text='london', normalized_text='london'), Entity(start_offset=309, end_offset=315, type='context', text='London', normalized_text='london'))], explanation_type='single_sentence'),\n",
       " 2634482286557850231: QEDExample(example_id=2634482286557850231, title='Walk the Line (soundtrack)', question='who sang the songs on walk the line', passage='Walk the Line : Original Motion Picture Soundtrack is the soundtrack album to the 2005 biographical drama film of the same name released November 15 , 2005 by Wind - Up Records . There are nine songs performed by Joaquin Phoenix ( as Johnny Cash ) , four songs by Reese Witherspoon ( as June Carter Cash ) , one song by Waylon Payne ( as Jerry Lee Lewis ) , one song by Johnathan Rice ( as Roy Orbison ) , two songs by Tyler Hilton ( as Elvis Presley ) , and one song by Shooter Jennings ( as Waylon Jennings ) . At the Golden Globe Awards Joaquin Phoenix was awarded the Best Actor - Musical or Comedy and Reese Witherspoon was awarded the Best Actress - Musical or Comedy , as well as the film won the Best Picture - Musical or Comedy . Joaquin Phoenix and Reese Witherspoon were also nominated for the Academy Award for Best Actor and Best Actress , which Witherspoon won .', sentence_starts=[0, 179, 513, 739], selected_sent={'start': 179, 'end': 513, 'string': 'There are nine songs performed by Joaquin Phoenix ( as Johnny Cash ) , four songs by Reese Witherspoon ( as June Carter Cash ) , one song by Waylon Payne ( as Jerry Lee Lewis ) , one song by Johnathan Rice ( as Roy Orbison ) , two songs by Tyler Hilton ( as Elvis Presley ) , and one song by Shooter Jennings ( as Waylon Jennings ) . '}, answer=[Entity(start_offset=189, end_offset=510, type='context', text='nine songs performed by Joaquin Phoenix ( as Johnny Cash ) , four songs by Reese Witherspoon ( as June Carter Cash ) , one song by Waylon Payne ( as Jerry Lee Lewis ) , one song by Johnathan Rice ( as Roy Orbison ) , two songs by Tyler Hilton ( as Elvis Presley ) , and one song by Shooter Jennings ( as Waylon Jennings )', normalized_text='nine songs performed by joaquin phoenix as johnny cash four songs by reese witherspoon as june carter cash one song by waylon payne as jerry lee lewis one song by johnathan rice as roy orbison two songs by tyler hilton as elvis presley and one song by shooter jennings as waylon jennings')], nq_answers=[[Entity(start_offset=213, end_offset=228, type='context', text='Joaquin Phoenix', normalized_text='joaquin phoenix'), Entity(start_offset=264, end_offset=281, type='context', text='Reese Witherspoon', normalized_text='reese witherspoon'), Entity(start_offset=320, end_offset=332, type='context', text='Waylon Payne', normalized_text='waylon payne'), Entity(start_offset=370, end_offset=384, type='context', text='Johnathan Rice', normalized_text='johnathan rice'), Entity(start_offset=419, end_offset=431, type='context', text='Tyler Hilton', normalized_text='tyler hilton'), Entity(start_offset=471, end_offset=487, type='context', text='Shooter Jennings', normalized_text='shooter jennings')], [Entity(start_offset=213, end_offset=510, type='context', text='Joaquin Phoenix ( as Johnny Cash ) , four songs by Reese Witherspoon ( as June Carter Cash ) , one song by Waylon Payne ( as Jerry Lee Lewis ) , one song by Johnathan Rice ( as Roy Orbison ) , two songs by Tyler Hilton ( as Elvis Presley ) , and one song by Shooter Jennings ( as Waylon Jennings )', normalized_text='joaquin phoenix as johnny cash four songs by reese witherspoon as june carter cash one song by waylon payne as jerry lee lewis one song by johnathan rice as roy orbison two songs by tyler hilton as elvis presley and one song by shooter jennings as waylon jennings')]], aligned_nps=[(Entity(start_offset=22, end_offset=35, type='question', text='walk the line', normalized_text='walk line'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -950492354533820780: QEDExample(example_id=-950492354533820780, title='History of the Great Wall of China', question='who was the great wall of china built to defend against', passage='The history of the Great Wall of China began when fortifications built by various states during the Spring and Autumn ( 771 -- 476 BC ) and Warring States periods ( 475 -- 221 BC ) were connected by the first emperor of China , Qin Shi Huang , to protect his newly founded Qin dynasty ( 221 -- 206 BC ) against incursions by nomads from Inner Asia . The walls were built of rammed earth , constructed using forced labour , and by 212 BC ran from Gansu to the coast of southern Manchuria .', sentence_starts=[0, 350], selected_sent={'start': 0, 'end': 350, 'string': 'The history of the Great Wall of China began when fortifications built by various states during the Spring and Autumn ( 771 -- 476 BC ) and Warring States periods ( 475 -- 221 BC ) were connected by the first emperor of China , Qin Shi Huang , to protect his newly founded Qin dynasty ( 221 -- 206 BC ) against incursions by nomads from Inner Asia . '}, answer=[Entity(start_offset=325, end_offset=347, type='context', text='nomads from Inner Asia', normalized_text='nomads from inner asia')], nq_answers=[[Entity(start_offset=325, end_offset=347, type='context', text='nomads from Inner Asia', normalized_text='nomads from inner asia')], [Entity(start_offset=325, end_offset=349, type='context', text='nomads from Inner Asia .', normalized_text='nomads from inner asia')]], aligned_nps=[(Entity(start_offset=8, end_offset=31, type='question', text='the great wall of china', normalized_text='great wall of china'), Entity(start_offset=15, end_offset=38, type='context', text='the Great Wall of China', normalized_text='great wall of china'))], explanation_type='single_sentence'),\n",
       " 5467017721645268678: QEDExample(example_id=5467017721645268678, title='Beauty and the Beast (2017 film)', question='who played the beast in the movie beauty and the beast', passage=\"Beauty and the Beast is a 2017 American musical romantic fantasy film directed by Bill Condon from a screenplay written by Stephen Chbosky and Evan Spiliotopoulos , and co-produced by Walt Disney Pictures and Mandeville Films . The film is based on Disney 's 1991 animated film of the same name , itself an adaptation of Jeanne - Marie Leprince de Beaumont 's eighteenth - century fairy tale . The film features an ensemble cast that includes Emma Watson and Dan Stevens as the eponymous characters with Luke Evans , Kevin Kline , Josh Gad , Ewan McGregor , Stanley Tucci , Audra McDonald , Gugu Mbatha - Raw , Ian McKellen , and Emma Thompson in supporting roles .\", sentence_starts=[0, 228, 394], selected_sent={'start': 394, 'end': 665, 'string': 'The film features an ensemble cast that includes Emma Watson and Dan Stevens as the eponymous characters with Luke Evans , Kevin Kline , Josh Gad , Ewan McGregor , Stanley Tucci , Audra McDonald , Gugu Mbatha - Raw , Ian McKellen , and Emma Thompson in supporting roles .'}, answer=[Entity(start_offset=459, end_offset=470, type='context', text='Dan Stevens', normalized_text='dan stevens')], nq_answers=[[Entity(start_offset=459, end_offset=470, type='context', text='Dan Stevens', normalized_text='dan stevens')]], aligned_nps=[(Entity(start_offset=24, end_offset=54, type='question', text='the movie beauty and the beast', normalized_text='movie beauty and beast'), Entity(start_offset=394, end_offset=402, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " -8227939188793834871: QEDExample(example_id=-8227939188793834871, title='Electromyography', question='what features of muscle contraction can be determined from an emg (electromyogram)', passage='Electromyography ( EMG ) is an electrodiagnostic medicine technique for evaluating and recording the electrical activity produced by skeletal muscles . EMG is performed using an instrument called an electromyograph to produce a record called an electromyogram . An electromyograph detects the electric potential generated by muscle cells when these cells are electrically or neurologically activated . The signals can be analyzed to detect medical abnormalities , activation level , or recruitment order , or to analyze the biomechanics of human or animal movement .', sentence_starts=[0, 152, 262, 402], selected_sent={'start': 402, 'end': 566, 'string': 'The signals can be analyzed to detect medical abnormalities , activation level , or recruitment order , or to analyze the biomechanics of human or animal movement .'}, answer=[Entity(start_offset=440, end_offset=564, type='context', text='medical abnormalities , activation level , or recruitment order , or to analyze the biomechanics of human or animal movement', normalized_text='medical abnormalities activation level or recruitment order or to analyze biomechanics of human or animal movement')], nq_answers=[[Entity(start_offset=293, end_offset=321, type='context', text='electric potential generated', normalized_text='electric potential generated')]], aligned_nps=[(Entity(start_offset=59, end_offset=82, type='question', text='an emg (electromyogram)', normalized_text='emg electromyogram'), Entity(start_offset=402, end_offset=413, type='context', text='The signals', normalized_text='signals'))], explanation_type='single_sentence'),\n",
       " -199874749415494596: QEDExample(example_id=-199874749415494596, title='Autumn', question='what is the meaning of the word autumn', passage='Autumn , also known as fall in American and Canadian English , is one of the four temperate seasons . Autumn marks the transition from summer to winter , in September ( Northern Hemisphere ) or March ( Southern Hemisphere ) , when the duration of daylight becomes noticeably shorter and the temperature cools down considerably . One of its main features is the shedding of leaves from deciduous trees .', sentence_starts=[0, 102, 329], selected_sent={'start': 0, 'end': 102, 'string': 'Autumn , also known as fall in American and Canadian English , is one of the four temperate seasons . '}, answer=[Entity(start_offset=23, end_offset=27, type='context', text='fall', normalized_text='fall')], nq_answers=[[Entity(start_offset=23, end_offset=27, type='context', text='fall', normalized_text='fall')]], aligned_nps=[(Entity(start_offset=23, end_offset=38, type='question', text='the word autumn', normalized_text='word autumn'), Entity(start_offset=0, end_offset=60, type='context', text='Autumn , also known as fall in American and Canadian English', normalized_text='autumn also known as fall in american and canadian english'))], explanation_type='single_sentence'),\n",
       " -7530958148001769429: QEDExample(example_id=-7530958148001769429, title='Law of attraction (New Thought)', question='what is the secret of the law of attraction', passage=\"In the New Thought philosophy , the law of attraction is the belief that by focusing on positive or negative thoughts people can bring positive or negative experiences into their life . The belief is based on the idea that people and their thoughts are both made from `` pure energy '' , and that through the process of `` like energy attracting like energy '' a person can improve their own health , wealth and personal relationships .\", sentence_starts=[0, 186], selected_sent={'start': 0, 'end': 186, 'string': 'In the New Thought philosophy , the law of attraction is the belief that by focusing on positive or negative thoughts people can bring positive or negative experiences into their life . '}, answer=[Entity(start_offset=73, end_offset=183, type='context', text='by focusing on positive or negative thoughts people can bring positive or negative experiences into their life', normalized_text='by focusing on positive or negative thoughts people can bring positive or negative experiences into their life')], nq_answers=[[Entity(start_offset=57, end_offset=183, type='context', text='the belief that by focusing on positive or negative thoughts people can bring positive or negative experiences into their life', normalized_text='belief that by focusing on positive or negative thoughts people can bring positive or negative experiences into their life')]], aligned_nps=[(Entity(start_offset=22, end_offset=43, type='question', text='the law of attraction', normalized_text='law of attraction'), Entity(start_offset=32, end_offset=53, type='context', text='the law of attraction', normalized_text='law of attraction'))], explanation_type='single_sentence'),\n",
       " 235827364638368133: QEDExample(example_id=235827364638368133, title='Boötes', question='how did the constellation bootes get its name', passage=\"Boötes / boʊˈoʊtiːz / is a constellation in the northern sky , located between 0 ° and + 60 ° declination , and 13 and 16 hours of right ascension on the celestial sphere . The name comes from the Greek Βοώτης , Boōtēs , meaning `` herdsman '' or `` plowman '' ( literally , `` ox - driver '' ; from βοῦς bous `` cow '' ) .\", sentence_starts=[0, 173], selected_sent={'start': 173, 'end': 323, 'string': \"The name comes from the Greek Βοώτης , Boōtēs , meaning `` herdsman '' or `` plowman '' ( literally , `` ox - driver '' ; from βοῦς bous `` cow '' ) .\"}, answer=[Entity(start_offset=193, end_offset=321, type='context', text=\"the Greek Βοώτης , Boōtēs , meaning `` herdsman '' or `` plowman '' ( literally , `` ox - driver '' ; from βοῦς bous `` cow '' )\", normalized_text='greek βοώτης boōtēs meaning herdsman or plowman literally ox driver from βοῦς bous cow')], nq_answers=[[Entity(start_offset=188, end_offset=321, type='context', text=\"from the Greek Βοώτης , Boōtēs , meaning `` herdsman '' or `` plowman '' ( literally , `` ox - driver '' ; from βοῦς bous `` cow '' )\", normalized_text='from greek βοώτης boōtēs meaning herdsman or plowman literally ox driver from βοῦς bous cow')], [Entity(start_offset=188, end_offset=260, type='context', text=\"from the Greek Βοώτης , Boōtēs , meaning `` herdsman '' or `` plowman ''\", normalized_text='from greek βοώτης boōtēs meaning herdsman or plowman')]], aligned_nps=[(Entity(start_offset=37, end_offset=45, type='question', text='its name', normalized_text='its name'), Entity(start_offset=173, end_offset=181, type='context', text='The name', normalized_text='name'))], explanation_type='single_sentence'),\n",
       " 1201307645900712502: QEDExample(example_id=1201307645900712502, title='Rocinante', question=\"what is don quixote's horse's name\", passage=\"Rocinante ( Spanish pronunciation : ( roθiˈnante ) ) is Don Quixote 's horse in the novel Don Quixote by Miguel de Cervantes . In many ways , Rocinante is not only Don Quixote 's horse , but also his double : like Don Quixote , he is awkward , past his prime , and engaged in a task beyond his capacities .\", sentence_starts=[0, 127], selected_sent={'start': 0, 'end': 127, 'string': \"Rocinante ( Spanish pronunciation : ( roθiˈnante ) ) is Don Quixote 's horse in the novel Don Quixote by Miguel de Cervantes . \"}, answer=[Entity(start_offset=0, end_offset=9, type='context', text='Rocinante', normalized_text='rocinante')], nq_answers=[[Entity(start_offset=0, end_offset=9, type='context', text='Rocinante', normalized_text='rocinante')], [Entity(start_offset=142, end_offset=151, type='context', text='Rocinante', normalized_text='rocinante')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text=\"don quixote's horse's name\", normalized_text='don quixotes horses name'), Entity(start_offset=56, end_offset=124, type='context', text=\"Don Quixote 's horse in the novel Don Quixote by Miguel de Cervantes\", normalized_text='don quixote s horse in novel don quixote by miguel de cervantes'))], explanation_type='single_sentence'),\n",
       " -1706439311294242589: QEDExample(example_id=-1706439311294242589, title='Fayetteville, North Carolina', question='what is the population of fayetteville north carolina', passage='Fayetteville has received the All - America City Award from the National Civic League three times . As of the 2010 census it had a population of 200,564 , with an estimated population of 204,408 in 2013 . It is the 6th - largest city in North Carolina . Fayetteville is in the Sandhills in the western part of the Coastal Plain region , on the Cape Fear River .', sentence_starts=[0, 100, 205, 254], selected_sent={'start': 100, 'end': 205, 'string': 'As of the 2010 census it had a population of 200,564 , with an estimated population of 204,408 in 2013 . '}, answer=[Entity(start_offset=163, end_offset=202, type='context', text='estimated population of 204,408 in 2013', normalized_text='estimated population of 204408 in 2013')], nq_answers=[[Entity(start_offset=187, end_offset=202, type='context', text='204,408 in 2013', normalized_text='204408 in 2013')]], aligned_nps=[(Entity(start_offset=26, end_offset=53, type='question', text='fayetteville north carolina', normalized_text='fayetteville north carolina'), Entity(start_offset=122, end_offset=124, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -3996506204460912130: QEDExample(example_id=-3996506204460912130, title='Sons of Anarchy', question='in sons of anarchy who is sam crow', passage=\"The Sons of Anarchy ( SOA ) is an outlaw motorcycle club with many charters in the United States as well as overseas . The show focuses on the original and founding ( `` mother '' ) charter , Sons of Anarchy Motorcycle Club , Redwood Original , referred to by the acronym SAMCRO or Sam Crow , located in the fictional town of Charming , California , adjacent to the Teller - Morrow auto mechanic shop . Its nickname is reflected in the original title for the show , Forever Sam Crow . Led by President Clay Morrow , the club ' protects ' and controls Charming through close community relationships , bribery , and violent intimidation . In the early seasons they are vehement about keeping `` hard '' drugs and drug dealers out of Charming . They also do not tolerate sex criminals . The club 's leadership are supporters of the IRA .\", sentence_starts=[0, 119, 403, 485, 637, 742, 784], selected_sent={'start': 119, 'end': 403, 'string': \"The show focuses on the original and founding ( `` mother '' ) charter , Sons of Anarchy Motorcycle Club , Redwood Original , referred to by the acronym SAMCRO or Sam Crow , located in the fictional town of Charming , California , adjacent to the Teller - Morrow auto mechanic shop . \"}, answer=[Entity(start_offset=192, end_offset=290, type='context', text='Sons of Anarchy Motorcycle Club , Redwood Original , referred to by the acronym SAMCRO or Sam Crow', normalized_text='sons of anarchy motorcycle club redwood original referred to by acronym samcro or sam crow')], nq_answers=[[Entity(start_offset=192, end_offset=290, type='context', text='Sons of Anarchy Motorcycle Club , Redwood Original , referred to by the acronym SAMCRO or Sam Crow', normalized_text='sons of anarchy motorcycle club redwood original referred to by acronym samcro or sam crow')], [Entity(start_offset=139, end_offset=242, type='context', text=\"the original and founding ( `` mother '' ) charter , Sons of Anarchy Motorcycle Club , Redwood Original\", normalized_text='original and founding mother charter sons of anarchy motorcycle club redwood original')]], aligned_nps=[(Entity(start_offset=3, end_offset=18, type='question', text='sons of anarchy', normalized_text='sons of anarchy'), Entity(start_offset=139, end_offset=400, type='context', text=\"the original and founding ( `` mother '' ) charter , Sons of Anarchy Motorcycle Club , Redwood Original , referred to by the acronym SAMCRO or Sam Crow , located in the fictional town of Charming , California , adjacent to the Teller - Morrow auto mechanic shop\", normalized_text='original and founding mother charter sons of anarchy motorcycle club redwood original referred to by acronym samcro or sam crow located in fictional town of charming california adjacent to teller morrow auto mechanic shop'))], explanation_type='single_sentence'),\n",
       " 5900080311660440587: QEDExample(example_id=5900080311660440587, title='Bromophenol blue', question='what is the purpose of the bromophenol blue dye in the samples', passage=\"Bromophenol blue ( 3 ′ , 3 '' , 5 ′ , 5 '' - tetrabromophenolsulfonphthalein , BPB , albutest ) is used as a pH indicator , a color marker , and a dye . It can be prepared by slowly adding excess bromine to a hot solution of phenolsulfonphthalein in glacial acetic acid .\", sentence_starts=[0, 153], selected_sent={'start': 0, 'end': 153, 'string': \"Bromophenol blue ( 3 ′ , 3 '' , 5 ′ , 5 '' - tetrabromophenolsulfonphthalein , BPB , albutest ) is used as a pH indicator , a color marker , and a dye . \"}, answer=[Entity(start_offset=107, end_offset=150, type='context', text='a pH indicator , a color marker , and a dye', normalized_text='ph indicator color marker and dye')], nq_answers=[[Entity(start_offset=107, end_offset=121, type='context', text='a pH indicator', normalized_text='ph indicator'), Entity(start_offset=124, end_offset=138, type='context', text='a color marker', normalized_text='color marker'), Entity(start_offset=145, end_offset=150, type='context', text='a dye', normalized_text='dye')], [Entity(start_offset=104, end_offset=121, type='context', text='as a pH indicator', normalized_text='as ph indicator'), Entity(start_offset=124, end_offset=138, type='context', text='a color marker', normalized_text='color marker'), Entity(start_offset=145, end_offset=150, type='context', text='a dye', normalized_text='dye')]], aligned_nps=[(Entity(start_offset=23, end_offset=62, type='question', text='the bromophenol blue dye in the samples', normalized_text='bromophenol blue dye in samples'), Entity(start_offset=0, end_offset=95, type='context', text=\"Bromophenol blue ( 3 ′ , 3 '' , 5 ′ , 5 '' - tetrabromophenolsulfonphthalein , BPB , albutest )\", normalized_text='bromophenol blue 3 ′ 3 5 ′ 5 tetrabromophenolsulfonphthalein bpb albutest'))], explanation_type='single_sentence'),\n",
       " -844607040165108603: QEDExample(example_id=-844607040165108603, title='I Love You, Man', question='who plays zoey in i love you man', passage=\"Peter Klaven ( Paul Rudd ) , a Los Angeles real estate agent , proposes to his girlfriend Zooey Rice ( Rashida Jones ) , and she accepts . Peter seems to not have any close friends to share the good news with , only family and mainly female acquaintances . After overhearing Zooey 's friends voicing their concerns over his lack of close male friends , Peter decides that he needs to find male friends in order to have a best man for the upcoming wedding .\", sentence_starts=[0, 139, 257], selected_sent={'start': 0, 'end': 139, 'string': 'Peter Klaven ( Paul Rudd ) , a Los Angeles real estate agent , proposes to his girlfriend Zooey Rice ( Rashida Jones ) , and she accepts . '}, answer=[Entity(start_offset=103, end_offset=116, type='context', text='Rashida Jones', normalized_text='rashida jones')], nq_answers=[[Entity(start_offset=103, end_offset=116, type='context', text='Rashida Jones', normalized_text='rashida jones')]], aligned_nps=[(Entity(start_offset=10, end_offset=14, type='question', text='zoey', normalized_text='zoey'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -8384749502417019982: QEDExample(example_id=-8384749502417019982, title='Mercy Mercy Me (The Ecology)', question='what is mercy mercy me by marvin gaye about', passage=\"`` Mercy Mercy Me ( The Ecology ) '' was the second single from Marvin Gaye 's 1971 album , What 's Going On . Following the breakthrough of the title track 's success , the song , written solely by Gaye , became regarded as one of popular music 's most poignant anthems of sorrow regarding the environment . Led by Gaye playing piano , strings conducted by Paul Riser and David Van De Pitte , multi-tracking vocals from Gaye and The Andantes , multiple background instruments provided by The Funk Brothers and a leading sax solo by Wild Bill Moore , the song rose to number 4 on Billboard 's Pop Singles chart and number one for two weeks on the R&B Singles charts on August 14 through to August 27 , 1971 . The distinctive percussive sound heard on the track was a wood block struck by a rubber mallet , drenched in studio reverb . The song also brought Gaye one of his rare appearances on the Adult Contemporary chart , where it peaked at number 34 . In Canada , `` Mercy Mercy Me '' spent two weeks at number 9 .\", sentence_starts=[0, 111, 309, 709, 834, 954], selected_sent={'start': 111, 'end': 309, 'string': \"Following the breakthrough of the title track 's success , the song , written solely by Gaye , became regarded as one of popular music 's most poignant anthems of sorrow regarding the environment . \"}, answer=[Entity(start_offset=274, end_offset=306, type='context', text='sorrow regarding the environment', normalized_text='sorrow regarding environment')], nq_answers=[[Entity(start_offset=274, end_offset=306, type='context', text='sorrow regarding the environment', normalized_text='sorrow regarding environment')], [Entity(start_offset=291, end_offset=306, type='context', text='the environment', normalized_text='environment')]], aligned_nps=[(Entity(start_offset=8, end_offset=37, type='question', text='mercy mercy me by marvin gaye', normalized_text='mercy mercy me by marvin gaye'), Entity(start_offset=170, end_offset=203, type='context', text='the song , written solely by Gaye', normalized_text='song written solely by gaye'))], explanation_type='single_sentence'),\n",
       " -4539390998265435397: QEDExample(example_id=-4539390998265435397, title='Utang na loob', question='what is the meaning of utang na loob', passage=\"Utang na loob is a Filipino cultural trait which , when translated literally , means `` a debt of one 's inner self ( loob ) . '' It is also often translated as a `` debt of gratitude . ''\", sentence_starts=[0, 130], selected_sent={'start': 0, 'end': 130, 'string': \"Utang na loob is a Filipino cultural trait which , when translated literally , means `` a debt of one 's inner self ( loob ) . '' \"}, answer=[Entity(start_offset=88, end_offset=124, type='context', text=\"a debt of one 's inner self ( loob )\", normalized_text='debt of one s inner self loob')], nq_answers=[[Entity(start_offset=85, end_offset=129, type='context', text=\"`` a debt of one 's inner self ( loob ) . ''\", normalized_text='debt of one s inner self loob')], [Entity(start_offset=88, end_offset=115, type='context', text=\"a debt of one 's inner self\", normalized_text='debt of one s inner self')]], aligned_nps=[(Entity(start_offset=23, end_offset=36, type='question', text='utang na loob', normalized_text='utang na loob'), Entity(start_offset=0, end_offset=13, type='context', text='Utang na loob', normalized_text='utang na loob'))], explanation_type='single_sentence'),\n",
       " -2320360237218325930: QEDExample(example_id=-2320360237218325930, title='Prisoners (Temporary Discharge for Ill Health) Act 1913', question='when was the cat and mouse act introduced', passage=\"The Prisoners ( Temporary Discharge for Ill Health ) Act , commonly referred to as the Cat and Mouse Act , was an Act of Parliament passed in Britain under Herbert Henry Asquith 's Liberal government in 1913 . Some members of the Women 's Social and Political Union ( WSPU , commonly referred to as suffragettes ) had been imprisoned for acts of vandalism in support of women 's suffrage . In protest to being imprisoned some of these suffragettes undertook hunger strikes . These suffragettes were then force - fed leading to a public outcry . This act was a response to the outcry ; it allowed the prisoners to be released on licence as soon as the hunger strike affected their health . They then had a period of time in which they could recover . After a predetermined period of time the prisoner would be rearrested to serve out the rest of their sentence . Conditions could be placed on the prisoner during the time of their release . The hunger strikes themselves were now technically legal . However , the Act allowed for the re-imprisonment of the hunger strikers upon their recovery on their original charges . The nickname of the Act came about because of a cat 's habit of playing with its prey ( a mouse ) before finishing it off .\", sentence_starts=[0, 210, 390, 475, 545, 689, 750, 862, 940, 999, 1120], selected_sent={'start': 0, 'end': 210, 'string': \"The Prisoners ( Temporary Discharge for Ill Health ) Act , commonly referred to as the Cat and Mouse Act , was an Act of Parliament passed in Britain under Herbert Henry Asquith 's Liberal government in 1913 . \"}, answer=[Entity(start_offset=203, end_offset=207, type='context', text='1913', normalized_text='1913')], nq_answers=[[Entity(start_offset=203, end_offset=207, type='context', text='1913', normalized_text='1913')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text='the cat and mouse act', normalized_text='cat and mouse act'), Entity(start_offset=0, end_offset=104, type='context', text='The Prisoners ( Temporary Discharge for Ill Health ) Act , commonly referred to as the Cat and Mouse Act', normalized_text='prisoners temporary discharge for ill health act commonly referred to as cat and mouse act'))], explanation_type='single_sentence'),\n",
       " -6446716584766134959: QEDExample(example_id=-6446716584766134959, title='Law & Order: Special Victims Unit (season 18)', question='when does season 18 of law and order svu start', passage='The eighteenth season of Law & Order : Special Victims Unit debuted on Wednesday , September 21 , 2016 , on NBC and finished on Wednesday , May 24 , 2017 , with a two - hour season finale .', sentence_starts=[0], selected_sent={'start': 0, 'end': 189, 'string': 'The eighteenth season of Law & Order : Special Victims Unit debuted on Wednesday , September 21 , 2016 , on NBC and finished on Wednesday , May 24 , 2017 , with a two - hour season finale .'}, answer=[Entity(start_offset=71, end_offset=102, type='context', text='Wednesday , September 21 , 2016', normalized_text='wednesday september 21 2016')], nq_answers=[[Entity(start_offset=71, end_offset=102, type='context', text='Wednesday , September 21 , 2016', normalized_text='wednesday september 21 2016')], [Entity(start_offset=83, end_offset=102, type='context', text='September 21 , 2016', normalized_text='september 21 2016')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='season 18 of law and order svu', normalized_text='season 18 of law and order svu'), Entity(start_offset=0, end_offset=59, type='context', text='The eighteenth season of Law & Order : Special Victims Unit', normalized_text='eighteenth season of law order special victims unit'))], explanation_type='single_sentence'),\n",
       " 2393689391949146066: QEDExample(example_id=2393689391949146066, title='Sex and the City', question='where did they live in sex and the city', passage=\"Set and filmed in New York City and based on the 1997 book of the same name by Candace Bushnell , the show follows the lives of a group of four women -- three in their mid-thirties and one in her forties -- who , despite their different natures and ever - changing sex lives , remain inseparable and confide in each other . Starring Sarah Jessica Parker ( as Carrie Bradshaw ) , Kim Cattrall ( as Samantha Jones ) , Kristin Davis ( as Charlotte York ) , and Cynthia Nixon ( as Miranda Hobbes ) , the quirky series had multiple continuing storylines that tackled relevant and modern social issues such as sexuality , safe sex , promiscuity , and femininity , while exploring the difference between friendships and romantic relationships . The deliberate omission of the better part of the early lives of the four women was the writers ' way of exploring social life -- from sex to relationships -- through each of their four very different , individual perspectives .\", sentence_starts=[0, 324, 738], selected_sent={'start': 0, 'end': 324, 'string': 'Set and filmed in New York City and based on the 1997 book of the same name by Candace Bushnell , the show follows the lives of a group of four women -- three in their mid-thirties and one in her forties -- who , despite their different natures and ever - changing sex lives , remain inseparable and confide in each other . '}, answer=[Entity(start_offset=18, end_offset=31, type='context', text='New York City', normalized_text='new york city')], nq_answers=[[Entity(start_offset=18, end_offset=31, type='context', text='New York City', normalized_text='new york city')]], aligned_nps=[(Entity(start_offset=23, end_offset=39, type='question', text='sex and the city', normalized_text='sex and city'), Entity(start_offset=98, end_offset=106, type='context', text='the show', normalized_text='show'))], explanation_type='single_sentence'),\n",
       " -4555137478319766304: QEDExample(example_id=-4555137478319766304, title='Jigsaw (2017 film)', question='when does the new saw 8 come out', passage='Filming began in November 2016 , with post-production following in January . The film was released in the United States on October 27 , 2017 , receiving generally unfavorable reviews from critics , and grossing a reported $102.9 million worldwide .', sentence_starts=[0, 77], selected_sent={'start': 77, 'end': 248, 'string': 'The film was released in the United States on October 27 , 2017 , receiving generally unfavorable reviews from critics , and grossing a reported $102.9 million worldwide .'}, answer=[Entity(start_offset=123, end_offset=140, type='context', text='October 27 , 2017', normalized_text='october 27 2017')], nq_answers=[[Entity(start_offset=123, end_offset=140, type='context', text='October 27 , 2017', normalized_text='october 27 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=23, type='question', text='the new saw 8', normalized_text='new saw 8'), Entity(start_offset=77, end_offset=85, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " 6276969298797177537: QEDExample(example_id=6276969298797177537, title='Criminal law', question='what is the main objective of criminal law', passage='Criminal Law is the body of law that relates to crime . It proscribes conduct perceived as threatening , harmful , or otherwise endangering to the property , health , safety , and moral welfare of people . Most criminal law is established by statute , which is to say that the laws are enacted by a legislature . It includes the punishment of people who violate these laws . Criminal law varies according to jurisdiction , and differs from civil law , where emphasis is more on dispute resolution and victim compensation than on punishment .', sentence_starts=[0, 56, 206, 313, 375], selected_sent={'start': 56, 'end': 206, 'string': 'It proscribes conduct perceived as threatening , harmful , or otherwise endangering to the property , health , safety , and moral welfare of people . '}, answer=[Entity(start_offset=59, end_offset=203, type='context', text='proscribes conduct perceived as threatening , harmful , or otherwise endangering to the property , health , safety , and moral welfare of people', normalized_text='proscribes conduct perceived as threatening harmful or otherwise endangering to property health safety and moral welfare of people')], nq_answers=[[Entity(start_offset=59, end_offset=203, type='context', text='proscribes conduct perceived as threatening , harmful , or otherwise endangering to the property , health , safety , and moral welfare of people', normalized_text='proscribes conduct perceived as threatening harmful or otherwise endangering to property health safety and moral welfare of people')]], aligned_nps=[(Entity(start_offset=30, end_offset=42, type='question', text='criminal law', normalized_text='criminal law'), Entity(start_offset=56, end_offset=58, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6611405972726453109: QEDExample(example_id=6611405972726453109, title='The Ranch (TV series)', question='what is the netflix show the ranch about', passage='The Ranch is an American comedy web television series starring Ashton Kutcher , Danny Masterson , Debra Winger , Elisha Cuthbert , and Sam Elliott that debuted in 2016 on Netflix . The show takes place on the fictional Iron River Ranch in the fictitious small town of Garrison , Colorado ; detailing the life of the Bennetts , a dysfunctional family consisting of two brothers , their rancher father , and his divorced wife and local bar owner . While the opening sequence shows scenes from Norwood and Ouray , Colorado and surrounding Ouray and San Miguel Counties , The Ranch is filmed on a sound stage in front of a live audience in Burbank , California . Each season consists of 20 episodes broken up into two parts , each containing 10 episodes .', sentence_starts=[0, 181, 446, 659], selected_sent={'start': 181, 'end': 446, 'string': 'The show takes place on the fictional Iron River Ranch in the fictitious small town of Garrison , Colorado ; detailing the life of the Bennetts , a dysfunctional family consisting of two brothers , their rancher father , and his divorced wife and local bar owner . '}, answer=[Entity(start_offset=300, end_offset=443, type='context', text='the life of the Bennetts , a dysfunctional family consisting of two brothers , their rancher father , and his divorced wife and local bar owner', normalized_text='life of bennetts dysfunctional family consisting of two brothers their rancher father and his divorced wife and local bar owner')], nq_answers=[[Entity(start_offset=327, end_offset=443, type='context', text='a dysfunctional family consisting of two brothers , their rancher father , and his divorced wife and local bar owner', normalized_text='dysfunctional family consisting of two brothers their rancher father and his divorced wife and local bar owner')]], aligned_nps=[(Entity(start_offset=8, end_offset=34, type='question', text='the netflix show the ranch', normalized_text='netflix show ranch'), Entity(start_offset=181, end_offset=189, type='context', text='The show', normalized_text='show'))], explanation_type='single_sentence'),\n",
       " -7812477442387862913: QEDExample(example_id=-7812477442387862913, title='Federal Reserve Board of Governors', question='who appoints the members of the board of governors of the federal reserve', passage='The Board of Governors of the Federal Reserve System , commonly known as the Federal Reserve Board , is the main governing body of the Federal Reserve System . It is charged with overseeing the Federal Reserve Banks and with helping implement monetary policy of the United States . Governors are appointed by the President of the United States and confirmed by the Senate for staggered 14 - year terms .', sentence_starts=[0, 160, 282], selected_sent={'start': 282, 'end': 403, 'string': 'Governors are appointed by the President of the United States and confirmed by the Senate for staggered 14 - year terms .'}, answer=[Entity(start_offset=309, end_offset=343, type='context', text='the President of the United States', normalized_text='president of united states')], nq_answers=[[Entity(start_offset=309, end_offset=343, type='context', text='the President of the United States', normalized_text='president of united states')]], aligned_nps=[(Entity(start_offset=13, end_offset=73, type='question', text='the members of the board of governors of the federal reserve', normalized_text='members of board of governors of federal reserve'), Entity(start_offset=282, end_offset=291, type='context', text='Governors', normalized_text='governors'))], explanation_type='single_sentence'),\n",
       " 1460738236019346895: QEDExample(example_id=1460738236019346895, title='Megalith', question='the most common form of megalithic architecture in europe is', passage='The most common type of megalithic construction in Europe is the portal tomb -- a chamber consisting of upright stones ( orthostats ) with one or more large flat capstones forming a roof . Many of these , though by no means all , contain human remains , but it is debatable whether use as burial sites was their primary function . The megalithic structures of Malta are believed to be the oldest in Europe , in particular Skorba Temples . Though generally known as dolmens , the correct term accepted by archaeologists is portal tomb . However many local names exist , such as anta in Galicia and Portugal , stazzone in Sardinia , hunebed in the Netherlands , Hünengrab in Germany , dysse in Denmark , and cromlech in Wales . It is assumed that most portal tombs were originally covered by earthen mounds .', sentence_starts=[0, 189, 331, 439, 536, 726], selected_sent={'start': 0, 'end': 189, 'string': 'The most common type of megalithic construction in Europe is the portal tomb -- a chamber consisting of upright stones ( orthostats ) with one or more large flat capstones forming a roof . '}, answer=[Entity(start_offset=61, end_offset=76, type='context', text='the portal tomb', normalized_text='portal tomb')], nq_answers=[[Entity(start_offset=61, end_offset=76, type='context', text='the portal tomb', normalized_text='portal tomb')], [Entity(start_offset=65, end_offset=76, type='context', text='portal tomb', normalized_text='portal tomb')]], aligned_nps=[(Entity(start_offset=0, end_offset=57, type='question', text='the most common form of megalithic architecture in europe', normalized_text='most common form of megalithic architecture in europe'), Entity(start_offset=0, end_offset=57, type='context', text='The most common type of megalithic construction in Europe', normalized_text='most common type of megalithic construction in europe'))], explanation_type='single_sentence'),\n",
       " -4548575647598061842: QEDExample(example_id=-4548575647598061842, title='Home and Family', question='where is hallmark channel home and family filmed', passage=\"Home and Family is a two - hour daily Hallmark series , recorded one day prior , in Los Angeles , California . Steines said that the decision for that was made to encourage actors to be on the show , without having to wake at 4 : 00 a.m. The focus of the show is simply entertainment and tips within a `` wholesome image '' . They refrain from discussions on current events or politics as well as censor themselves in speech , such as the word `` breast '' is not allowed to be used .\", sentence_starts=[0, 111, 238, 326], selected_sent={'start': 0, 'end': 111, 'string': 'Home and Family is a two - hour daily Hallmark series , recorded one day prior , in Los Angeles , California . '}, answer=[Entity(start_offset=84, end_offset=108, type='context', text='Los Angeles , California', normalized_text='los angeles california')], nq_answers=[[Entity(start_offset=84, end_offset=108, type='context', text='Los Angeles , California', normalized_text='los angeles california')]], aligned_nps=[(Entity(start_offset=9, end_offset=41, type='question', text='hallmark channel home and family', normalized_text='hallmark channel home and family'), Entity(start_offset=0, end_offset=15, type='context', text='Home and Family', normalized_text='home and family'))], explanation_type='single_sentence'),\n",
       " -6612294468579893046: QEDExample(example_id=-6612294468579893046, title='Pure Country', question='who plays dusty in the movie pure country', passage=\"The film begins with various shots of the audience chanting `` Dusty ! '' , which is repeated throughout . Meanwhile , the band begins , as the smoke and the lights are turned on , we see Wyatt `` Dusty '' Chandler ( George Strait ) entering the stage , and performing `` Heartland '' , `` Baby Your Baby '' , and a shortened version of `` Where the Sidewalk Ends '' . Dusty feels that his elaborate stage show is overwhelming his music , a suspicion confirmed one night when he purposely forgets several bars of a chart - topping hit and his fans do n't even notice . Disillusioned , Dusty walks off after the concert without telling his manager , Lula ( Lesley Ann Warren ) . The only person he tells is his best friend and drummer , Earl ( John Doe ) , and that he is `` taking a walk , '' but does not say exactly where he is going or for how long . Dusty is singing a blurry version of `` Where the Sidewalk Ends '' . In a down home bar , we see Al ( Mark Walters ) . Dusty had breakfast with the Tucker family during this scene .\", sentence_starts=[0, 107, 369, 569, 678, 854, 923, 973], selected_sent={'start': 107, 'end': 369, 'string': \"Meanwhile , the band begins , as the smoke and the lights are turned on , we see Wyatt `` Dusty '' Chandler ( George Strait ) entering the stage , and performing `` Heartland '' , `` Baby Your Baby '' , and a shortened version of `` Where the Sidewalk Ends '' . \"}, answer=[Entity(start_offset=217, end_offset=230, type='context', text='George Strait', normalized_text='george strait')], nq_answers=[[Entity(start_offset=217, end_offset=230, type='context', text='George Strait', normalized_text='george strait')]], aligned_nps=[(Entity(start_offset=10, end_offset=15, type='question', text='dusty', normalized_text='dusty'), Entity(start_offset=188, end_offset=232, type='context', text=\"Wyatt `` Dusty '' Chandler ( George Strait )\", normalized_text='wyatt dusty chandler george strait')), (Entity(start_offset=19, end_offset=41, type='question', text='the movie pure country', normalized_text='movie pure country'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -4940597866631356964: QEDExample(example_id=-4940597866631356964, title='Assyrian captivity', question='who did the assyrians conquer in 722 bce', passage='In 722 BCE , nearly ten to twenty years after the initial deportations , the ruling city of the Northern Kingdom of Israel , Samaria , was finally taken by Sargon II after a three - year siege started by Shalmaneser V .', sentence_starts=[0], selected_sent={'start': 0, 'end': 219, 'string': 'In 722 BCE , nearly ten to twenty years after the initial deportations , the ruling city of the Northern Kingdom of Israel , Samaria , was finally taken by Sargon II after a three - year siege started by Shalmaneser V .'}, answer=[Entity(start_offset=73, end_offset=132, type='context', text='the ruling city of the Northern Kingdom of Israel , Samaria', normalized_text='ruling city of northern kingdom of israel samaria')], nq_answers=[[Entity(start_offset=73, end_offset=132, type='context', text='the ruling city of the Northern Kingdom of Israel , Samaria', normalized_text='ruling city of northern kingdom of israel samaria')]], aligned_nps=[(Entity(start_offset=33, end_offset=40, type='question', text='722 bce', normalized_text='722 bce'), Entity(start_offset=3, end_offset=10, type='context', text='722 BCE', normalized_text='722 bce')), (Entity(start_offset=8, end_offset=21, type='question', text='the assyrians', normalized_text='assyrians'), Entity(start_offset=156, end_offset=165, type='context', text='Sargon II', normalized_text='sargon ii'))], explanation_type='single_sentence'),\n",
       " 5277662244732096245: QEDExample(example_id=5277662244732096245, title='Sports in St. Louis', question='how many nfl teams has st louis had', passage='St. Louis has been the home of four National Football League ( NFL ) franchises :', sentence_starts=[0], selected_sent={'start': 0, 'end': 81, 'string': 'St. Louis has been the home of four National Football League ( NFL ) franchises :'}, answer=[Entity(start_offset=31, end_offset=35, type='context', text='four', normalized_text='four')], nq_answers=[[Entity(start_offset=31, end_offset=35, type='context', text='four', normalized_text='four')]], aligned_nps=[(Entity(start_offset=23, end_offset=31, type='question', text='st louis', normalized_text='st louis'), Entity(start_offset=0, end_offset=9, type='context', text='St. Louis', normalized_text='st louis'))], explanation_type='single_sentence'),\n",
       " 7268313204343326672: QEDExample(example_id=7268313204343326672, title='List of Pro Football Hall of Fame inductees', question='how many players in football hall of fame', passage=\"The Pro Football Hall of Fame includes players , coaches , and contributors ( e.g. , owners , general managers and team or league officials ) who have `` made outstanding contributions to professional football '' . The charter class of seventeen was selected in 1963 . As of 2018 , 318 individuals have been elected .\", sentence_starts=[0, 215, 269], selected_sent={'start': 269, 'end': 317, 'string': 'As of 2018 , 318 individuals have been elected .'}, answer=[Entity(start_offset=282, end_offset=285, type='context', text='318', normalized_text='318')], nq_answers=[[Entity(start_offset=282, end_offset=285, type='context', text='318', normalized_text='318')], [Entity(start_offset=282, end_offset=297, type='context', text='318 individuals', normalized_text='318 individuals')]], aligned_nps=[(Entity(start_offset=20, end_offset=41, type='question', text='football hall of fame', normalized_text='football hall of fame'), Entity(start_offset=308, end_offset=315, type='context', text='elected', normalized_text='elected'))], explanation_type='single_sentence'),\n",
       " -8951937367079407640: QEDExample(example_id=-8951937367079407640, title='River Irk', question='where does the river irk start and finish', passage='It rises to the east of Royton and runs west past Chadderton , Middleton and Blackley before merging with the River Irwell in Manchester city centre .', sentence_starts=[0], selected_sent={'start': 0, 'end': 150, 'string': 'It rises to the east of Royton and runs west past Chadderton , Middleton and Blackley before merging with the River Irwell in Manchester city centre .'}, answer=[Entity(start_offset=16, end_offset=148, type='context', text='east of Royton and runs west past Chadderton , Middleton and Blackley before merging with the River Irwell in Manchester city centre', normalized_text='east of royton and runs west past chadderton middleton and blackley before merging with river irwell in manchester city centre')], nq_answers=[[Entity(start_offset=16, end_offset=30, type='context', text='east of Royton', normalized_text='east of royton'), Entity(start_offset=93, end_offset=148, type='context', text='merging with the River Irwell in Manchester city centre', normalized_text='merging with river irwell in manchester city centre')], [Entity(start_offset=3, end_offset=148, type='context', text='rises to the east of Royton and runs west past Chadderton , Middleton and Blackley before merging with the River Irwell in Manchester city centre', normalized_text='rises to east of royton and runs west past chadderton middleton and blackley before merging with river irwell in manchester city centre')], [Entity(start_offset=12, end_offset=30, type='context', text='the east of Royton', normalized_text='east of royton'), Entity(start_offset=106, end_offset=148, type='context', text='the River Irwell in Manchester city centre', normalized_text='river irwell in manchester city centre')]], aligned_nps=[(Entity(start_offset=11, end_offset=24, type='question', text='the river irk', normalized_text='river irk'), Entity(start_offset=0, end_offset=2, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 1996292107460275608: QEDExample(example_id=1996292107460275608, title='A Walk Among the Tombstones (film)', question='where was the movie a walk among the tombstones filmed', passage=\"Filming began on March 3 , 2013 in New York City . Producers invited author Block to the set to watch filming . On the casting of Neeson , Block said , `` Readers often ask who 'd be my ideal Matt Scudder , and I usually change the subject . But now it 's safe to tell you that , ever since I saw him in Michael Collins , Neeson has been up at the top of my personal Scudder wish list . I could n't be happier about either the star or the writer / director , both of them genuine artists and brilliant professionals . My book 's in good hands . ''\", sentence_starts=[0, 51, 112, 242, 387, 518], selected_sent={'start': 0, 'end': 51, 'string': 'Filming began on March 3 , 2013 in New York City . '}, answer=[Entity(start_offset=35, end_offset=48, type='context', text='New York City', normalized_text='new york city')], nq_answers=[[Entity(start_offset=35, end_offset=48, type='context', text='New York City', normalized_text='new york city')]], aligned_nps=[(Entity(start_offset=10, end_offset=47, type='question', text='the movie a walk among the tombstones', normalized_text='movie walk among tombstones'), Entity(start_offset=0, end_offset=7, type='context', text='Filming', normalized_text='filming'))], explanation_type='single_sentence'),\n",
       " 3176201802456368482: QEDExample(example_id=3176201802456368482, title='Universal Declaration of Human Rights', question='what is united nations declaration of human rights', passage=\"The Declaration consists of thirty articles affirming an individual 's rights which , although not legally binding in themselves , have been elaborated in subsequent international treaties , economic transfers , regional human rights instruments , national constitutions , and other laws . The Declaration was the first step in the process of formulating the International Bill of Human Rights , which was completed in 1966 , and came into force in 1976 , after a sufficient number of countries had ratified them .\", sentence_starts=[0, 290], selected_sent={'start': 0, 'end': 290, 'string': \"The Declaration consists of thirty articles affirming an individual 's rights which , although not legally binding in themselves , have been elaborated in subsequent international treaties , economic transfers , regional human rights instruments , national constitutions , and other laws . \"}, answer=[Entity(start_offset=28, end_offset=287, type='context', text=\"thirty articles affirming an individual 's rights which , although not legally binding in themselves , have been elaborated in subsequent international treaties , economic transfers , regional human rights instruments , national constitutions , and other laws\", normalized_text='thirty articles affirming individual s rights which although not legally binding in themselves have been elaborated in subsequent international treaties economic transfers regional human rights instruments national constitutions and other laws')], nq_answers=[[Entity(start_offset=16, end_offset=77, type='context', text=\"consists of thirty articles affirming an individual 's rights\", normalized_text='consists of thirty articles affirming individual s rights')]], aligned_nps=[(Entity(start_offset=8, end_offset=50, type='question', text='united nations declaration of human rights', normalized_text='united nations declaration of human rights'), Entity(start_offset=0, end_offset=15, type='context', text='The Declaration', normalized_text='declaration'))], explanation_type='single_sentence'),\n",
       " -519208105586656163: QEDExample(example_id=-519208105586656163, title='Super Bowl ring', question='what nfl team has the most expensive super bowl ring', passage=\"These rings are typically made of yellow or white gold with diamonds . They usually include the team name , team logo , and Super Bowl number ( usually indicated in Roman numerals ) . The NFL contributes up to $5,000 per ring for up to 150 rings for o the winning team ; any additional costs are borne by the team . Most rings are manufactured by memorabilia company Jostens . In 2015 , the rings for the New England Patriots reportedly cost $36,500 each , making them the most expensive rings Jostens has ever produced . The winning team can typically present rings to whomever they choose , including usually , but not limited to : players ( active roster or injured ) , coaches , trainers , executives , personnel , and general staff . Some teams have given rings to former players and coaches that were on the team at some point during the season , despite not having been on the winning roster for the Super Bowl itself . Sometimes a team will give rings to fans as part of a charity raffle . Teams can distribute any number of rings . A recent trend over the last 15 -- 20 years has been lesser rings awarded to front office staff . These are commonly called `` B '' and `` C '' level rings and are smaller and contain fewer diamonds or contain faux diamonds . The first instance of this was the Redskins Super Bowl XVII ring when many in the front office received rings that were not solid gold and contained cubic zirconia stones ( which resemble diamonds ) . When Tampa Bay won Super Bowl XXXVII , the players and coaches received rings with a diamond - centered Lombardi trophy . Some staff received rings with a metal Lombardi trophy and real diamonds surrounding the trophy and the `` C '' level ring did not contain any diamonds .\", sentence_starts=[0, 71, 184, 316, 377, 522, 739, 927, 998, 1041, 1139, 1267, 1468, 1590], selected_sent={'start': 377, 'end': 522, 'string': 'In 2015 , the rings for the New England Patriots reportedly cost $36,500 each , making them the most expensive rings Jostens has ever produced . '}, answer=[Entity(start_offset=401, end_offset=425, type='context', text='the New England Patriots', normalized_text='new england patriots')], nq_answers=[[Entity(start_offset=405, end_offset=425, type='context', text='New England Patriots', normalized_text='new england patriots')], [Entity(start_offset=401, end_offset=425, type='context', text='the New England Patriots', normalized_text='new england patriots')]], aligned_nps=[(Entity(start_offset=37, end_offset=47, type='question', text='super bowl', normalized_text='super bowl'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 5117748440024890059: QEDExample(example_id=5117748440024890059, title='Russian Provisional Government', question='what event caused the duma to establish a provisional government in russia', passage=\"The Russian Provisional Government ( Russian : Временное правительство России , tr . Vremennoye pravitel'stvo Rossii ) was a provisional government of Russia established immediately following the abdication of Tsar Nicholas II of the Russian Empire on 2 March ( 15 March , New Style ) 1917 . The intention of the provisional government was the organization of elections to the Russian Constituent Assembly and its convention . The provisional government lasted approximately eight months , and ceased to exist when the Bolsheviks gained power after the October Revolution in October ( November , N.S. ) 1917 . According to Harold Whitmore Williams the history of eight months during which Russia was ruled by the Provisional Government was the history of the steady and systematic disorganisation of the army .\", sentence_starts=[0, 85, 292, 427, 610], selected_sent={'start': 0, 'end': 292, 'string': \"The Russian Provisional Government ( Russian : Временное правительство России , tr . Vremennoye pravitel'stvo Rossii ) was a provisional government of Russia established immediately following the abdication of Tsar Nicholas II of the Russian Empire on 2 March ( 15 March , New Style ) 1917 . \"}, answer=[Entity(start_offset=192, end_offset=289, type='context', text='the abdication of Tsar Nicholas II of the Russian Empire on 2 March ( 15 March , New Style ) 1917', normalized_text='abdication of tsar nicholas ii of russian empire on 2 march 15 march new style 1917')], nq_answers=[[Entity(start_offset=192, end_offset=248, type='context', text='the abdication of Tsar Nicholas II of the Russian Empire', normalized_text='abdication of tsar nicholas ii of russian empire')], [Entity(start_offset=192, end_offset=259, type='context', text='the abdication of Tsar Nicholas II of the Russian Empire on 2 March', normalized_text='abdication of tsar nicholas ii of russian empire on 2 march')]], aligned_nps=[(Entity(start_offset=40, end_offset=74, type='question', text='a provisional government in russia', normalized_text='provisional government in russia'), Entity(start_offset=0, end_offset=118, type='context', text=\"The Russian Provisional Government ( Russian : Временное правительство России , tr . Vremennoye pravitel'stvo Rossii )\", normalized_text='russian provisional government russian временное правительство россии tr vremennoye pravitelstvo rossii'))], explanation_type='single_sentence'),\n",
       " -3199049010322899939: QEDExample(example_id=-3199049010322899939, title='Phoenix Marketcity (Chennai)', question='who is the owner of phoenix mall in chennai', passage='This mall was jointly developed by Phoenix Mills Limited and Sharyans Resources . Phoenix Mall Chennai is part of a development which includes a premium residential space as part of Phase I. Phase II development includes a luxury mall and residential space .', sentence_starts=[0, 82], selected_sent={'start': 0, 'end': 82, 'string': 'This mall was jointly developed by Phoenix Mills Limited and Sharyans Resources . '}, answer=[Entity(start_offset=35, end_offset=79, type='context', text='Phoenix Mills Limited and Sharyans Resources', normalized_text='phoenix mills limited and sharyans resources')], nq_answers=[[Entity(start_offset=35, end_offset=79, type='context', text='Phoenix Mills Limited and Sharyans Resources', normalized_text='phoenix mills limited and sharyans resources')], [Entity(start_offset=35, end_offset=56, type='context', text='Phoenix Mills Limited', normalized_text='phoenix mills limited'), Entity(start_offset=61, end_offset=79, type='context', text='Sharyans Resources', normalized_text='sharyans resources')]], aligned_nps=[(Entity(start_offset=20, end_offset=43, type='question', text='phoenix mall in chennai', normalized_text='phoenix mall in chennai'), Entity(start_offset=0, end_offset=9, type='context', text='This mall', normalized_text='this mall'))], explanation_type='single_sentence'),\n",
       " 6475776155210751728: QEDExample(example_id=6475776155210751728, title='American entry into World War I', question='when did the usa join world war one', passage='The American entry into World War I came in April 1917 , after more than two and a half years of efforts by President Woodrow Wilson to keep the United States out of the war . Apart from an Anglophile element urging early support for the British , American public opinion reflected that of the president : the sentiment for neutrality was particularly strong among Irish Americans , German Americans and Scandinavian Americans , as well as among church leaders and among women in general . On the other hand , even before World War I had broken out , American opinion had been more negative toward Germany than towards any other country in Europe . Over time , especially after reports of atrocities in Belgium in 1914 and following the sinking of the passenger liner RMS Lusitania in 1915 , the American citizens increasingly came to see Germany as the aggressor in Europe .', sentence_starts=[0, 176, 490, 649], selected_sent={'start': 0, 'end': 176, 'string': 'The American entry into World War I came in April 1917 , after more than two and a half years of efforts by President Woodrow Wilson to keep the United States out of the war . '}, answer=[Entity(start_offset=44, end_offset=54, type='context', text='April 1917', normalized_text='april 1917')], nq_answers=[[Entity(start_offset=44, end_offset=54, type='context', text='April 1917', normalized_text='april 1917')], [Entity(start_offset=41, end_offset=54, type='context', text='in April 1917', normalized_text='in april 1917')]], aligned_nps=[(Entity(start_offset=22, end_offset=35, type='question', text='world war one', normalized_text='world war one'), Entity(start_offset=24, end_offset=35, type='context', text='World War I', normalized_text='world war i'))], explanation_type='single_sentence'),\n",
       " -3201738781499395165: QEDExample(example_id=-3201738781499395165, title=\"Don't Take Your Guns to Town\", question=\"who sings don't take your guns to town\", passage=\"`` Do n't Take Your Guns to Town '' is a 1958 single by Johnny Cash . The single was his fifth release to reach the number one position on the country chart , where it stayed for six weeks . `` Do n't Take Your Guns to Town '' was also a crossover hit peaking at number thirty - two on the pop chart . The song is also included in the live album VH1 Storytellers : Johnny Cash & Willie Nelson . The song was covered by U2 on their 2001 single `` Elevation '' .\", sentence_starts=[0, 70, 191, 302, 395], selected_sent={'start': 0, 'end': 70, 'string': \"`` Do n't Take Your Guns to Town '' is a 1958 single by Johnny Cash . \"}, answer=[Entity(start_offset=56, end_offset=67, type='context', text='Johnny Cash', normalized_text='johnny cash')], nq_answers=[[Entity(start_offset=56, end_offset=67, type='context', text='Johnny Cash', normalized_text='johnny cash')], [Entity(start_offset=56, end_offset=67, type='context', text='Johnny Cash', normalized_text='johnny cash'), Entity(start_offset=419, end_offset=421, type='context', text='U2', normalized_text='u2')]], aligned_nps=[(Entity(start_offset=10, end_offset=38, type='question', text=\"don't take your guns to town\", normalized_text='dont take your guns to town'), Entity(start_offset=3, end_offset=32, type='context', text=\"Do n't Take Your Guns to Town\", normalized_text='do nt take your guns to town'))], explanation_type='single_sentence'),\n",
       " -2306775016318180243: QEDExample(example_id=-2306775016318180243, title='My Kinsman, Major Molineux', question=\"who is the young man in hawthorne's my kinsman major molineux\", passage=\"In about 1732 , Robin , a youth , arrives by ferry in Boston seeking his kinsman , Major Molineux , an official in the British Colonial government , who has promised him work . Yet no one in town tells him where the major is . A rich man threatens the youth with prison , and an innkeeper calls him a runaway bond - servant . At the inn , he meets a man with a face described as looking like the devil - two protrusions emanating from his forehead ( like horns ) , eyes burning like ' fire in a cave ' - who seems at the center of many evil things . Later , he runs into the man again , but this time his face is painted black and red . After blocking his path with a cudgel , he finally gets the answer that his kinsman will soon pass by . He waits at the spot on the steps of a church where he is greeted by the first polite gentleman he has met all night . Soon , the two men hear the roar of an approaching mob . At its head is the man with the red and black face and in its midst is Major Molineux , tarred and feathered . The crowd is in an uproar , and everyone is laughing . Soon , so is young Robin , as his eyes meet those of the Major , who knows him right away . Disillusioned , the youth asks the gentleman the way back to the ferry . Yet the latter restrains him , saying that it is still possible for him to thrive without his kinsman 's protection .\", sentence_starts=[0, 177, 227, 326, 550, 637, 741, 860, 917, 1028, 1083, 1175, 1248], selected_sent={'start': 0, 'end': 177, 'string': 'In about 1732 , Robin , a youth , arrives by ferry in Boston seeking his kinsman , Major Molineux , an official in the British Colonial government , who has promised him work . '}, answer=[Entity(start_offset=16, end_offset=21, type='context', text='Robin', normalized_text='robin')], nq_answers=[[Entity(start_offset=16, end_offset=21, type='context', text='Robin', normalized_text='robin')], [Entity(start_offset=16, end_offset=31, type='context', text='Robin , a youth', normalized_text='robin youth')]], aligned_nps=[(Entity(start_offset=7, end_offset=61, type='question', text=\"the young man in hawthorne's my kinsman major molineux\", normalized_text='young man in hawthornes my kinsman major molineux'), Entity(start_offset=16, end_offset=31, type='context', text='Robin , a youth', normalized_text='robin youth'))], explanation_type='single_sentence'),\n",
       " 4102709688357090054: QEDExample(example_id=4102709688357090054, title='Three-point field goal', question='when did the nba create the 3 point line', passage='In the 1979 -- 80 season , after having tested it in the previous pre-season , the NBA adopted the three - point line despite the view of many that it was a gimmick . Chris Ford of the Boston Celtics is widely credited with making the first three - point shot in NBA history on October 12 , 1979 . Kevin Grevey of the Washington Bullets also made one on the same day .', sentence_starts=[0, 167, 298], selected_sent={'start': 0, 'end': 167, 'string': 'In the 1979 -- 80 season , after having tested it in the previous pre-season , the NBA adopted the three - point line despite the view of many that it was a gimmick . '}, answer=[Entity(start_offset=7, end_offset=76, type='context', text='1979 -- 80 season , after having tested it in the previous pre-season', normalized_text='1979 80 season after having tested it in previous preseason')], nq_answers=[[Entity(start_offset=0, end_offset=24, type='context', text='In the 1979 -- 80 season', normalized_text='in 1979 80 season')], [Entity(start_offset=3, end_offset=24, type='context', text='the 1979 -- 80 season', normalized_text='1979 80 season')], [Entity(start_offset=7, end_offset=24, type='context', text='1979 -- 80 season', normalized_text='1979 80 season')]], aligned_nps=[(Entity(start_offset=9, end_offset=16, type='question', text='the nba', normalized_text='nba'), Entity(start_offset=79, end_offset=86, type='context', text='the NBA', normalized_text='nba')), (Entity(start_offset=24, end_offset=40, type='question', text='the 3 point line', normalized_text='3 point line'), Entity(start_offset=95, end_offset=117, type='context', text='the three - point line', normalized_text='three point line'))], explanation_type='single_sentence'),\n",
       " -1591814844395063631: QEDExample(example_id=-1591814844395063631, title='2012 Aurora shooting', question='what theater number was the aurora shooting in', passage='The shooting occurred in Theater 9 at the Century 16 multiplex ( operated by Cinemark ) , located at the Town Center at Aurora shopping mall at 14300 E. Alameda Avenue . Police said Holmes bought a ticket , entered the theater , and sat in the front row . About 20 minutes into the film , he left theater 9 through an emergency exit door beside the movie screen , with direct access to the lightly used parking area at the back of the complex , while propping the door slightly open with a plastic tablecloth holder . There were about 400 people inside theater 9 .', sentence_starts=[0, 170, 256, 518], selected_sent={'start': 0, 'end': 170, 'string': 'The shooting occurred in Theater 9 at the Century 16 multiplex ( operated by Cinemark ) , located at the Town Center at Aurora shopping mall at 14300 E. Alameda Avenue . '}, answer=[Entity(start_offset=25, end_offset=34, type='context', text='Theater 9', normalized_text='theater 9')], nq_answers=[[Entity(start_offset=33, end_offset=34, type='context', text='9', normalized_text='9')], [Entity(start_offset=25, end_offset=34, type='context', text='Theater 9', normalized_text='theater 9')], [Entity(start_offset=22, end_offset=62, type='context', text='in Theater 9 at the Century 16 multiplex', normalized_text='in theater 9 at century 16 multiplex')]], aligned_nps=[(Entity(start_offset=24, end_offset=43, type='question', text='the aurora shooting', normalized_text='aurora shooting'), Entity(start_offset=0, end_offset=12, type='context', text='The shooting', normalized_text='shooting'))], explanation_type='single_sentence'),\n",
       " -3259277719781782681: QEDExample(example_id=-3259277719781782681, title='I Can Only Imagine (MercyMe song)', question='who wrote the country song i can only imagine', passage=\"`` I Can Only Imagine '' ( sometimes shortened to `` Imagine '' ) is a single recorded by Christian rock band MercyMe . Written and composed by lead vocalist Bart Millard , the song , based around a main piano track , was inspired by the death of Millard 's father and considers what it would be like in Heaven and to be standing before God . The song was first issued as a track on MercyMe 's 1999 album The Worship Project , which was released on an independent record label . The song was re-recorded and included on their 2001 major - label debut album Almost There as the fifth song on the album .\", sentence_starts=[0, 120, 343, 479], selected_sent={'start': 120, 'end': 343, 'string': \"Written and composed by lead vocalist Bart Millard , the song , based around a main piano track , was inspired by the death of Millard 's father and considers what it would be like in Heaven and to be standing before God . \"}, answer=[Entity(start_offset=158, end_offset=170, type='context', text='Bart Millard', normalized_text='bart millard')], nq_answers=[[Entity(start_offset=158, end_offset=170, type='context', text='Bart Millard', normalized_text='bart millard')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='the country song i can only imagine', normalized_text='country song i can only imagine'), Entity(start_offset=173, end_offset=215, type='context', text='the song , based around a main piano track', normalized_text='song based around main piano track'))], explanation_type='single_sentence'),\n",
       " 5591916631811807548: QEDExample(example_id=5591916631811807548, title='Tertiary education fees in Australia', question='when did university stop being free in australia', passage=\"In 1989 , the Hawke Labor Government began gradually re-introducing fees for university study . It set up the Higher Education Contributions Scheme ( HECS ) , which was first proposed by Professor Murray Wells and subsequently developed by economist and lecturer at the Australian National University , Bruce Chapman and championed by Education Minister John Dawkins ( see Dawkins Revolution ) . Under the original HECS , a $1,800 fee was charged to all university students , and the Commonwealth paid the balance . A student could defer payment of this HECS amount ( in which case it was called a HECS debt ) and repay the debt through the tax system , when the student 's income exceeds a threshold level . As part of the reforms , Colleges of Advanced Education entered the University sector by various means . The HECS system was accepted by both federal political parties and has survived until today , though with a number of changes .\", sentence_starts=[0, 96, 396, 516, 709, 814], selected_sent={'start': 0, 'end': 96, 'string': 'In 1989 , the Hawke Labor Government began gradually re-introducing fees for university study . '}, answer=[Entity(start_offset=3, end_offset=7, type='context', text='1989', normalized_text='1989')], nq_answers=[[Entity(start_offset=3, end_offset=7, type='context', text='1989', normalized_text='1989')]], aligned_nps=[(Entity(start_offset=39, end_offset=48, type='question', text='australia', normalized_text='australia'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -1577046769595264411: QEDExample(example_id=-1577046769595264411, title='Peromyscus maniculatus', question='where do deer mice live in the us', passage='Peromyscus maniculatus is a rodent native to North America . It is most commonly called the deer mouse , although that name is common to most species of Peromyscus , and thus is often called the North American deermouse and is fairly widespread across the continent , with the major exception being the southeast United States and the far north .', sentence_starts=[0, 61], selected_sent={'start': 61, 'end': 346, 'string': 'It is most commonly called the deer mouse , although that name is common to most species of Peromyscus , and thus is often called the North American deermouse and is fairly widespread across the continent , with the major exception being the southeast United States and the far north .'}, answer=[Entity(start_offset=234, end_offset=344, type='context', text='widespread across the continent , with the major exception being the southeast United States and the far north', normalized_text='widespread across continent with major exception being southeast united states and far north')], nq_answers=[[Entity(start_offset=227, end_offset=344, type='context', text='fairly widespread across the continent , with the major exception being the southeast United States and the far north', normalized_text='fairly widespread across continent with major exception being southeast united states and far north')]], aligned_nps=[(Entity(start_offset=9, end_offset=18, type='question', text='deer mice', normalized_text='deer mice'), Entity(start_offset=61, end_offset=63, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 8798495197440000280: QEDExample(example_id=8798495197440000280, title='Hypertext Transfer Protocol', question='the first line of http request message is called ____', passage=\"In HTTP / 1.0 and since , the first line of the HTTP response is called the status line and includes a numeric status code ( such as `` 404 '' ) and a textual reason phrase ( such as `` Not Found '' ) . The way the user agent handles the response primarily depends on the code and secondarily on the other response header fields . Custom status codes can be used since , if the user agent encounters a code it does not recognize , it can use the first digit of the code to determine the general class of the response .\", sentence_starts=[0, 203, 331], selected_sent={'start': 0, 'end': 203, 'string': \"In HTTP / 1.0 and since , the first line of the HTTP response is called the status line and includes a numeric status code ( such as `` 404 '' ) and a textual reason phrase ( such as `` Not Found '' ) . \"}, answer=[Entity(start_offset=72, end_offset=87, type='context', text='the status line', normalized_text='status line')], nq_answers=[[Entity(start_offset=76, end_offset=87, type='context', text='status line', normalized_text='status line')], [Entity(start_offset=72, end_offset=87, type='context', text='the status line', normalized_text='status line')]], aligned_nps=[(Entity(start_offset=4, end_offset=38, type='question', text='first line of http request message', normalized_text='first line of http request message'), Entity(start_offset=26, end_offset=61, type='context', text='the first line of the HTTP response', normalized_text='first line of http response'))], explanation_type='single_sentence'),\n",
       " -1732398282020420825: QEDExample(example_id=-1732398282020420825, title='MAP sensor', question='where is the manifold absolute pressure sensor located', passage=\"The manifold absolute pressure sensor ( MAP sensor ) is one of the sensors used in an internal combustion engine 's electronic control system .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 143, 'string': \"The manifold absolute pressure sensor ( MAP sensor ) is one of the sensors used in an internal combustion engine 's electronic control system .\"}, answer=[Entity(start_offset=83, end_offset=141, type='context', text=\"an internal combustion engine 's electronic control system\", normalized_text='internal combustion engine s electronic control system')], nq_answers=[[Entity(start_offset=86, end_offset=141, type='context', text=\"internal combustion engine 's electronic control system\", normalized_text='internal combustion engine s electronic control system')]], aligned_nps=[(Entity(start_offset=9, end_offset=46, type='question', text='the manifold absolute pressure sensor', normalized_text='manifold absolute pressure sensor'), Entity(start_offset=0, end_offset=52, type='context', text='The manifold absolute pressure sensor ( MAP sensor )', normalized_text='manifold absolute pressure sensor map sensor'))], explanation_type='single_sentence'),\n",
       " -1259577751352734948: QEDExample(example_id=-1259577751352734948, title='I Wanna Dance with Somebody (Who Loves Me)', question='who wrote i want to dance with somebody by whitney houston', passage=\"`` I Wanna Dance with Somebody ( Who Loves Me ) '' is the first single from Whitney Houston 's second studio album Whitney . It was produced by Narada Michael Walden , and written by George Merrill and Shannon Rubicam of the band Boy Meets Girl , who had previously written the number - one Whitney Houston hit `` How Will I Know . '' The original arrangement was written for her grandnephew Mau Rosillo when he was 9 years old , as he was a well - renoun dancer .\", sentence_starts=[0, 125, 335], selected_sent={'start': 125, 'end': 335, 'string': \"It was produced by Narada Michael Walden , and written by George Merrill and Shannon Rubicam of the band Boy Meets Girl , who had previously written the number - one Whitney Houston hit `` How Will I Know . '' \"}, answer=[Entity(start_offset=183, end_offset=244, type='context', text='George Merrill and Shannon Rubicam of the band Boy Meets Girl', normalized_text='george merrill and shannon rubicam of band boy meets girl')], nq_answers=[[Entity(start_offset=172, end_offset=244, type='context', text='written by George Merrill and Shannon Rubicam of the band Boy Meets Girl', normalized_text='written by george merrill and shannon rubicam of band boy meets girl')], [Entity(start_offset=183, end_offset=197, type='context', text='George Merrill', normalized_text='george merrill'), Entity(start_offset=202, end_offset=217, type='context', text='Shannon Rubicam', normalized_text='shannon rubicam')], [Entity(start_offset=183, end_offset=217, type='context', text='George Merrill and Shannon Rubicam', normalized_text='george merrill and shannon rubicam')], [Entity(start_offset=183, end_offset=244, type='context', text='George Merrill and Shannon Rubicam of the band Boy Meets Girl', normalized_text='george merrill and shannon rubicam of band boy meets girl')]], aligned_nps=[(Entity(start_offset=10, end_offset=58, type='question', text='i want to dance with somebody by whitney houston', normalized_text='i want to dance with somebody by whitney houston'), Entity(start_offset=125, end_offset=127, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -6339722844243759601: QEDExample(example_id=-6339722844243759601, title='The Lord of the Rings: The Fellowship of the Ring', question=\"the fellowship of the ring director's cut length\", passage='In November 2002 , an extended edition was released on VHS and DVD , with 30 minutes of new material , added special effects and music , plus 20 minutes of fan - club credits , totalling to 228 minutes . The DVD set included four commentaries and over three hours of supplementary material .', sentence_starts=[0, 204], selected_sent={'start': 0, 'end': 204, 'string': 'In November 2002 , an extended edition was released on VHS and DVD , with 30 minutes of new material , added special effects and music , plus 20 minutes of fan - club credits , totalling to 228 minutes . '}, answer=[Entity(start_offset=190, end_offset=201, type='context', text='228 minutes', normalized_text='228 minutes')], nq_answers=[[Entity(start_offset=190, end_offset=201, type='context', text='228 minutes', normalized_text='228 minutes')]], aligned_nps=[(Entity(start_offset=0, end_offset=41, type='question', text=\"the fellowship of the ring director's cut\", normalized_text='fellowship of ring directors cut'), Entity(start_offset=19, end_offset=38, type='context', text='an extended edition', normalized_text='extended edition'))], explanation_type='single_sentence'),\n",
       " -8846576882654798687: QEDExample(example_id=-8846576882654798687, title='Computer data storage', question='where is most data stored on a computer', passage='Primary storage ( also known as main memory or internal memory ) , often referred to simply as memory , is the only one directly accessible to the CPU . The CPU continuously reads instructions stored there and executes them as required . Any data actively operated on is also stored there in uniform manner .', sentence_starts=[0, 153, 238], selected_sent={'start': 0, 'end': 153, 'string': 'Primary storage ( also known as main memory or internal memory ) , often referred to simply as memory , is the only one directly accessible to the CPU . '}, answer=[Entity(start_offset=0, end_offset=64, type='context', text='Primary storage ( also known as main memory or internal memory )', normalized_text='primary storage also known as main memory or internal memory')], nq_answers=[[Entity(start_offset=0, end_offset=101, type='context', text='Primary storage ( also known as main memory or internal memory ) , often referred to simply as memory', normalized_text='primary storage also known as main memory or internal memory often referred to simply as memory')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2963242422999718442: QEDExample(example_id=2963242422999718442, title='Climate of South Africa', question='during which season does cape town receive rainfall', passage='South Africa experiences a high degree of sunshine with rainfall about half of the global average , increasing from west to east , and with semi-desert regions in the north - west . While the Western Cape has a Mediterranean climate with winter rainfall , most of the country experiences summer rain .', sentence_starts=[0, 182], selected_sent={'start': 182, 'end': 301, 'string': 'While the Western Cape has a Mediterranean climate with winter rainfall , most of the country experiences summer rain .'}, answer=[Entity(start_offset=238, end_offset=244, type='context', text='winter', normalized_text='winter')], nq_answers=[[Entity(start_offset=238, end_offset=244, type='context', text='winter', normalized_text='winter'), Entity(start_offset=288, end_offset=294, type='context', text='summer', normalized_text='summer')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3339006116507262453: QEDExample(example_id=-3339006116507262453, title='The Impalas', question='who sang i ran all the way home', passage=\"The Impalas were an American doo - wop group in the late 1950s , best known for their hit , `` Sorry ( I Ran All the Way Home ) '' .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 132, 'string': \"The Impalas were an American doo - wop group in the late 1950s , best known for their hit , `` Sorry ( I Ran All the Way Home ) '' .\"}, answer=[Entity(start_offset=0, end_offset=11, type='context', text='The Impalas', normalized_text='impalas')], nq_answers=[[Entity(start_offset=0, end_offset=11, type='context', text='The Impalas', normalized_text='impalas')]], aligned_nps=[(Entity(start_offset=9, end_offset=31, type='question', text='i ran all the way home', normalized_text='i ran all way home'), Entity(start_offset=80, end_offset=130, type='context', text=\"their hit , `` Sorry ( I Ran All the Way Home ) ''\", normalized_text='their hit sorry i ran all way home'))], explanation_type='single_sentence'),\n",
       " 4073418639113603971: QEDExample(example_id=4073418639113603971, title='I Dig Rock and Roll Music', question='who sang i dig rock and roll music', passage=\"`` I Dig Rock and Roll Music '' is a 1967 song by the American folk group Peter , Paul and Mary , written by Paul Stookey , James Mason and Dave Dixon .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 152, 'string': \"`` I Dig Rock and Roll Music '' is a 1967 song by the American folk group Peter , Paul and Mary , written by Paul Stookey , James Mason and Dave Dixon .\"}, answer=[Entity(start_offset=74, end_offset=95, type='context', text='Peter , Paul and Mary', normalized_text='peter paul and mary')], nq_answers=[[Entity(start_offset=74, end_offset=95, type='context', text='Peter , Paul and Mary', normalized_text='peter paul and mary')], [Entity(start_offset=54, end_offset=95, type='context', text='American folk group Peter , Paul and Mary', normalized_text='american folk group peter paul and mary')]], aligned_nps=[(Entity(start_offset=9, end_offset=34, type='question', text='i dig rock and roll music', normalized_text='i dig rock and roll music'), Entity(start_offset=3, end_offset=28, type='context', text='I Dig Rock and Roll Music', normalized_text='i dig rock and roll music'))], explanation_type='single_sentence'),\n",
       " -2380769225463379264: QEDExample(example_id=-2380769225463379264, title='Camel', question='what is the name of a camel with 2 humps', passage=\"A camel is an even - toed ungulate in the genus Camelus , bearing distinctive fatty deposits known as `` humps '' on its back . The three surviving species of camel are the dromedary , or one - humped camel ( C. dromedarius ) , which inhabits the Middle East and the Horn of Africa ; the Bactrian , or two - humped camel ( C. bactrianus ) , which inhabits Central Asia ; and the critically endangered wild Bactrian camel ( C. ferus ) that has limited populations in remote areas of northwest China and Mongolia . Bactrian camels take their name from the historical Bactria region of Central Asia . Additionally one other species of camel in the separate genus Camelops , C. hesternus lived in western North America and became extinct when humans entered the continent at the end of the Pleistocene . Both the dromedary and the Bactrian camels have been domesticated ; they provide milk , meat , hair for textiles or goods such as felted pouches , and are working animals with tasks ranging from human transport to bearing loads .\", sentence_starts=[0, 128, 513, 598, 800], selected_sent={'start': 128, 'end': 513, 'string': 'The three surviving species of camel are the dromedary , or one - humped camel ( C. dromedarius ) , which inhabits the Middle East and the Horn of Africa ; the Bactrian , or two - humped camel ( C. bactrianus ) , which inhabits Central Asia ; and the critically endangered wild Bactrian camel ( C. ferus ) that has limited populations in remote areas of northwest China and Mongolia . '}, answer=[Entity(start_offset=288, end_offset=320, type='context', text='Bactrian , or two - humped camel', normalized_text='bactrian or two humped camel')], nq_answers=[[Entity(start_offset=288, end_offset=338, type='context', text='Bactrian , or two - humped camel ( C. bactrianus )', normalized_text='bactrian or two humped camel c bactrianus')], [Entity(start_offset=288, end_offset=296, type='context', text='Bactrian', normalized_text='bactrian')], [Entity(start_offset=284, end_offset=296, type='context', text='the Bactrian', normalized_text='bactrian')]], aligned_nps=[(Entity(start_offset=20, end_offset=40, type='question', text='a camel with 2 humps', normalized_text='camel with 2 humps'), Entity(start_offset=284, end_offset=338, type='context', text='the Bactrian , or two - humped camel ( C. bactrianus )', normalized_text='bactrian or two humped camel c bactrianus'))], explanation_type='single_sentence'),\n",
       " -2026243617985325453: QEDExample(example_id=-2026243617985325453, title='Adjusted gross income', question='where do you find the adjusted gross income', passage='Adjusted gross income is calculated by subtracting Above - the - line deduction from gross income .', sentence_starts=[0], selected_sent={'start': 0, 'end': 99, 'string': 'Adjusted gross income is calculated by subtracting Above - the - line deduction from gross income .'}, answer=[Entity(start_offset=39, end_offset=97, type='context', text='subtracting Above - the - line deduction from gross income', normalized_text='subtracting above line deduction from gross income')], nq_answers=[[Entity(start_offset=25, end_offset=97, type='context', text='calculated by subtracting Above - the - line deduction from gross income', normalized_text='calculated by subtracting above line deduction from gross income')], [Entity(start_offset=36, end_offset=97, type='context', text='by subtracting Above - the - line deduction from gross income', normalized_text='by subtracting above line deduction from gross income')]], aligned_nps=[(Entity(start_offset=18, end_offset=43, type='question', text='the adjusted gross income', normalized_text='adjusted gross income'), Entity(start_offset=0, end_offset=21, type='context', text='Adjusted gross income', normalized_text='adjusted gross income'))], explanation_type='single_sentence'),\n",
       " 3244394342108563307: QEDExample(example_id=3244394342108563307, title='Romantic music', question='how did orchestra change in the romantic period', passage='In the Romantic period , music became more expressive and emotional , expanding to encompass literary , artistic , and philosophical themes . Famous early Romantic composers include Beethoven ( whose works span both this period and the preceding Classical period ) , Schubert , Schumann , Chopin , Mendelssohn , Bellini , and Berlioz . The late 19th century saw a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble . Also , public concerts became a key part of urban middle class society , in contrast to earlier periods , when concerts were mainly paid for by and performed for aristocrats . Famous composers from the second half of the century include Bruckner , Johann Strauss II , Brahms , Liszt , Tchaikovsky , Dvořák , Verdi , and Wagner . Between 1890 and 1910 , a third wave of composers including Mahler , Richard Strauss , Puccini , and Sibelius built on the work of middle Romantic composers to create even more complex -- and often much longer -- musical works . A prominent mark of late 19th century music is its nationalistic fervor , as exemplified by such figures as Dvořák , Sibelius , and Grieg . Other prominent late - century figures include Saint - Saëns , Fauré , Rachmaninoff and Franck .', sentence_starts=[0, 142, 336, 490, 666, 819, 1048, 1188], selected_sent={'start': 336, 'end': 490, 'string': 'The late 19th century saw a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble . '}, answer=[Entity(start_offset=373, end_offset=487, type='context', text='expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble', normalized_text='expansion in size of orchestra and in dynamic range and diversity of instruments used in this ensemble')], nq_answers=[[Entity(start_offset=362, end_offset=487, type='context', text='a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble', normalized_text='dramatic expansion in size of orchestra and in dynamic range and diversity of instruments used in this ensemble')]], aligned_nps=[(Entity(start_offset=8, end_offset=17, type='question', text='orchestra', normalized_text='orchestra'), Entity(start_offset=398, end_offset=411, type='context', text='the orchestra', normalized_text='orchestra')), (Entity(start_offset=28, end_offset=47, type='question', text='the romantic period', normalized_text='romantic period'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 4674269357266381610: QEDExample(example_id=4674269357266381610, title='Cool Hand Luke', question='who plays the walking boss in cool hand luke', passage=\"Decorated war veteran Lucas `` Luke '' Jackson ( Paul Newman ) , is arrested for cutting parking meters off their poles one drunken night . He is sentenced to two years in prison and sent to a Florida chain gang prison run by a stern warden , the Captain ( Strother Martin ) , and a stoic rifleman , Walking Boss Godfrey ( Morgan Woodward ) , whose eyes are always covered by a pair of mirrored sunglasses. Carr ( Clifton James ) the floorwalker , tells the rules to the new set of prisoners , with any violations resulting in spending the night in `` the box , '' a small square room with limited air and very little room to move .\", sentence_starts=[0, 140], selected_sent={'start': 140, 'end': 632, 'string': \"He is sentenced to two years in prison and sent to a Florida chain gang prison run by a stern warden , the Captain ( Strother Martin ) , and a stoic rifleman , Walking Boss Godfrey ( Morgan Woodward ) , whose eyes are always covered by a pair of mirrored sunglasses. Carr ( Clifton James ) the floorwalker , tells the rules to the new set of prisoners , with any violations resulting in spending the night in `` the box , '' a small square room with limited air and very little room to move .\"}, answer=[Entity(start_offset=323, end_offset=338, type='context', text='Morgan Woodward', normalized_text='morgan woodward')], nq_answers=[[Entity(start_offset=323, end_offset=338, type='context', text='Morgan Woodward', normalized_text='morgan woodward')]], aligned_nps=[(Entity(start_offset=10, end_offset=26, type='question', text='the walking boss', normalized_text='walking boss'), Entity(start_offset=281, end_offset=340, type='context', text='a stoic rifleman , Walking Boss Godfrey ( Morgan Woodward )', normalized_text='stoic rifleman walking boss godfrey morgan woodward')), (Entity(start_offset=30, end_offset=44, type='question', text='cool hand luke', normalized_text='cool hand luke'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -7306805811512692008: QEDExample(example_id=-7306805811512692008, title='Red River of the South', question='where does the red river start and end in louisiana', passage='The Red River is the second - largest river basin in the southern Great Plains . It rises in two branches in the Texas Panhandle and flows east , where it acts as the border between the states of Texas and Oklahoma . It forms a short border between Texas and Arkansas before entering Arkansas , turning south near Fulton , Arkansas , and flowing into Louisiana , where it flows into the Atchafalaya River . The total length of the river is 1,360 miles ( 2,190 km ) , with a mean flow of over 57,000 cubic feet per second ( 1,600 m / s ) at the mouth .', sentence_starts=[0, 81, 217, 407], selected_sent={'start': 217, 'end': 407, 'string': 'It forms a short border between Texas and Arkansas before entering Arkansas , turning south near Fulton , Arkansas , and flowing into Louisiana , where it flows into the Atchafalaya River . '}, answer=[Entity(start_offset=295, end_offset=404, type='context', text='turning south near Fulton , Arkansas , and flowing into Louisiana , where it flows into the Atchafalaya River', normalized_text='turning south near fulton arkansas and flowing into louisiana where it flows into atchafalaya river')], nq_answers=[[Entity(start_offset=109, end_offset=128, type='context', text='the Texas Panhandle', normalized_text='texas panhandle')]], aligned_nps=[(Entity(start_offset=11, end_offset=24, type='question', text='the red river', normalized_text='red river'), Entity(start_offset=217, end_offset=219, type='context', text='It', normalized_text='it')), (Entity(start_offset=42, end_offset=51, type='question', text='louisiana', normalized_text='louisiana'), Entity(start_offset=351, end_offset=360, type='context', text='Louisiana', normalized_text='louisiana'))], explanation_type='single_sentence'),\n",
       " -6311914778265000994: QEDExample(example_id=-6311914778265000994, title='Identity documents in the United States', question='where can i get a state issued id', passage=\"A driver 's license is issued by each state 's DMV , which is required to drive . Each state 's DMV also issues a nearly - identical `` non-driver identification card '' to identify persons who are unable or do not want to drive , which is typically treated like a driver 's license for all purposes , except for proving that a person has the right to drive .\", sentence_starts=[0, 82], selected_sent={'start': 82, 'end': 359, 'string': \"Each state 's DMV also issues a nearly - identical `` non-driver identification card '' to identify persons who are unable or do not want to drive , which is typically treated like a driver 's license for all purposes , except for proving that a person has the right to drive .\"}, answer=[Entity(start_offset=82, end_offset=99, type='context', text=\"Each state 's DMV\", normalized_text='each state s dmv')], nq_answers=[[Entity(start_offset=33, end_offset=50, type='context', text=\"each state 's DMV\", normalized_text='each state s dmv')], [Entity(start_offset=96, end_offset=99, type='context', text='DMV', normalized_text='dmv')], [Entity(start_offset=47, end_offset=50, type='context', text='DMV', normalized_text='dmv')]], aligned_nps=[(Entity(start_offset=16, end_offset=33, type='question', text='a state issued id', normalized_text='state issued id'), Entity(start_offset=112, end_offset=169, type='context', text=\"a nearly - identical `` non-driver identification card ''\", normalized_text='nearly identical nondriver identification card'))], explanation_type='single_sentence'),\n",
       " 1547647803339899015: QEDExample(example_id=1547647803339899015, title='Nil Darpan', question='who translated the play neel darpan into english', passage='The play was received with mixed results upon its release . The play was translated by Reverend J. Long for which he was sentenced to prison and charged with sedition .', sentence_starts=[0, 60], selected_sent={'start': 60, 'end': 168, 'string': 'The play was translated by Reverend J. Long for which he was sentenced to prison and charged with sedition .'}, answer=[Entity(start_offset=87, end_offset=103, type='context', text='Reverend J. Long', normalized_text='reverend j long')], nq_answers=[[Entity(start_offset=87, end_offset=103, type='context', text='Reverend J. Long', normalized_text='reverend j long')]], aligned_nps=[(Entity(start_offset=15, end_offset=35, type='question', text='the play neel darpan', normalized_text='play neel darpan'), Entity(start_offset=60, end_offset=68, type='context', text='The play', normalized_text='play'))], explanation_type='single_sentence'),\n",
       " -1636103814308578967: QEDExample(example_id=-1636103814308578967, title='Combustion', question='what must be present for a combustion reaction to occur', passage='Combustion / kəmˈbʌs. tʃ ən / or burning is a high - temperature exothermic redox chemical reaction between a fuel ( the reductant ) and an oxidant , usually atmospheric oxygen , that produces oxidized , often gaseous products , in a mixture termed as smoke . Combustion in a fire produces a flame , and the heat produced can make combustion self - sustaining . Combustion is often a complicated sequence of elementary radical reactions . Solid fuels , such as wood and coal , first undergo endothermic pyrolysis to produce gaseous fuels whose combustion then supplies the heat required to produce more of them . Combustion is often hot enough that light in the form of either glowing or a flame is produced . A simple example can be seen in the combustion of hydrogen and oxygen into water vapor , a reaction commonly used to fuel rocket engines . This reaction releases 242 kJ / mol of heat and reduces the enthalpy accordingly ( at constant temperature and pressure ) :', sentence_starts=[0, 260, 362, 439, 613, 710, 849], selected_sent={'start': 0, 'end': 260, 'string': 'Combustion / kəmˈbʌs. tʃ ən / or burning is a high - temperature exothermic redox chemical reaction between a fuel ( the reductant ) and an oxidant , usually atmospheric oxygen , that produces oxidized , often gaseous products , in a mixture termed as smoke . '}, answer=[Entity(start_offset=108, end_offset=176, type='context', text='a fuel ( the reductant ) and an oxidant , usually atmospheric oxygen', normalized_text='fuel reductant and oxidant usually atmospheric oxygen')], nq_answers=[[Entity(start_offset=108, end_offset=147, type='context', text='a fuel ( the reductant ) and an oxidant', normalized_text='fuel reductant and oxidant')], [Entity(start_offset=108, end_offset=132, type='context', text='a fuel ( the reductant )', normalized_text='fuel reductant'), Entity(start_offset=137, end_offset=176, type='context', text='an oxidant , usually atmospheric oxygen', normalized_text='oxidant usually atmospheric oxygen')]], aligned_nps=[(Entity(start_offset=25, end_offset=46, type='question', text='a combustion reaction', normalized_text='combustion reaction'), Entity(start_offset=0, end_offset=40, type='context', text='Combustion / kəmˈbʌs. tʃ ən / or burning', normalized_text='combustion kəmˈbʌs tʃ ən or burning'))], explanation_type='single_sentence'),\n",
       " 6299363353334329511: QEDExample(example_id=6299363353334329511, title='Federal Unemployment Tax Act', question='under the federal unemployment tax act which party pays unemployment taxes', passage='The Federal Unemployment Tax Act ( or FUTA , I.R.C. ch. 23 ) is a United States federal law that imposes a federal employer tax used to help fund state workforce agencies . Employers report this tax by filing an annual Form 940 with the Internal Revenue Service . In some cases , the employer is required to pay the tax in installments during the tax year .', sentence_starts=[0, 52, 173, 264], selected_sent={'start': 173, 'end': 264, 'string': 'Employers report this tax by filing an annual Form 940 with the Internal Revenue Service . '}, answer=[Entity(start_offset=173, end_offset=182, type='context', text='Employers', normalized_text='employers')], nq_answers=[[Entity(start_offset=173, end_offset=182, type='context', text='Employers', normalized_text='employers')], [Entity(start_offset=280, end_offset=292, type='context', text='the employer', normalized_text='employer')]], aligned_nps=[(Entity(start_offset=56, end_offset=74, type='question', text='unemployment taxes', normalized_text='unemployment taxes'), Entity(start_offset=190, end_offset=198, type='context', text='this tax', normalized_text='this tax')), (Entity(start_offset=6, end_offset=38, type='question', text='the federal unemployment tax act', normalized_text='federal unemployment tax act'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 8188550931836037275: QEDExample(example_id=8188550931836037275, title='Thin film', question='what is meant by thin film in physics', passage='A thin film is a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness . The controlled synthesis of materials as thin films ( a process referred to as deposition ) is a fundamental step in many applications . A familiar example is the household mirror , which typically has a thin metal coating on the back of a sheet of glass to form a reflective interface . The process of silvering was once commonly used to produce mirrors , while more recently the metal layer is deposited using techniques such as sputtering . Advances in thin film deposition techniques during the 20th century have enabled a wide range of technological breakthroughs in areas such as magnetic recording media , electronic semiconductor devices , LEDs , optical coatings ( such as antireflective coatings ) , hard coatings on cutting tools , and for both energy generation ( e.g. thin - film solar cells ) and storage ( thin - film batteries ) . It is also being applied to pharmaceuticals , via thin - film drug delivery . A stack of thin films is called a multilayer .', sentence_starts=[0, 125, 262, 413, 569, 972, 1050], selected_sent={'start': 0, 'end': 125, 'string': 'A thin film is a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness . '}, answer=[Entity(start_offset=15, end_offset=122, type='context', text='a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness', normalized_text='layer of material ranging from fractions of nanometer monolayer to several micrometers in thickness')], nq_answers=[[Entity(start_offset=15, end_offset=122, type='context', text='a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness', normalized_text='layer of material ranging from fractions of nanometer monolayer to several micrometers in thickness')]], aligned_nps=[(Entity(start_offset=17, end_offset=26, type='question', text='thin film', normalized_text='thin film'), Entity(start_offset=0, end_offset=11, type='context', text='A thin film', normalized_text='thin film'))], explanation_type='single_sentence'),\n",
       " 8324017764283655875: QEDExample(example_id=8324017764283655875, title='Colon Street', question='what is the oldest street in the philippines', passage='Colon Street is a historical street in downtown Cebu City that is often called the oldest and the shortest national road in the Philippines . It is named after Cristóbal Colón ( Christopher Columbus ) . It traces its origins to the town plan by Miguel Lopez de Legazpi , the Spanish conquistador who arrived in the Philippines to establish a colony in 1565 .', sentence_starts=[0, 142, 203], selected_sent={'start': 0, 'end': 142, 'string': 'Colon Street is a historical street in downtown Cebu City that is often called the oldest and the shortest national road in the Philippines . '}, answer=[Entity(start_offset=0, end_offset=12, type='context', text='Colon Street', normalized_text='colon street')], nq_answers=[[Entity(start_offset=0, end_offset=12, type='context', text='Colon Street', normalized_text='colon street')], [Entity(start_offset=48, end_offset=57, type='context', text='Cebu City', normalized_text='cebu city')]], aligned_nps=[(Entity(start_offset=29, end_offset=44, type='question', text='the philippines', normalized_text='philippines'), Entity(start_offset=124, end_offset=139, type='context', text='the Philippines', normalized_text='philippines'))], explanation_type='single_sentence'),\n",
       " 5971688090041626059: QEDExample(example_id=5971688090041626059, title='Gulf Stream', question=\"the gulf stream the world's fastest ocean current flows along the western side of this water body\", passage='The Gulf Stream , together with its northern extension the North Atlantic Drift , is a warm and swift Atlantic ocean current that originates in the Gulf of Mexico and stretches to the tip of Florida , and follows the eastern coastlines of the United States and Newfoundland before crossing the Atlantic Ocean . The process of western intensification causes the Gulf Stream to be a northward accelerating current off the east coast of North America . At about 40 ° 0 ′ N 30 ° 0 ′ W \\ufeff / \\ufeff 40.000 ° N 30.000 ° W \\ufeff / 40.000 ; - 30.000 , it splits in two , with the northern stream , the North Atlantic Drift , crossing to Northern Europe and the southern stream , the Canary Current , recirculating off West Africa .', sentence_starts=[0, 311, 450], selected_sent={'start': 0, 'end': 311, 'string': 'The Gulf Stream , together with its northern extension the North Atlantic Drift , is a warm and swift Atlantic ocean current that originates in the Gulf of Mexico and stretches to the tip of Florida , and follows the eastern coastlines of the United States and Newfoundland before crossing the Atlantic Ocean . '}, answer=[Entity(start_offset=102, end_offset=116, type='context', text='Atlantic ocean', normalized_text='atlantic ocean')], nq_answers=[[Entity(start_offset=102, end_offset=116, type='context', text='Atlantic ocean', normalized_text='atlantic ocean')]], aligned_nps=[(Entity(start_offset=0, end_offset=49, type='question', text=\"the gulf stream the world's fastest ocean current\", normalized_text='gulf stream worlds fastest ocean current'), Entity(start_offset=0, end_offset=15, type='context', text='The Gulf Stream', normalized_text='gulf stream'))], explanation_type='single_sentence'),\n",
       " 1550160746045175408: QEDExample(example_id=1550160746045175408, title='Category:Nuclear power plants in Washington (state)', question='how many nuclear power plants in washington state', passage='The following 3 pages are in this category , out of 3 total . This list may not reflect recent changes ( learn more ) .', sentence_starts=[0, 62], selected_sent={'start': 0, 'end': 62, 'string': 'The following 3 pages are in this category , out of 3 total . '}, answer=[Entity(start_offset=52, end_offset=53, type='context', text='3', normalized_text='3')], nq_answers=[[Entity(start_offset=14, end_offset=15, type='context', text='3', normalized_text='3')]], aligned_nps=[(Entity(start_offset=9, end_offset=49, type='question', text='nuclear power plants in washington state', normalized_text='nuclear power plants in washington state'), Entity(start_offset=29, end_offset=42, type='context', text='this category', normalized_text='this category'))], explanation_type='single_sentence'),\n",
       " -2034478087738208526: QEDExample(example_id=-2034478087738208526, title='Michael Stivic', question='who played mike stivic on all in the family', passage=\"Michael Casimir `` Mike '' Stivic is a fictional character on the 1970s American television sitcom All in the Family . He was the live - in son - in - law of the series ' lead character , Archie Bunker , who frequently called him `` Meathead '' . Michael was the husband of Archie 's daughter Gloria ( played by Sally Struthers ) . Rob Reiner played the role of Michael Stivic throughout the series .\", sentence_starts=[0, 119, 247, 332], selected_sent={'start': 332, 'end': 400, 'string': 'Rob Reiner played the role of Michael Stivic throughout the series .'}, answer=[Entity(start_offset=332, end_offset=342, type='context', text='Rob Reiner', normalized_text='rob reiner')], nq_answers=[[Entity(start_offset=332, end_offset=342, type='context', text='Rob Reiner', normalized_text='rob reiner')]], aligned_nps=[(Entity(start_offset=11, end_offset=22, type='question', text='mike stivic', normalized_text='mike stivic'), Entity(start_offset=362, end_offset=376, type='context', text='Michael Stivic', normalized_text='michael stivic')), (Entity(start_offset=26, end_offset=43, type='question', text='all in the family', normalized_text='all in family'), Entity(start_offset=388, end_offset=398, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " 580055902888419406: QEDExample(example_id=580055902888419406, title='2018 College Football Playoff National Championship', question='where is the college championship game being played at', passage='The College Football Playoff selection committee chose the semifinalists following the conclusion of the 2017 regular season . Alabama and Georgia advanced to the national championship after winning the semifinal games hosted by the Sugar Bowl and the Rose Bowl , respectively , on January 1 , 2018 . The championship game was played at Mercedes - Benz Stadium in Atlanta , Georgia on January 8 , 2018 .', sentence_starts=[0, 127, 301], selected_sent={'start': 301, 'end': 403, 'string': 'The championship game was played at Mercedes - Benz Stadium in Atlanta , Georgia on January 8 , 2018 .'}, answer=[Entity(start_offset=337, end_offset=381, type='context', text='Mercedes - Benz Stadium in Atlanta , Georgia', normalized_text='mercedes benz stadium in atlanta georgia')], nq_answers=[[Entity(start_offset=337, end_offset=381, type='context', text='Mercedes - Benz Stadium in Atlanta , Georgia', normalized_text='mercedes benz stadium in atlanta georgia')]], aligned_nps=[(Entity(start_offset=9, end_offset=38, type='question', text='the college championship game', normalized_text='college championship game'), Entity(start_offset=301, end_offset=322, type='context', text='The championship game', normalized_text='championship game'))], explanation_type='single_sentence'),\n",
       " 2532633865902253646: QEDExample(example_id=2532633865902253646, title='What I Like About You (song)', question='who sang what i like about you originally', passage=\"`` What I Like About You '' is a song by American rock band The Romantics . The song , written by Romantics members Wally Palmar , Mike Skill and Jimmy Marinos in 1979 is included on the band 's self - titled debut album ( 1980 ) , and was also released as a single . Marinos , the band 's drummer , is the lead vocalist on the song . The band filmed a music video for the song that appeared frequently on MTV during the early 1980s .\", sentence_starts=[0, 76, 268, 335], selected_sent={'start': 0, 'end': 76, 'string': \"`` What I Like About You '' is a song by American rock band The Romantics . \"}, answer=[Entity(start_offset=60, end_offset=73, type='context', text='The Romantics', normalized_text='romantics')], nq_answers=[[Entity(start_offset=41, end_offset=73, type='context', text='American rock band The Romantics', normalized_text='american rock band romantics')], [Entity(start_offset=60, end_offset=75, type='context', text='The Romantics .', normalized_text='romantics')], [Entity(start_offset=60, end_offset=73, type='context', text='The Romantics', normalized_text='romantics')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text='what i like about you', normalized_text='what i like about you'), Entity(start_offset=3, end_offset=24, type='context', text='What I Like About You', normalized_text='what i like about you'))], explanation_type='single_sentence'),\n",
       " -1861449238368733677: QEDExample(example_id=-1861449238368733677, title='Hector (ship)', question='when did the ship hector arrived in pictou', passage='Hector was a ship famous for having been part of the first significant migration of Scottish settlers to Nova Scotia in 1773 . The replica of the original ship is located at the Hector Heritage Quay , a heritage center run by local volunteers , in Pictou .', sentence_starts=[0, 127], selected_sent={'start': 0, 'end': 127, 'string': 'Hector was a ship famous for having been part of the first significant migration of Scottish settlers to Nova Scotia in 1773 . '}, answer=[Entity(start_offset=120, end_offset=124, type='context', text='1773', normalized_text='1773')], nq_answers=[[Entity(start_offset=120, end_offset=124, type='context', text='1773', normalized_text='1773')]], aligned_nps=[(Entity(start_offset=9, end_offset=24, type='question', text='the ship hector', normalized_text='ship hector'), Entity(start_offset=0, end_offset=6, type='context', text='Hector', normalized_text='hector')), (Entity(start_offset=36, end_offset=42, type='question', text='pictou', normalized_text='pictou'), Entity(start_offset=105, end_offset=116, type='context', text='Nova Scotia', normalized_text='nova scotia'))], explanation_type='single_sentence'),\n",
       " 24224390922062302: QEDExample(example_id=24224390922062302, title='Lonely Boy (Andrew Gold song)', question='who sang the song oh what a lonely boy', passage=\"`` Lonely Boy '' is an international hit song from 1977 , written and recorded by Andrew Gold in 1976 for his album What 's Wrong with This Picture ? It spent five months on the American charts , peaking at number seven in both Canada and the United States , and number 11 in the United Kingdom . While `` Lonely Boy '' would be Gold 's biggest U.S. hit , his `` Never Let Her Slip Away '' achieved greater success in the U.K.\", sentence_starts=[0, 150, 297], selected_sent={'start': 0, 'end': 150, 'string': \"`` Lonely Boy '' is an international hit song from 1977 , written and recorded by Andrew Gold in 1976 for his album What 's Wrong with This Picture ? \"}, answer=[Entity(start_offset=82, end_offset=93, type='context', text='Andrew Gold', normalized_text='andrew gold')], nq_answers=[[Entity(start_offset=82, end_offset=93, type='context', text='Andrew Gold', normalized_text='andrew gold')]], aligned_nps=[(Entity(start_offset=9, end_offset=38, type='question', text='the song oh what a lonely boy', normalized_text='song oh what lonely boy'), Entity(start_offset=3, end_offset=13, type='context', text='Lonely Boy', normalized_text='lonely boy'))], explanation_type='single_sentence'),\n",
       " 189474589921171775: QEDExample(example_id=189474589921171775, title='History of agriculture', question='where did the cultivation of agriculture first arise', passage='The history of agriculture records the domestication of plants and animals and the development and dissemination of techniques for raising them productively . Agriculture began independently in different parts of the globe , and included a diverse range of taxa . At least eleven separate regions of the Old and New World were involved as independent centers of origin .', sentence_starts=[0, 159, 264], selected_sent={'start': 264, 'end': 370, 'string': 'At least eleven separate regions of the Old and New World were involved as independent centers of origin .'}, answer=[Entity(start_offset=264, end_offset=321, type='context', text='At least eleven separate regions of the Old and New World', normalized_text='at least eleven separate regions of old and new world')], nq_answers=[[Entity(start_offset=273, end_offset=321, type='context', text='eleven separate regions of the Old and New World', normalized_text='eleven separate regions of old and new world')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='the cultivation of agriculture', normalized_text='cultivation of agriculture'), Entity(start_offset=339, end_offset=368, type='context', text='independent centers of origin', normalized_text='independent centers of origin'))], explanation_type='single_sentence'),\n",
       " -5653778591571381839: QEDExample(example_id=-5653778591571381839, title='Cylinder', question='how many plane surfaces does a cylinder have', passage='A solid bounded by a cylindrical surface and two parallel planes is called a ( solid ) cylinder . The line segments determined by an element of the cylindrical surface between the two parallel planes is called an element of the cylinder . All the elements of a cylinder have equal lengths . The region bounded by the cylindrical surface in either of the parallel planes is called a base of the cylinder . The two bases of a cylinder are congruent figures . If the elements of the cylinder are perpendicular to the planes containing the bases , the cylinder is a right cylinder , otherwise it is called an oblique cylinder . If the bases are disks ( regions whose boundary is a circle ) the cylinder is called a circular cylinder . In some elementary treatments , a cylinder always means a circular cylinder .', sentence_starts=[0, 98, 239, 291, 405, 457, 624, 731], selected_sent={'start': 0, 'end': 98, 'string': 'A solid bounded by a cylindrical surface and two parallel planes is called a ( solid ) cylinder . '}, answer=[Entity(start_offset=45, end_offset=48, type='context', text='two', normalized_text='two')], nq_answers=[[Entity(start_offset=45, end_offset=64, type='context', text='two parallel planes', normalized_text='two parallel planes')], [Entity(start_offset=45, end_offset=48, type='context', text='two', normalized_text='two')]], aligned_nps=[(Entity(start_offset=29, end_offset=39, type='question', text='a cylinder', normalized_text='cylinder'), Entity(start_offset=75, end_offset=95, type='context', text='a ( solid ) cylinder', normalized_text='solid cylinder'))], explanation_type='single_sentence'),\n",
       " 6657198138282369001: QEDExample(example_id=6657198138282369001, title='The Championships, Wimbledon', question='in which city are the wimbledon game held', passage='The Championships , Wimbledon , commonly known simply as Wimbledon , is the oldest tennis tournament in the world , and is widely regarded as the most prestigious . It has been held at the All England Club in Wimbledon , London , since 1877 and is played on outdoor grass courts .', sentence_starts=[0, 165], selected_sent={'start': 165, 'end': 280, 'string': 'It has been held at the All England Club in Wimbledon , London , since 1877 and is played on outdoor grass courts .'}, answer=[Entity(start_offset=221, end_offset=227, type='context', text='London', normalized_text='london')], nq_answers=[[Entity(start_offset=209, end_offset=227, type='context', text='Wimbledon , London', normalized_text='wimbledon london')], [Entity(start_offset=221, end_offset=227, type='context', text='London', normalized_text='london')]], aligned_nps=[(Entity(start_offset=18, end_offset=36, type='question', text='the wimbledon game', normalized_text='wimbledon game'), Entity(start_offset=165, end_offset=167, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -6158470117924840303: QEDExample(example_id=-6158470117924840303, title='The Phantom of the Opera (1986 musical)', question='who played the first phantom of the opera', passage=\"The musical opened in London 's West End in 1986 , and on Broadway in 1988 . It won the 1986 Olivier Award and the 1988 Tony Award for Best Musical , and Michael Crawford ( in the title role ) won the Olivier and Tony Awards for Best Actor in a Musical . It is the longest running show in Broadway history by a wide margin , and celebrated its 10,000 th Broadway performance on 11 February 2012 , the first production ever to do so . It is the second longest - running West End musical , after Les Misérables , and the third longest - running West End show overall , after The Mousetrap .\", sentence_starts=[0, 77, 255, 434], selected_sent={'start': 77, 'end': 255, 'string': 'It won the 1986 Olivier Award and the 1988 Tony Award for Best Musical , and Michael Crawford ( in the title role ) won the Olivier and Tony Awards for Best Actor in a Musical . '}, answer=[Entity(start_offset=154, end_offset=170, type='context', text='Michael Crawford', normalized_text='michael crawford')], nq_answers=[[Entity(start_offset=154, end_offset=170, type='context', text='Michael Crawford', normalized_text='michael crawford')]], aligned_nps=[(Entity(start_offset=11, end_offset=41, type='question', text='the first phantom of the opera', normalized_text='first phantom of opera'), Entity(start_offset=176, end_offset=190, type='context', text='the title role', normalized_text='title role'))], explanation_type='single_sentence'),\n",
       " 9084604251611519852: QEDExample(example_id=9084604251611519852, title='Cooling tower', question='why does cooling water run through the condenser', passage='Cooling towers originated in the 19th century through the development of condensers for use with the steam engine . Condensers use relatively cool water , via various means , to condense the steam coming out of the cylinders or turbines . This reduces the back pressure , which in turn reduces the steam consumption , and thus the fuel consumption , while at the same time increasing power and recycling boiler - water . However the condensers require an ample supply of cooling water , without which they are impractical . The consumption of cooling water by inland processing and power plants is estimated to reduce power availability for the majority of thermal power plants by 2040 -- 2069 . While water usage is not an issue with marine engines , it forms a significant limitation for many land - based systems .', sentence_starts=[0, 116, 239, 421, 524, 696], selected_sent={'start': 116, 'end': 239, 'string': 'Condensers use relatively cool water , via various means , to condense the steam coming out of the cylinders or turbines . '}, answer=[Entity(start_offset=175, end_offset=236, type='context', text='to condense the steam coming out of the cylinders or turbines', normalized_text='to condense steam coming out of cylinders or turbines')], nq_answers=[[Entity(start_offset=178, end_offset=196, type='context', text='condense the steam', normalized_text='condense steam')], [Entity(start_offset=175, end_offset=236, type='context', text='to condense the steam coming out of the cylinders or turbines', normalized_text='to condense steam coming out of cylinders or turbines')]], aligned_nps=[(Entity(start_offset=35, end_offset=48, type='question', text='the condenser', normalized_text='condenser'), Entity(start_offset=116, end_offset=126, type='context', text='Condensers', normalized_text='condensers'))], explanation_type='single_sentence'),\n",
       " 2254570797818322097: QEDExample(example_id=2254570797818322097, title='Bat Masterson (TV series)', question='who played bat masterson in the tv series', passage='Bat Masterson is an American Western television series which showed a fictionalized account of the life of real - life marshal / gambler / dandy Bat Masterson . The title character was played by Gene Barry and the half - hour black - and - white shows ran on NBC from 1958 to 1961 . The series was produced by Ziv Television Productions .', sentence_starts=[0, 161, 283], selected_sent={'start': 161, 'end': 283, 'string': 'The title character was played by Gene Barry and the half - hour black - and - white shows ran on NBC from 1958 to 1961 . '}, answer=[Entity(start_offset=195, end_offset=205, type='context', text='Gene Barry', normalized_text='gene barry')], nq_answers=[[Entity(start_offset=195, end_offset=205, type='context', text='Gene Barry', normalized_text='gene barry')]], aligned_nps=[(Entity(start_offset=11, end_offset=24, type='question', text='bat masterson', normalized_text='bat masterson'), Entity(start_offset=161, end_offset=180, type='context', text='The title character', normalized_text='title character')), (Entity(start_offset=28, end_offset=41, type='question', text='the tv series', normalized_text='tv series'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -7524627393810362735: QEDExample(example_id=-7524627393810362735, title='Curling at the Winter Olympics', question=\"when did men's curling start in the olympics\", passage='Curling was included in the program of the inaugural Winter Olympic Games in 1924 in Chamonix although the results of that competition were not considered official by the International Olympic Committee until 2006 . Curling was a demonstration sport at the 1932 Games , and then again after a lengthy absence in 1988 and 1992 . The sport was finally added to the official program for the 1998 Nagano Games .', sentence_starts=[0, 216, 328], selected_sent={'start': 0, 'end': 216, 'string': 'Curling was included in the program of the inaugural Winter Olympic Games in 1924 in Chamonix although the results of that competition were not considered official by the International Olympic Committee until 2006 . '}, answer=[Entity(start_offset=77, end_offset=81, type='context', text='1924', normalized_text='1924')], nq_answers=[[Entity(start_offset=388, end_offset=392, type='context', text='1998', normalized_text='1998')], [Entity(start_offset=388, end_offset=405, type='context', text='1998 Nagano Games', normalized_text='1998 nagano games')], [Entity(start_offset=77, end_offset=81, type='context', text='1924', normalized_text='1924')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -8982983311407124347: QEDExample(example_id=-8982983311407124347, title='Corpus luteum', question='which hormone is released from the ruptured follicle or corpus luteum', passage=\"The corpus luteum ( Latin for `` yellow body '' ; plural corpora lutea ) is a temporary endocrine structure in female ovaries and is involved in the production of relatively high levels of progesterone , moderate levels of estradiol , inhibin A and small amounts of estrogen . It is the remains of the ovarian follicle that has released a mature ovum during a previous ovulation . It is colored as a result of concentrating carotenoids ( including lutein ) from the diet and secretes a moderate amount of estrogen to inhibit further release of gonadotropin - releasing hormone ( GnRH ) and thus secretion of luteinizing hormone ( LH ) and follicle - stimulating hormone ( FSH ) . A new corpus luteum develops with each menstrual cycle .\", sentence_starts=[0, 277, 381, 680], selected_sent={'start': 381, 'end': 680, 'string': 'It is colored as a result of concentrating carotenoids ( including lutein ) from the diet and secretes a moderate amount of estrogen to inhibit further release of gonadotropin - releasing hormone ( GnRH ) and thus secretion of luteinizing hormone ( LH ) and follicle - stimulating hormone ( FSH ) . '}, answer=[Entity(start_offset=505, end_offset=513, type='context', text='estrogen', normalized_text='estrogen')], nq_answers=[[Entity(start_offset=505, end_offset=513, type='context', text='estrogen', normalized_text='estrogen')], [Entity(start_offset=189, end_offset=201, type='context', text='progesterone', normalized_text='progesterone'), Entity(start_offset=223, end_offset=232, type='context', text='estradiol', normalized_text='estradiol'), Entity(start_offset=235, end_offset=244, type='context', text='inhibin A', normalized_text='inhibin'), Entity(start_offset=266, end_offset=274, type='context', text='estrogen', normalized_text='estrogen')]], aligned_nps=[(Entity(start_offset=31, end_offset=69, type='question', text='the ruptured follicle or corpus luteum', normalized_text='ruptured follicle or corpus luteum'), Entity(start_offset=381, end_offset=383, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 7821914058328978278: QEDExample(example_id=7821914058328978278, title='White Flag (song)', question='who sings i will go down with this ship', passage=\"`` White Flag '' is a song by English singer - songwriter Dido , released as the lead single from her second studio album Life for Rent on 1 September 2003 . The song is considered one of her signature songs , and helped Life for Rent sell over ten million copies worldwide . The song was nominated for the Best Female Pop Vocal Performance at the 46th Grammy Awards , but lost to Christina Aguilera 's `` Beautiful '' . It won the Best British Single at the 2004 Brit Awards .\", sentence_starts=[0, 158, 276, 421], selected_sent={'start': 0, 'end': 158, 'string': \"`` White Flag '' is a song by English singer - songwriter Dido , released as the lead single from her second studio album Life for Rent on 1 September 2003 . \"}, answer=[Entity(start_offset=58, end_offset=62, type='context', text='Dido', normalized_text='dido')], nq_answers=[[Entity(start_offset=58, end_offset=62, type='context', text='Dido', normalized_text='dido')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text='i will go down with this ship', normalized_text='i will go down with this ship'), Entity(start_offset=3, end_offset=13, type='context', text='White Flag', normalized_text='white flag'))], explanation_type='single_sentence'),\n",
       " -7597333071901977632: QEDExample(example_id=-7597333071901977632, title='Hidalgo (surname)', question='where does the last name hidalgo come from', passage='Hidalgo is a Spanish surname . Notable people with the surname include :', sentence_starts=[0, 31], selected_sent={'start': 0, 'end': 31, 'string': 'Hidalgo is a Spanish surname . '}, answer=[Entity(start_offset=13, end_offset=20, type='context', text='Spanish', normalized_text='spanish')], nq_answers=[[Entity(start_offset=13, end_offset=20, type='context', text='Spanish', normalized_text='spanish')]], aligned_nps=[(Entity(start_offset=11, end_offset=32, type='question', text='the last name hidalgo', normalized_text='last name hidalgo'), Entity(start_offset=0, end_offset=7, type='context', text='Hidalgo', normalized_text='hidalgo'))], explanation_type='single_sentence'),\n",
       " -3395327864419725898: QEDExample(example_id=-3395327864419725898, title='One Piece at a Time', question='jonny cash one piece at a time car', passage=\"Beginning almost immediately , the singer and a co-worker decide to `` steal '' a Cadillac by way of using their assembly line jobs to obtain the parts via salami slicing . He takes the small parts home hidden in his unusually large lunch box ; larger parts are smuggled out in his co-worker's motorhome .\", sentence_starts=[0, 173], selected_sent={'start': 0, 'end': 173, 'string': \"Beginning almost immediately , the singer and a co-worker decide to `` steal '' a Cadillac by way of using their assembly line jobs to obtain the parts via salami slicing . \"}, answer=[Entity(start_offset=80, end_offset=90, type='context', text='a Cadillac', normalized_text='cadillac')], nq_answers=[[Entity(start_offset=82, end_offset=90, type='context', text='Cadillac', normalized_text='cadillac')]], aligned_nps=[(Entity(start_offset=0, end_offset=34, type='question', text='jonny cash one piece at a time car', normalized_text='jonny cash one piece at time car'), Entity(start_offset=80, end_offset=90, type='context', text='a Cadillac', normalized_text='cadillac'))], explanation_type='single_sentence'),\n",
       " -7441083894056118490: QEDExample(example_id=-7441083894056118490, title='Canadian Pacific Railway', question='when was the canadian pacific railway started and finished', passage=\"The railway was originally built between Eastern Canada and British Columbia between 1881 and 1885 ( connecting with Ottawa Valley and Georgian Bay area lines built earlier ) , fulfilling a promise extended to British Columbia when it entered Confederation in 1871 . It was Canada 's first transcontinental railway , but no longer reaches the Atlantic coast . Primarily a freight railway , the CPR was for decades the only practical means of long - distance passenger transport in most regions of Canada , and was instrumental in the settlement and development of Western Canada . The CPR became one of the largest and most powerful companies in Canada , a position it held as late as 1975 . Its primary passenger services were eliminated in 1986 , after being assumed by Via Rail Canada in 1978 . A beaver was chosen as the railway 's logo in honor of Sir Donald A Smith ( 1st . Baron Strathcona and Mount Royal ) who had risen from Factor to Govenor of the Hudson 's Bay Company over a lengthy career in the beaver fur trade . Smith was a principal financier of the C.P.R. staking much of his personal wealth . In 1885 he drove the last spike to complete the transcontinental line .\", sentence_starts=[0, 267, 360, 581, 692, 798, 880, 1029, 1075, 1113], selected_sent={'start': 0, 'end': 267, 'string': 'The railway was originally built between Eastern Canada and British Columbia between 1881 and 1885 ( connecting with Ottawa Valley and Georgian Bay area lines built earlier ) , fulfilling a promise extended to British Columbia when it entered Confederation in 1871 . '}, answer=[Entity(start_offset=85, end_offset=98, type='context', text='1881 and 1885', normalized_text='1881 and 1885')], nq_answers=[[Entity(start_offset=77, end_offset=98, type='context', text='between 1881 and 1885', normalized_text='between 1881 and 1885')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the canadian pacific railway', normalized_text='canadian pacific railway'), Entity(start_offset=0, end_offset=11, type='context', text='The railway', normalized_text='railway'))], explanation_type='single_sentence'),\n",
       " -7366805671983604343: QEDExample(example_id=-7366805671983604343, title='Florida International University pedestrian bridge collapse', question='who built pedestrian bridge at florida international university', passage='The main companies behind the construction project are Munilla Construction Management ( MCM ) , a Miami - based construction management firm , and FIGG Bridge Engineers , a Tallahassee - based firm . Unlike most bridges in Florida , the design for this project was overseen by the university itself , not the Florida Department of Transportation .', sentence_starts=[0, 201], selected_sent={'start': 0, 'end': 201, 'string': 'The main companies behind the construction project are Munilla Construction Management ( MCM ) , a Miami - based construction management firm , and FIGG Bridge Engineers , a Tallahassee - based firm . '}, answer=[Entity(start_offset=55, end_offset=198, type='context', text='Munilla Construction Management ( MCM ) , a Miami - based construction management firm , and FIGG Bridge Engineers , a Tallahassee - based firm', normalized_text='munilla construction management mcm miami based construction management firm and figg bridge engineers tallahassee based firm')], nq_answers=[[Entity(start_offset=55, end_offset=94, type='context', text='Munilla Construction Management ( MCM )', normalized_text='munilla construction management mcm'), Entity(start_offset=148, end_offset=169, type='context', text='FIGG Bridge Engineers', normalized_text='figg bridge engineers')], [Entity(start_offset=55, end_offset=141, type='context', text='Munilla Construction Management ( MCM ) , a Miami - based construction management firm', normalized_text='munilla construction management mcm miami based construction management firm'), Entity(start_offset=148, end_offset=198, type='context', text='FIGG Bridge Engineers , a Tallahassee - based firm', normalized_text='figg bridge engineers tallahassee based firm')]], aligned_nps=[(Entity(start_offset=10, end_offset=63, type='question', text='pedestrian bridge at florida international university', normalized_text='pedestrian bridge at florida international university'), Entity(start_offset=26, end_offset=50, type='context', text='the construction project', normalized_text='construction project'))], explanation_type='single_sentence'),\n",
       " 1281705529368409187: QEDExample(example_id=1281705529368409187, title=\"Heart and Soul (T'Pau song)\", question='band who had a hit with heart and soul crossword', passage=\"`` Heart and Soul '' is a song by British pop band T'Pau . Featuring vocalist Carol Decker performing overlapping lyrics , the song was released as the group 's first single in 1987 from their debut album Bridge of Spies . Following its inclusion in a Pepe Jeans advert , the single reached No. 4 in both the US and UK charts .\", sentence_starts=[0, 59, 223], selected_sent={'start': 0, 'end': 59, 'string': \"`` Heart and Soul '' is a song by British pop band T'Pau . \"}, answer=[Entity(start_offset=51, end_offset=56, type='context', text=\"T'Pau\", normalized_text='tpau')], nq_answers=[[Entity(start_offset=34, end_offset=56, type='context', text=\"British pop band T'Pau\", normalized_text='british pop band tpau')], [Entity(start_offset=51, end_offset=56, type='context', text=\"T'Pau\", normalized_text='tpau')]], aligned_nps=[(Entity(start_offset=24, end_offset=38, type='question', text='heart and soul', normalized_text='heart and soul'), Entity(start_offset=3, end_offset=17, type='context', text='Heart and Soul', normalized_text='heart and soul'))], explanation_type='single_sentence'),\n",
       " 7324393995968514241: QEDExample(example_id=7324393995968514241, title='De La Rosa', question='where does the name de la rosa come from', passage=\"De la Rosa is a Spanish surname , which means `` of the rose '' . It may refer to :\", sentence_starts=[0, 66], selected_sent={'start': 0, 'end': 66, 'string': \"De la Rosa is a Spanish surname , which means `` of the rose '' . \"}, answer=[Entity(start_offset=16, end_offset=23, type='context', text='Spanish', normalized_text='spanish')], nq_answers=[[Entity(start_offset=16, end_offset=23, type='context', text='Spanish', normalized_text='spanish')], [Entity(start_offset=14, end_offset=63, type='context', text=\"a Spanish surname , which means `` of the rose ''\", normalized_text='spanish surname which means of rose')]], aligned_nps=[(Entity(start_offset=11, end_offset=30, type='question', text='the name de la rosa', normalized_text='name de la rosa'), Entity(start_offset=0, end_offset=10, type='context', text='De la Rosa', normalized_text='de la rosa'))], explanation_type='single_sentence'),\n",
       " 1389300307230755697: QEDExample(example_id=1389300307230755697, title='I Knew the Bride', question='who sang i knew the bride when she used to rock and roll', passage=\"`` I Knew the Bride ( When She Used to Rock ' n ' Roll ) '' is a song written by Nick Lowe and first popularized by Dave Edmunds . It was released on Edmunds 's 1977 album Get It and a year later in a live version by Nick Lowe 's Last Chicken in the Shop on Live Stiffs Live .\", sentence_starts=[0, 131], selected_sent={'start': 0, 'end': 131, 'string': \"`` I Knew the Bride ( When She Used to Rock ' n ' Roll ) '' is a song written by Nick Lowe and first popularized by Dave Edmunds . \"}, answer=[Entity(start_offset=116, end_offset=128, type='context', text='Dave Edmunds', normalized_text='dave edmunds')], nq_answers=[[Entity(start_offset=116, end_offset=128, type='context', text='Dave Edmunds', normalized_text='dave edmunds')]], aligned_nps=[(Entity(start_offset=9, end_offset=56, type='question', text='i knew the bride when she used to rock and roll', normalized_text='i knew bride when she used to rock and roll'), Entity(start_offset=3, end_offset=54, type='context', text=\"I Knew the Bride ( When She Used to Rock ' n ' Roll\", normalized_text='i knew bride when she used to rock n roll'))], explanation_type='single_sentence'),\n",
       " 2320889729188644029: QEDExample(example_id=2320889729188644029, title='Wheel', question='when was the wheel introduced to north america', passage=\"Although large - scale use of wheels did not occur in the Americas prior to European contact , numerous small wheeled artifacts , identified as children 's toys , have been found in Mexican archeological sites , some dating to about 1500 BC . It is thought that the primary obstacle to large - scale development of the wheel in the Americas was the absence of domesticated large animals which could be used to pull wheeled carriages . The closest relative of cattle present in Americas in pre-Columbian times , the American Bison , is difficult to domesticate and was never domesticated by Native Americans ; several horse species existed until about 12,000 years ago , but ultimately became extinct . The only large animal that was domesticated in the Western hemisphere , the llama , did not spread far beyond the Andes by the time of the arrival of Columbus .\", sentence_starts=[0, 243, 435, 702], selected_sent={'start': 0, 'end': 243, 'string': \"Although large - scale use of wheels did not occur in the Americas prior to European contact , numerous small wheeled artifacts , identified as children 's toys , have been found in Mexican archeological sites , some dating to about 1500 BC . \"}, answer=[Entity(start_offset=227, end_offset=240, type='context', text='about 1500 BC', normalized_text='about 1500 bc')], nq_answers=[[Entity(start_offset=227, end_offset=240, type='context', text='about 1500 BC', normalized_text='about 1500 bc')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -2452563949551576138: QEDExample(example_id=-2452563949551576138, title='50 home run club', question='most home runs by 2 teammates in a season', passage='In total , 29 players have reached the 50 home run club in MLB history and nine have done so more than once . Of these , seventeen were right - handed batters , eleven were left - handed , and one was a switch hitter , meaning he could bat from either side of the plate . Four of these players ( including two active members of the 50 home run club ) have played for only one major league team . The New York Yankees are the only franchise to have five players reach the milestone while on their roster : Ruth , Mickey Mantle , Roger Maris , Alex Rodriguez , and Aaron Judge . Ten players are also members of the 500 home run club and two of them ( Willie Mays and Rodriguez ) are also members of the 3,000 hit club . Ten players won the Most Valuable Player ( MVP ) Award in the same year as their 50 home run season . Mantle is the only player to have earned the Major League Triple Crown alongside achieving 50 home runs , leading both leagues in batting average , home runs and runs batted in ( RBI ) . Mantle and Maris -- collectively known as the M&M Boys -- are the only teammates to reach the 50 home run club in the same season , hitting a combined 115 home runs in 1961 and breaking the single - season record for home runs by a pair of teammates . Albert Belle is the only player to amass 50 or more doubles in addition to attaining 50 home runs . Prince Fielder , at 23 years and 139 days , was the youngest player to reach the milestone while Bonds , at age 37 , was the oldest .', sentence_starts=[0, 110, 272, 396, 577, 718, 820, 1007, 1259, 1359], selected_sent={'start': 1007, 'end': 1259, 'string': 'Mantle and Maris -- collectively known as the M&M Boys -- are the only teammates to reach the 50 home run club in the same season , hitting a combined 115 home runs in 1961 and breaking the single - season record for home runs by a pair of teammates . '}, answer=[Entity(start_offset=1158, end_offset=1161, type='context', text='115', normalized_text='115')], nq_answers=[[Entity(start_offset=512, end_offset=525, type='context', text='Mickey Mantle', normalized_text='mickey mantle'), Entity(start_offset=528, end_offset=539, type='context', text='Roger Maris', normalized_text='roger maris')], [Entity(start_offset=1158, end_offset=1161, type='context', text='115', normalized_text='115')], [Entity(start_offset=1147, end_offset=1171, type='context', text='a combined 115 home runs', normalized_text='combined 115 home runs')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -1221510361770214831: QEDExample(example_id=-1221510361770214831, title='Jesse Williams (actor)', question=\"actor who plays dr avery on grey's anatomy\", passage=\"Jesse Wesley Williams ( born August 5 , 1981 ) is an American actor , director , teacher and activist , best known for his role as Dr. Jackson Avery on the ABC Television series Grey 's Anatomy . He also appeared in the 2013 film The Butler as civil rights leader Rev. James Lawson . His other roles have included Holden in The Cabin in the Woods ( 2012 ) ; Officer Eddie Quinlan in Brooklyn 's Finest ( 2009 ) ; and Leo in The Sisterhood of the Traveling Pants 2 ( 2008 ) .\", sentence_starts=[0, 196, 284], selected_sent={'start': 0, 'end': 196, 'string': \"Jesse Wesley Williams ( born August 5 , 1981 ) is an American actor , director , teacher and activist , best known for his role as Dr. Jackson Avery on the ABC Television series Grey 's Anatomy . \"}, answer=[Entity(start_offset=0, end_offset=21, type='context', text='Jesse Wesley Williams', normalized_text='jesse wesley williams')], nq_answers=[[Entity(start_offset=0, end_offset=21, type='context', text='Jesse Wesley Williams', normalized_text='jesse wesley williams')]], aligned_nps=[(Entity(start_offset=16, end_offset=24, type='question', text='dr avery', normalized_text='dr avery'), Entity(start_offset=131, end_offset=148, type='context', text='Dr. Jackson Avery', normalized_text='dr jackson avery')), (Entity(start_offset=28, end_offset=42, type='question', text=\"grey's anatomy\", normalized_text='greys anatomy'), Entity(start_offset=152, end_offset=193, type='context', text=\"the ABC Television series Grey 's Anatomy\", normalized_text='abc television series grey s anatomy'))], explanation_type='single_sentence'),\n",
       " -4944968641603604544: QEDExample(example_id=-4944968641603604544, title='Buffy the Vampire Slayer (film)', question='who played buffy the vampire slayer in the movie', passage=\"High school senior Buffy Summers ( Kristy Swanson ) is introduced as a stereotypical `` popular girl '' at Hemery High School in Los Angeles whose main concerns are shopping and spending time with her rich , snooty friends and her boyfriend , Jeffrey . While at school one day , she is approached by a man who calls himself Merrick ( Donald Sutherland ) . He informs her that she is The Slayer , or Chosen One , destined to kill vampires , and he is a Watcher whose duty it is to guide and train her . She initially rebukes his claims , but is convinced that he is right when he is able to describe a recurring dream of hers in detail . In addition , Buffy is exhibiting uncanny abilities not known to her , including heightened agility , senses , and endurance , yet she repeatedly tries Merrick 's patience with her frivolous nature , indifference to slaying and sharp - tongued remarks .\", sentence_starts=[0, 253, 356, 502, 637], selected_sent={'start': 0, 'end': 253, 'string': \"High school senior Buffy Summers ( Kristy Swanson ) is introduced as a stereotypical `` popular girl '' at Hemery High School in Los Angeles whose main concerns are shopping and spending time with her rich , snooty friends and her boyfriend , Jeffrey . \"}, answer=[Entity(start_offset=35, end_offset=49, type='context', text='Kristy Swanson', normalized_text='kristy swanson')], nq_answers=[[Entity(start_offset=35, end_offset=49, type='context', text='Kristy Swanson', normalized_text='kristy swanson')]], aligned_nps=[(Entity(start_offset=11, end_offset=35, type='question', text='buffy the vampire slayer', normalized_text='buffy vampire slayer'), Entity(start_offset=0, end_offset=51, type='context', text='High school senior Buffy Summers ( Kristy Swanson )', normalized_text='high school senior buffy summers kristy swanson')), (Entity(start_offset=39, end_offset=48, type='question', text='the movie', normalized_text='movie'), Entity(start_offset=55, end_offset=65, type='context', text='introduced', normalized_text='introduced'))], explanation_type='single_sentence'),\n",
       " -4639303836852821525: QEDExample(example_id=-4639303836852821525, title='The Great British Bake Off', question='who won season 2 of great british baking show', passage='The programme was originally presented by Sue Perkins and Mel Giedroyc , with Mary Berry and Paul Hollywood the judges . The current presenters are Noel Fielding and Sandi Toksvig with Hollywood and Prue Leith on the judging panel . In chronological order , the winners are Edd Kimber , Joanne Wheatley , John Whaite , Frances Quinn , Nancy Birtwhistle , Nadiya Hussain , Candice Brown and Sophie Faldo .', sentence_starts=[0, 121, 233], selected_sent={'start': 233, 'end': 404, 'string': 'In chronological order , the winners are Edd Kimber , Joanne Wheatley , John Whaite , Frances Quinn , Nancy Birtwhistle , Nadiya Hussain , Candice Brown and Sophie Faldo .'}, answer=[Entity(start_offset=287, end_offset=302, type='context', text='Joanne Wheatley', normalized_text='joanne wheatley')], nq_answers=[[Entity(start_offset=287, end_offset=302, type='context', text='Joanne Wheatley', normalized_text='joanne wheatley')]], aligned_nps=[(Entity(start_offset=20, end_offset=45, type='question', text='great british baking show', normalized_text='great british baking show'), Entity(start_offset=258, end_offset=269, type='context', text='the winners', normalized_text='winners'))], explanation_type='single_sentence'),\n",
       " 7798941921420035933: QEDExample(example_id=7798941921420035933, title='Julie Kavner', question=\"who does marge's voice on the simpsons\", passage=\"Julie Deborah Kavner ( born September 7 , 1950 ) is an American actress , voice actress and comedian . She first attracted notice for her role as Valerie Harper 's character 's younger sister Brenda in the sitcom Rhoda for which she won a Primetime Emmy Award for Outstanding Supporting Actress in a Comedy Series . She is best known for her voice role as Marge Simpson on the animated television series The Simpsons . She also voices other characters for the show , including Jacqueline Bouvier , and Patty and Selma Bouvier .\", sentence_starts=[0, 103, 316, 419], selected_sent={'start': 316, 'end': 419, 'string': 'She is best known for her voice role as Marge Simpson on the animated television series The Simpsons . '}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='Julie Deborah Kavner', normalized_text='julie deborah kavner')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='Julie Deborah Kavner', normalized_text='julie deborah kavner')]], aligned_nps=[(Entity(start_offset=9, end_offset=14, type='question', text='marge', normalized_text='marge'), Entity(start_offset=356, end_offset=369, type='context', text='Marge Simpson', normalized_text='marge simpson')), (Entity(start_offset=26, end_offset=38, type='question', text='the simpsons', normalized_text='simpsons'), Entity(start_offset=373, end_offset=416, type='context', text='the animated television series The Simpsons', normalized_text='animated television series simpsons'))], explanation_type='single_sentence'),\n",
       " 3661671296233148968: QEDExample(example_id=3661671296233148968, title='URL', question='what is the general structure of an url', passage='Most web browsers display the URL of a web page above the page in an address bar . A typical URL could have the form http://www.example.com/index.html , which indicates a protocol ( http ) , a hostname ( www.example.com ) , and a file name ( index. html ) .', sentence_starts=[0, 83], selected_sent={'start': 83, 'end': 257, 'string': 'A typical URL could have the form http://www.example.com/index.html , which indicates a protocol ( http ) , a hostname ( www.example.com ) , and a file name ( index. html ) .'}, answer=[Entity(start_offset=117, end_offset=255, type='context', text='http://www.example.com/index.html , which indicates a protocol ( http ) , a hostname ( www.example.com ) , and a file name ( index. html )', normalized_text='httpwwwexamplecomindexhtml which indicates protocol http hostname wwwexamplecom and file name index html')], nq_answers=[[Entity(start_offset=169, end_offset=179, type='context', text='a protocol', normalized_text='protocol'), Entity(start_offset=191, end_offset=201, type='context', text='a hostname', normalized_text='hostname'), Entity(start_offset=228, end_offset=239, type='context', text='a file name', normalized_text='file name')]], aligned_nps=[(Entity(start_offset=33, end_offset=39, type='question', text='an url', normalized_text='url'), Entity(start_offset=83, end_offset=96, type='context', text='A typical URL', normalized_text='typical url'))], explanation_type='single_sentence'),\n",
       " 2191432481376971337: QEDExample(example_id=2191432481376971337, title='Baltimore Colts relocation to Indianapolis', question='who owned the colts when they left baltimore', passage=\"The Baltimore Colts relocation to Indianapolis was a successful effort by the then - owner of the Baltimore Colts ( Robert Irsay ) to move the American football team from Baltimore , Maryland to Indianapolis , Indiana . The team began play as the Indianapolis Colts for the 1984 National Football League ( NFL ) season . The Colts ' move was completely unannounced and occurred in the early hours of March 29 , 1984 , after years of lobbying for a new stadium to replace the inadequate Memorial Stadium . The franchise 's move continues to embitter many Baltimore natives decades afterward , and would have a lasting impact on the NFL , including another controversial relocation twelve years later that resulted in Baltimore receiving its current NFL team , the Ravens .\", sentence_starts=[0, 220, 321, 505], selected_sent={'start': 0, 'end': 220, 'string': 'The Baltimore Colts relocation to Indianapolis was a successful effort by the then - owner of the Baltimore Colts ( Robert Irsay ) to move the American football team from Baltimore , Maryland to Indianapolis , Indiana . '}, answer=[Entity(start_offset=116, end_offset=128, type='context', text='Robert Irsay', normalized_text='robert irsay')], nq_answers=[[Entity(start_offset=116, end_offset=128, type='context', text='Robert Irsay', normalized_text='robert irsay')]], aligned_nps=[(Entity(start_offset=10, end_offset=19, type='question', text='the colts', normalized_text='colts'), Entity(start_offset=0, end_offset=19, type='context', text='The Baltimore Colts', normalized_text='baltimore colts'))], explanation_type='single_sentence'),\n",
       " 3921893340037155734: QEDExample(example_id=3921893340037155734, title='Harry Potter (film series)', question='when did the first movie of harry potter come out', passage=\"Harry Potter is a British - American film series based on the Harry Potter novels by author J.K. Rowling . The series is distributed by Warner Bros. and consists of eight fantasy films , beginning with Harry Potter and the Philosopher 's Stone ( 2001 ) and culminating with Harry Potter and the Deathly Hallows -- Part 2 ( 2011 ) . A spin - off prequel series will consist of five films , starting with Fantastic Beasts and Where to Find Them ( 2016 ) , marking the beginning of the Wizarding World shared media franchise .\", sentence_starts=[0, 97, 107, 332], selected_sent={'start': 107, 'end': 332, 'string': \"The series is distributed by Warner Bros. and consists of eight fantasy films , beginning with Harry Potter and the Philosopher 's Stone ( 2001 ) and culminating with Harry Potter and the Deathly Hallows -- Part 2 ( 2011 ) . \"}, answer=[Entity(start_offset=246, end_offset=250, type='context', text='2001', normalized_text='2001')], nq_answers=[[Entity(start_offset=246, end_offset=250, type='context', text='2001', normalized_text='2001')]], aligned_nps=[(Entity(start_offset=9, end_offset=40, type='question', text='the first movie of harry potter', normalized_text='first movie of harry potter'), Entity(start_offset=202, end_offset=252, type='context', text=\"Harry Potter and the Philosopher 's Stone ( 2001 )\", normalized_text='harry potter and philosopher s stone 2001'))], explanation_type='single_sentence'),\n",
       " -7796843053651293950: QEDExample(example_id=-7796843053651293950, title='Federal Communications Commission', question='the federal communications commission\\u200b (fcc) controls and\\u200b regulates', passage='The Federal Communications Commission ( FCC ) is an independent agency of the United States government created by statute ( 47 U.S.C. § 151 and 47 U.S.C. § 154 ) to regulate interstate communications by radio , television , wire , satellite , and cable . The FCC works towards six goals in the areas of broadband , competition , the spectrum , the media , public safety and homeland security , and modernizing itself .', sentence_starts=[0, 255], selected_sent={'start': 0, 'end': 255, 'string': 'The Federal Communications Commission ( FCC ) is an independent agency of the United States government created by statute ( 47 U.S.C. § 151 and 47 U.S.C. § 154 ) to regulate interstate communications by radio , television , wire , satellite , and cable . '}, answer=[Entity(start_offset=174, end_offset=252, type='context', text='interstate communications by radio , television , wire , satellite , and cable', normalized_text='interstate communications by radio television wire satellite and cable')], nq_answers=[[Entity(start_offset=174, end_offset=252, type='context', text='interstate communications by radio , television , wire , satellite , and cable', normalized_text='interstate communications by radio television wire satellite and cable')]], aligned_nps=[(Entity(start_offset=0, end_offset=44, type='question', text='the federal communications commission\\u200b (fcc)', normalized_text='federal communications commission\\u200b fcc'), Entity(start_offset=0, end_offset=45, type='context', text='The Federal Communications Commission ( FCC )', normalized_text='federal communications commission fcc'))], explanation_type='single_sentence'),\n",
       " 5679714123144678326: QEDExample(example_id=5679714123144678326, title='Brenda Walsh (character)', question='when do dylan and brenda get back together', passage=\"As a result , all Brenda 's friends apologized for their behavior towards her . During the fourth season , Brenda is interested in the drama department but it also led to problems : she spoiled her first audition and then went to the director of the play to try again and convince him . She then got the role , but a student made a rumor saying that she had slept to have the role . Unfortunately , this student was the girlfriend of Steve Sanders and the latter believed the rumors , others refusing more or less to believe the denials of Brenda . Steve understood his mistake when the student asked him to attack Brenda to make her miss rehearsals . A little later , Steve 's friend tried to commit suicide , but Brenda and Steve joined forces to save her and Steve was finally compensated by following Brenda 's debut on stage . The director 's praise led her to accept the latter at the Royal Academy of Dramatic Arts ( RADA ) in London for a year . After Kelly and Dylan last broke up , Brenda finally learned that a relationship was possible between Kelly and Brandon and expressed her blessing . She later spent her last night with Dylan , telling her she would not be gone forever . The couple will reconcile briefly in the final scene of the fourth season , though ( because of Shannen Doherty 's departure ) Brenda 's character was removed from the script and she never returned to Beverly Hills .\", sentence_starts=[0, 80, 287, 383, 549, 652, 832, 954, 1103, 1191], selected_sent={'start': 1191, 'end': 1407, 'string': \"The couple will reconcile briefly in the final scene of the fourth season , though ( because of Shannen Doherty 's departure ) Brenda 's character was removed from the script and she never returned to Beverly Hills .\"}, answer=[Entity(start_offset=1225, end_offset=1264, type='context', text='in the final scene of the fourth season', normalized_text='in final scene of fourth season')], nq_answers=[[Entity(start_offset=1228, end_offset=1264, type='context', text='the final scene of the fourth season', normalized_text='final scene of fourth season')]], aligned_nps=[(Entity(start_offset=8, end_offset=24, type='question', text='dylan and brenda', normalized_text='dylan and brenda'), Entity(start_offset=1191, end_offset=1201, type='context', text='The couple', normalized_text='couple'))], explanation_type='single_sentence'),\n",
       " -4450680238419666813: QEDExample(example_id=-4450680238419666813, title='Battle of Britain Memorial Flight', question='where is the battle of britain flight based', passage='The flight is administratively part of No. 1 Group RAF , flying out of RAF Coningsby in Lincolnshire .', sentence_starts=[0], selected_sent={'start': 0, 'end': 102, 'string': 'The flight is administratively part of No. 1 Group RAF , flying out of RAF Coningsby in Lincolnshire .'}, answer=[Entity(start_offset=71, end_offset=100, type='context', text='RAF Coningsby in Lincolnshire', normalized_text='raf coningsby in lincolnshire')], nq_answers=[[Entity(start_offset=71, end_offset=100, type='context', text='RAF Coningsby in Lincolnshire', normalized_text='raf coningsby in lincolnshire')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the battle of britain flight', normalized_text='battle of britain flight'), Entity(start_offset=0, end_offset=10, type='context', text='The flight', normalized_text='flight'))], explanation_type='single_sentence'),\n",
       " -3645082395283907461: QEDExample(example_id=-3645082395283907461, title='I Can Only Imagine (film)', question='when is i can only imagine coming out', passage='I Can Only Imagine was released in the United States on March 16 , 2018 . It has grossed $80 million worldwide against a production budget of $7 million , and is the third highest - grossing music biopic of all - time in the United States . Some critics praised it as inspiring and noted it as an improvement compared to other faith - based films , while others called it flat and by - the - numbers .', sentence_starts=[0, 74, 241], selected_sent={'start': 0, 'end': 74, 'string': 'I Can Only Imagine was released in the United States on March 16 , 2018 . '}, answer=[Entity(start_offset=56, end_offset=71, type='context', text='March 16 , 2018', normalized_text='march 16 2018')], nq_answers=[[Entity(start_offset=56, end_offset=71, type='context', text='March 16 , 2018', normalized_text='march 16 2018')]], aligned_nps=[(Entity(start_offset=8, end_offset=26, type='question', text='i can only imagine', normalized_text='i can only imagine'), Entity(start_offset=0, end_offset=18, type='context', text='I Can Only Imagine', normalized_text='i can only imagine'))], explanation_type='single_sentence'),\n",
       " -6458938316606245406: QEDExample(example_id=-6458938316606245406, title=\"Kansas Jayhawks men's basketball\", question='who has the most conference championships in college basketball', passage='In 2008 , ESPN ranked Kansas second on a list of the most prestigious programs of the modern college basketball era . Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 ) , the longest current streak of consecutive NCAA winning seasons ( 35 ) , the most winning seasons in Division I history ( 97 ) , the most non-losing seasons (. 500 or better ) in NCAA history ( 100 ) , the most conference championships in Division I history ( 61 ) , the most consecutive regular season conference titles in Division I ( 14 ) , the most First Team All Americans in Division I history ( 22 ) , and the most First Team All American Selections in Division I history ( 29 ) . As of the last complete season , the program ranks third in Division I all - time winning percentage (. 725 ) and second in Division I all - time wins ( 2,217 ) .', sentence_starts=[0, 118, 711], selected_sent={'start': 118, 'end': 711, 'string': 'Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 ) , the longest current streak of consecutive NCAA winning seasons ( 35 ) , the most winning seasons in Division I history ( 97 ) , the most non-losing seasons (. 500 or better ) in NCAA history ( 100 ) , the most conference championships in Division I history ( 61 ) , the most consecutive regular season conference titles in Division I ( 14 ) , the most First Team All Americans in Division I history ( 22 ) , and the most First Team All American Selections in Division I history ( 29 ) . '}, answer=[Entity(start_offset=118, end_offset=124, type='context', text='Kansas', normalized_text='kansas')], nq_answers=[[Entity(start_offset=22, end_offset=28, type='context', text='Kansas', normalized_text='kansas')], [Entity(start_offset=118, end_offset=124, type='context', text='Kansas', normalized_text='kansas')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 4220294884897994209: QEDExample(example_id=4220294884897994209, title='List of tallest buildings', question='which is the tallest building in the world 2018', passage=\"The international non-profit organization Council on Tall Buildings and Urban Habitat ( CTBUH ) was formed in 1969 and announces the title of `` The World 's Tallest Building '' and sets the standards by which buildings are measured . It maintains a list of the 100 tallest completed buildings in the world . The organization currently ranks Burj Khalifa in Dubai as the tallest at 828 m ( 2,717 ft ) . The CTBUH only recognizes buildings that are complete however , and some buildings included within the lists in this article are not considered finished by the CTBUH .\", sentence_starts=[0, 235, 309, 403], selected_sent={'start': 309, 'end': 403, 'string': 'The organization currently ranks Burj Khalifa in Dubai as the tallest at 828 m ( 2,717 ft ) . '}, answer=[Entity(start_offset=342, end_offset=354, type='context', text='Burj Khalifa', normalized_text='burj khalifa')], nq_answers=[[Entity(start_offset=342, end_offset=363, type='context', text='Burj Khalifa in Dubai', normalized_text='burj khalifa in dubai')]], aligned_nps=[(Entity(start_offset=9, end_offset=47, type='question', text='the tallest building in the world 2018', normalized_text='tallest building in world 2018'), Entity(start_offset=367, end_offset=378, type='context', text='the tallest', normalized_text='tallest'))], explanation_type='single_sentence'),\n",
       " 6366355994259775888: QEDExample(example_id=6366355994259775888, title='History of the New York Giants (baseball)', question='where did the new york giants baseball play', passage=\"The New York Giants were the New York City -- based incarnation of the present day San Francisco Giants prior to the team 's relocation to San Francisco in 1958 . The franchise was based in the New York metropolitan area from the team 's inception in 1883 through the 1957 season . During most of its seasons in New York , the Giants played home games in the Polo Grounds in the Upper Manhattan region of New York City .\", sentence_starts=[0, 163, 282], selected_sent={'start': 282, 'end': 420, 'string': 'During most of its seasons in New York , the Giants played home games in the Polo Grounds in the Upper Manhattan region of New York City .'}, answer=[Entity(start_offset=355, end_offset=418, type='context', text='the Polo Grounds in the Upper Manhattan region of New York City', normalized_text='polo grounds in upper manhattan region of new york city')], nq_answers=[[Entity(start_offset=352, end_offset=418, type='context', text='in the Polo Grounds in the Upper Manhattan region of New York City', normalized_text='in polo grounds in upper manhattan region of new york city')], [Entity(start_offset=355, end_offset=418, type='context', text='the Polo Grounds in the Upper Manhattan region of New York City', normalized_text='polo grounds in upper manhattan region of new york city')]], aligned_nps=[(Entity(start_offset=10, end_offset=29, type='question', text='the new york giants', normalized_text='new york giants'), Entity(start_offset=323, end_offset=333, type='context', text='the Giants', normalized_text='giants'))], explanation_type='single_sentence'),\n",
       " 6497460116946232542: QEDExample(example_id=6497460116946232542, title='Ecliptic', question=\"the plane of earth's orbit is called the\", passage=\"The ecliptic is the circular path on the celestial sphere that the Sun appears to follow over the course of a year ; it is the basis of the ecliptic coordinate system . The term also refers to the plane of this path , which is coplanar with Earth 's orbit around the Sun ( and hence the Sun 's apparent orbit around Earth ) . The ecliptic is not normally noticeable from Earth 's surface because Earth rotates , carrying the observer through the cycles of sunrise and sunset , which obscure the Sun 's apparent motion against the background of fixed stars .\", sentence_starts=[0, 169, 326], selected_sent={'start': 169, 'end': 326, 'string': \"The term also refers to the plane of this path , which is coplanar with Earth 's orbit around the Sun ( and hence the Sun 's apparent orbit around Earth ) . \"}, answer=[Entity(start_offset=4, end_offset=12, type='context', text='ecliptic', normalized_text='ecliptic')], nq_answers=[[Entity(start_offset=4, end_offset=12, type='context', text='ecliptic', normalized_text='ecliptic')]], aligned_nps=[(Entity(start_offset=0, end_offset=26, type='question', text=\"the plane of earth's orbit\", normalized_text='plane of earths orbit'), Entity(start_offset=193, end_offset=215, type='context', text='the plane of this path', normalized_text='plane of this path'))], explanation_type='single_sentence'),\n",
       " -8358994218007709832: QEDExample(example_id=-8358994218007709832, title='Brother (Needtobreathe song)', question='who sang the song brother let me be your shelter', passage=\"`` Brother '' is a song by American Christian rock band Needtobreathe . It was released as the fifth single from Rivers in the Wasteland on February 2 , 2015 . The official single version features Gavin DeGraw and was released to Hot AC radio on May 4 , 2015 . The song was written by Bear and Bo Rinehart , and produced by Dave Tozer , using elements of Ed Cash 's LP version . The song peaked at number 8 on Billboard Hot Rock Songs , number 1 on Billboard Hot Christian Songs , and number 98 on the Billboard Hot 100 , becoming the band 's first chart entry , and highest peak on the chart .\", sentence_starts=[0, 72, 160, 261, 379], selected_sent={'start': 0, 'end': 72, 'string': \"`` Brother '' is a song by American Christian rock band Needtobreathe . \"}, answer=[Entity(start_offset=56, end_offset=69, type='context', text='Needtobreathe', normalized_text='needtobreathe')], nq_answers=[[Entity(start_offset=27, end_offset=69, type='context', text='American Christian rock band Needtobreathe', normalized_text='american christian rock band needtobreathe')], [Entity(start_offset=56, end_offset=69, type='context', text='Needtobreathe', normalized_text='needtobreathe')]], aligned_nps=[(Entity(start_offset=9, end_offset=48, type='question', text='the song brother let me be your shelter', normalized_text='song brother let me be your shelter'), Entity(start_offset=3, end_offset=10, type='context', text='Brother', normalized_text='brother'))], explanation_type='single_sentence'),\n",
       " -3093951657047573607: QEDExample(example_id=-3093951657047573607, title='Iron ore mining in Western Australia', question='where does iron ore come from in australia', passage=\"Western Australia 's iron ore output for 2011 was 474 million tonnes , 97 % of Australian production . The bulk of Western Australian ore went to China , which imported 70 percent of 2010 production , followed by Japan with 19 % and South Korea with 10 % . The state has the world 's largest Economic Demonstrated Resources of iron ore with 22 % of the world 's iron ore followed by Brazil with 17 % , Russia with 15 % and China with 14 % .\", sentence_starts=[0, 103, 257], selected_sent={'start': 0, 'end': 103, 'string': \"Western Australia 's iron ore output for 2011 was 474 million tonnes , 97 % of Australian production . \"}, answer=[Entity(start_offset=0, end_offset=17, type='context', text='Western Australia', normalized_text='western australia')], nq_answers=[[Entity(start_offset=0, end_offset=17, type='context', text='Western Australia', normalized_text='western australia')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2387972819898409326: QEDExample(example_id=2387972819898409326, title='Wedding soup', question='what type of pasta goes in italian wedding soup', passage='Wedding soup consists of green vegetables ( usually endive and escarole or cabbage , lettuce , kale , and / or spinach ) and meat ( usually meatballs and / or sausage some times chicken containing Italian parsley and parmesan cheese ) in a clear chicken - based broth . Wedding soup sometimes contains pasta ( usually cavatelli , acini di pepe , pastina , orzo , etc . ) , lentils , or grated parmesan cheese .', sentence_starts=[0, 270], selected_sent={'start': 270, 'end': 410, 'string': 'Wedding soup sometimes contains pasta ( usually cavatelli , acini di pepe , pastina , orzo , etc . ) , lentils , or grated parmesan cheese .'}, answer=[Entity(start_offset=310, end_offset=368, type='context', text='usually cavatelli , acini di pepe , pastina , orzo , etc .', normalized_text='usually cavatelli acini di pepe pastina orzo etc')], nq_answers=[[Entity(start_offset=310, end_offset=368, type='context', text='usually cavatelli , acini di pepe , pastina , orzo , etc .', normalized_text='usually cavatelli acini di pepe pastina orzo etc')]], aligned_nps=[(Entity(start_offset=27, end_offset=47, type='question', text='italian wedding soup', normalized_text='italian wedding soup'), Entity(start_offset=270, end_offset=282, type='context', text='Wedding soup', normalized_text='wedding soup'))], explanation_type='single_sentence'),\n",
       " 175824256524792922: QEDExample(example_id=175824256524792922, title='Geraldine Somerville', question=\"who plays harry's mom in harry potter\", passage='Geraldine Margaret Agnew - Somerville ( born 19 May 1967 ) is an Irish born actress known for her role as Detective Sergeant Jane Penhaligon in Cracker ( 1993 -- 95 ) , for which she was nominated for the 1995 BAFTA TV Award for Best Actress , and for playing Lily Potter in the Harry Potter film series . Her other film appearances include Gosford Park ( 2001 ) , My Week with Marilyn ( 2011 ) and Grace of Monaco ( 2014 ) .', sentence_starts=[0, 306], selected_sent={'start': 0, 'end': 306, 'string': 'Geraldine Margaret Agnew - Somerville ( born 19 May 1967 ) is an Irish born actress known for her role as Detective Sergeant Jane Penhaligon in Cracker ( 1993 -- 95 ) , for which she was nominated for the 1995 BAFTA TV Award for Best Actress , and for playing Lily Potter in the Harry Potter film series . '}, answer=[Entity(start_offset=0, end_offset=37, type='context', text='Geraldine Margaret Agnew - Somerville', normalized_text='geraldine margaret agnew somerville')], nq_answers=[[Entity(start_offset=0, end_offset=37, type='context', text='Geraldine Margaret Agnew - Somerville', normalized_text='geraldine margaret agnew somerville')]], aligned_nps=[(Entity(start_offset=10, end_offset=21, type='question', text=\"harry's mom\", normalized_text='harrys mom'), Entity(start_offset=260, end_offset=271, type='context', text='Lily Potter', normalized_text='lily potter')), (Entity(start_offset=25, end_offset=37, type='question', text='harry potter', normalized_text='harry potter'), Entity(start_offset=275, end_offset=303, type='context', text='the Harry Potter film series', normalized_text='harry potter film series'))], explanation_type='single_sentence'),\n",
       " -8223571798173928629: QEDExample(example_id=-8223571798173928629, title=\"Girl, You'll Be a Woman Soon\", question=\"who sang you'll be a woman soon in pulp fiction\", passage=\"`` Girl , You 'll Be a Woman Soon '' is a song written by American musician Neil Diamond , whose recording of it on Bang Records reached number 10 on the US pop singles chart in 1967 . The song enjoyed a second life when it appeared on the 1994 Pulp Fiction soundtrack , performed by rock band Urge Overkill . Other versions have been recorded by Cliff Richard ( 1968 ) , Jackie Edwards ( 1968 ) , the Biddu Orchestra ( 1978 ) , and 16 Volt ( 1998 ) .\", sentence_starts=[0, 185, 310], selected_sent={'start': 185, 'end': 310, 'string': 'The song enjoyed a second life when it appeared on the 1994 Pulp Fiction soundtrack , performed by rock band Urge Overkill . '}, answer=[Entity(start_offset=294, end_offset=307, type='context', text='Urge Overkill', normalized_text='urge overkill')], nq_answers=[[Entity(start_offset=294, end_offset=307, type='context', text='Urge Overkill', normalized_text='urge overkill')], [Entity(start_offset=284, end_offset=307, type='context', text='rock band Urge Overkill', normalized_text='rock band urge overkill')]], aligned_nps=[(Entity(start_offset=9, end_offset=31, type='question', text=\"you'll be a woman soon\", normalized_text='youll be woman soon'), Entity(start_offset=185, end_offset=193, type='context', text='The song', normalized_text='song'))], explanation_type='single_sentence'),\n",
       " 6972056626325669866: QEDExample(example_id=6972056626325669866, title='Anant Chaturdashi', question='in the honour of which god is anant chaturdashi celebrated', passage='Anant Chaturdashi is the last day of the Hindu festival of Ganeshotsav . It is generally the 10th or 11th day after Ganesh Chaturthi . All the Ganesh deities brought into homes and communities are immersed in the sea or nearby lakes and rivers . On this day , people travel to waterfronts with the idols dancing and singing in large processions . Lord Ganesha is departed , only to be welcomed the next year with equal excitement .', sentence_starts=[0, 73, 135, 246, 347], selected_sent={'start': 135, 'end': 246, 'string': 'All the Ganesh deities brought into homes and communities are immersed in the sea or nearby lakes and rivers . '}, answer=[Entity(start_offset=143, end_offset=149, type='context', text='Ganesh', normalized_text='ganesh')], nq_answers=[[Entity(start_offset=143, end_offset=149, type='context', text='Ganesh', normalized_text='ganesh')]], aligned_nps=[(Entity(start_offset=30, end_offset=47, type='question', text='anant chaturdashi', normalized_text='anant chaturdashi'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 41048767348738867: QEDExample(example_id=41048767348738867, title='Sound film', question='when did audio video and the film industry begin', passage=\"The primary steps in the commercialization of sound cinema were taken in the mid - to late 1920s . At first , the sound films which included synchronized dialogue , known as `` talking pictures '' , or `` talkies '' , were exclusively shorts . The earliest feature - length movies with recorded sound included only music and effects . The first feature film originally presented as a talkie was The Jazz Singer , released in October 1927 . A major hit , it was made with Vitaphone , which was at the time the leading brand of sound - on - disc technology . Sound - on - film , however , would soon become the standard for talking pictures .\", sentence_starts=[0, 99, 244, 335, 440, 557], selected_sent={'start': 0, 'end': 99, 'string': 'The primary steps in the commercialization of sound cinema were taken in the mid - to late 1920s . '}, answer=[Entity(start_offset=73, end_offset=96, type='context', text='the mid - to late 1920s', normalized_text='mid to late 1920s')], nq_answers=[[Entity(start_offset=70, end_offset=96, type='context', text='in the mid - to late 1920s', normalized_text='in mid to late 1920s')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2541316470469570888: QEDExample(example_id=2541316470469570888, title='Sentence clause structure', question='what kind of sentence contains an independent clause and a dependent clause', passage='A simple sentence consists of only one clause . A compound sentence consists of two or more independent clauses . A complex sentence has at least one independent clause plus at least one dependent clause . A set of words with no independent clause may be an incomplete sentence , also called a sentence fragment .', sentence_starts=[0, 48, 114, 206], selected_sent={'start': 114, 'end': 206, 'string': 'A complex sentence has at least one independent clause plus at least one dependent clause . '}, answer=[Entity(start_offset=114, end_offset=132, type='context', text='A complex sentence', normalized_text='complex sentence')], nq_answers=[[Entity(start_offset=114, end_offset=132, type='context', text='A complex sentence', normalized_text='complex sentence')], [Entity(start_offset=116, end_offset=132, type='context', text='complex sentence', normalized_text='complex sentence')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 3239205946903665891: QEDExample(example_id=3239205946903665891, title='The Wealth of Nations', question='what was the book wealth of nations about', passage=\"An Inquiry into the Nature and Causes of the Wealth of Nations , generally referred to by its shortened title The Wealth of Nations , is the magnum opus of the Scottish economist and moral philosopher Adam Smith . First published in 1776 , the book offers one of the world 's first collected descriptions of what builds nations ' wealth , and is today a fundamental work in classical economics . By reflecting upon the economics at the beginning of the Industrial Revolution , the book touches upon such broad topics as the division of labour , productivity , and free markets .\", sentence_starts=[0, 214, 396], selected_sent={'start': 214, 'end': 396, 'string': \"First published in 1776 , the book offers one of the world 's first collected descriptions of what builds nations ' wealth , and is today a fundamental work in classical economics . \"}, answer=[Entity(start_offset=308, end_offset=336, type='context', text=\"what builds nations ' wealth\", normalized_text='what builds nations wealth')], nq_answers=[[Entity(start_offset=308, end_offset=336, type='context', text=\"what builds nations ' wealth\", normalized_text='what builds nations wealth')]], aligned_nps=[(Entity(start_offset=9, end_offset=35, type='question', text='the book wealth of nations', normalized_text='book wealth of nations'), Entity(start_offset=240, end_offset=248, type='context', text='the book', normalized_text='book'))], explanation_type='single_sentence'),\n",
       " 7211011040021040393: QEDExample(example_id=7211011040021040393, title='Book of Life', question='who is written in the book of life', passage='In Christianity and Judaism , the Book of Life ( Hebrew : ספר החיים , transliterated Sefer HaChaim ; Greek : βιβλίον τῆς ζωῆς Biblíon tēs Zōēs ) is the book in which God records the names of every person who is destined for Heaven or the World to Come . According to the Talmud it is open on Rosh Hashanah , as is its analog for the wicked , the Book of the Dead . For this reason extra mention is made for the Book of Life during Amidah recitations during the Days of Awe , the ten days between Rosh Hashanah , the Jewish new year , and Yom Kippur , the day of atonement ( the two High Holidays , particularly in the prayer Unetaneh Tokef ) .', sentence_starts=[0, 254, 365], selected_sent={'start': 0, 'end': 254, 'string': 'In Christianity and Judaism , the Book of Life ( Hebrew : ספר החיים , transliterated Sefer HaChaim ; Greek : βιβλίον τῆς ζωῆς Biblíon tēs Zōēs ) is the book in which God records the names of every person who is destined for Heaven or the World to Come . '}, answer=[Entity(start_offset=191, end_offset=251, type='context', text='every person who is destined for Heaven or the World to Come', normalized_text='every person who is destined for heaven or world to come')], nq_answers=[[Entity(start_offset=191, end_offset=251, type='context', text='every person who is destined for Heaven or the World to Come', normalized_text='every person who is destined for heaven or world to come')]], aligned_nps=[(Entity(start_offset=18, end_offset=34, type='question', text='the book of life', normalized_text='book of life'), Entity(start_offset=30, end_offset=144, type='context', text='the Book of Life ( Hebrew : ספר החיים , transliterated Sefer HaChaim ; Greek : βιβλίον τῆς ζωῆς Biblíon tēs Zōēs )', normalized_text='book of life hebrew ספר החיים transliterated sefer hachaim greek βιβλίον τῆς ζωῆς biblíon tēs zōēs'))], explanation_type='single_sentence'),\n",
       " -1204722541964024977: QEDExample(example_id=-1204722541964024977, title='Australia', question=\"what is australia's location in the world and region\", passage=\"Australia ( / əˈstreɪliə / ( listen ) , / ɒ - / ) , officially the Commonwealth of Australia , is a sovereign country comprising the mainland of the Australian continent , the island of Tasmania and numerous smaller islands . It is the largest country in Oceania and the world 's sixth - largest country by total area . The neighbouring countries are Papua New Guinea , Indonesia and East Timor to the north ; the Solomon Islands and Vanuatu to the north - east ; and New Zealand to the south - east . Australia 's capital is Canberra , and its largest urban area is Sydney .\", sentence_starts=[0, 226, 320, 502], selected_sent={'start': 226, 'end': 320, 'string': \"It is the largest country in Oceania and the world 's sixth - largest country by total area . \"}, answer=[Entity(start_offset=255, end_offset=262, type='context', text='Oceania', normalized_text='oceania')], nq_answers=[[Entity(start_offset=255, end_offset=262, type='context', text='Oceania', normalized_text='oceania')]], aligned_nps=[(Entity(start_offset=8, end_offset=17, type='question', text='australia', normalized_text='australia'), Entity(start_offset=226, end_offset=228, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -5631283176059213935: QEDExample(example_id=-5631283176059213935, title=\"The Joker's Wild\", question='who was the original host of jokers wild', passage='Jack Barry , who created the show and eventually used it to revive his partnership with longtime producer Dan Enright , hosted all versions of the show up until his death in May 1984 .', sentence_starts=[0], selected_sent={'start': 0, 'end': 184, 'string': 'Jack Barry , who created the show and eventually used it to revive his partnership with longtime producer Dan Enright , hosted all versions of the show up until his death in May 1984 .'}, answer=[Entity(start_offset=0, end_offset=10, type='context', text='Jack Barry', normalized_text='jack barry')], nq_answers=[[Entity(start_offset=0, end_offset=10, type='context', text='Jack Barry', normalized_text='jack barry')]], aligned_nps=[(Entity(start_offset=29, end_offset=40, type='question', text='jokers wild', normalized_text='jokers wild'), Entity(start_offset=143, end_offset=151, type='context', text='the show', normalized_text='show'))], explanation_type='single_sentence'),\n",
       " 5864829737616734737: QEDExample(example_id=5864829737616734737, title='Deep-cycle battery', question='difference between deep cycle and starting marine battery', passage='Deep - cycle lead - acid batteries generally fall into two distinct categories ; flooded ( FLA ) and valve - regulated lead - acid ( VRLA ) , with the VRLA type further subdivided into two types , Absorbed Glass Mat ( AGM ) and Gel . The reinforcement of absorbed glass mat separators helps to reduce damage caused by spilling and jolting vibrations . Further , flooded deep - cycle batteries can be divided into subcategories of Tubular - plated Opzs or flat plated . The difference generally affects the cycle life and performance of the cell . The structural difference between deep - cycle batteries and cranking batteries is in the lead battery plates . Deep cycle battery plates have thicker active plates , with higher - density active paste material and thicker separators . Alloys used for the plates in a deep cycle battery may contain more antimony than that of starting batteries . The thicker battery plates resist corrosion through extended charge and discharge cycles .', sentence_starts=[0, 234, 352, 469, 547, 659, 783, 894], selected_sent={'start': 783, 'end': 894, 'string': 'Alloys used for the plates in a deep cycle battery may contain more antimony than that of starting batteries . '}, answer=[Entity(start_offset=783, end_offset=859, type='context', text='Alloys used for the plates in a deep cycle battery may contain more antimony', normalized_text='alloys used for plates in deep cycle battery may contain more antimony')], nq_answers=[[Entity(start_offset=783, end_offset=891, type='context', text='Alloys used for the plates in a deep cycle battery may contain more antimony than that of starting batteries', normalized_text='alloys used for plates in deep cycle battery may contain more antimony than that of starting batteries')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -718217992489656032: QEDExample(example_id=-718217992489656032, title='Computer security', question='five tools of security management to overcome computer crime', passage=\"Andersson and Reimers ( 2014 ) found that employees often do not see themselves as part of the organization Information Security `` effort '' and often take actions that ignore organizational Information Security best interests . Research shows Information security culture needs to be improved continuously . In '' Information Security Culture from Analysis to Change '' , authors commented , '' It ′ sa never ending process , a cycle of evaluation and change or maintenance . '' To manage the information security culture , five steps should be taken : Pre-evaluation , strategic planning , operative planning , implementation , and post-evaluation .\", sentence_starts=[0, 230, 310, 481], selected_sent={'start': 481, 'end': 652, 'string': 'To manage the information security culture , five steps should be taken : Pre-evaluation , strategic planning , operative planning , implementation , and post-evaluation .'}, answer=[Entity(start_offset=555, end_offset=650, type='context', text='Pre-evaluation , strategic planning , operative planning , implementation , and post-evaluation', normalized_text='preevaluation strategic planning operative planning implementation and postevaluation')], nq_answers=[[Entity(start_offset=555, end_offset=569, type='context', text='Pre-evaluation', normalized_text='preevaluation'), Entity(start_offset=572, end_offset=590, type='context', text='strategic planning', normalized_text='strategic planning'), Entity(start_offset=593, end_offset=611, type='context', text='operative planning', normalized_text='operative planning'), Entity(start_offset=614, end_offset=628, type='context', text='implementation', normalized_text='implementation'), Entity(start_offset=635, end_offset=650, type='context', text='post-evaluation', normalized_text='postevaluation')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -5551039786517755042: QEDExample(example_id=-5551039786517755042, title=\"There's a Hole in My Bucket\", question=\"who sings there's a hole in my bucket\", passage=\"`` There 's a Hole in My Bucket '' ( or `` ... in the Bucket '' ) is a children 's song , based on a dialogue between two characters , called Henry and Liza , about a leaky bucket . The song describes a deadlock situation : Henry has a leaky bucket , and Liza tells him to repair it . To fix the leaky bucket , he needs straw . To cut the straw , he needs an axe . To sharpen the axe , he needs to wet the sharpening stone . To wet the stone , he needs water . But to fetch water , he needs the bucket , which has a hole in it .\", sentence_starts=[0, 182, 285, 328, 365, 425, 461], selected_sent={'start': 0, 'end': 182, 'string': \"`` There 's a Hole in My Bucket '' ( or `` ... in the Bucket '' ) is a children 's song , based on a dialogue between two characters , called Henry and Liza , about a leaky bucket . \"}, answer=[Entity(start_offset=118, end_offset=156, type='context', text='two characters , called Henry and Liza', normalized_text='two characters called henry and liza')], nq_answers=[[Entity(start_offset=118, end_offset=156, type='context', text='two characters , called Henry and Liza', normalized_text='two characters called henry and liza')]], aligned_nps=[(Entity(start_offset=10, end_offset=37, type='question', text=\"there's a hole in my bucket\", normalized_text='theres hole in my bucket'), Entity(start_offset=0, end_offset=65, type='context', text=\"`` There 's a Hole in My Bucket '' ( or `` ... in the Bucket '' )\", normalized_text='there s hole in my bucket or in bucket'))], explanation_type='single_sentence'),\n",
       " 5584540254904933863: QEDExample(example_id=5584540254904933863, title=\"What Are We Doin' in Love\", question='who sang what are we doing in love', passage=\"`` What Are We Doin ' in Love '' is a song written by Randy Goodrum and recorded by American country music artist Dottie West with the uncredited vocals of Kenny Rogers . It was released in March 1981 as the second single from the album Wild West . `` What Are We Doin ' in Love '' was the duo 's third and final number one on the country chart .\", sentence_starts=[0, 171, 249], selected_sent={'start': 0, 'end': 171, 'string': \"`` What Are We Doin ' in Love '' is a song written by Randy Goodrum and recorded by American country music artist Dottie West with the uncredited vocals of Kenny Rogers . \"}, answer=[Entity(start_offset=114, end_offset=168, type='context', text='Dottie West with the uncredited vocals of Kenny Rogers', normalized_text='dottie west with uncredited vocals of kenny rogers')], nq_answers=[[Entity(start_offset=84, end_offset=168, type='context', text='American country music artist Dottie West with the uncredited vocals of Kenny Rogers', normalized_text='american country music artist dottie west with uncredited vocals of kenny rogers')], [Entity(start_offset=114, end_offset=168, type='context', text='Dottie West with the uncredited vocals of Kenny Rogers', normalized_text='dottie west with uncredited vocals of kenny rogers')], [Entity(start_offset=84, end_offset=125, type='context', text='American country music artist Dottie West', normalized_text='american country music artist dottie west'), Entity(start_offset=156, end_offset=168, type='context', text='Kenny Rogers', normalized_text='kenny rogers')], [Entity(start_offset=114, end_offset=125, type='context', text='Dottie West', normalized_text='dottie west'), Entity(start_offset=156, end_offset=168, type='context', text='Kenny Rogers', normalized_text='kenny rogers')]], aligned_nps=[(Entity(start_offset=9, end_offset=34, type='question', text='what are we doing in love', normalized_text='what are we doing in love'), Entity(start_offset=3, end_offset=29, type='context', text=\"What Are We Doin ' in Love\", normalized_text='what are we doin in love'))], explanation_type='single_sentence'),\n",
       " 97369777493072047: QEDExample(example_id=97369777493072047, title='Toddler', question='at what age are you no longer a toddler', passage=\"A toddler is a child 12 to 36 months old . The toddler years are a time of great cognitive , emotional and social development . The word is derived from `` to toddle '' , which means to walk unsteadily , like a child of this age .\", sentence_starts=[0, 43, 128], selected_sent={'start': 0, 'end': 43, 'string': 'A toddler is a child 12 to 36 months old . '}, answer=[Entity(start_offset=27, end_offset=36, type='context', text='36 months', normalized_text='36 months')], nq_answers=[[Entity(start_offset=27, end_offset=36, type='context', text='36 months', normalized_text='36 months')]], aligned_nps=[(Entity(start_offset=30, end_offset=39, type='question', text='a toddler', normalized_text='toddler'), Entity(start_offset=0, end_offset=9, type='context', text='A toddler', normalized_text='toddler'))], explanation_type='single_sentence'),\n",
       " 3537093784371401720: QEDExample(example_id=3537093784371401720, title='Ordeal by Innocence (TV series)', question='how many episodes are there in ordeal by innocence', passage='Ordeal by Innocence is a three part BBC drama that was first broadcast during April 2018 . It is based on the Agatha Christie novel of the same name and is the third English language filmed version to be broadcast . The drama stars Bill Nighy , Anna Chancellor , Alice Eve and Eleanor Tomlinson amongst others .', sentence_starts=[0, 91, 216], selected_sent={'start': 0, 'end': 91, 'string': 'Ordeal by Innocence is a three part BBC drama that was first broadcast during April 2018 . '}, answer=[Entity(start_offset=25, end_offset=30, type='context', text='three', normalized_text='three')], nq_answers=[[Entity(start_offset=25, end_offset=30, type='context', text='three', normalized_text='three')], [Entity(start_offset=25, end_offset=35, type='context', text='three part', normalized_text='three part')]], aligned_nps=[(Entity(start_offset=31, end_offset=50, type='question', text='ordeal by innocence', normalized_text='ordeal by innocence'), Entity(start_offset=0, end_offset=19, type='context', text='Ordeal by Innocence', normalized_text='ordeal by innocence'))], explanation_type='single_sentence'),\n",
       " -6982991192528081677: QEDExample(example_id=-6982991192528081677, title='Costume party', question='what does fancy dress mean in the uk', passage='A costume party ( American English ) or a fancy dress party ( British English ) is a type of party , common mainly in contemporary Western culture , where guests dress up in costumes . Costumed Halloween parties are popular in the United States , Canada , Australia , and New Zealand .', sentence_starts=[0, 185], selected_sent={'start': 0, 'end': 185, 'string': 'A costume party ( American English ) or a fancy dress party ( British English ) is a type of party , common mainly in contemporary Western culture , where guests dress up in costumes . '}, answer=[Entity(start_offset=155, end_offset=182, type='context', text='guests dress up in costumes', normalized_text='guests dress up in costumes')], nq_answers=[[Entity(start_offset=0, end_offset=9, type='context', text='A costume', normalized_text='costume')], [Entity(start_offset=83, end_offset=182, type='context', text='a type of party , common mainly in contemporary Western culture , where guests dress up in costumes', normalized_text='type of party common mainly in contemporary western culture where guests dress up in costumes')], [Entity(start_offset=155, end_offset=182, type='context', text='guests dress up in costumes', normalized_text='guests dress up in costumes')], [Entity(start_offset=174, end_offset=182, type='context', text='costumes', normalized_text='costumes')]], aligned_nps=[(Entity(start_offset=10, end_offset=21, type='question', text='fancy dress', normalized_text='fancy dress'), Entity(start_offset=42, end_offset=53, type='context', text='fancy dress', normalized_text='fancy dress'))], explanation_type='single_sentence'),\n",
       " -8907983336222744574: QEDExample(example_id=-8907983336222744574, title='Intermaxillary segment', question='the intermaxillary segment formed by the fusion of the', passage=\"The intermaxillary segment in an embryo is a mass of tissue formed by the merging of tissues in the vicinity of the nose . It is essential for human survival . It is primordial , since in the further development of the embryo this particular mass no longer appears , but parts of it remain in `` the intermaxillary portion of the upper jaw , the portion of the upper lip , and the primary palate '' .\", sentence_starts=[0, 123, 160], selected_sent={'start': 0, 'end': 123, 'string': 'The intermaxillary segment in an embryo is a mass of tissue formed by the merging of tissues in the vicinity of the nose . '}, answer=[Entity(start_offset=85, end_offset=120, type='context', text='tissues in the vicinity of the nose', normalized_text='tissues in vicinity of nose')], nq_answers=[[Entity(start_offset=85, end_offset=120, type='context', text='tissues in the vicinity of the nose', normalized_text='tissues in vicinity of nose')]], aligned_nps=[(Entity(start_offset=0, end_offset=26, type='question', text='the intermaxillary segment', normalized_text='intermaxillary segment'), Entity(start_offset=0, end_offset=26, type='context', text='The intermaxillary segment', normalized_text='intermaxillary segment'))], explanation_type='single_sentence'),\n",
       " -6751220433242447969: QEDExample(example_id=-6751220433242447969, title='The Bastard Executioner', question='how many seasons of the bastard executioner are there', passage='The Bastard Executioner is an American historical fiction drama television series , created by Kurt Sutter and aired on FX from September 15 , 2015 , to November 17 , 2015 . On November 18 , 2015 , Sutter announced that FX had cancelled the series after one season .', sentence_starts=[0, 174], selected_sent={'start': 174, 'end': 266, 'string': 'On November 18 , 2015 , Sutter announced that FX had cancelled the series after one season .'}, answer=[Entity(start_offset=254, end_offset=257, type='context', text='one', normalized_text='one')], nq_answers=[[Entity(start_offset=254, end_offset=257, type='context', text='one', normalized_text='one')], [Entity(start_offset=254, end_offset=264, type='context', text='one season', normalized_text='one season')]], aligned_nps=[(Entity(start_offset=20, end_offset=43, type='question', text='the bastard executioner', normalized_text='bastard executioner'), Entity(start_offset=237, end_offset=247, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " -7607921794902030568: QEDExample(example_id=-7607921794902030568, title='Jean Valjean', question='why did jean valjean take care of cosette', passage=\"A short chapter , mainly consisting of two newspaper articles , informs the reader , that Jean Valjean has been re-arrested while getting into the stagecoach to Montfermeil ( on his way to get Fantine 's eight - year - old daughter , Cosette , whom he had promised to rescue ) . In July 1823 , he was condemned to death for the 40 - sous theft and the escape from the jail in Montreuil - sur - Mer , as the prosecutor claims that Valjean was part of a gang of street robbers and the latter refuses to defend himself . His sentence was graciously reduced by the king to only life in prison instead of death . Before he was captured , Jean Valjean had already traveled near to Montfermeil and buried all the money he 'd saved as M. Madeleine -- a chapter tells of a worker in Montfermeil , a former Toulon convict , who claims having seen , according to a local fairy tale , the devil burying his treasure in the forest . No further explanation is ever given as to why , having buried his money near Montfermeil , Valjean had traveled back to Paris and then attempted to travel back to Montfermeil .\", sentence_starts=[0, 279, 518, 608, 920], selected_sent={'start': 0, 'end': 279, 'string': \"A short chapter , mainly consisting of two newspaper articles , informs the reader , that Jean Valjean has been re-arrested while getting into the stagecoach to Montfermeil ( on his way to get Fantine 's eight - year - old daughter , Cosette , whom he had promised to rescue ) . \"}, answer=[Entity(start_offset=249, end_offset=264, type='context', text='he had promised', normalized_text='he had promised')], nq_answers=[[Entity(start_offset=249, end_offset=264, type='context', text='he had promised', normalized_text='he had promised')]], aligned_nps=[(Entity(start_offset=8, end_offset=20, type='question', text='jean valjean', normalized_text='jean valjean'), Entity(start_offset=90, end_offset=102, type='context', text='Jean Valjean', normalized_text='jean valjean')), (Entity(start_offset=34, end_offset=41, type='question', text='cosette', normalized_text='cosette'), Entity(start_offset=193, end_offset=241, type='context', text=\"Fantine 's eight - year - old daughter , Cosette\", normalized_text='fantine s eight year old daughter cosette'))], explanation_type='single_sentence'),\n",
       " 5518515944351776633: QEDExample(example_id=5518515944351776633, title='Bantu Education Act, 1953', question='what was the purpose of the bantu education act', passage=\"The Bantu Education Act , 1953 ( Act No. 47 of 1953 ; later renamed the Black Education Act , 1953 ) was a South African segregation law which legalised several aspects of the apartheid system . Its major provision was enforcing racially separated educational facilities . Even universities were made `` tribal '' , and all but three missionary schools chose to close down when the government no longer would help support their schools . Very few authorities continued using their own finances to support education for native Africans . In 1959 , this type of education was extended to `` non white '' universities and colleges with the Extension of University Education Act , and the internationally prestigious University College of Fort Hare was taken over by the government and degraded to being part of the Bantu education system . It is often argued that the policy of Bantu ( African ) education was aimed to direct black or non-white youth to the unskilled labour market , although Hendrik Verwoerd , at the time Minister of Native Affairs , claimed that the aim was to solve South Africa 's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups .\", sentence_starts=[0, 195, 273, 438, 537, 837], selected_sent={'start': 0, 'end': 195, 'string': 'The Bantu Education Act , 1953 ( Act No. 47 of 1953 ; later renamed the Black Education Act , 1953 ) was a South African segregation law which legalised several aspects of the apartheid system . '}, answer=[Entity(start_offset=143, end_offset=192, type='context', text='legalised several aspects of the apartheid system', normalized_text='legalised several aspects of apartheid system')], nq_answers=[[Entity(start_offset=143, end_offset=192, type='context', text='legalised several aspects of the apartheid system', normalized_text='legalised several aspects of apartheid system')], [Entity(start_offset=219, end_offset=270, type='context', text='enforcing racially separated educational facilities', normalized_text='enforcing racially separated educational facilities')]], aligned_nps=[(Entity(start_offset=24, end_offset=47, type='question', text='the bantu education act', normalized_text='bantu education act'), Entity(start_offset=0, end_offset=100, type='context', text='The Bantu Education Act , 1953 ( Act No. 47 of 1953 ; later renamed the Black Education Act , 1953 )', normalized_text='bantu education act 1953 act no 47 of 1953 later renamed black education act 1953'))], explanation_type='single_sentence'),\n",
       " -6527462410412242988: QEDExample(example_id=-6527462410412242988, title='Martian polar ice caps', question='what is the snow on mars made of', passage=\"The planet Mars has two permanent polar ice caps . During a pole 's winter , it lies in continuous darkness , chilling the surface and causing the deposition of 25 -- 30 % of the atmosphere into slabs of CO ice ( dry ice ) . When the poles are again exposed to sunlight , the frozen CO sublimes , creating enormous winds that sweep off the poles as fast as 400 km / h . These seasonal actions transport large amounts of dust and water vapor , giving rise to Earth - like frost and large cirrus clouds . Clouds of water - ice were photographed by the Opportunity rover in 2004 .\", sentence_starts=[0, 51, 225, 370, 503], selected_sent={'start': 51, 'end': 225, 'string': \"During a pole 's winter , it lies in continuous darkness , chilling the surface and causing the deposition of 25 -- 30 % of the atmosphere into slabs of CO ice ( dry ice ) . \"}, answer=[Entity(start_offset=204, end_offset=206, type='context', text='CO', normalized_text='co')], nq_answers=[[Entity(start_offset=204, end_offset=222, type='context', text='CO ice ( dry ice )', normalized_text='co ice dry ice')]], aligned_nps=[(Entity(start_offset=20, end_offset=24, type='question', text='mars', normalized_text='mars'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2155345050664800035: QEDExample(example_id=-2155345050664800035, title='Elena Gilbert', question='when does elena turn into a vampire in the tv series', passage=\"Much of Elena 's story revolves around her relationships with vampires Stefan Salvatore and his older brother , Damon . It is revealed that Elena is a Petrova Doppelgänger , which is thus responsible for her being identical to her ancestor , Katherine Pierce ( née Katerina Petrova ) . This also has the implication of making her a supernatural creature . Dobrev portrayed the `` conniving '' Katherine as well , who is opposite of Elena . The actress stated that it has been a challenge distinguishing the two , and enjoys playing them both . In the television series 's fourth season , Elena becomes a vampire and deals with the struggles that come with her change . She took the cure and became human again towards the end of the sixth season . In the finale of the sixth season , Kai linked Elena to Bonnie 's life by magic . Elena will only wake up when Bonnie dies in around 60 years . She was locked inside the Salvatore tomb , which was changed in the seventh season , and was relocated in Brooklyn , New York . In late 2016 , when it was announced that the eighth season would be the final season , Dobrev was in talks about returning to the television series to reprise her role in the final episode . After much speculation . Dobrev 's return was confirmed on January 26 , 2017 , via an Instagram post . Dobrev appeared in the final episode of the show as both Elena and her evil doppelgänger Katherine Pierce .\", sentence_starts=[0, 120, 286, 356, 440, 544, 669, 748, 830, 892, 1020, 1212, 1237, 1315], selected_sent={'start': 544, 'end': 669, 'string': \"In the television series 's fourth season , Elena becomes a vampire and deals with the struggles that come with her change . \"}, answer=[Entity(start_offset=547, end_offset=585, type='context', text=\"the television series 's fourth season\", normalized_text='television series s fourth season')], nq_answers=[[Entity(start_offset=544, end_offset=585, type='context', text=\"In the television series 's fourth season\", normalized_text='in television series s fourth season')], [Entity(start_offset=572, end_offset=585, type='context', text='fourth season', normalized_text='fourth season')]], aligned_nps=[(Entity(start_offset=39, end_offset=52, type='question', text='the tv series', normalized_text='tv series'), Entity(start_offset=547, end_offset=568, type='context', text='the television series', normalized_text='television series')), (Entity(start_offset=10, end_offset=15, type='question', text='elena', normalized_text='elena'), Entity(start_offset=588, end_offset=593, type='context', text='Elena', normalized_text='elena'))], explanation_type='single_sentence'),\n",
       " -816889472900831237: QEDExample(example_id=-816889472900831237, title='Howard University', question='what part of dc is howard university in', passage=\"The 256 - acre ( 1.04 km ; 0.400 sq mi ) campus often referred to as `` The Mecca '' is located in northwest Washington . Major improvements , additions , and changes occurred at the school in the aftermath of World War I. New buildings were built under the direction of architect Albert Cassell . Howard 's buildings and plant have a value of $567.6 million .\", sentence_starts=[0, 122, 298], selected_sent={'start': 0, 'end': 122, 'string': \"The 256 - acre ( 1.04 km ; 0.400 sq mi ) campus often referred to as `` The Mecca '' is located in northwest Washington . \"}, answer=[Entity(start_offset=99, end_offset=108, type='context', text='northwest', normalized_text='northwest')], nq_answers=[[Entity(start_offset=99, end_offset=108, type='context', text='northwest', normalized_text='northwest')], [Entity(start_offset=99, end_offset=119, type='context', text='northwest Washington', normalized_text='northwest washington')], [Entity(start_offset=96, end_offset=119, type='context', text='in northwest Washington', normalized_text='in northwest washington')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -2630456458869795232: QEDExample(example_id=-2630456458869795232, title='Justice League', question='who do they fight in the justice league', passage='The Justice League often unite to face supervillains who pose catastrophic challenges to the world .', sentence_starts=[0], selected_sent={'start': 0, 'end': 100, 'string': 'The Justice League often unite to face supervillains who pose catastrophic challenges to the world .'}, answer=[Entity(start_offset=39, end_offset=98, type='context', text='supervillains who pose catastrophic challenges to the world', normalized_text='supervillains who pose catastrophic challenges to world')], nq_answers=[[Entity(start_offset=39, end_offset=98, type='context', text='supervillains who pose catastrophic challenges to the world', normalized_text='supervillains who pose catastrophic challenges to world')]], aligned_nps=[(Entity(start_offset=21, end_offset=39, type='question', text='the justice league', normalized_text='justice league'), Entity(start_offset=0, end_offset=18, type='context', text='The Justice League', normalized_text='justice league'))], explanation_type='single_sentence'),\n",
       " -296081142113102965: QEDExample(example_id=-296081142113102965, title='Bishop', question='what is the role of a bishop in the bible', passage=\"In Timothy and Titus in the New Testament a more clearly defined episcopate can be seen . We are told that Paul had left Timothy in Ephesus and Titus in Crete to oversee the local church ( 1Tim 1 : 3 and Titus 1 : 5 ) . Paul commands Titus to ordain presbyters / bishops and to exercise general oversight , telling him to `` rebuke with all authority '' ( Titus 2 : 15 ) .\", sentence_starts=[0, 90, 220], selected_sent={'start': 220, 'end': 372, 'string': \"Paul commands Titus to ordain presbyters / bishops and to exercise general oversight , telling him to `` rebuke with all authority '' ( Titus 2 : 15 ) .\"}, answer=[Entity(start_offset=278, end_offset=304, type='context', text='exercise general oversight', normalized_text='exercise general oversight')], nq_answers=[[Entity(start_offset=243, end_offset=304, type='context', text='ordain presbyters / bishops and to exercise general oversight', normalized_text='ordain presbyters bishops and to exercise general oversight')]], aligned_nps=[(Entity(start_offset=32, end_offset=41, type='question', text='the bible', normalized_text='bible'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3271852979242251966: QEDExample(example_id=3271852979242251966, title='The History of Little Goody Two-Shoes', question='where did the term goody two shoes come from', passage=\"The History of Little Goody Two - Shoes is a children 's story published by John Newbery in London in 1765 . The story popularized the phrase `` goody two - shoes '' , often used to describe an excessively virtuous person , a do - gooder .\", sentence_starts=[0, 109], selected_sent={'start': 109, 'end': 239, 'string': \"The story popularized the phrase `` goody two - shoes '' , often used to describe an excessively virtuous person , a do - gooder .\"}, answer=[Entity(start_offset=0, end_offset=39, type='context', text='The History of Little Goody Two - Shoes', normalized_text='history of little goody two shoes')], nq_answers=[[Entity(start_offset=0, end_offset=39, type='context', text='The History of Little Goody Two - Shoes', normalized_text='history of little goody two shoes')]], aligned_nps=[(Entity(start_offset=10, end_offset=44, type='question', text='the term goody two shoes come from', normalized_text='term goody two shoes come from'), Entity(start_offset=131, end_offset=237, type='context', text=\"the phrase `` goody two - shoes '' , often used to describe an excessively virtuous person , a do - gooder\", normalized_text='phrase goody two shoes often used to describe excessively virtuous person do gooder'))], explanation_type='single_sentence'),\n",
       " 4440911260005876349: QEDExample(example_id=4440911260005876349, title='List of states and union territories of India by population', question='state the position of india in terms of population size', passage=\"India is a union of 29 states and 7 union territories . As of 2011 , with an estimated population of 1.2 billion , India is the world 's second most populous country after the People 's Republic of China . India occupies 2.4 % of the world 's land surface area and is home to 17.5 % of the world 's population . After the Indo - Gangetic Plain , the eastern and western coastal regions of the Deccan Plateau are the most densely populated regions of India . The Thar Desert in western Rajasthan is one of the most densely populated deserts in the world . The northern and north - eastern states along the Himalayas contain cold arid deserts with fertile valleys .\", sentence_starts=[0, 56, 206, 312, 458, 555], selected_sent={'start': 56, 'end': 206, 'string': \"As of 2011 , with an estimated population of 1.2 billion , India is the world 's second most populous country after the People 's Republic of China . \"}, answer=[Entity(start_offset=137, end_offset=143, type='context', text='second', normalized_text='second')], nq_answers=[[Entity(start_offset=137, end_offset=143, type='context', text='second', normalized_text='second')], [Entity(start_offset=124, end_offset=165, type='context', text=\"the world 's second most populous country\", normalized_text='world s second most populous country')]], aligned_nps=[(Entity(start_offset=22, end_offset=27, type='question', text='india', normalized_text='india'), Entity(start_offset=115, end_offset=120, type='context', text='India', normalized_text='india'))], explanation_type='single_sentence'),\n",
       " 3172949410241605868: QEDExample(example_id=3172949410241605868, title='Indian National Congress', question='who became a leader of the indian national congress', passage='The Indian National Congress ( pronunciation ( help info ) ) ( INC , often called Congress ) is a broadly based political party in India . Founded in 1885 , it was the first modern nationalist movement to emerge in the British Empire in Asia and Africa . From the late 19th century , and especially after 1920 , under the leadership of Mahatma Gandhi , Congress became the principal leader of the Indian independence movement , with over 15 million members and over 70 million participants . Congress led India to independence from Great Britain , and powerfully influenced other anti-colonial nationalist movements in the British Empire .', sentence_starts=[0, 52, 139, 255, 492], selected_sent={'start': 255, 'end': 492, 'string': 'From the late 19th century , and especially after 1920 , under the leadership of Mahatma Gandhi , Congress became the principal leader of the Indian independence movement , with over 15 million members and over 70 million participants . '}, answer=[Entity(start_offset=336, end_offset=350, type='context', text='Mahatma Gandhi', normalized_text='mahatma gandhi')], nq_answers=[[Entity(start_offset=336, end_offset=350, type='context', text='Mahatma Gandhi', normalized_text='mahatma gandhi')]], aligned_nps=[(Entity(start_offset=23, end_offset=51, type='question', text='the indian national congress', normalized_text='indian national congress'), Entity(start_offset=353, end_offset=361, type='context', text='Congress', normalized_text='congress'))], explanation_type='single_sentence'),\n",
       " 159123015669900402: QEDExample(example_id=159123015669900402, title='Filename extension', question='what is the filename extension used for all java source files', passage='When the Internet age first arrived , those using Windows systems that were still restricted to 8.3 filename formats had to create web pages with names ending in . HTM , while those using Macintosh or UNIX computers could use the recommended . html filename extension . This also became a problem for programmers experimenting with the Java programming language , since it requires source code files to have the four - letter suffix . java and compiles object code output files with the five - letter . class suffix .', sentence_starts=[0, 270], selected_sent={'start': 270, 'end': 517, 'string': 'This also became a problem for programmers experimenting with the Java programming language , since it requires source code files to have the four - letter suffix . java and compiles object code output files with the five - letter . class suffix .'}, answer=[Entity(start_offset=433, end_offset=439, type='context', text='. java', normalized_text='java')], nq_answers=[[Entity(start_offset=433, end_offset=439, type='context', text='. java', normalized_text='java')], [Entity(start_offset=408, end_offset=439, type='context', text='the four - letter suffix . java', normalized_text='four letter suffix java')]], aligned_nps=[(Entity(start_offset=40, end_offset=61, type='question', text='all java source files', normalized_text='all java source files'), Entity(start_offset=382, end_offset=399, type='context', text='source code files', normalized_text='source code files'))], explanation_type='single_sentence'),\n",
       " 7990281571644070368: QEDExample(example_id=7990281571644070368, title='Whip (politics)', question='what is the job of the whip in congress', passage=\"In countries influenced by the British political system , a whip is an official of a political party whose task is to ensure party discipline in a legislature . Whips are the party 's `` enforcers '' ; they invite their fellow legislators to attend voting sessions and to vote according to the official party policy . The term is taken from the `` whipper - in '' during a hunt , who tries to prevent the hounds from wandering away from the pack .\", sentence_starts=[0, 161, 318], selected_sent={'start': 0, 'end': 161, 'string': 'In countries influenced by the British political system , a whip is an official of a political party whose task is to ensure party discipline in a legislature . '}, answer=[Entity(start_offset=115, end_offset=158, type='context', text='to ensure party discipline in a legislature', normalized_text='to ensure party discipline in legislature')], nq_answers=[[Entity(start_offset=115, end_offset=141, type='context', text='to ensure party discipline', normalized_text='to ensure party discipline')], [Entity(start_offset=118, end_offset=158, type='context', text='ensure party discipline in a legislature', normalized_text='ensure party discipline in legislature')]], aligned_nps=[(Entity(start_offset=19, end_offset=27, type='question', text='the whip', normalized_text='whip'), Entity(start_offset=58, end_offset=64, type='context', text='a whip', normalized_text='whip'))], explanation_type='single_sentence'),\n",
       " -3697600391347486989: QEDExample(example_id=-3697600391347486989, title='Emperor of Japan', question=\"what is the emperor's role in japan\", passage=\"The Emperor of Japan is the head of the Imperial Family and the traditional head of state of Japan . According to the 1947 constitution , he is `` the symbol of the State and of the unity of the people '' and he has `` no powers related to government '' . Historically , he was also the highest authority of the Shinto religion . In Japanese , the Emperor is called Tennō ( 天皇 ) , which translates to `` heavenly sovereign '' . In English , the use of the term Mikado ( 帝 ) for the Emperor was once common , but is now considered obsolete .\", sentence_starts=[0, 101, 256, 330, 428], selected_sent={'start': 101, 'end': 256, 'string': \"According to the 1947 constitution , he is `` the symbol of the State and of the unity of the people '' and he has `` no powers related to government '' . \"}, answer=[Entity(start_offset=147, end_offset=250, type='context', text=\"the symbol of the State and of the unity of the people '' and he has `` no powers related to government\", normalized_text='symbol of state and of unity of people and he has no powers related to government')], nq_answers=[[Entity(start_offset=144, end_offset=204, type='context', text=\"`` the symbol of the State and of the unity of the people ''\", normalized_text='symbol of state and of unity of people')]], aligned_nps=[(Entity(start_offset=8, end_offset=19, type='question', text='the emperor', normalized_text='emperor'), Entity(start_offset=138, end_offset=140, type='context', text='he', normalized_text='he')), (Entity(start_offset=30, end_offset=35, type='question', text='japan', normalized_text='japan'), Entity(start_offset=114, end_offset=135, type='context', text='the 1947 constitution', normalized_text='1947 constitution'))], explanation_type='single_sentence'),\n",
       " -3530165048900528552: QEDExample(example_id=-3530165048900528552, title='Foreign exchange option', question='which foreign currency option is the\\u200b right but not the\\u200b obligation to buy foreign\\u200b currency', passage='In finance , a foreign exchange option ( commonly shortened to just FX option or currency option ) is a derivative financial instrument that gives the right but not the obligation to exchange money denominated in one currency into another currency at a pre-agreed exchange rate on a specified date . See Foreign exchange derivative .', sentence_starts=[0, 300], selected_sent={'start': 0, 'end': 300, 'string': 'In finance , a foreign exchange option ( commonly shortened to just FX option or currency option ) is a derivative financial instrument that gives the right but not the obligation to exchange money denominated in one currency into another currency at a pre-agreed exchange rate on a specified date . '}, answer=[Entity(start_offset=13, end_offset=98, type='context', text='a foreign exchange option ( commonly shortened to just FX option or currency option )', normalized_text='foreign exchange option commonly shortened to just fx option or currency option')], nq_answers=[[Entity(start_offset=13, end_offset=98, type='context', text='a foreign exchange option ( commonly shortened to just FX option or currency option )', normalized_text='foreign exchange option commonly shortened to just fx option or currency option')], [Entity(start_offset=15, end_offset=38, type='context', text='foreign exchange option', normalized_text='foreign exchange option')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2795932191977151266: QEDExample(example_id=2795932191977151266, title='House of Representatives (Nigeria)', question='how many house of representative do we have in nigeria', passage='The current House of Representatives , formed following elections held in April 2015 , has a total of 360 members who are elected in single - member constituencies using the simple majority ( or first - past - the - post ) system . Members serve four - year terms . The Speaker of the Nigerian House of Representatives is the presiding officer of the house .', sentence_starts=[0, 232, 266], selected_sent={'start': 0, 'end': 232, 'string': 'The current House of Representatives , formed following elections held in April 2015 , has a total of 360 members who are elected in single - member constituencies using the simple majority ( or first - past - the - post ) system . '}, answer=[Entity(start_offset=102, end_offset=105, type='context', text='360', normalized_text='360')], nq_answers=[[Entity(start_offset=102, end_offset=105, type='context', text='360', normalized_text='360')], [Entity(start_offset=102, end_offset=113, type='context', text='360 members', normalized_text='360 members')]], aligned_nps=[(Entity(start_offset=47, end_offset=54, type='question', text='nigeria', normalized_text='nigeria'), Entity(start_offset=0, end_offset=36, type='context', text='The current House of Representatives', normalized_text='current house of representatives'))], explanation_type='single_sentence'),\n",
       " 4714895284721516061: QEDExample(example_id=4714895284721516061, title='Dan Haggerty', question='who was the actor who played grizzly adams', passage=\"Daniel Francis `` Dan '' Haggerty ( November 19 , 1941 -- January 15 , 2016 ) was an American actor , best known for playing the title role in The Life and Times of Grizzly Adams .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 180, 'string': \"Daniel Francis `` Dan '' Haggerty ( November 19 , 1941 -- January 15 , 2016 ) was an American actor , best known for playing the title role in The Life and Times of Grizzly Adams .\"}, answer=[Entity(start_offset=0, end_offset=33, type='context', text=\"Daniel Francis `` Dan '' Haggerty\", normalized_text='daniel francis dan haggerty')], nq_answers=[[Entity(start_offset=0, end_offset=33, type='context', text=\"Daniel Francis `` Dan '' Haggerty\", normalized_text='daniel francis dan haggerty')], [Entity(start_offset=15, end_offset=33, type='context', text=\"`` Dan '' Haggerty\", normalized_text='dan haggerty')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3995871984744853423: QEDExample(example_id=-3995871984744853423, title='Tierra del Fuego', question='where is the tierra del fuego located on a map', passage=\"Tierra del Fuego ( / tiˈɛərə dɛl ˈfweɪɡoʊ / , Spanish : ( ˈtjera ðel ˈfweɣo ) ; Spanish for `` Land of Fire '' ) is an archipelago off the southernmost tip of the South American mainland , across the Strait of Magellan . The archipelago consists of the main island , Isla Grande de Tierra del Fuego , with an area of 48,100 km ( 18,572 sq mi ) , and a group of many islands , including Cape Horn and Diego Ramírez Islands . Tierra del Fuego is divided between Chile and Argentina , with the latter controlling the eastern half of the main island and the former the western half plus the islands south of Beagle Channel . The southernmost extent of the archipelago is at about latitude 55 S .\", sentence_starts=[0, 221, 424, 621], selected_sent={'start': 0, 'end': 221, 'string': \"Tierra del Fuego ( / tiˈɛərə dɛl ˈfweɪɡoʊ / , Spanish : ( ˈtjera ðel ˈfweɣo ) ; Spanish for `` Land of Fire '' ) is an archipelago off the southernmost tip of the South American mainland , across the Strait of Magellan . \"}, answer=[Entity(start_offset=131, end_offset=218, type='context', text='off the southernmost tip of the South American mainland , across the Strait of Magellan', normalized_text='off southernmost tip of south american mainland across strait of magellan')], nq_answers=[[Entity(start_offset=131, end_offset=218, type='context', text='off the southernmost tip of the South American mainland , across the Strait of Magellan', normalized_text='off southernmost tip of south american mainland across strait of magellan')], [Entity(start_offset=135, end_offset=186, type='context', text='the southernmost tip of the South American mainland', normalized_text='southernmost tip of south american mainland')]], aligned_nps=[(Entity(start_offset=9, end_offset=29, type='question', text='the tierra del fuego', normalized_text='tierra del fuego'), Entity(start_offset=0, end_offset=112, type='context', text=\"Tierra del Fuego ( / tiˈɛərə dɛl ˈfweɪɡoʊ / , Spanish : ( ˈtjera ðel ˈfweɣo ) ; Spanish for `` Land of Fire '' )\", normalized_text='tierra del fuego tiˈɛərə dɛl ˈfweɪɡoʊ spanish ˈtjera ðel ˈfweɣo spanish for land of fire'))], explanation_type='single_sentence'),\n",
       " -4523406960144718852: QEDExample(example_id=-4523406960144718852, title='State of the Union', question='when is the state of the union addressed', passage='Although the language of this State of the Union Clause of the Constitution is not specific , since the 1930s , the President makes this report annually in late January or early February . Between 1934 and 2013 the date has been as early as January 3 , and as late as February 12 .', sentence_starts=[0, 189], selected_sent={'start': 0, 'end': 189, 'string': 'Although the language of this State of the Union Clause of the Constitution is not specific , since the 1930s , the President makes this report annually in late January or early February . '}, answer=[Entity(start_offset=156, end_offset=186, type='context', text='late January or early February', normalized_text='late january or early february')], nq_answers=[[Entity(start_offset=229, end_offset=279, type='context', text='as early as January 3 , and as late as February 12', normalized_text='as early as january 3 and as late as february 12')]], aligned_nps=[(Entity(start_offset=8, end_offset=40, type='question', text='the state of the union addressed', normalized_text='state of union addressed'), Entity(start_offset=132, end_offset=143, type='context', text='this report', normalized_text='this report'))], explanation_type='single_sentence'),\n",
       " -2622854017829301835: QEDExample(example_id=-2622854017829301835, title='Cory', question='different ways to spell corey for a boy', passage='Alternative spellings for Cory are Corey , Coire , Corie , Corrie , Curry ( surname ) , Correy , Kory , Khouri , and Kori .', sentence_starts=[0], selected_sent={'start': 0, 'end': 123, 'string': 'Alternative spellings for Cory are Corey , Coire , Corie , Corrie , Curry ( surname ) , Correy , Kory , Khouri , and Kori .'}, answer=[Entity(start_offset=26, end_offset=121, type='context', text='Cory are Corey , Coire , Corie , Corrie , Curry ( surname ) , Correy , Kory , Khouri , and Kori', normalized_text='cory are corey coire corie corrie curry surname correy kory khouri and kori')], nq_answers=[[Entity(start_offset=35, end_offset=121, type='context', text='Corey , Coire , Corie , Corrie , Curry ( surname ) , Correy , Kory , Khouri , and Kori', normalized_text='corey coire corie corrie curry surname correy kory khouri and kori')], [Entity(start_offset=26, end_offset=30, type='context', text='Cory', normalized_text='cory'), Entity(start_offset=43, end_offset=48, type='context', text='Coire', normalized_text='coire'), Entity(start_offset=51, end_offset=56, type='context', text='Corie', normalized_text='corie'), Entity(start_offset=59, end_offset=65, type='context', text='Corrie', normalized_text='corrie'), Entity(start_offset=88, end_offset=94, type='context', text='Correy', normalized_text='correy'), Entity(start_offset=97, end_offset=101, type='context', text='Kory', normalized_text='kory'), Entity(start_offset=104, end_offset=110, type='context', text='Khouri', normalized_text='khouri'), Entity(start_offset=117, end_offset=121, type='context', text='Kori', normalized_text='kori'), Entity(start_offset=35, end_offset=40, type='context', text='Corey', normalized_text='corey')]], aligned_nps=[(Entity(start_offset=24, end_offset=29, type='question', text='corey', normalized_text='corey'), Entity(start_offset=0, end_offset=21, type='context', text='Alternative spellings', normalized_text='alternative spellings'))], explanation_type='single_sentence'),\n",
       " 3480908309420822259: QEDExample(example_id=3480908309420822259, title=\"Should've Been a Cowboy\", question='who sang the song should have been a cowboy', passage=\"`` Should 've Been a Cowboy '' is a song written and recorded by American country music artist Toby Keith . It was released on February 8 , 1993 as his debut single , and was served as the first single released from Keith 's self - titled debut studio album , Toby Keith . On June 5 , 1993 , it reached number one on the US Hot Country Songs chart and the Canadian RPM Country Tracks . It also peaked at number 93 on the Billboard Hot 100 , making it a minor crossover hit .\", sentence_starts=[0, 108, 273, 386], selected_sent={'start': 0, 'end': 108, 'string': \"`` Should 've Been a Cowboy '' is a song written and recorded by American country music artist Toby Keith . \"}, answer=[Entity(start_offset=95, end_offset=105, type='context', text='Toby Keith', normalized_text='toby keith')], nq_answers=[[Entity(start_offset=95, end_offset=105, type='context', text='Toby Keith', normalized_text='toby keith')], [Entity(start_offset=65, end_offset=105, type='context', text='American country music artist Toby Keith', normalized_text='american country music artist toby keith')]], aligned_nps=[(Entity(start_offset=9, end_offset=43, type='question', text='the song should have been a cowboy', normalized_text='song should have been cowboy'), Entity(start_offset=3, end_offset=27, type='context', text=\"Should 've Been a Cowboy\", normalized_text='should ve been cowboy'))], explanation_type='single_sentence'),\n",
       " -4323000711881657078: QEDExample(example_id=-4323000711881657078, title='Bernard Hill', question='who played king theoden in lord of the rings', passage=\"Bernard Hill ( born 17 December 1944 ) is an English film , stage and television actor . He is known for playing Yosser Hughes , the troubled ' hard man ' whose life is falling apart in Alan Bleasdale 's groundbreaking 1980s TV drama Boys from the Blackstuff and , more recently , as the Duke of Norfolk in the BBC adaptation of Dame Hilary Mantel 's Wolf Hall . He is also known for roles in blockbuster films , including Captain Edward Smith in Titanic , King Théoden in The Lord of the Rings film trilogy and Luther Plunkitt , the Warden of San Quentin Prison in the Clint Eastwood film True Crime .\", sentence_starts=[0, 89, 363], selected_sent={'start': 363, 'end': 602, 'string': 'He is also known for roles in blockbuster films , including Captain Edward Smith in Titanic , King Théoden in The Lord of the Rings film trilogy and Luther Plunkitt , the Warden of San Quentin Prison in the Clint Eastwood film True Crime .'}, answer=[Entity(start_offset=0, end_offset=12, type='context', text='Bernard Hill', normalized_text='bernard hill')], nq_answers=[[Entity(start_offset=0, end_offset=12, type='context', text='Bernard Hill', normalized_text='bernard hill')]], aligned_nps=[(Entity(start_offset=11, end_offset=23, type='question', text='king theoden', normalized_text='king theoden'), Entity(start_offset=457, end_offset=469, type='context', text='King Théoden', normalized_text='king théoden')), (Entity(start_offset=27, end_offset=44, type='question', text='lord of the rings', normalized_text='lord of rings'), Entity(start_offset=473, end_offset=507, type='context', text='The Lord of the Rings film trilogy', normalized_text='lord of rings film trilogy'))], explanation_type='single_sentence'),\n",
       " -3556174730654201439: QEDExample(example_id=-3556174730654201439, title='Outlier', question='what are the outliers in a data set', passage='In statistics , an outlier is an observation point that is distant from other observations . An outlier may be due to variability in the measurement or it may indicate experimental error ; the latter are sometimes excluded from the data set . An outlier can cause serious problems in statistical analyses .', sentence_starts=[0, 93, 243], selected_sent={'start': 0, 'end': 93, 'string': 'In statistics , an outlier is an observation point that is distant from other observations . '}, answer=[Entity(start_offset=30, end_offset=90, type='context', text='an observation point that is distant from other observations', normalized_text='observation point that is distant from other observations')], nq_answers=[[Entity(start_offset=30, end_offset=90, type='context', text='an observation point that is distant from other observations', normalized_text='observation point that is distant from other observations')], [Entity(start_offset=30, end_offset=92, type='context', text='an observation point that is distant from other observations .', normalized_text='observation point that is distant from other observations')]], aligned_nps=[(Entity(start_offset=9, end_offset=35, type='question', text='the outliers in a data set', normalized_text='outliers in data set'), Entity(start_offset=16, end_offset=26, type='context', text='an outlier', normalized_text='outlier'))], explanation_type='single_sentence'),\n",
       " 9078092620239351027: QEDExample(example_id=9078092620239351027, title='500 Days of Summer', question='where was the movie 500 days of summer filmed', passage=\"David Ng of the Los Angeles Times describes architecture as a star of the film . Tom is seen reading Alain de Botton 's The Architecture of Happiness . The film was originally set in San Francisco but was later moved to Los Angeles and the script rewritten to make better use of the location . Buildings used include the Los Angeles Music Center ( which includes the Dorothy Chandler Pavilion ) and the towers of California Plaza . The older Fine Arts Building is featured in the film , in a scene where Tom shows it to Summer and mentions its designers , Walker and Eisen , two of his favorite architects , although he incorrectly gives the partners ' names as `` Walker and Eisner . ''\", sentence_starts=[0, 81, 152, 294, 432], selected_sent={'start': 152, 'end': 294, 'string': 'The film was originally set in San Francisco but was later moved to Los Angeles and the script rewritten to make better use of the location . '}, answer=[Entity(start_offset=220, end_offset=231, type='context', text='Los Angeles', normalized_text='los angeles')], nq_answers=[[Entity(start_offset=220, end_offset=231, type='context', text='Los Angeles', normalized_text='los angeles')], [Entity(start_offset=16, end_offset=27, type='context', text='Los Angeles', normalized_text='los angeles')]], aligned_nps=[(Entity(start_offset=10, end_offset=38, type='question', text='the movie 500 days of summer', normalized_text='movie 500 days of summer'), Entity(start_offset=152, end_offset=160, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " 4747795168824294053: QEDExample(example_id=4747795168824294053, title='Claire Holt', question='who played emma in h2o just add water', passage='Claire Rhiannon Holt ( born 11 June 1988 ) is an Australian actress , known for her roles as Rebekah Mikaelson in the television series The Vampire Diaries and its spinoff series The Originals , Samara Cook in Pretty Little Liars , Emma in H O : Just Add Water , and Kate in the survival horror film 47 Meters Down .', sentence_starts=[0], selected_sent={'start': 0, 'end': 316, 'string': 'Claire Rhiannon Holt ( born 11 June 1988 ) is an Australian actress , known for her roles as Rebekah Mikaelson in the television series The Vampire Diaries and its spinoff series The Originals , Samara Cook in Pretty Little Liars , Emma in H O : Just Add Water , and Kate in the survival horror film 47 Meters Down .'}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='Claire Rhiannon Holt', normalized_text='claire rhiannon holt')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='Claire Rhiannon Holt', normalized_text='claire rhiannon holt')]], aligned_nps=[(Entity(start_offset=11, end_offset=15, type='question', text='emma', normalized_text='emma'), Entity(start_offset=232, end_offset=236, type='context', text='Emma', normalized_text='emma')), (Entity(start_offset=19, end_offset=37, type='question', text='h2o just add water', normalized_text='h2o just add water'), Entity(start_offset=240, end_offset=260, type='context', text='H O : Just Add Water', normalized_text='h o just add water'))], explanation_type='single_sentence'),\n",
       " -1173252802989599019: QEDExample(example_id=-1173252802989599019, title='Bigg Boss Kannada 5', question='who is the winner of bigg boss kannada season', passage='Bigg Boss Kannada 5 ( BBK5 ) was the fifth season of the Kannada television series Bigg Boss Kannada , that premiered on 15 October 2017 . Sudeep reprised his role as the host of the show . The finale of the season took place 28 January 2018 , and rapper Chandan Shetty was declared the winner of the show and was awarded the prize money of ₹ 50 lakh . Sales representative Diwaker was voted the runner - up .', sentence_starts=[0, 139, 190, 353], selected_sent={'start': 190, 'end': 353, 'string': 'The finale of the season took place 28 January 2018 , and rapper Chandan Shetty was declared the winner of the show and was awarded the prize money of ₹ 50 lakh . '}, answer=[Entity(start_offset=255, end_offset=269, type='context', text='Chandan Shetty', normalized_text='chandan shetty')], nq_answers=[[Entity(start_offset=255, end_offset=269, type='context', text='Chandan Shetty', normalized_text='chandan shetty')], [Entity(start_offset=248, end_offset=269, type='context', text='rapper Chandan Shetty', normalized_text='rapper chandan shetty')]], aligned_nps=[(Entity(start_offset=7, end_offset=45, type='question', text='the winner of bigg boss kannada season', normalized_text='winner of bigg boss kannada season'), Entity(start_offset=283, end_offset=305, type='context', text='the winner of the show', normalized_text='winner of show'))], explanation_type='single_sentence'),\n",
       " -8950878510839541193: QEDExample(example_id=-8950878510839541193, title='The Outlaw Josey Wales', question='where was the outlaw of josey wales filmed', passage=\"Cinematographer Bruce Surtees , James Fargo , and Fritz Manes scouted for locations and eventually found sites in Utah , Arizona , Wyoming , and Oroville , California even before they saw the final script . Kaufman cast Chief Dan George , who had been nominated for an Academy Award for Supporting Actor in Little Big Man , as the old Cherokee Lone Watie . Sondra Locke , also a previous Academy Award nominee , was cast by Eastwood against Kaufman 's wishes as the granddaughter of the old settler woman , Laura Lee . This marked the beginning of a close relationship between Eastwood and Locke that would last six films and the beginning of a romance that would last into the late 1980s . Ferris Webster was hired as the film 's editor and Jerry Fielding as composer .\", sentence_starts=[0, 207, 357, 519, 691], selected_sent={'start': 0, 'end': 207, 'string': 'Cinematographer Bruce Surtees , James Fargo , and Fritz Manes scouted for locations and eventually found sites in Utah , Arizona , Wyoming , and Oroville , California even before they saw the final script . '}, answer=[Entity(start_offset=114, end_offset=166, type='context', text='Utah , Arizona , Wyoming , and Oroville , California', normalized_text='utah arizona wyoming and oroville california')], nq_answers=[[Entity(start_offset=114, end_offset=118, type='context', text='Utah', normalized_text='utah'), Entity(start_offset=121, end_offset=128, type='context', text='Arizona', normalized_text='arizona'), Entity(start_offset=131, end_offset=138, type='context', text='Wyoming', normalized_text='wyoming'), Entity(start_offset=145, end_offset=166, type='context', text='Oroville , California', normalized_text='oroville california')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='the outlaw of josey wales', normalized_text='outlaw of josey wales'), Entity(start_offset=188, end_offset=206, type='context', text='the final script .', normalized_text='final script'))], explanation_type='single_sentence'),\n",
       " 3249143050053167368: QEDExample(example_id=3249143050053167368, title='Lars and the Real Girl', question='where was lars and the real girl filmed', passage=\"The film , set in the American state of Wisconsin , was filmed with a US $ 12 million budget on location in Alton , Elora , King Township , Toronto , Uxbridge , and Whitevale , all located in the Canadian province of Ontario . Film credits include Rosalie MacKintosh as `` Bianca wrangler '' and Karly Bowen as `` assistant Bianca wrangler . ''\", sentence_starts=[0, 227], selected_sent={'start': 0, 'end': 227, 'string': 'The film , set in the American state of Wisconsin , was filmed with a US $ 12 million budget on location in Alton , Elora , King Township , Toronto , Uxbridge , and Whitevale , all located in the Canadian province of Ontario . '}, answer=[Entity(start_offset=108, end_offset=224, type='context', text='Alton , Elora , King Township , Toronto , Uxbridge , and Whitevale , all located in the Canadian province of Ontario', normalized_text='alton elora king township toronto uxbridge and whitevale all located in canadian province of ontario')], nq_answers=[[Entity(start_offset=93, end_offset=224, type='context', text='on location in Alton , Elora , King Township , Toronto , Uxbridge , and Whitevale , all located in the Canadian province of Ontario', normalized_text='on location in alton elora king township toronto uxbridge and whitevale all located in canadian province of ontario')], [Entity(start_offset=108, end_offset=224, type='context', text='Alton , Elora , King Township , Toronto , Uxbridge , and Whitevale , all located in the Canadian province of Ontario', normalized_text='alton elora king township toronto uxbridge and whitevale all located in canadian province of ontario')], [Entity(start_offset=189, end_offset=224, type='context', text='in the Canadian province of Ontario', normalized_text='in canadian province of ontario')]], aligned_nps=[(Entity(start_offset=10, end_offset=32, type='question', text='lars and the real girl', normalized_text='lars and real girl'), Entity(start_offset=0, end_offset=8, type='context', text='The film', normalized_text='film'))], explanation_type='single_sentence'),\n",
       " 7723222099975907336: QEDExample(example_id=7723222099975907336, title='Extinction', question='what is the most important reason that species are going extinct', passage=\"Currently , environmental groups and some governments are concerned with the extinction of species caused by humanity , and they try to prevent further extinctions through a variety of conservation programs . Humans can cause extinction of a species through overharvesting , pollution , habitat destruction , introduction of invasive species ( such as new predators and food competitors ) , overhunting , and other influences . Explosive , unsustainable human population growth is an essential cause of the extinction crisis . According to the International Union for Conservation of Nature ( IUCN ) , 784 extinctions have been recorded since the year 1500 , the arbitrary date selected to define `` recent '' extinctions , up to the year 2004 ; with many more likely to have gone unnoticed . Several species have also been listed as extinct since 2004 .\", sentence_starts=[0, 209, 428, 527, 793], selected_sent={'start': 428, 'end': 527, 'string': 'Explosive , unsustainable human population growth is an essential cause of the extinction crisis . '}, answer=[Entity(start_offset=428, end_offset=477, type='context', text='Explosive , unsustainable human population growth', normalized_text='explosive unsustainable human population growth')], nq_answers=[[Entity(start_offset=428, end_offset=477, type='context', text='Explosive , unsustainable human population growth', normalized_text='explosive unsustainable human population growth')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 4869593212087031152: QEDExample(example_id=4869593212087031152, title=\"Don't You Worry Child\", question=\"where was don't you worry child filmed\", passage=\"A music video for the song was released on 14 September 2012 , filmed on location at the group 's final British performance on 14 July 2012 at the National Bowl in Milton Keynes . As of October 2017 , the music video has over 450 million views on YouTube .\", sentence_starts=[0, 180], selected_sent={'start': 0, 'end': 180, 'string': \"A music video for the song was released on 14 September 2012 , filmed on location at the group 's final British performance on 14 July 2012 at the National Bowl in Milton Keynes . \"}, answer=[Entity(start_offset=82, end_offset=177, type='context', text=\"at the group 's final British performance on 14 July 2012 at the National Bowl in Milton Keynes\", normalized_text='at group s final british performance on 14 july 2012 at national bowl in milton keynes')], nq_answers=[[Entity(start_offset=70, end_offset=177, type='context', text=\"on location at the group 's final British performance on 14 July 2012 at the National Bowl in Milton Keynes\", normalized_text='on location at group s final british performance on 14 july 2012 at national bowl in milton keynes')], [Entity(start_offset=82, end_offset=177, type='context', text=\"at the group 's final British performance on 14 July 2012 at the National Bowl in Milton Keynes\", normalized_text='at group s final british performance on 14 july 2012 at national bowl in milton keynes')]], aligned_nps=[(Entity(start_offset=10, end_offset=31, type='question', text=\"don't you worry child\", normalized_text='dont you worry child'), Entity(start_offset=0, end_offset=26, type='context', text='A music video for the song', normalized_text='music video for song'))], explanation_type='single_sentence'),\n",
       " 2370076891269438265: QEDExample(example_id=2370076891269438265, title='Spanish Steps', question='where are the spanish steps located in italy', passage='The Spanish Steps ( Italian : Scalinata di Trinità dei Monti ) are a set of steps in Rome , Italy , climbing a steep slope between the Piazza di Spagna at the base and Piazza Trinità dei Monti , dominated by the Trinità dei Monti church at the top .', sentence_starts=[0], selected_sent={'start': 0, 'end': 249, 'string': 'The Spanish Steps ( Italian : Scalinata di Trinità dei Monti ) are a set of steps in Rome , Italy , climbing a steep slope between the Piazza di Spagna at the base and Piazza Trinità dei Monti , dominated by the Trinità dei Monti church at the top .'}, answer=[Entity(start_offset=85, end_offset=192, type='context', text='Rome , Italy , climbing a steep slope between the Piazza di Spagna at the base and Piazza Trinità dei Monti', normalized_text='rome italy climbing steep slope between piazza di spagna at base and piazza trinità dei monti')], nq_answers=[[Entity(start_offset=85, end_offset=89, type='context', text='Rome', normalized_text='rome')], [Entity(start_offset=109, end_offset=247, type='context', text='a steep slope between the Piazza di Spagna at the base and Piazza Trinità dei Monti , dominated by the Trinità dei Monti church at the top', normalized_text='steep slope between piazza di spagna at base and piazza trinità dei monti dominated by trinità dei monti church at top')]], aligned_nps=[(Entity(start_offset=10, end_offset=27, type='question', text='the spanish steps', normalized_text='spanish steps'), Entity(start_offset=0, end_offset=62, type='context', text='The Spanish Steps ( Italian : Scalinata di Trinità dei Monti )', normalized_text='spanish steps italian scalinata di trinità dei monti')), (Entity(start_offset=39, end_offset=44, type='question', text='italy', normalized_text='italy'), Entity(start_offset=92, end_offset=97, type='context', text='Italy', normalized_text='italy'))], explanation_type='single_sentence'),\n",
       " 3631867991857999976: QEDExample(example_id=3631867991857999976, title='Hydrogen bond', question='other than water what else has hydrogen bonds', passage='Hydrogen bonds can occur between molecules ( intermolecular ) or within different parts of a single molecule ( intramolecular ) . Depending on the nature of the donor and acceptor atoms which constitute the bond , their geometry , and environment , the energy of a hydrogen bond can vary between 1 and 40 kcal / mol . This makes them somewhat stronger than a van der Waals interaction , and weaker than covalent or ionic bonds . This type of bond can occur in inorganic molecules such as water and in organic molecules like DNA and proteins .', sentence_starts=[0, 130, 318, 429], selected_sent={'start': 429, 'end': 542, 'string': 'This type of bond can occur in inorganic molecules such as water and in organic molecules like DNA and proteins .'}, answer=[Entity(start_offset=457, end_offset=540, type='context', text='in inorganic molecules such as water and in organic molecules like DNA and proteins', normalized_text='in inorganic molecules such as water and in organic molecules like dna and proteins')], nq_answers=[[Entity(start_offset=460, end_offset=493, type='context', text='inorganic molecules such as water', normalized_text='inorganic molecules such as water'), Entity(start_offset=501, end_offset=540, type='context', text='organic molecules like DNA and proteins', normalized_text='organic molecules like dna and proteins')]], aligned_nps=[(Entity(start_offset=31, end_offset=45, type='question', text='hydrogen bonds', normalized_text='hydrogen bonds'), Entity(start_offset=429, end_offset=446, type='context', text='This type of bond', normalized_text='this type of bond'))], explanation_type='single_sentence'),\n",
       " -7311149600272472027: QEDExample(example_id=-7311149600272472027, title='Human hair color', question='what percentage of the population is naturally blonde', passage=\"Blond hair can have almost any proportion of pheomelanin and eumelanin , but has only small amounts of both . More pheomelanin creates a more golden or strawberry blond color , and more eumelanin creates an ash or sandy blond color . Many children born with blond hair develop darker hair as they age , with the majority of natural blonds developing a hair color of a dark blond hue by the time they reach middle age . Pregnancy hormones hasten this process . Natural light blond hair is rare in adulthood , with claims of the world 's population ranging from 2 % naturally blond to 16 % in the US . Blond hair is most commonly found in Northern and Western Europeans and their descendants but can be found spread around most of Europe . Studies in 2012 showed that naturally blond hair of Melanesians is caused by a recessive mutation in tyrosinase - related protein 1 ( TYRP1 ) . In the Solomon Islands , 26 % of the population carry the gene ; however , it is absent outside of Oceania .\", sentence_starts=[0, 110, 234, 419, 460, 600, 738, 882], selected_sent={'start': 460, 'end': 600, 'string': \"Natural light blond hair is rare in adulthood , with claims of the world 's population ranging from 2 % naturally blond to 16 % in the US . \"}, answer=[Entity(start_offset=560, end_offset=587, type='context', text='2 % naturally blond to 16 %', normalized_text='2 naturally blond to 16')], nq_answers=[[Entity(start_offset=555, end_offset=597, type='context', text='from 2 % naturally blond to 16 % in the US', normalized_text='from 2 naturally blond to 16 in us')], [Entity(start_offset=523, end_offset=597, type='context', text=\"the world 's population ranging from 2 % naturally blond to 16 % in the US\", normalized_text='world s population ranging from 2 naturally blond to 16 in us')], [Entity(start_offset=560, end_offset=563, type='context', text='2 %', normalized_text='2')], [Entity(start_offset=513, end_offset=597, type='context', text=\"claims of the world 's population ranging from 2 % naturally blond to 16 % in the US\", normalized_text='claims of world s population ranging from 2 naturally blond to 16 in us')]], aligned_nps=[(Entity(start_offset=19, end_offset=33, type='question', text='the population', normalized_text='population'), Entity(start_offset=523, end_offset=546, type='context', text=\"the world 's population\", normalized_text='world s population'))], explanation_type='single_sentence'),\n",
       " 3416599804922847770: QEDExample(example_id=3416599804922847770, title='Alpine lake', question='what is the definition of an alpine lake', passage='Alpine lakes are classified as lakes or reservoirs at high altitudes , usually starting around 5,000 feet ( 1524 metres ) in elevation above sea level or above the tree line .', sentence_starts=[0], selected_sent={'start': 0, 'end': 175, 'string': 'Alpine lakes are classified as lakes or reservoirs at high altitudes , usually starting around 5,000 feet ( 1524 metres ) in elevation above sea level or above the tree line .'}, answer=[Entity(start_offset=31, end_offset=173, type='context', text='lakes or reservoirs at high altitudes , usually starting around 5,000 feet ( 1524 metres ) in elevation above sea level or above the tree line', normalized_text='lakes or reservoirs at high altitudes usually starting around 5000 feet 1524 metres in elevation above sea level or above tree line')], nq_answers=[[Entity(start_offset=31, end_offset=173, type='context', text='lakes or reservoirs at high altitudes , usually starting around 5,000 feet ( 1524 metres ) in elevation above sea level or above the tree line', normalized_text='lakes or reservoirs at high altitudes usually starting around 5000 feet 1524 metres in elevation above sea level or above tree line')]], aligned_nps=[(Entity(start_offset=26, end_offset=40, type='question', text='an alpine lake', normalized_text='alpine lake'), Entity(start_offset=0, end_offset=12, type='context', text='Alpine lakes', normalized_text='alpine lakes'))], explanation_type='single_sentence'),\n",
       " -3653614166480549899: QEDExample(example_id=-3653614166480549899, title='We Are the World', question='who sang first line of we are the world', passage=\"`` We Are the World '' is sung from a first person viewpoint , allowing the audience to `` internalize '' the message by singing the word we together . It has been described as `` an appeal to human compassion '' . The first lines in the song 's repetitive chorus proclaim , `` We are the world , we are the children , we are the ones who make a brighter day , so let 's start giving '' . `` We Are the World '' opens with Lionel Richie , Stevie Wonder , Paul Simon , Kenny Rogers , James Ingram , Tina Turner , and Billy Joel singing the first verse . Michael Jackson and Diana Ross follow , completing the first chorus together . Dionne Warwick , Willie Nelson , and Al Jarreau sing the second verse , before Bruce Springsteen , Kenny Loggins , Steve Perry , and Daryl Hall go through the second chorus . Co-writer Jackson , Huey Lewis , Cyndi Lauper , and Kim Carnes follow with the song 's bridge . This structuring of the song is said to `` create a sense of continuous surprise and emotional buildup '' . `` We Are the World '' concludes with Bob Dylan and Ray Charles singing a full chorus , Wonder and Springsteen duetting , and ad libs from Charles and Ingram .\", sentence_starts=[0, 152, 215, 389, 553, 632, 807, 903, 1011], selected_sent={'start': 389, 'end': 553, 'string': \"`` We Are the World '' opens with Lionel Richie , Stevie Wonder , Paul Simon , Kenny Rogers , James Ingram , Tina Turner , and Billy Joel singing the first verse . \"}, answer=[Entity(start_offset=423, end_offset=436, type='context', text='Lionel Richie', normalized_text='lionel richie')], nq_answers=[[Entity(start_offset=423, end_offset=436, type='context', text='Lionel Richie', normalized_text='lionel richie'), Entity(start_offset=439, end_offset=452, type='context', text='Stevie Wonder', normalized_text='stevie wonder'), Entity(start_offset=455, end_offset=465, type='context', text='Paul Simon', normalized_text='paul simon'), Entity(start_offset=468, end_offset=480, type='context', text='Kenny Rogers', normalized_text='kenny rogers'), Entity(start_offset=483, end_offset=495, type='context', text='James Ingram', normalized_text='james ingram'), Entity(start_offset=498, end_offset=509, type='context', text='Tina Turner', normalized_text='tina turner'), Entity(start_offset=516, end_offset=526, type='context', text='Billy Joel', normalized_text='billy joel')]], aligned_nps=[(Entity(start_offset=23, end_offset=39, type='question', text='we are the world', normalized_text='we are world'), Entity(start_offset=392, end_offset=408, type='context', text='We Are the World', normalized_text='we are world'))], explanation_type='single_sentence'),\n",
       " -6284503594240226071: QEDExample(example_id=-6284503594240226071, title='History of Maryland', question='who formed and first came to the colony of maryland', passage='The recorded history of Maryland dates back to when Europeans began exploring the area , starting with the Italian / Venetian John Cabot ( c. 1450 -- c. 1500 ) , exploring the coast of the continent of North America for England in 1498 . The first European settlements were made in 1634 , when the English arrived in significant numbers and created a permanent colony . Maryland was notable for having been established with religious freedom for Roman Catholics . Like other colonies of the Chesapeake Bay , its economy was based on tobacco as a commodity crop , cultivated primarily by African slave labor , although many young people came from Britain as indentured servants in the early years .', sentence_starts=[0, 238, 370, 464], selected_sent={'start': 238, 'end': 370, 'string': 'The first European settlements were made in 1634 , when the English arrived in significant numbers and created a permanent colony . '}, answer=[Entity(start_offset=294, end_offset=305, type='context', text='the English', normalized_text='english')], nq_answers=[[Entity(start_offset=294, end_offset=305, type='context', text='the English', normalized_text='english')]], aligned_nps=[(Entity(start_offset=29, end_offset=51, type='question', text='the colony of maryland', normalized_text='colony of maryland'), Entity(start_offset=349, end_offset=367, type='context', text='a permanent colony', normalized_text='permanent colony'))], explanation_type='single_sentence'),\n",
       " 3311962143974666464: QEDExample(example_id=3311962143974666464, title='King cobra', question='how much venom can a king cobra produce', passage=\"This species is capable of delivering a fatal bite and the victim may receive a large quantity of venom with a dose of 200 to 500 mg up to 7 ml . Engelmann and Obst ( 1981 ) list the average venom yield at 420 mg ( dry weight ) . Accordingly , large quantities of antivenom may be needed to reverse the progression of symptoms developed if bitten by a king cobra . The toxins affect the victim 's central nervous system , resulting in severe pain , blurred vision , vertigo , drowsiness , and eventually paralysis . If the envenomation is serious , it progresses to cardiovascular collapse , and the victim falls into a coma . Death soon follows due to respiratory failure . Bites from a king cobra may result in a rapid fatality which can be as early as 30 minutes after the envenomation . The king cobra 's envenomation was even recorded to be capable of killing elephants within hours .\", sentence_starts=[0, 146, 230, 365, 516, 627, 675, 791], selected_sent={'start': 0, 'end': 146, 'string': 'This species is capable of delivering a fatal bite and the victim may receive a large quantity of venom with a dose of 200 to 500 mg up to 7 ml . '}, answer=[Entity(start_offset=133, end_offset=143, type='context', text='up to 7 ml', normalized_text='up to 7 ml')], nq_answers=[[Entity(start_offset=133, end_offset=143, type='context', text='up to 7 ml', normalized_text='up to 7 ml')], [Entity(start_offset=206, end_offset=212, type='context', text='420 mg', normalized_text='420 mg')], [Entity(start_offset=119, end_offset=132, type='context', text='200 to 500 mg', normalized_text='200 to 500 mg')]], aligned_nps=[(Entity(start_offset=19, end_offset=31, type='question', text='a king cobra', normalized_text='king cobra'), Entity(start_offset=0, end_offset=12, type='context', text='This species', normalized_text='this species'))], explanation_type='single_sentence'),\n",
       " -4529708874973104813: QEDExample(example_id=-4529708874973104813, title='List of most-liked Instagram pictures', question='whats the most liked picture on instagram 2018', passage=\"This list contains the top ten pictures with the most likes on the social photo - sharing platform Instagram ; Instagram does not provide an official list . As of April 2018 , the name announcement of Kylie Jenner 's first child is the most - liked picture with over 17 million likes . Additionally , Kylie Jenner has the most pictures in the top ten with four , including the top three overall . Most of Jenner 's top pictures feature her newborn daughter , Stormi Webster .\", sentence_starts=[0, 157, 286, 397], selected_sent={'start': 157, 'end': 286, 'string': \"As of April 2018 , the name announcement of Kylie Jenner 's first child is the most - liked picture with over 17 million likes . \"}, answer=[Entity(start_offset=185, end_offset=228, type='context', text=\"announcement of Kylie Jenner 's first child\", normalized_text='announcement of kylie jenner s first child')], nq_answers=[[Entity(start_offset=176, end_offset=228, type='context', text=\"the name announcement of Kylie Jenner 's first child\", normalized_text='name announcement of kylie jenner s first child')]], aligned_nps=[(Entity(start_offset=42, end_offset=46, type='question', text='2018', normalized_text='2018'), Entity(start_offset=169, end_offset=173, type='context', text='2018', normalized_text='2018')), (Entity(start_offset=6, end_offset=41, type='question', text='the most liked picture on instagram', normalized_text='most liked picture on instagram'), Entity(start_offset=232, end_offset=256, type='context', text='the most - liked picture', normalized_text='most liked picture'))], explanation_type='single_sentence'),\n",
       " 2162587275527723755: QEDExample(example_id=2162587275527723755, title='Edinburgh Festival Fringe', question='where does the edinburgh fringe festival take place', passage=\"The Edinburgh Festival Fringe ( often referred to as simply The Fringe ) is the world 's largest arts festival , which in 2017 spanned 25 days and featured 53,232 performances of 3,398 shows in 300 venues . Established in 1947 as an alternative to the Edinburgh International Festival , it takes place annually in Edinburgh , Scotland , in the month of August .\", sentence_starts=[0, 207], selected_sent={'start': 207, 'end': 361, 'string': 'Established in 1947 as an alternative to the Edinburgh International Festival , it takes place annually in Edinburgh , Scotland , in the month of August .'}, answer=[Entity(start_offset=314, end_offset=334, type='context', text='Edinburgh , Scotland', normalized_text='edinburgh scotland')], nq_answers=[[Entity(start_offset=311, end_offset=334, type='context', text='in Edinburgh , Scotland', normalized_text='in edinburgh scotland')]], aligned_nps=[(Entity(start_offset=11, end_offset=40, type='question', text='the edinburgh fringe festival', normalized_text='edinburgh fringe festival'), Entity(start_offset=287, end_offset=289, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 1875157261182375834: QEDExample(example_id=1875157261182375834, title='Elimination Chamber (2018)', question='who won the wwe championship elimination chamber 2018', passage=\"Six matches were contested at the event , including one on the pre-show . In the main event , Roman Reigns won the first - ever seven - man Elimination Chamber match to become the number one contender against Brock Lesnar for the Universal Championship at WrestleMania 34 . On the undercard , Alexa Bliss retained the Raw Women 's Championship in the first - ever women 's Elimination Chamber match , and Asuka defeated Nia Jax to extend her undefeated streak and to keep Jax from being added to her WrestleMania 34 championship match . The event was also notable for Ronda Rousey signing her Raw contract , where she had a confrontation with Chief Operating Officer Triple H and Raw Commissioner Stephanie McMahon , which was the former 's first appearance since the night after Survivor Series .\", sentence_starts=[0, 74, 274, 537], selected_sent={'start': 74, 'end': 274, 'string': 'In the main event , Roman Reigns won the first - ever seven - man Elimination Chamber match to become the number one contender against Brock Lesnar for the Universal Championship at WrestleMania 34 . '}, answer=[Entity(start_offset=94, end_offset=106, type='context', text='Roman Reigns', normalized_text='roman reigns')], nq_answers=[[Entity(start_offset=94, end_offset=106, type='context', text='Roman Reigns', normalized_text='roman reigns')]], aligned_nps=[(Entity(start_offset=8, end_offset=53, type='question', text='the wwe championship elimination chamber 2018', normalized_text='wwe championship elimination chamber 2018'), Entity(start_offset=77, end_offset=91, type='context', text='the main event', normalized_text='main event'))], explanation_type='single_sentence'),\n",
       " 8926902974073457645: QEDExample(example_id=8926902974073457645, title='Safe Haven (novel)', question='where does safe haven take place in the book', passage=\"Erin flees her abusive alcoholic husband , Kevin , takes on a different identity and changes her name to Katie . She arrives in Southport , North Carolina . Finding work at a seafood restaurant , she becomes friends with her neighbor , Jo , and gets to know the town 's general store owner , Alex .\", sentence_starts=[0, 113, 157], selected_sent={'start': 113, 'end': 157, 'string': 'She arrives in Southport , North Carolina . '}, answer=[Entity(start_offset=128, end_offset=154, type='context', text='Southport , North Carolina', normalized_text='southport north carolina')], nq_answers=[[Entity(start_offset=128, end_offset=154, type='context', text='Southport , North Carolina', normalized_text='southport north carolina')]], aligned_nps=[(Entity(start_offset=11, end_offset=21, type='question', text='safe haven', normalized_text='safe haven'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -3997272399784107764: QEDExample(example_id=-3997272399784107764, title='How the Grinch Stole Christmas!', question='dogs name in the grinch who stole christmas', passage=\"The Grinch is a bitter , grouchy , cave - dwelling creature with a heart `` two sizes too small '' who is living as a hermit on the snowy Mount Crumpit , a steep high mountain just north of the town of Whoville , home of the merry and warm - hearted Whos . His only companion is his unloved , but loyal dog , Max . From his cave , the Grinch can hear the noisy Christmas festivities that take place in Whoville . Continuously annoyed , he decides to devise a wicked scheme by stealing their presents , trees , and food for their Christmas feast . He crudely disguises himself as Santa Claus , and forces Max , disguised as a reindeer , to drag a sleigh down the mountain towards Whoville . Once at Whoville , the Grinch slides down the chimney of one house and steals all of the Whos ' Christmas presents , the Christmas tree , and the log for their fire . He is briefly interrupted in his burglary by Cindy Lou , a little Who girl , but concocts a crafty lie to effect his escape from her home . After stealing from one house , he does the same thing to all the other houses in the village of Whoville .\", sentence_starts=[0, 257, 315, 413, 547, 690, 857, 997], selected_sent={'start': 257, 'end': 315, 'string': 'His only companion is his unloved , but loyal dog , Max . '}, answer=[Entity(start_offset=309, end_offset=312, type='context', text='Max', normalized_text='max')], nq_answers=[[Entity(start_offset=309, end_offset=312, type='context', text='Max', normalized_text='max')]], aligned_nps=[(Entity(start_offset=13, end_offset=43, type='question', text='the grinch who stole christmas', normalized_text='grinch who stole christmas'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 3977993332190439710: QEDExample(example_id=3977993332190439710, title='One Thing Leads to Another', question='who sings the song one thing leads to another', passage=\"`` One Thing Leads to Another '' is a song by new wave rock band The Fixx , from their album Reach the Beach .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 110, 'string': \"`` One Thing Leads to Another '' is a song by new wave rock band The Fixx , from their album Reach the Beach .\"}, answer=[Entity(start_offset=65, end_offset=73, type='context', text='The Fixx', normalized_text='fixx')], nq_answers=[[Entity(start_offset=46, end_offset=73, type='context', text='new wave rock band The Fixx', normalized_text='new wave rock band fixx')]], aligned_nps=[(Entity(start_offset=10, end_offset=45, type='question', text='the song one thing leads to another', normalized_text='song one thing leads to another'), Entity(start_offset=3, end_offset=29, type='context', text='One Thing Leads to Another', normalized_text='one thing leads to another'))], explanation_type='single_sentence'),\n",
       " 2926188566262428863: QEDExample(example_id=2926188566262428863, title='Fleet vehicle', question='what does it mean if a car is a fleet vehicle', passage=\"Fleet vehicles are groups of motor vehicles owned or leased by a business , government agency or other organization rather than by an individual or family . Typical examples are vehicles operated by car rental companies , taxicab companies , public utilities , public bus companies , and police departments . In addition , many businesses purchase or lease fleet vehicles to deliver goods to customers , or for sales representatives to travel to clients . In some jurisdictions and countries , fleet vehicle also means vehicles that are privately owned by employees , or on novated leases , but are used for work purposes ; this is called the ' grey fleet ' .\", sentence_starts=[0, 157, 309, 456], selected_sent={'start': 0, 'end': 157, 'string': 'Fleet vehicles are groups of motor vehicles owned or leased by a business , government agency or other organization rather than by an individual or family . '}, answer=[Entity(start_offset=19, end_offset=154, type='context', text='groups of motor vehicles owned or leased by a business , government agency or other organization rather than by an individual or family', normalized_text='groups of motor vehicles owned or leased by business government agency or other organization rather than by individual or family')], nq_answers=[[Entity(start_offset=19, end_offset=154, type='context', text='groups of motor vehicles owned or leased by a business , government agency or other organization rather than by an individual or family', normalized_text='groups of motor vehicles owned or leased by business government agency or other organization rather than by individual or family')], [Entity(start_offset=44, end_offset=154, type='context', text='owned or leased by a business , government agency or other organization rather than by an individual or family', normalized_text='owned or leased by business government agency or other organization rather than by individual or family')]], aligned_nps=[(Entity(start_offset=30, end_offset=45, type='question', text='a fleet vehicle', normalized_text='fleet vehicle'), Entity(start_offset=0, end_offset=14, type='context', text='Fleet vehicles', normalized_text='fleet vehicles'))], explanation_type='single_sentence'),\n",
       " -599106694350296477: QEDExample(example_id=-599106694350296477, title='Roar (song)', question='theme of the song roar by katy perry', passage=\"`` Roar '' is a song by American singer Katy Perry for her fourth studio album , Prism ( 2013 ) . It was released as the lead single from the record on August 10 , 2013 . Perry co-wrote the song with Bonnie McKee and its producers Dr. Luke , Max Martin , and Cirkut . It is a pop song containing elements of arena rock and lyrics centering on standing up for oneself and self - empowerment . Some critics praised the track 's production while others felt that its lyrics contained `` clichés '' .\", sentence_starts=[0, 98, 171, 268, 392], selected_sent={'start': 268, 'end': 392, 'string': 'It is a pop song containing elements of arena rock and lyrics centering on standing up for oneself and self - empowerment . '}, answer=[Entity(start_offset=343, end_offset=389, type='context', text='standing up for oneself and self - empowerment', normalized_text='standing up for oneself and self empowerment')], nq_answers=[[Entity(start_offset=343, end_offset=366, type='context', text='standing up for oneself', normalized_text='standing up for oneself'), Entity(start_offset=371, end_offset=389, type='context', text='self - empowerment', normalized_text='self empowerment')]], aligned_nps=[(Entity(start_offset=9, end_offset=36, type='question', text='the song roar by katy perry', normalized_text='song roar by katy perry'), Entity(start_offset=268, end_offset=270, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 6341281025332348318: QEDExample(example_id=6341281025332348318, title='National Football League Draft', question='who picks the players in the nfl draft', passage=\"The National Football League Draft , also called the Player Selection Meeting , is an annual event in which it serves as the league 's most common source of player recruitment . The basic design of the draft is that each team is given a position in the drafting order in reverse order relative to its record in the previous year , which means that the last place team is positioned first . From this position , the team can either select a player or trade their position to another team for other draft positions , a player or players , or any combination thereof . The round is complete when each team has either selected a player or traded its draft position . Certain aspects of the draft , including team positioning and the number of rounds in the draft , have seen revisions since its first creation in 1936 , but the fundamental methodology has remained the same . Currently the draft consists of seven rounds . The original rationale in creating the draft was to increase the competitive parity between the teams as the worst team would , ideally , have chosen the best player available .\", sentence_starts=[0, 178, 390, 566, 663, 872, 919], selected_sent={'start': 390, 'end': 566, 'string': 'From this position , the team can either select a player or trade their position to another team for other draft positions , a player or players , or any combination thereof . '}, answer=[Entity(start_offset=411, end_offset=419, type='context', text='the team', normalized_text='team')], nq_answers=[[Entity(start_offset=593, end_offset=602, type='context', text='each team', normalized_text='each team')]], aligned_nps=[(Entity(start_offset=25, end_offset=38, type='question', text='the nfl draft', normalized_text='nfl draft'), Entity(start_offset=390, end_offset=408, type='context', text='From this position', normalized_text='from this position'))], explanation_type='single_sentence'),\n",
       " 1656636013570720778: QEDExample(example_id=1656636013570720778, title='California Gold Rush', question='who discovered gold in the sierra nevada of california', passage=\"The California Gold Rush ( 1848 -- 1855 ) began on January 24 , 1848 , when gold was found by James W. Marshall at Sutter 's Mill in Coloma , California . The news of gold brought some 300,000 people to California from the rest of the United States and abroad . The sudden influx of immigration and gold into the money supply reinvigorated the American economy , and California became one of the few American states to go directly to statehood without first being a territory , in the Compromise of 1850 . The Gold Rush had severe effects on Native Californians and resulted in a precipitous population decline from disease , genocide and starvation . By the time it ended , California had gone from a thinly populated ex-Mexican territory to the home state of the first nominee for the Republican Party .\", sentence_starts=[0, 155, 262, 506, 652], selected_sent={'start': 0, 'end': 155, 'string': \"The California Gold Rush ( 1848 -- 1855 ) began on January 24 , 1848 , when gold was found by James W. Marshall at Sutter 's Mill in Coloma , California . \"}, answer=[Entity(start_offset=94, end_offset=111, type='context', text='James W. Marshall', normalized_text='james w marshall')], nq_answers=[[Entity(start_offset=94, end_offset=111, type='context', text='James W. Marshall', normalized_text='james w marshall')]], aligned_nps=[(Entity(start_offset=44, end_offset=54, type='question', text='california', normalized_text='california'), Entity(start_offset=142, end_offset=152, type='context', text='California', normalized_text='california'))], explanation_type='single_sentence'),\n",
       " 6797662554091549033: QEDExample(example_id=6797662554091549033, title='Rear-view mirror', question='which mirror is used in vehicles for rear view', passage=\"A rear - view mirror ( or rearview mirror ) is a mirror in automobiles and other vehicles , designed to allow the driver to see rearward through the vehicle 's rear window ( rear windshield ) .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 193, 'string': \"A rear - view mirror ( or rearview mirror ) is a mirror in automobiles and other vehicles , designed to allow the driver to see rearward through the vehicle 's rear window ( rear windshield ) .\"}, answer=[Entity(start_offset=0, end_offset=43, type='context', text='A rear - view mirror ( or rearview mirror )', normalized_text='rear view mirror or rearview mirror')], nq_answers=[[Entity(start_offset=2, end_offset=20, type='context', text='rear - view mirror', normalized_text='rear view mirror')]], aligned_nps=[(Entity(start_offset=24, end_offset=32, type='question', text='vehicles', normalized_text='vehicles'), Entity(start_offset=59, end_offset=89, type='context', text='automobiles and other vehicles', normalized_text='automobiles and other vehicles'))], explanation_type='single_sentence'),\n",
       " 647605647914971565: QEDExample(example_id=647605647914971565, title='The Phantom of the Opera (1986 musical)', question='who wrote lyrics for phantom of the opera', passage=\"The Phantom of the Opera is a musical with music by Andrew Lloyd Webber and lyrics by Charles Hart and Richard Stilgoe . Lloyd Webber and Stilgoe also wrote the musical 's book together . Based on the French novel Le Fantôme de l'Opéra by Gaston Leroux , its central plot revolves around a beautiful soprano , Christine Daaé , who becomes the obsession of a mysterious , disfigured musical genius living in the subterranean labyrinth beneath the Opera Populaire .\", sentence_starts=[0, 121, 188], selected_sent={'start': 0, 'end': 121, 'string': 'The Phantom of the Opera is a musical with music by Andrew Lloyd Webber and lyrics by Charles Hart and Richard Stilgoe . '}, answer=[Entity(start_offset=86, end_offset=118, type='context', text='Charles Hart and Richard Stilgoe', normalized_text='charles hart and richard stilgoe')], nq_answers=[[Entity(start_offset=86, end_offset=118, type='context', text='Charles Hart and Richard Stilgoe', normalized_text='charles hart and richard stilgoe')], [Entity(start_offset=86, end_offset=98, type='context', text='Charles Hart', normalized_text='charles hart'), Entity(start_offset=103, end_offset=118, type='context', text='Richard Stilgoe', normalized_text='richard stilgoe')]], aligned_nps=[(Entity(start_offset=21, end_offset=41, type='question', text='phantom of the opera', normalized_text='phantom of opera'), Entity(start_offset=0, end_offset=24, type='context', text='The Phantom of the Opera', normalized_text='phantom of opera'))], explanation_type='single_sentence'),\n",
       " 6268706985209815767: QEDExample(example_id=6268706985209815767, title='Mount & Blade: With Fire & Sword', question='mount and blade with fire and sword time period', passage=\"Mount & Blade : With Fire & Sword is a stand - alone expansion for the action role - playing video game Mount & Blade . The game is developed by Sich Studio and TaleWorlds and was published by Paradox Interactive in Europe . The game and its storyline is loosely based on the novel With Fire and Sword by Henryk Sienkiewicz , depicting Poland 's 1648 - 51 war against Khmelnytsky Uprising in Ukraine , and its sequels dealing with the invasion of Poland by Sweden and with Polish wars against the Ottoman Empire .\", sentence_starts=[0, 120, 225], selected_sent={'start': 225, 'end': 513, 'string': \"The game and its storyline is loosely based on the novel With Fire and Sword by Henryk Sienkiewicz , depicting Poland 's 1648 - 51 war against Khmelnytsky Uprising in Ukraine , and its sequels dealing with the invasion of Poland by Sweden and with Polish wars against the Ottoman Empire .\"}, answer=[Entity(start_offset=336, end_offset=511, type='context', text=\"Poland 's 1648 - 51 war against Khmelnytsky Uprising in Ukraine , and its sequels dealing with the invasion of Poland by Sweden and with Polish wars against the Ottoman Empire\", normalized_text='poland s 1648 51 war against khmelnytsky uprising in ukraine and its sequels dealing with invasion of poland by sweden and with polish wars against ottoman empire')], nq_answers=[[Entity(start_offset=346, end_offset=355, type='context', text='1648 - 51', normalized_text='1648 51')]], aligned_nps=[(Entity(start_offset=0, end_offset=35, type='question', text='mount and blade with fire and sword', normalized_text='mount and blade with fire and sword'), Entity(start_offset=225, end_offset=233, type='context', text='The game', normalized_text='game'))], explanation_type='single_sentence'),\n",
       " -508693030088387759: QEDExample(example_id=-508693030088387759, title='Trolls: The Beat Goes On!', question='who plays poppy in the beat goes on', passage=\"Trolls : The Beat Goes On ! is a 2018 American animated television series produced by DreamWorks Animation that is based on the 3D computer - animated musical romantic comedy film Trolls . The series premiered on Netflix on January 19 , 2018 exclusively in the United States , Canada , Latin America , United Kingdom , Ireland , Australia , New Zealand , the Nordics , Benelux , and France . Amanda Leighton , Skylar Astin , Kari Wahlgren , Sam Lerner , David Kaye , David Fynn , Sean T. Krishnan , Kevin Michael Richardson , and Fryda Wolff provide the new voices for Poppy , Branch , Bridget , King Gristle , King Peppy , Biggie , Guy Diamond , Smidge , and DJ Suki and Satin & Chenille for this series respectively ; only Ron Funches and Walt Dohrn reprise their roles as Cooper and Cloud Guy , also respectively . Matt Lowe also voices Creek in the series , who returns in `` Creek Week '' .\", sentence_starts=[0, 189, 392, 818], selected_sent={'start': 392, 'end': 818, 'string': 'Amanda Leighton , Skylar Astin , Kari Wahlgren , Sam Lerner , David Kaye , David Fynn , Sean T. Krishnan , Kevin Michael Richardson , and Fryda Wolff provide the new voices for Poppy , Branch , Bridget , King Gristle , King Peppy , Biggie , Guy Diamond , Smidge , and DJ Suki and Satin & Chenille for this series respectively ; only Ron Funches and Walt Dohrn reprise their roles as Cooper and Cloud Guy , also respectively . '}, answer=[Entity(start_offset=392, end_offset=407, type='context', text='Amanda Leighton', normalized_text='amanda leighton')], nq_answers=[[Entity(start_offset=392, end_offset=407, type='context', text='Amanda Leighton', normalized_text='amanda leighton')]], aligned_nps=[(Entity(start_offset=10, end_offset=15, type='question', text='poppy', normalized_text='poppy'), Entity(start_offset=569, end_offset=574, type='context', text='Poppy', normalized_text='poppy')), (Entity(start_offset=19, end_offset=35, type='question', text='the beat goes on', normalized_text='beat goes on'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 4985796605690666040: QEDExample(example_id=4985796605690666040, title='Shooting ranges in the United States', question='do you have to have a gun permit to shoot at a range', passage='Typically , no license or advanced training beyond just firearm familiarization ( for rentals ) and range rules familiarization is usually required for using a shooting range in the United States ; the only common requirement is that the shooter must be at least 18 or 21 years old ( or have a legal guardian present ) , and must sign a waiver prior to shooting .', sentence_starts=[0], selected_sent={'start': 0, 'end': 363, 'string': 'Typically , no license or advanced training beyond just firearm familiarization ( for rentals ) and range rules familiarization is usually required for using a shooting range in the United States ; the only common requirement is that the shooter must be at least 18 or 21 years old ( or have a legal guardian present ) , and must sign a waiver prior to shooting .'}, answer=[Entity(start_offset=0, end_offset=127, type='context', text='Typically , no license or advanced training beyond just firearm familiarization ( for rentals ) and range rules familiarization', normalized_text='typically no license or advanced training beyond just firearm familiarization for rentals and range rules familiarization')], nq_answers=[[Entity(start_offset=12, end_offset=195, type='context', text='no license or advanced training beyond just firearm familiarization ( for rentals ) and range rules familiarization is usually required for using a shooting range in the United States', normalized_text='no license or advanced training beyond just firearm familiarization for rentals and range rules familiarization is usually required for using shooting range in united states')], [Entity(start_offset=0, end_offset=14, type='context', text='Typically , no', normalized_text='typically no')]], aligned_nps=[(Entity(start_offset=45, end_offset=52, type='question', text='a range', normalized_text='range'), Entity(start_offset=158, end_offset=174, type='context', text='a shooting range', normalized_text='shooting range'))], explanation_type='single_sentence'),\n",
       " 1469385897647131068: QEDExample(example_id=1469385897647131068, title='2015 Rugby World Cup', question='where was the 2015 rugby union world cup held', passage='The 2015 Rugby World Cup was the eighth Rugby World Cup , the quadrennial rugby union world championship . The tournament was hosted by England from 18 September to 31 October . Of the 20 countries competing in the World Cup in 2011 , there was only one change : Uruguay replaced Russia . This was the first World Cup with no new teams to the tournament .', sentence_starts=[0, 107, 178, 289], selected_sent={'start': 107, 'end': 178, 'string': 'The tournament was hosted by England from 18 September to 31 October . '}, answer=[Entity(start_offset=136, end_offset=143, type='context', text='England', normalized_text='england')], nq_answers=[[Entity(start_offset=136, end_offset=143, type='context', text='England', normalized_text='england')]], aligned_nps=[(Entity(start_offset=10, end_offset=40, type='question', text='the 2015 rugby union world cup', normalized_text='2015 rugby union world cup'), Entity(start_offset=107, end_offset=121, type='context', text='The tournament', normalized_text='tournament'))], explanation_type='single_sentence'),\n",
       " -716176363900512091: QEDExample(example_id=-716176363900512091, title='Deposition (phase transition)', question='phase change from gas to solid is called', passage='Deposition is a thermodynamic process , a phase transition in which gas transforms into solid without passing through the liquid phase . The reverse of deposition is sublimation and hence sometimes deposition is called desublimation .', sentence_starts=[0, 137], selected_sent={'start': 0, 'end': 137, 'string': 'Deposition is a thermodynamic process , a phase transition in which gas transforms into solid without passing through the liquid phase . '}, answer=[Entity(start_offset=0, end_offset=10, type='context', text='Deposition', normalized_text='deposition')], nq_answers=[[Entity(start_offset=0, end_offset=10, type='context', text='Deposition', normalized_text='deposition'), Entity(start_offset=219, end_offset=232, type='context', text='desublimation', normalized_text='desublimation')], [Entity(start_offset=0, end_offset=10, type='context', text='Deposition', normalized_text='deposition')]], aligned_nps=[(Entity(start_offset=0, end_offset=30, type='question', text='phase change from gas to solid', normalized_text='phase change from gas to solid'), Entity(start_offset=40, end_offset=134, type='context', text='a phase transition in which gas transforms into solid without passing through the liquid phase', normalized_text='phase transition in which gas transforms into solid without passing through liquid phase'))], explanation_type='single_sentence'),\n",
       " 4245798066923223457: QEDExample(example_id=4245798066923223457, title='NBA All-Star Game Most Valuable Player Award', question='who has the most all star mvp awards', passage=\"Bob Pettit and Kobe Bryant are the only two players to win the All - Star Game MVP four times . Oscar Robertson , Michael Jordan , Shaquille O'Neal , and LeBron James have each won the award three times , while Bob Cousy , Julius Erving , Isiah Thomas , Magic Johnson , Karl Malone , Allen Iverson , and Russell Westbrook have all won the award twice . James ' first All - Star MVP in 2006 made him the youngest to have ever won the award at the age of 21 years , 1 month . Kyrie Irving , winner of the 2014 All - Star Game MVP , is the second - youngest at 21 years , 10 months . They are notable as being the two youngest to win the award , both as Cleveland Cavaliers . Four of the games had joint winners -- Elgin Baylor and Pettit in 1959 , John Stockton and Malone in 1993 , O'Neal and Tim Duncan in 2000 , and O'Neal and Bryant in 2009 . O'Neal became the first player in All - Star history to share two MVP awards as well as the first player to win the award with multiple teams . The Los Angeles Lakers have had eleven winners while the Boston Celtics have had eight . Duncan of the U.S. Virgin Islands and Irving of Australia are the only winners not born in the United States . Both Duncan and Irving are American citizens , but are considered `` international '' players by the NBA because they were not born in one of the fifty states or Washington , D.C. No player trained entirely outside the U.S. has won the award ; Irving lived in the U.S. since age two , and Duncan played U.S. college basketball at Wake Forest .\", sentence_starts=[0, 96, 353, 474, 581, 673, 845, 989, 1078, 1189, 1369], selected_sent={'start': 0, 'end': 96, 'string': 'Bob Pettit and Kobe Bryant are the only two players to win the All - Star Game MVP four times . '}, answer=[Entity(start_offset=0, end_offset=26, type='context', text='Bob Pettit and Kobe Bryant', normalized_text='bob pettit and kobe bryant')], nq_answers=[[Entity(start_offset=0, end_offset=10, type='context', text='Bob Pettit', normalized_text='bob pettit'), Entity(start_offset=15, end_offset=26, type='context', text='Kobe Bryant', normalized_text='kobe bryant')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -774521643378360615: QEDExample(example_id=-774521643378360615, title='pH', question='what is the definition of ph in water', passage='In chemistry , pH ( / piːˈ ( h ) eɪ tʃ / ) ( potential of hydrogen ) is a numeric scale used to specify the acidity or basicity of an aqueous solution . It is approximately the negative of the base 10 logarithm of the molar concentration , measured in units of moles per liter , of hydrogen ions . More precisely it is the negative of the base 10 logarithm of the activity of the hydrogen ion . Solutions with a pH less than 7 are acidic and solutions with a pH greater than 7 are basic . Pure water is neutral , at pH 7 ( 25 ° C ) , being neither an acid nor a base . Contrary to popular belief , the pH value can be less than 0 or greater than 14 for very strong acids and bases respectively .', sentence_starts=[0, 153, 298, 395, 489, 569], selected_sent={'start': 489, 'end': 569, 'string': 'Pure water is neutral , at pH 7 ( 25 ° C ) , being neither an acid nor a base . '}, answer=[Entity(start_offset=503, end_offset=520, type='context', text='neutral , at pH 7', normalized_text='neutral at ph 7')], nq_answers=[[Entity(start_offset=503, end_offset=566, type='context', text='neutral , at pH 7 ( 25 ° C ) , being neither an acid nor a base', normalized_text='neutral at ph 7 25 ° c being neither acid nor base')], [Entity(start_offset=45, end_offset=66, type='context', text='potential of hydrogen', normalized_text='potential of hydrogen')]], aligned_nps=[(Entity(start_offset=32, end_offset=37, type='question', text='water', normalized_text='water'), Entity(start_offset=489, end_offset=499, type='context', text='Pure water', normalized_text='pure water'))], explanation_type='single_sentence'),\n",
       " -4418682909598136345: QEDExample(example_id=-4418682909598136345, title=\"Edible bird's nest\", question=\"where does bird's nest soup come from\", passage=\"Edible bird 's nests are bird nests created by edible - nest swiftlets using solidified saliva , which are harvested for human consumption . They are particularly prized in Chinese culture due to their rarity , and supposedly high nutritional value and exquisite flavor . Edible bird 's nests are among the most expensive animal products consumed by humans , with nests being sold recently at prices up to about US $ 2,000 per kilogram , depending on grading . The type or grading of bird 's nest depends on the type of bird as well as the diet of the bird . It differs in colour from white to dark brown . The Chinese believe that it promotes good health , especially for the skin . The nests have been used in Chinese cooking for over 400 years , most often as bird 's nest soup .\", sentence_starts=[0, 141, 272, 461, 559, 607, 684], selected_sent={'start': 684, 'end': 782, 'string': \"The nests have been used in Chinese cooking for over 400 years , most often as bird 's nest soup .\"}, answer=[Entity(start_offset=712, end_offset=719, type='context', text='Chinese', normalized_text='chinese')], nq_answers=[[Entity(start_offset=25, end_offset=94, type='context', text='bird nests created by edible - nest swiftlets using solidified saliva', normalized_text='bird nests created by edible nest swiftlets using solidified saliva')]], aligned_nps=[(Entity(start_offset=11, end_offset=27, type='question', text=\"bird's nest soup\", normalized_text='birds nest soup'), Entity(start_offset=763, end_offset=780, type='context', text=\"bird 's nest soup\", normalized_text='bird s nest soup'))], explanation_type='single_sentence'),\n",
       " -4809486218828226485: QEDExample(example_id=-4809486218828226485, title='Startup neutron source', question='where do the neutrons come from in nuclear fission', passage='Startup neutron source is a neutron source used for stable and reliable initiation of nuclear chain reaction in nuclear reactors , when they are loaded with fresh nuclear fuel , whose neutron flux from spontaneous fission is insufficient for a reliable startup , or after prolonged shutdown periods . Neutron sources ensure a constant minimal population of neutrons in the reactor core , sufficient for a smooth startup . Without them , the reactor could suffer fast power excursions during startup from state with too few self - generated neutrons ( new core or after extended shutdown ) .', sentence_starts=[0, 301, 422], selected_sent={'start': 0, 'end': 301, 'string': 'Startup neutron source is a neutron source used for stable and reliable initiation of nuclear chain reaction in nuclear reactors , when they are loaded with fresh nuclear fuel , whose neutron flux from spontaneous fission is insufficient for a reliable startup , or after prolonged shutdown periods . '}, answer=[Entity(start_offset=0, end_offset=22, type='context', text='Startup neutron source', normalized_text='startup neutron source')], nq_answers=[[Entity(start_offset=0, end_offset=22, type='context', text='Startup neutron source', normalized_text='startup neutron source')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -58163792752112756: QEDExample(example_id=-58163792752112756, title='South Carolina in the American Civil War', question='what was one reason south carolina gave for its decision to secede from the union', passage=\"Alfred P. Aldrich , a South Carolinian politician from Barnwell , stated that declaring secession would be necessary if a Republican candidate were to win the 1860 U.S. presidential election , stating that it was the only way for the state to preserve slavery and diminish the influence of the anti-slavery Republican Party , which , were its goals of abolition realized , would result in the `` destruction of the South '' :\", sentence_starts=[0], selected_sent={'start': 0, 'end': 425, 'string': \"Alfred P. Aldrich , a South Carolinian politician from Barnwell , stated that declaring secession would be necessary if a Republican candidate were to win the 1860 U.S. presidential election , stating that it was the only way for the state to preserve slavery and diminish the influence of the anti-slavery Republican Party , which , were its goals of abolition realized , would result in the `` destruction of the South '' :\"}, answer=[Entity(start_offset=206, end_offset=423, type='context', text=\"it was the only way for the state to preserve slavery and diminish the influence of the anti-slavery Republican Party , which , were its goals of abolition realized , would result in the `` destruction of the South ''\", normalized_text='it was only way for state to preserve slavery and diminish influence of antislavery republican party which were its goals of abolition realized would result in destruction of south')], nq_answers=[[Entity(start_offset=240, end_offset=259, type='context', text='to preserve slavery', normalized_text='to preserve slavery'), Entity(start_offset=264, end_offset=323, type='context', text='diminish the influence of the anti-slavery Republican Party', normalized_text='diminish influence of antislavery republican party')], [Entity(start_offset=206, end_offset=423, type='context', text=\"it was the only way for the state to preserve slavery and diminish the influence of the anti-slavery Republican Party , which , were its goals of abolition realized , would result in the `` destruction of the South ''\", normalized_text='it was only way for state to preserve slavery and diminish influence of antislavery republican party which were its goals of abolition realized would result in destruction of south')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 5537254681877187953: QEDExample(example_id=5537254681877187953, title='Full-time', question='hours of work to be considered full time', passage=\"Full - time employment is employment in which a person works a minimum number of hours defined as such by his / her employer . Full - time employment often comes with benefits that are not typically offered to part - time , temporary , or flexible workers , such as annual leave , sickleave , and health insurance . Part - time jobs are mistakenly thought by some to not be careers . However , legislation exists to stop employers from discriminating against part - time workers so this should not be a factor when making decisions on career advancement . They generally pay more than part - time jobs per hour , and this is similarly discriminatory if the pay decision is based on part - time status as a primary factor . The Fair Labor Standards Act ( FLSA ) does not define full - time employment or part - time employment . This is a matter generally to be determined by the employer ( US Department of Labor ) . The definition by employer can vary and is generally published in a company 's Employee Handbook . Companies commonly require from 35 to 40 hours per week to be defined as full - time and therefore eligible for benefits .\", sentence_starts=[0, 127, 316, 384, 556, 723, 828, 917, 1016], selected_sent={'start': 1016, 'end': 1138, 'string': 'Companies commonly require from 35 to 40 hours per week to be defined as full - time and therefore eligible for benefits .'}, answer=[Entity(start_offset=1048, end_offset=1071, type='context', text='35 to 40 hours per week', normalized_text='35 to 40 hours per week')], nq_answers=[[Entity(start_offset=1043, end_offset=1071, type='context', text='from 35 to 40 hours per week', normalized_text='from 35 to 40 hours per week')], [Entity(start_offset=1048, end_offset=1071, type='context', text='35 to 40 hours per week', normalized_text='35 to 40 hours per week')], [Entity(start_offset=1016, end_offset=1100, type='context', text='Companies commonly require from 35 to 40 hours per week to be defined as full - time', normalized_text='companies commonly require from 35 to 40 hours per week to be defined as full time')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 6309445075358131629: QEDExample(example_id=6309445075358131629, title='The Birds and the Bees (Jewel Akens song)', question='who sang let me tell you about the birds and the bees', passage=\"`` The Birds and the Bees '' was a 1964 single release by Jewel Akens with a lyric based on the `` birds and the bees '' idiom commonly referenced with regard to affording young people their introductory sex education . An international hit in 1965 , `` The Birds and the Bees '' was reminiscent of such 1950s ' honky tonk - style hits as `` Blueberry Hill '' by Fats Domino and `` Kansas City '' by Wilbert Harrison .\", sentence_starts=[0, 220], selected_sent={'start': 0, 'end': 220, 'string': \"`` The Birds and the Bees '' was a 1964 single release by Jewel Akens with a lyric based on the `` birds and the bees '' idiom commonly referenced with regard to affording young people their introductory sex education . \"}, answer=[Entity(start_offset=58, end_offset=69, type='context', text='Jewel Akens', normalized_text='jewel akens')], nq_answers=[[Entity(start_offset=58, end_offset=69, type='context', text='Jewel Akens', normalized_text='jewel akens')]], aligned_nps=[(Entity(start_offset=9, end_offset=53, type='question', text='let me tell you about the birds and the bees', normalized_text='let me tell you about birds and bees'), Entity(start_offset=3, end_offset=25, type='context', text='The Birds and the Bees', normalized_text='birds and bees'))], explanation_type='single_sentence'),\n",
       " 5487540490957673313: QEDExample(example_id=5487540490957673313, title='List of Super Bowl champions', question='who has more super bowl wins nfc or afc', passage=\"Before the 1970 merger between the American Football League ( AFL ) and the National Football League ( NFL ) , the two leagues met in four such contests . The first two were known as the `` AFL -- NFL World Championship Game '' . Super Bowl III in January 1969 was the first such game that carried the `` Super Bowl '' moniker , the names `` Super Bowl I '' and `` Super Bowl II '' were only retroactively applied to the first two games . The NFC / NFL leads in Super Bowl wins with 26 , while the AFC / AFL has won 25 . Nineteen different franchises , including teams that relocated to another city , have won the Super Bowl .\", sentence_starts=[0, 155, 230, 439, 521], selected_sent={'start': 439, 'end': 521, 'string': 'The NFC / NFL leads in Super Bowl wins with 26 , while the AFC / AFL has won 25 . '}, answer=[Entity(start_offset=439, end_offset=452, type='context', text='The NFC / NFL', normalized_text='nfc nfl')], nq_answers=[[Entity(start_offset=443, end_offset=452, type='context', text='NFC / NFL', normalized_text='nfc nfl')], [Entity(start_offset=443, end_offset=446, type='context', text='NFC', normalized_text='nfc')]], aligned_nps=[(Entity(start_offset=29, end_offset=32, type='question', text='nfc', normalized_text='nfc'), Entity(start_offset=439, end_offset=452, type='context', text='The NFC / NFL', normalized_text='nfc nfl')), (Entity(start_offset=13, end_offset=23, type='question', text='super bowl', normalized_text='super bowl'), Entity(start_offset=462, end_offset=472, type='context', text='Super Bowl', normalized_text='super bowl')), (Entity(start_offset=36, end_offset=39, type='question', text='afc', normalized_text='afc'), Entity(start_offset=494, end_offset=507, type='context', text='the AFC / AFL', normalized_text='afc afl'))], explanation_type='single_sentence'),\n",
       " 8654444840445750317: QEDExample(example_id=8654444840445750317, title='Steffy Forrester', question=\"who is stephanie's mom on the bold and the beautiful\", passage=\"Steffy Forrester is a fictional character from the American CBS soap opera The Bold and the Beautiful . Introduced by Bradley Bell , she is currently portrayed by Jacqueline MacInnes Wood . Steffy and her twin sister Phoebe ( MacKenzie Mauzy ) were born onscreen as the daughters of supercouple Ridge Forrester ( Ronn Moss , later Thorsten Kaye ) and Taylor Hayes ( Hunter Tylo ) during the episode airing on September 21 , 1999 . For the character 's first five - year period , she appeared as a minor . In 2005 , Steffy was rapidly aged to a teenager , and in 2008 she appeared as an adult when Wood took over the role . Wood portrayed the role continuously until 2013 , when she decided to leave her regular capacity with the series ; following a series of guest appearances , Wood returned as a series regular in 2015 .\", sentence_starts=[0, 104, 190, 431, 505, 623], selected_sent={'start': 104, 'end': 190, 'string': 'Introduced by Bradley Bell , she is currently portrayed by Jacqueline MacInnes Wood . '}, answer=[Entity(start_offset=163, end_offset=187, type='context', text='Jacqueline MacInnes Wood', normalized_text='jacqueline macinnes wood')], nq_answers=[[Entity(start_offset=295, end_offset=310, type='context', text='Ridge Forrester', normalized_text='ridge forrester')], [Entity(start_offset=351, end_offset=363, type='context', text='Taylor Hayes', normalized_text='taylor hayes')], [Entity(start_offset=366, end_offset=377, type='context', text='Hunter Tylo', normalized_text='hunter tylo')]], aligned_nps=[(Entity(start_offset=7, end_offset=22, type='question', text=\"stephanie's mom\", normalized_text='stephanies mom'), Entity(start_offset=133, end_offset=136, type='context', text='she', normalized_text='she')), (Entity(start_offset=26, end_offset=52, type='question', text='the bold and the beautiful', normalized_text='bold and beautiful'), Entity(start_offset=150, end_offset=159, type='context', text='portrayed', normalized_text='portrayed'))], explanation_type='single_sentence'),\n",
       " 6872093854408039409: QEDExample(example_id=6872093854408039409, title='Fold mountains', question='what tectonic setting is responsible for the folded mountains of pennsylvania and the high himalaya', passage='Fold mountains form when two tectonic plates move towards each other at a convergent plate boundary . Fold mountains form from sedimentary rocks that accumulate along the margins of continents . When plates and the continents riding on them collide , the accumulated layers of rock may crumple and fold like a tablecloth that is pushed across a table , particularly if there is a mechanically weak layer such as salt .', sentence_starts=[0, 102, 195], selected_sent={'start': 0, 'end': 102, 'string': 'Fold mountains form when two tectonic plates move towards each other at a convergent plate boundary . '}, answer=[Entity(start_offset=72, end_offset=99, type='context', text='a convergent plate boundary', normalized_text='convergent plate boundary')], nq_answers=[[Entity(start_offset=72, end_offset=99, type='context', text='a convergent plate boundary', normalized_text='convergent plate boundary')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -8022345911863395279: QEDExample(example_id=-8022345911863395279, title='Trinitarian formula', question='the father son and holy spirit in latin', passage=\"The trinitarian formula is the phrase `` in the name of the Father , and of the Son , and of the Holy Spirit '' ( original Greek εἰς τὸ ὄνομα τοῦ Πατρὸς καὶ τοῦ Υἱοῦ καὶ τοῦ Ἁγίου Πνεύματος , eis to onoma tou Patros kai tou Huiou kai tou Hagiou Pneumatos , or in Latin in nomine Patris et Filii et Spiritus Sancti ) , or words to that form and effect referring to the three persons of the Christian Trinity . It is often followed by an `` Amen '' .\", sentence_starts=[0, 409], selected_sent={'start': 0, 'end': 409, 'string': \"The trinitarian formula is the phrase `` in the name of the Father , and of the Son , and of the Holy Spirit '' ( original Greek εἰς τὸ ὄνομα τοῦ Πατρὸς καὶ τοῦ Υἱοῦ καὶ τοῦ Ἁγίου Πνεύματος , eis to onoma tou Patros kai tou Huiou kai tou Hagiou Pneumatos , or in Latin in nomine Patris et Filii et Spiritus Sancti ) , or words to that form and effect referring to the three persons of the Christian Trinity . \"}, answer=[Entity(start_offset=269, end_offset=313, type='context', text='in nomine Patris et Filii et Spiritus Sancti', normalized_text='in nomine patris et filii et spiritus sancti')], nq_answers=[[Entity(start_offset=269, end_offset=313, type='context', text='in nomine Patris et Filii et Spiritus Sancti', normalized_text='in nomine patris et filii et spiritus sancti')], [Entity(start_offset=279, end_offset=313, type='context', text='Patris et Filii et Spiritus Sancti', normalized_text='patris et filii et spiritus sancti')]], aligned_nps=[(Entity(start_offset=34, end_offset=39, type='question', text='latin', normalized_text='latin'), Entity(start_offset=263, end_offset=268, type='context', text='Latin', normalized_text='latin')), (Entity(start_offset=0, end_offset=30, type='question', text='the father son and holy spirit', normalized_text='father son and holy spirit'), Entity(start_offset=27, end_offset=315, type='context', text=\"the phrase `` in the name of the Father , and of the Son , and of the Holy Spirit '' ( original Greek εἰς τὸ ὄνομα τοῦ Πατρὸς καὶ τοῦ Υἱοῦ καὶ τοῦ Ἁγίου Πνεύματος , eis to onoma tou Patros kai tou Huiou kai tou Hagiou Pneumatos , or in Latin in nomine Patris et Filii et Spiritus Sancti )\", normalized_text='phrase in name of father and of son and of holy spirit original greek εἰς τὸ ὄνομα τοῦ πατρὸς καὶ τοῦ υἱοῦ καὶ τοῦ ἁγίου πνεύματος eis to onoma tou patros kai tou huiou kai tou hagiou pneumatos or in latin in nomine patris et filii et spiritus sancti'))], explanation_type='single_sentence'),\n",
       " -5491608596844802544: QEDExample(example_id=-5491608596844802544, title='British anti-invasion preparations of 1803–05', question='why did britain declare war on france in 1803', passage=\"British anti-invasion preparations of 1803 -- 05 were the military and civilian responses in the United Kingdom to Napoleon 's planned invasion of the United Kingdom . They included mobilization of the population on a scale not previously attempted in Britain , with a combined military force of over 615,000 in December 1803 . Much of the southern English coast was fortified to repel a French landing . However Napoleon never attempted his planned invasion and so the preparations were never put to the test .\", sentence_starts=[0, 168, 328, 405], selected_sent={'start': 0, 'end': 168, 'string': \"British anti-invasion preparations of 1803 -- 05 were the military and civilian responses in the United Kingdom to Napoleon 's planned invasion of the United Kingdom . \"}, answer=[Entity(start_offset=115, end_offset=165, type='context', text=\"Napoleon 's planned invasion of the United Kingdom\", normalized_text='napoleon s planned invasion of united kingdom')], nq_answers=[[Entity(start_offset=115, end_offset=165, type='context', text=\"Napoleon 's planned invasion of the United Kingdom\", normalized_text='napoleon s planned invasion of united kingdom')]], aligned_nps=[(Entity(start_offset=41, end_offset=45, type='question', text='1803', normalized_text='1803'), Entity(start_offset=38, end_offset=42, type='context', text='1803', normalized_text='1803')), (Entity(start_offset=8, end_offset=15, type='question', text='britain', normalized_text='britain'), Entity(start_offset=93, end_offset=111, type='context', text='the United Kingdom', normalized_text='united kingdom'))], explanation_type='single_sentence'),\n",
       " 1065612251914840415: QEDExample(example_id=1065612251914840415, title=\"Say You'll Haunt Me\", question=\"who is the girl in the stone sour video say you'll haunt me\", passage=\"The video begins with a car ( 1972 Plymouth Barracuda ) pulling into a creepy alleyway with Corey Taylor being pulled out of the trunk by his bandmates . He is then lead upstairs to be strapped into a chair and interrogated by a woman ( Joanna Moskawa ) who seems to have an aggression towards him . As this is happening , ghostly images of the band perform in front of each member , the video also features these images solo inside an abandoned warehouse including Taylor . Taylor is then blindfolded and then a weird screen is brought out . Corey then walks into the room from the shadows , with a shaved head , wearing a suit and sunglasses . He takes the sunglasses off and then the blindfold is removed , revealing the woman from before . At the end of the solo and the final `` everything to '' shaved Corey presses the button and the other Corey is then seen singing on the screen . The lady panics from this sight and the rest of the band have smiles on their faces . At the end of the video the band leaves the lady tied . Right before it fades to black , the screen says `` What did you see ? '' This was part of a contest that the band held to see the concept of the video , which had a code which read `` I am you '' which explains the fact Corey was replaced with the woman .\", sentence_starts=[0, 154, 300, 475, 543, 646, 744, 890, 976, 1032, 1106], selected_sent={'start': 154, 'end': 300, 'string': 'He is then lead upstairs to be strapped into a chair and interrogated by a woman ( Joanna Moskawa ) who seems to have an aggression towards him . '}, answer=[Entity(start_offset=237, end_offset=251, type='context', text='Joanna Moskawa', normalized_text='joanna moskawa')], nq_answers=[[Entity(start_offset=237, end_offset=251, type='context', text='Joanna Moskawa', normalized_text='joanna moskawa')]], aligned_nps=[(Entity(start_offset=19, end_offset=59, type='question', text=\"the stone sour video say you'll haunt me\", normalized_text='stone sour video say youll haunt me'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 4258647591080003263: QEDExample(example_id=4258647591080003263, title='List of The Lion King characters', question='what kind of bird is in the lion king', passage=\"Zazu ( voiced by Rowan Atkinson in The Lion King , Edward Hibbert in Timon & Pumbaa , The Lion King II : Simba 's Pride , and The Lion King 11⁄2 , and Jeff Bennett in The Lion Guard ) is a red - billed hornbill and majordomo to Mufasa and later Simba . After Mufasa 's death , Zazu becomes a prisoner of Scar before Pumbaa breaks the bone cage releasing him when Simba returns to the Pride Lands . He eventually acts as a scout and advises Simba on royal protocol . In the musical , Zazu is a puppet controlled by an actor dressed in blue striped clothes and a bowler hat , much like a stereotypical butler . Zazu 's blue feathers have been replaced with white and the puppet is partially constructed from parachute silk with a slinky contained in the neck for ease in movement .\", sentence_starts=[0, 253, 398, 466, 609], selected_sent={'start': 0, 'end': 253, 'string': \"Zazu ( voiced by Rowan Atkinson in The Lion King , Edward Hibbert in Timon & Pumbaa , The Lion King II : Simba 's Pride , and The Lion King 11⁄2 , and Jeff Bennett in The Lion Guard ) is a red - billed hornbill and majordomo to Mufasa and later Simba . \"}, answer=[Entity(start_offset=187, end_offset=210, type='context', text='a red - billed hornbill', normalized_text='red billed hornbill')], nq_answers=[[Entity(start_offset=187, end_offset=210, type='context', text='a red - billed hornbill', normalized_text='red billed hornbill')], [Entity(start_offset=189, end_offset=210, type='context', text='red - billed hornbill', normalized_text='red billed hornbill')]], aligned_nps=[(Entity(start_offset=24, end_offset=37, type='question', text='the lion king', normalized_text='lion king'), Entity(start_offset=35, end_offset=48, type='context', text='The Lion King', normalized_text='lion king'))], explanation_type='single_sentence'),\n",
       " -1626541047372980132: QEDExample(example_id=-1626541047372980132, title='Red Guards', question='when did the red guards start and end', passage=\"Red Guards ( simplified Chinese : 红 卫兵 ; traditional Chinese : 紅衛兵 ; pinyin : Hóng Wèibīng ) were a student mass paramilitary social movement mobilized by Mao Zedong in 1966 and 1967 , during the Cultural Revolution . According to a Red Guard leader , the movement 's aims were as follows :\", sentence_starts=[0, 218], selected_sent={'start': 0, 'end': 218, 'string': 'Red Guards ( simplified Chinese : 红 卫兵 ; traditional Chinese : 紅衛兵 ; pinyin : Hóng Wèibīng ) were a student mass paramilitary social movement mobilized by Mao Zedong in 1966 and 1967 , during the Cultural Revolution . '}, answer=[Entity(start_offset=169, end_offset=182, type='context', text='1966 and 1967', normalized_text='1966 and 1967')], nq_answers=[[Entity(start_offset=169, end_offset=182, type='context', text='1966 and 1967', normalized_text='1966 and 1967')], [Entity(start_offset=166, end_offset=182, type='context', text='in 1966 and 1967', normalized_text='in 1966 and 1967')]], aligned_nps=[(Entity(start_offset=9, end_offset=23, type='question', text='the red guards', normalized_text='red guards'), Entity(start_offset=0, end_offset=92, type='context', text='Red Guards ( simplified Chinese : 红 卫兵 ; traditional Chinese : 紅衛兵 ; pinyin : Hóng Wèibīng )', normalized_text='red guards simplified chinese 红 卫兵 traditional chinese 紅衛兵 pinyin hóng wèibīng'))], explanation_type='single_sentence'),\n",
       " -693847391395525804: QEDExample(example_id=-693847391395525804, title='Library Literature and Information Science', question='what type of database is library literature and information science', passage='Library Literature and Information Science is a bibliographic database that indexes over 410 library and information science periodicals published internationally . It also covers books , chapters within books , library school theses , and pamphlets . In 2011 , the H.W. Wilson Company , the firm that created the index , sold it to EBSCO Publishing along with other H.W. Wilson indexes and databases .', sentence_starts=[0, 165, 252, 271, 372], selected_sent={'start': 0, 'end': 165, 'string': 'Library Literature and Information Science is a bibliographic database that indexes over 410 library and information science periodicals published internationally . '}, answer=[Entity(start_offset=48, end_offset=61, type='context', text='bibliographic', normalized_text='bibliographic')], nq_answers=[[Entity(start_offset=48, end_offset=61, type='context', text='bibliographic', normalized_text='bibliographic')], [Entity(start_offset=48, end_offset=70, type='context', text='bibliographic database', normalized_text='bibliographic database')]], aligned_nps=[(Entity(start_offset=25, end_offset=67, type='question', text='library literature and information science', normalized_text='library literature and information science'), Entity(start_offset=0, end_offset=42, type='context', text='Library Literature and Information Science', normalized_text='library literature and information science'))], explanation_type='single_sentence'),\n",
       " 4019335299699332844: QEDExample(example_id=4019335299699332844, title='From Russia with Love (soundtrack)', question='who sang the theme song from russia with love', passage=\"John Barry , arranger of Monty Norman 's `` James Bond Theme '' for Dr. No , would be the dominant Bond series composer for most of its history and the inspiration for fellow series composer , David Arnold ( who uses cues from this soundtrack in his own for Tomorrow Never Dies ) . The theme song was composed by Lionel Bart of Oliver ! fame and sung by Matt Monro .\", sentence_starts=[0, 282, 337], selected_sent={'start': 282, 'end': 366, 'string': 'The theme song was composed by Lionel Bart of Oliver ! fame and sung by Matt Monro .'}, answer=[Entity(start_offset=354, end_offset=364, type='context', text='Matt Monro', normalized_text='matt monro')], nq_answers=[[Entity(start_offset=354, end_offset=364, type='context', text='Matt Monro', normalized_text='matt monro')]], aligned_nps=[(Entity(start_offset=9, end_offset=45, type='question', text='the theme song from russia with love', normalized_text='theme song from russia with love'), Entity(start_offset=282, end_offset=296, type='context', text='The theme song', normalized_text='theme song'))], explanation_type='single_sentence'),\n",
       " 8852834747561852791: QEDExample(example_id=8852834747561852791, title='Germ theory of disease', question='who established the idea that microorganisms play a role in disease', passage=\"The Italian Agostino Bassi was the first person to prove that a disease was caused by a microorganism when he conducted a series of experiments between 1808 and 1813 , demonstrating that a `` vegetable parasite '' caused a disease in silkworms known as calcinaccio -- this disease was devastating the French silk industry at the time . The `` vegetable parasite '' is now known to be a fungus pathogenic to insects called Beauveria bassiana ( named after Bassi ) .\", sentence_starts=[0, 336], selected_sent={'start': 0, 'end': 336, 'string': \"The Italian Agostino Bassi was the first person to prove that a disease was caused by a microorganism when he conducted a series of experiments between 1808 and 1813 , demonstrating that a `` vegetable parasite '' caused a disease in silkworms known as calcinaccio -- this disease was devastating the French silk industry at the time . \"}, answer=[Entity(start_offset=12, end_offset=26, type='context', text='Agostino Bassi', normalized_text='agostino bassi')], nq_answers=[[Entity(start_offset=12, end_offset=26, type='context', text='Agostino Bassi', normalized_text='agostino bassi')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 8095779539186493860: QEDExample(example_id=8095779539186493860, title='Commonwealth (U.S. state)', question='how many us states are commonwealths and which states are they', passage=\"Commonwealth is a designation used by four of the 50 states of the United States in their full official state names : Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia ) , Massachusetts , Pennsylvania , and Virginia . Each was , prior to 1776 , a British colony , or parts thereof , and share a strong influence of English common law in some of their laws and institutions .\", sentence_starts=[0, 313], selected_sent={'start': 0, 'end': 313, 'string': \"Commonwealth is a designation used by four of the 50 states of the United States in their full official state names : Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia ) , Massachusetts , Pennsylvania , and Virginia . \"}, answer=[Entity(start_offset=38, end_offset=310, type='context', text=\"four of the 50 states of the United States in their full official state names : Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia ) , Massachusetts , Pennsylvania , and Virginia\", normalized_text='four of 50 states of united states in their full official state names kentucky law creating kentucky names it state of kentucky but it was originally part of land grant of colony of virginia massachusetts pennsylvania and virginia')], nq_answers=[[Entity(start_offset=118, end_offset=126, type='context', text='Kentucky', normalized_text='kentucky'), Entity(start_offset=267, end_offset=280, type='context', text='Massachusetts', normalized_text='massachusetts'), Entity(start_offset=283, end_offset=295, type='context', text='Pennsylvania', normalized_text='pennsylvania'), Entity(start_offset=302, end_offset=310, type='context', text='Virginia', normalized_text='virginia')]], aligned_nps=[(Entity(start_offset=9, end_offset=11, type='question', text='us', normalized_text='us'), Entity(start_offset=63, end_offset=80, type='context', text='the United States', normalized_text='united states'))], explanation_type='single_sentence'),\n",
       " 4989141810567668595: QEDExample(example_id=4989141810567668595, title='Kaley Cuoco', question='who is the actress that plays penny on the big bang theory', passage=\"Kaley Christine Cuoco ( / ˈkeɪli ˈkwoʊkoʊ / KAY - lee KWOH - koh ; born November 30 , 1985 ) is an American actress . After a series of supporting film and television roles in the late 1990s , she landed her breakthrough role as Bridget Hennessy on the ABC sitcom 8 Simple Rules , on which she starred from 2002 to 2005 . Thereafter , Cuoco appeared as Billie Jenkins on the final season of the television series Charmed ( 2005 -- 2006 ) . Since 2007 , she has starred as Penny on the CBS sitcom The Big Bang Theory , for which she has received Satellite , Critics ' Choice , and People 's Choice Awards . Cuoco 's film work includes roles in To Be Fat like Me ( 2007 ) , Hop ( 2011 ) and Authors Anonymous ( 2014 ) . She received a star on the Hollywood Walk of Fame in 2014 . In October 2017 , Cuoco founded Yes , Norman Productions .\", sentence_starts=[0, 118, 322, 440, 606, 718, 778], selected_sent={'start': 440, 'end': 606, 'string': \"Since 2007 , she has starred as Penny on the CBS sitcom The Big Bang Theory , for which she has received Satellite , Critics ' Choice , and People 's Choice Awards . \"}, answer=[Entity(start_offset=0, end_offset=21, type='context', text='Kaley Christine Cuoco', normalized_text='kaley christine cuoco')], nq_answers=[[Entity(start_offset=0, end_offset=21, type='context', text='Kaley Christine Cuoco', normalized_text='kaley christine cuoco')]], aligned_nps=[(Entity(start_offset=30, end_offset=35, type='question', text='penny', normalized_text='penny'), Entity(start_offset=472, end_offset=477, type='context', text='Penny', normalized_text='penny')), (Entity(start_offset=39, end_offset=58, type='question', text='the big bang theory', normalized_text='big bang theory'), Entity(start_offset=481, end_offset=515, type='context', text='the CBS sitcom The Big Bang Theory', normalized_text='cbs sitcom big bang theory'))], explanation_type='single_sentence'),\n",
       " -435045979542112632: QEDExample(example_id=-435045979542112632, title='Princes in the Tower', question='who was the father of the princes in the tower', passage=\"`` The Princes in the Tower '' is an expression frequently used to refer to Edward V , King of England and Richard of Shrewsbury , Duke of York . The two brothers were the only sons of Edward IV of England and Elizabeth Woodville surviving at the time of their father 's death in 1483 . When they were 12 and 9 years old , respectively , they were lodged in the Tower of London by the man appointed to look after them , their uncle , the Lord Protector : Richard , Duke of Gloucester . This was supposedly in preparation for Edward 's forthcoming coronation as king . However , Richard took the throne for himself and the boys disappeared .\", sentence_starts=[0, 146, 287, 486, 568], selected_sent={'start': 146, 'end': 287, 'string': \"The two brothers were the only sons of Edward IV of England and Elizabeth Woodville surviving at the time of their father 's death in 1483 . \"}, answer=[Entity(start_offset=185, end_offset=205, type='context', text='Edward IV of England', normalized_text='edward iv of england')], nq_answers=[[Entity(start_offset=185, end_offset=205, type='context', text='Edward IV of England', normalized_text='edward iv of england')], [Entity(start_offset=185, end_offset=194, type='context', text='Edward IV', normalized_text='edward iv')]], aligned_nps=[(Entity(start_offset=22, end_offset=46, type='question', text='the princes in the tower', normalized_text='princes in tower'), Entity(start_offset=146, end_offset=162, type='context', text='The two brothers', normalized_text='two brothers'))], explanation_type='single_sentence'),\n",
       " -1580637763990313083: QEDExample(example_id=-1580637763990313083, title='Muhammad Ali', question='when did muhammad ali win an olympic gold medal', passage=\"Clay was born and raised in Louisville , Kentucky , and began training as an amateur boxer when he was 12 years old . At age 18 , he won a gold medal in the light heavyweight division at the 1960 Summer Olympics in Rome and turned professional later that year . At age 22 in 1964 , he won the WBA , WBC , and lineal heavyweight titles from Sonny Liston in a major upset . Clay then converted to Islam and changed his name from Cassius Clay , which he called his `` slave name '' , to Muhammad Ali . He set an example of racial pride for African Americans and resistance to white domination during the Civil Rights Movement .\", sentence_starts=[0, 118, 262, 372, 499], selected_sent={'start': 118, 'end': 262, 'string': 'At age 18 , he won a gold medal in the light heavyweight division at the 1960 Summer Olympics in Rome and turned professional later that year . '}, answer=[Entity(start_offset=191, end_offset=195, type='context', text='1960', normalized_text='1960')], nq_answers=[[Entity(start_offset=191, end_offset=195, type='context', text='1960', normalized_text='1960')], [Entity(start_offset=184, end_offset=219, type='context', text='at the 1960 Summer Olympics in Rome', normalized_text='at 1960 summer olympics in rome')]], aligned_nps=[(Entity(start_offset=9, end_offset=25, type='question', text='muhammad ali win', normalized_text='muhammad ali win'), Entity(start_offset=130, end_offset=132, type='context', text='he', normalized_text='he'))], explanation_type='single_sentence'),\n",
       " -8153368396899020971: QEDExample(example_id=-8153368396899020971, title=\"Harry Potter and the Philosopher's Stone\", question=\"when was harry potter and the philosopher's stone made\", passage=\"Harry Potter and the Philosopher 's Stone is a fantasy novel written by British author J.K. Rowling . It is the first novel in the Harry Potter series and Rowling 's debut novel , first published in 1997 by Bloomsbury . It was published in the United States as Harry Potter and the Sorcerer 's Stone by Scholastic Corporation in 1998 . The plot follows Harry Potter , a young wizard who discovers his magical heritage as he makes close friends and a few enemies in his first year at the Hogwarts School of Witchcraft and Wizardry . With the help of his friends , Harry faces an attempted comeback by the dark wizard Lord Voldemort , who killed Harry 's parents , but failed to kill Harry when he was just 15 months old .\", sentence_starts=[0, 92, 102, 220, 336, 532], selected_sent={'start': 102, 'end': 220, 'string': \"It is the first novel in the Harry Potter series and Rowling 's debut novel , first published in 1997 by Bloomsbury . \"}, answer=[Entity(start_offset=199, end_offset=203, type='context', text='1997', normalized_text='1997')], nq_answers=[[Entity(start_offset=199, end_offset=203, type='context', text='1997', normalized_text='1997')]], aligned_nps=[(Entity(start_offset=9, end_offset=49, type='question', text=\"harry potter and the philosopher's stone\", normalized_text='harry potter and philosophers stone'), Entity(start_offset=102, end_offset=104, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -1043054449143427368: QEDExample(example_id=-1043054449143427368, title='Life Changes (Thomas Rhett album)', question=\"when does thomas rhett's new album come out\", passage=\"Life Changes is the third studio album from American singer Thomas Rhett . Released on September 8 , 2017 through Valory Music Group , Rhett produced the album alongside Dann Huff , Jesse Frasure , Julian Bunetta and Joe London . It includes the chart - topping singles `` Craving You '' with Maren Morris , and Unforgettable . The album debuted at No. 1 with 123,000 album - equivalent units , giving Rhett his first number one album on the Billboard 200 .\", sentence_starts=[0, 75, 230, 328], selected_sent={'start': 75, 'end': 230, 'string': 'Released on September 8 , 2017 through Valory Music Group , Rhett produced the album alongside Dann Huff , Jesse Frasure , Julian Bunetta and Joe London . '}, answer=[Entity(start_offset=87, end_offset=105, type='context', text='September 8 , 2017', normalized_text='september 8 2017')], nq_answers=[[Entity(start_offset=87, end_offset=105, type='context', text='September 8 , 2017', normalized_text='september 8 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text=\"thomas rhett's new album\", normalized_text='thomas rhetts new album'), Entity(start_offset=150, end_offset=159, type='context', text='the album', normalized_text='album'))], explanation_type='single_sentence'),\n",
       " -7518405190999038417: QEDExample(example_id=-7518405190999038417, title='Assassination of Archduke Franz Ferdinand of Austria', question='who was assassinated during a visit to sarajevo in bosnia', passage=\"The assassination of Archduke Franz Ferdinand of Austria , heir presumptive to the Austro - Hungarian throne , and his wife Sophie , Duchess of Hohenberg , occurred on 28 June 1914 in Sarajevo when they were mortally wounded by Gavrilo Princip . Princip was one of a group of six assassins ( five Serbs and one Bosniak ) coordinated by Danilo Ilić , a Bosnian Serb and a member of the Black Hand secret society . The political objective of the assassination was to break off Austria - Hungary 's South Slav provinces so they could be combined into a Yugoslavia . The assassins ' motives were consistent with the movement that later became known as Young Bosnia . The assassination led directly to the First World War when Austria - Hungary subsequently issued an ultimatum to the Kingdom of Serbia , which was partially rejected . Austria - Hungary then declared war , triggering actions leading to war between most European states .\", sentence_starts=[0, 246, 413, 563, 663, 831], selected_sent={'start': 0, 'end': 246, 'string': 'The assassination of Archduke Franz Ferdinand of Austria , heir presumptive to the Austro - Hungarian throne , and his wife Sophie , Duchess of Hohenberg , occurred on 28 June 1914 in Sarajevo when they were mortally wounded by Gavrilo Princip . '}, answer=[Entity(start_offset=21, end_offset=153, type='context', text='Archduke Franz Ferdinand of Austria , heir presumptive to the Austro - Hungarian throne , and his wife Sophie , Duchess of Hohenberg', normalized_text='archduke franz ferdinand of austria heir presumptive to austro hungarian throne and his wife sophie duchess of hohenberg')], nq_answers=[[Entity(start_offset=21, end_offset=56, type='context', text='Archduke Franz Ferdinand of Austria', normalized_text='archduke franz ferdinand of austria')]], aligned_nps=[(Entity(start_offset=39, end_offset=57, type='question', text='sarajevo in bosnia', normalized_text='sarajevo in bosnia'), Entity(start_offset=184, end_offset=192, type='context', text='Sarajevo', normalized_text='sarajevo'))], explanation_type='single_sentence'),\n",
       " -510907719981675661: QEDExample(example_id=-510907719981675661, title='Chyme', question='what allows chyme to enter the small intestine', passage=\"Chyme or chymus ( / kaɪm / ; from Greek χυμός khymos , `` juice '' ) is the semi-fluid mass of partly digested food that is expelled by the stomach , through the pyloric valve , into the duodenum ( the beginning of the small intestine ) .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 238, 'string': \"Chyme or chymus ( / kaɪm / ; from Greek χυμός khymos , `` juice '' ) is the semi-fluid mass of partly digested food that is expelled by the stomach , through the pyloric valve , into the duodenum ( the beginning of the small intestine ) .\"}, answer=[Entity(start_offset=158, end_offset=175, type='context', text='the pyloric valve', normalized_text='pyloric valve')], nq_answers=[[Entity(start_offset=162, end_offset=175, type='context', text='pyloric valve', normalized_text='pyloric valve')], [Entity(start_offset=158, end_offset=175, type='context', text='the pyloric valve', normalized_text='pyloric valve')]], aligned_nps=[(Entity(start_offset=12, end_offset=17, type='question', text='chyme', normalized_text='chyme'), Entity(start_offset=0, end_offset=68, type='context', text=\"Chyme or chymus ( / kaɪm / ; from Greek χυμός khymos , `` juice '' )\", normalized_text='chyme or chymus kaɪm from greek χυμός khymos juice')), (Entity(start_offset=27, end_offset=46, type='question', text='the small intestine', normalized_text='small intestine'), Entity(start_offset=215, end_offset=234, type='context', text='the small intestine', normalized_text='small intestine'))], explanation_type='single_sentence'),\n",
       " -4042391161693864280: QEDExample(example_id=-4042391161693864280, title='Great Is Thy Faithfulness', question='author of the hymn great is thy faithfulness', passage='Great Is Thy Faithfulness is a popular Christian hymn written by Thomas Chisholm ( 1866 -- 1960 ) with music composed by William M. Runyan ( 1870 -- 1957 ) in Baldwin , Kansas , U.S. .', sentence_starts=[0], selected_sent={'start': 0, 'end': 184, 'string': 'Great Is Thy Faithfulness is a popular Christian hymn written by Thomas Chisholm ( 1866 -- 1960 ) with music composed by William M. Runyan ( 1870 -- 1957 ) in Baldwin , Kansas , U.S. .'}, answer=[Entity(start_offset=65, end_offset=80, type='context', text='Thomas Chisholm', normalized_text='thomas chisholm')], nq_answers=[[Entity(start_offset=65, end_offset=80, type='context', text='Thomas Chisholm', normalized_text='thomas chisholm')], [Entity(start_offset=65, end_offset=80, type='context', text='Thomas Chisholm', normalized_text='thomas chisholm'), Entity(start_offset=121, end_offset=138, type='context', text='William M. Runyan', normalized_text='william m runyan')], [Entity(start_offset=54, end_offset=80, type='context', text='written by Thomas Chisholm', normalized_text='written by thomas chisholm'), Entity(start_offset=103, end_offset=138, type='context', text='music composed by William M. Runyan', normalized_text='music composed by william m runyan')]], aligned_nps=[(Entity(start_offset=10, end_offset=44, type='question', text='the hymn great is thy faithfulness', normalized_text='hymn great is thy faithfulness'), Entity(start_offset=0, end_offset=25, type='context', text='Great Is Thy Faithfulness', normalized_text='great is thy faithfulness'))], explanation_type='single_sentence'),\n",
       " 7598777188623034272: QEDExample(example_id=7598777188623034272, title='Sacred Valley', question='what is the altitude of the sacred valley in peru', passage='The valley , running generally west to east , is understood to include everything along the Urubamba River between the town and Inca ruins at Písac westward to Machu Piccu , 100 kilometres ( 62 mi ) distant . The Sacred Valley has elevations above sea level along the river ranging from 3,000 metres ( 9,800 ft ) at Pisac to 2,050 metres ( 6,730 ft ) at the Urubamba River below the citadel of Macchu Piccu . On both sides of the river , the mountains rise to much higher elevations , especially to the south where two prominent mountains overlook the valley : Sahuasiray , 5,818 metres ( 19,088 ft ) and Veronica , 5,893 metres ( 19,334 ft ) in elevation . The intensely cultivated valley floor is about 1 kilometre ( 0.62 mi ) wide on average . Side valleys and agricultural terraces ( andenes ) expand the cultivatable area .', sentence_starts=[0, 209, 409, 658, 747], selected_sent={'start': 209, 'end': 409, 'string': 'The Sacred Valley has elevations above sea level along the river ranging from 3,000 metres ( 9,800 ft ) at Pisac to 2,050 metres ( 6,730 ft ) at the Urubamba River below the citadel of Macchu Piccu . '}, answer=[Entity(start_offset=282, end_offset=406, type='context', text='from 3,000 metres ( 9,800 ft ) at Pisac to 2,050 metres ( 6,730 ft ) at the Urubamba River below the citadel of Macchu Piccu', normalized_text='from 3000 metres 9800 ft at pisac to 2050 metres 6730 ft at urubamba river below citadel of macchu piccu')], nq_answers=[[Entity(start_offset=287, end_offset=372, type='context', text='3,000 metres ( 9,800 ft ) at Pisac to 2,050 metres ( 6,730 ft ) at the Urubamba River', normalized_text='3000 metres 9800 ft at pisac to 2050 metres 6730 ft at urubamba river')], [Entity(start_offset=274, end_offset=372, type='context', text='ranging from 3,000 metres ( 9,800 ft ) at Pisac to 2,050 metres ( 6,730 ft ) at the Urubamba River', normalized_text='ranging from 3000 metres 9800 ft at pisac to 2050 metres 6730 ft at urubamba river')], [Entity(start_offset=274, end_offset=406, type='context', text='ranging from 3,000 metres ( 9,800 ft ) at Pisac to 2,050 metres ( 6,730 ft ) at the Urubamba River below the citadel of Macchu Piccu', normalized_text='ranging from 3000 metres 9800 ft at pisac to 2050 metres 6730 ft at urubamba river below citadel of macchu piccu')]], aligned_nps=[(Entity(start_offset=24, end_offset=49, type='question', text='the sacred valley in peru', normalized_text='sacred valley in peru'), Entity(start_offset=209, end_offset=226, type='context', text='The Sacred Valley', normalized_text='sacred valley'))], explanation_type='single_sentence'),\n",
       " 3196153695189700947: QEDExample(example_id=3196153695189700947, title='Republic Day (India)', question='why 26 january is celebrated as republic day in hindi', passage='Republic Day honours the date on which the Constitution of India came into effect on 26 January 1950 replacing the Government of India Act ( 1935 ) as the governing document of India .', sentence_starts=[0], selected_sent={'start': 0, 'end': 184, 'string': 'Republic Day honours the date on which the Constitution of India came into effect on 26 January 1950 replacing the Government of India Act ( 1935 ) as the governing document of India .'}, answer=[Entity(start_offset=21, end_offset=182, type='context', text='the date on which the Constitution of India came into effect on 26 January 1950 replacing the Government of India Act ( 1935 ) as the governing document of India', normalized_text='date on which constitution of india came into effect on 26 january 1950 replacing government of india act 1935 as governing document of india')], nq_answers=[[Entity(start_offset=39, end_offset=100, type='context', text='the Constitution of India came into effect on 26 January 1950', normalized_text='constitution of india came into effect on 26 january 1950')], [Entity(start_offset=13, end_offset=100, type='context', text='honours the date on which the Constitution of India came into effect on 26 January 1950', normalized_text='honours date on which constitution of india came into effect on 26 january 1950')]], aligned_nps=[(Entity(start_offset=32, end_offset=44, type='question', text='republic day', normalized_text='republic day'), Entity(start_offset=0, end_offset=12, type='context', text='Republic Day', normalized_text='republic day'))], explanation_type='single_sentence'),\n",
       " -4366283268910846199: QEDExample(example_id=-4366283268910846199, title='Ark of the Covenant', question='where was the ark of the covenant built', passage=\"The biblical account relates that , approximately one year after the Israelites ' exodus from Egypt , the Ark was created according to the pattern given to Moses by God when the Israelites were encamped at the foot of biblical Mount Sinai . Thereafter , the gold - plated acacia chest was carried by its staves while en route by the Levites approximately 2,000 cubits ( approximately 800 meters or 2,600 feet ) in advance of the people when on the march or before the Israelite army , the host of fighting men . When carried , the Ark was always hidden under a large veil made of skins and blue cloth , always carefully concealed , even from the eyes of the priests and the Levites who carried it . God was said to have spoken with Moses `` from between the two cherubim '' on the Ark 's cover . When at rest the tabernacle was set up and the holy Ark was placed under the veil of the covering , the staves of it crossing the middle side bars to hold it up off the ground .\", sentence_starts=[0, 241, 512, 699, 796], selected_sent={'start': 0, 'end': 241, 'string': \"The biblical account relates that , approximately one year after the Israelites ' exodus from Egypt , the Ark was created according to the pattern given to Moses by God when the Israelites were encamped at the foot of biblical Mount Sinai . \"}, answer=[Entity(start_offset=227, end_offset=238, type='context', text='Mount Sinai', normalized_text='mount sinai')], nq_answers=[[Entity(start_offset=206, end_offset=238, type='context', text='the foot of biblical Mount Sinai', normalized_text='foot of biblical mount sinai')], [Entity(start_offset=203, end_offset=238, type='context', text='at the foot of biblical Mount Sinai', normalized_text='at foot of biblical mount sinai')]], aligned_nps=[(Entity(start_offset=10, end_offset=33, type='question', text='the ark of the covenant', normalized_text='ark of covenant'), Entity(start_offset=102, end_offset=109, type='context', text='the Ark', normalized_text='ark'))], explanation_type='single_sentence'),\n",
       " -1317942101497986450: QEDExample(example_id=-1317942101497986450, title='Game of Thrones (season 8)', question='when is season 8 for game of thrones', passage='The season will be adapted for television by David Benioff and D.B. Weiss . Filming officially began on October 23 , 2017 . The season is scheduled to premiere in 2019 .', sentence_starts=[0, 68, 76, 124], selected_sent={'start': 124, 'end': 169, 'string': 'The season is scheduled to premiere in 2019 .'}, answer=[Entity(start_offset=163, end_offset=167, type='context', text='2019', normalized_text='2019')], nq_answers=[[Entity(start_offset=163, end_offset=167, type='context', text='2019', normalized_text='2019')], [Entity(start_offset=160, end_offset=167, type='context', text='in 2019', normalized_text='in 2019')]], aligned_nps=[(Entity(start_offset=8, end_offset=36, type='question', text='season 8 for game of thrones', normalized_text='season 8 for game of thrones'), Entity(start_offset=124, end_offset=134, type='context', text='The season', normalized_text='season'))], explanation_type='single_sentence'),\n",
       " -2751908283042856030: QEDExample(example_id=-2751908283042856030, title='I Want a Hippopotamus for Christmas', question='who sang original i want a hippopotamus for christmas', passage=\"`` I Want a Hippopotamus for Christmas '' is a Christmas novelty song written by John Rox ( 1902 -- 1957 ) and performed by Gayla Peevey ( 10 years old at the time ) in 1953 . The song peaked at number 24 on Billboard magazine 's pop chart in December 1953 .\", sentence_starts=[0, 176], selected_sent={'start': 0, 'end': 176, 'string': \"`` I Want a Hippopotamus for Christmas '' is a Christmas novelty song written by John Rox ( 1902 -- 1957 ) and performed by Gayla Peevey ( 10 years old at the time ) in 1953 . \"}, answer=[Entity(start_offset=124, end_offset=136, type='context', text='Gayla Peevey', normalized_text='gayla peevey')], nq_answers=[[Entity(start_offset=124, end_offset=136, type='context', text='Gayla Peevey', normalized_text='gayla peevey')]], aligned_nps=[(Entity(start_offset=9, end_offset=53, type='question', text='original i want a hippopotamus for christmas', normalized_text='original i want hippopotamus for christmas'), Entity(start_offset=3, end_offset=38, type='context', text='I Want a Hippopotamus for Christmas', normalized_text='i want hippopotamus for christmas'))], explanation_type='single_sentence'),\n",
       " -4094761539773366482: QEDExample(example_id=-4094761539773366482, title='Intolerable Acts', question='what act did parliament pass after the boston tea party', passage='The Intolerable Acts was the term used by American Patriots for a series of punitive laws passed by the British Parliament in 1774 after the Boston Tea Party . The laws were meant to punish the Massachusetts colonists for their defiance in the Boston Tea Party protest in reaction to changes in taxation by the British to the detriment of Colonial goods . In Great Britain , these laws were referred to as the Coercive Acts .', sentence_starts=[0, 160, 356], selected_sent={'start': 0, 'end': 160, 'string': 'The Intolerable Acts was the term used by American Patriots for a series of punitive laws passed by the British Parliament in 1774 after the Boston Tea Party . '}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='The Intolerable Acts', normalized_text='intolerable acts')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='The Intolerable Acts', normalized_text='intolerable acts')], [Entity(start_offset=4, end_offset=20, type='context', text='Intolerable Acts', normalized_text='intolerable acts')], [Entity(start_offset=406, end_offset=423, type='context', text='the Coercive Acts', normalized_text='coercive acts')]], aligned_nps=[(Entity(start_offset=13, end_offset=23, type='question', text='parliament', normalized_text='parliament'), Entity(start_offset=100, end_offset=122, type='context', text='the British Parliament', normalized_text='british parliament')), (Entity(start_offset=35, end_offset=55, type='question', text='the boston tea party', normalized_text='boston tea party'), Entity(start_offset=137, end_offset=157, type='context', text='the Boston Tea Party', normalized_text='boston tea party'))], explanation_type='single_sentence'),\n",
       " 5639549384591145661: QEDExample(example_id=5639549384591145661, title='2017 NFL season', question='when is the end of the football season', passage='The 2017 NFL season is the 98th and current season in the history of the National Football League ( NFL ) . The season began on September 7 , 2017 , with the Kansas City Chiefs defeating the defending Super Bowl LI champion New England Patriots 42 -- 27 in the NFL Kickoff Game . The season will conclude on February 4 , 2018 , with Super Bowl LII which will pit the National Football Conference ( NFC ) champion Philadelphia Eagles against the American Football Conference ( AFC ) champion New England Patriots .', sentence_starts=[0, 108, 280], selected_sent={'start': 280, 'end': 513, 'string': 'The season will conclude on February 4 , 2018 , with Super Bowl LII which will pit the National Football Conference ( NFC ) champion Philadelphia Eagles against the American Football Conference ( AFC ) champion New England Patriots .'}, answer=[Entity(start_offset=308, end_offset=325, type='context', text='February 4 , 2018', normalized_text='february 4 2018')], nq_answers=[[Entity(start_offset=308, end_offset=347, type='context', text='February 4 , 2018 , with Super Bowl LII', normalized_text='february 4 2018 with super bowl lii')], [Entity(start_offset=308, end_offset=325, type='context', text='February 4 , 2018', normalized_text='february 4 2018')]], aligned_nps=[(Entity(start_offset=19, end_offset=38, type='question', text='the football season', normalized_text='football season'), Entity(start_offset=280, end_offset=290, type='context', text='The season', normalized_text='season'))], explanation_type='single_sentence'),\n",
       " 2129315990503064870: QEDExample(example_id=2129315990503064870, title='Ouija', question='when did the ouija board game come out', passage='Following its commercial introduction by businessman Elijah Bond on July 1 , 1890 , the ouija board was regarded as a parlor game unrelated to the occult until American spiritualist Pearl Curran popularized its use as a divining tool during World War I. Spiritualists believed that the dead were able to contact the living and reportedly used a talking board very similar to a modern ouija board at their camps in Ohio in 1886 to ostensibly enable faster communication with spirits .', sentence_starts=[0], selected_sent={'start': 0, 'end': 483, 'string': 'Following its commercial introduction by businessman Elijah Bond on July 1 , 1890 , the ouija board was regarded as a parlor game unrelated to the occult until American spiritualist Pearl Curran popularized its use as a divining tool during World War I. Spiritualists believed that the dead were able to contact the living and reportedly used a talking board very similar to a modern ouija board at their camps in Ohio in 1886 to ostensibly enable faster communication with spirits .'}, answer=[Entity(start_offset=68, end_offset=81, type='context', text='July 1 , 1890', normalized_text='july 1 1890')], nq_answers=[[Entity(start_offset=68, end_offset=81, type='context', text='July 1 , 1890', normalized_text='july 1 1890')]], aligned_nps=[(Entity(start_offset=9, end_offset=29, type='question', text='the ouija board game', normalized_text='ouija board game'), Entity(start_offset=84, end_offset=99, type='context', text='the ouija board', normalized_text='ouija board'))], explanation_type='single_sentence'),\n",
       " -1425049791898563664: QEDExample(example_id=-1425049791898563664, title='Do not go gentle into that good night', question='who said i will not go quietly into the night', passage=\"`` Do not go gentle into that good night '' is a poem in the form of a villanelle , and the most famous work of Welsh poet Dylan Thomas ( 1914 -- 1953 ) . Though first published in the journal Botteghe Oscure in 1951 , it was written in 1947 when he was in Florence with his family . It was published , along with other stories previously written , as part of his In Country Sleep , And Other Poems in 1952 .\", sentence_starts=[0, 155, 284], selected_sent={'start': 0, 'end': 155, 'string': \"`` Do not go gentle into that good night '' is a poem in the form of a villanelle , and the most famous work of Welsh poet Dylan Thomas ( 1914 -- 1953 ) . \"}, answer=[Entity(start_offset=123, end_offset=135, type='context', text='Dylan Thomas', normalized_text='dylan thomas')], nq_answers=[[Entity(start_offset=123, end_offset=135, type='context', text='Dylan Thomas', normalized_text='dylan thomas')], [Entity(start_offset=112, end_offset=135, type='context', text='Welsh poet Dylan Thomas', normalized_text='welsh poet dylan thomas')]], aligned_nps=[(Entity(start_offset=9, end_offset=45, type='question', text='i will not go quietly into the night', normalized_text='i will not go quietly into night'), Entity(start_offset=3, end_offset=40, type='context', text='Do not go gentle into that good night', normalized_text='do not go gentle into that good night'))], explanation_type='single_sentence'),\n",
       " 8761534532663338953: QEDExample(example_id=8761534532663338953, title='Health and Safety Executive', question='what is the role of the hse inspectorate', passage='The Health and Safety Executive ( HSE ) is the body responsible for the encouragement , regulation and enforcement of workplace health , safety and welfare , and for research into occupational risks in Great Britain . It is a non-departmental public body of the United Kingdom with its headquarters in Liverpool , England . In Northern Ireland , these duties lie with the Health and Safety Executive for Northern Ireland . The HSE was created by the Health and Safety at Work etc . Act 1974 , and has since absorbed earlier regulatory bodies such as the Factory Inspectorate and the Railway Inspectorate though the Railway Inspectorate was transferred to the Office of Rail Regulation in April 2006 . The HSE is sponsored by the Department for Work and Pensions . As part of its work , HSE investigates industrial accidents , small and large , including major incidents such as the explosion and fire at Buncefield in 2005 . Though it formerly reported to the Health and Safety Commission , on 1 April 2008 , the two bodies merged .', sentence_starts=[0, 218, 324, 423, 482, 701, 764, 925], selected_sent={'start': 0, 'end': 218, 'string': 'The Health and Safety Executive ( HSE ) is the body responsible for the encouragement , regulation and enforcement of workplace health , safety and welfare , and for research into occupational risks in Great Britain . '}, answer=[Entity(start_offset=68, end_offset=215, type='context', text='the encouragement , regulation and enforcement of workplace health , safety and welfare , and for research into occupational risks in Great Britain', normalized_text='encouragement regulation and enforcement of workplace health safety and welfare and for research into occupational risks in great britain')], nq_answers=[[Entity(start_offset=52, end_offset=215, type='context', text='responsible for the encouragement , regulation and enforcement of workplace health , safety and welfare , and for research into occupational risks in Great Britain', normalized_text='responsible for encouragement regulation and enforcement of workplace health safety and welfare and for research into occupational risks in great britain')], [Entity(start_offset=68, end_offset=215, type='context', text='the encouragement , regulation and enforcement of workplace health , safety and welfare , and for research into occupational risks in Great Britain', normalized_text='encouragement regulation and enforcement of workplace health safety and welfare and for research into occupational risks in great britain')]], aligned_nps=[(Entity(start_offset=20, end_offset=40, type='question', text='the hse inspectorate', normalized_text='hse inspectorate'), Entity(start_offset=0, end_offset=39, type='context', text='The Health and Safety Executive ( HSE )', normalized_text='health and safety executive hse'))], explanation_type='single_sentence'),\n",
       " -1464218253776053027: QEDExample(example_id=-1464218253776053027, title='Wall Street Crash of 1929', question='what was the wall street crash in 1929', passage=\"The Wall Street Crash of 1929 , also known as Black Tuesday ( October 29 ) , the Great Crash , or the Stock Market Crash of 1929 , began on October 24 , 1929 ( `` Black Thursday '' ) , and was the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ) , when taking into consideration the full extent and duration of its after effects . The crash , which followed the London Stock Exchange 's crash of September , signalled the beginning of the 12 - year Great Depression that affected all Western industrialized countries .\", sentence_starts=[0, 434], selected_sent={'start': 0, 'end': 434, 'string': \"The Wall Street Crash of 1929 , also known as Black Tuesday ( October 29 ) , the Great Crash , or the Stock Market Crash of 1929 , began on October 24 , 1929 ( `` Black Thursday '' ) , and was the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ) , when taking into consideration the full extent and duration of its after effects . \"}, answer=[Entity(start_offset=193, end_offset=431, type='context', text='the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ) , when taking into consideration the full extent and duration of its after effects', normalized_text='most devastating stock market crash in history of united states acting as most significant predicting indicator of great depression when taking into consideration full extent and duration of its after effects')], nq_answers=[[Entity(start_offset=193, end_offset=431, type='context', text='the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ) , when taking into consideration the full extent and duration of its after effects', normalized_text='most devastating stock market crash in history of united states acting as most significant predicting indicator of great depression when taking into consideration full extent and duration of its after effects')], [Entity(start_offset=193, end_offset=268, type='context', text='the most devastating stock market crash in the history of the United States', normalized_text='most devastating stock market crash in history of united states')]], aligned_nps=[(Entity(start_offset=9, end_offset=38, type='question', text='the wall street crash in 1929', normalized_text='wall street crash in 1929'), Entity(start_offset=0, end_offset=128, type='context', text='The Wall Street Crash of 1929 , also known as Black Tuesday ( October 29 ) , the Great Crash , or the Stock Market Crash of 1929', normalized_text='wall street crash of 1929 also known as black tuesday october 29 great crash or stock market crash of 1929'))], explanation_type='single_sentence'),\n",
       " -8762144002773697012: QEDExample(example_id=-8762144002773697012, title='Atmosphere of Earth', question=\"all the gases in the earth's atmosphere\", passage=\"By volume , dry air contains 78.09 % nitrogen , 20.95 % oxygen , 0.93 % argon , 0.04 % carbon dioxide , and small amounts of other gases . Air also contains a variable amount of water vapor , on average around 1 % at sea level , and 0.4 % over the entire atmosphere . Air content and atmospheric pressure vary at different layers , and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth 's troposphere and in artificial atmospheres .\", sentence_starts=[0, 139, 268], selected_sent={'start': 0, 'end': 139, 'string': 'By volume , dry air contains 78.09 % nitrogen , 20.95 % oxygen , 0.93 % argon , 0.04 % carbon dioxide , and small amounts of other gases . '}, answer=[Entity(start_offset=29, end_offset=136, type='context', text='78.09 % nitrogen , 20.95 % oxygen , 0.93 % argon , 0.04 % carbon dioxide , and small amounts of other gases', normalized_text='7809 nitrogen 2095 oxygen 093 argon 004 carbon dioxide and small amounts of other gases')], nq_answers=[[Entity(start_offset=37, end_offset=45, type='context', text='nitrogen', normalized_text='nitrogen'), Entity(start_offset=56, end_offset=62, type='context', text='oxygen', normalized_text='oxygen'), Entity(start_offset=72, end_offset=77, type='context', text='argon', normalized_text='argon'), Entity(start_offset=87, end_offset=101, type='context', text='carbon dioxide', normalized_text='carbon dioxide'), Entity(start_offset=108, end_offset=136, type='context', text='small amounts of other gases', normalized_text='small amounts of other gases')]], aligned_nps=[(Entity(start_offset=17, end_offset=39, type='question', text=\"the earth's atmosphere\", normalized_text='earths atmosphere'), Entity(start_offset=12, end_offset=19, type='context', text='dry air', normalized_text='dry air'))], explanation_type='single_sentence'),\n",
       " 4145408349385326530: QEDExample(example_id=4145408349385326530, title='Galvez', question='where does the last name galvez come from', passage='Galvez is a Spanish surname .', sentence_starts=[0], selected_sent={'start': 0, 'end': 29, 'string': 'Galvez is a Spanish surname .'}, answer=[Entity(start_offset=12, end_offset=19, type='context', text='Spanish', normalized_text='spanish')], nq_answers=[[Entity(start_offset=12, end_offset=27, type='context', text='Spanish surname', normalized_text='spanish surname')], [Entity(start_offset=12, end_offset=19, type='context', text='Spanish', normalized_text='spanish')]], aligned_nps=[(Entity(start_offset=11, end_offset=31, type='question', text='the last name galvez', normalized_text='last name galvez'), Entity(start_offset=0, end_offset=6, type='context', text='Galvez', normalized_text='galvez'))], explanation_type='single_sentence'),\n",
       " -2622805360660993548: QEDExample(example_id=-2622805360660993548, title='Lewis and Clark Expedition', question='on which river did the exploration of the louisiana purchase begin', passage=\"According to Thomas Jefferson himself , one goal was to find `` the most direct and practicable water communication across this continent , for the purposes of commerce . '' Jefferson also placed special importance on declaring U.S. sovereignty over the land occupied by the many different tribes of Native Americans along the Missouri River , and getting an accurate sense of the resources in the recently completed Louisiana Purchase . The expedition made notable contributions to science , but scientific research was not the main goal of the mission .\", sentence_starts=[0, 174, 438], selected_sent={'start': 174, 'end': 438, 'string': 'Jefferson also placed special importance on declaring U.S. sovereignty over the land occupied by the many different tribes of Native Americans along the Missouri River , and getting an accurate sense of the resources in the recently completed Louisiana Purchase . '}, answer=[Entity(start_offset=323, end_offset=341, type='context', text='the Missouri River', normalized_text='missouri river')], nq_answers=[[Entity(start_offset=327, end_offset=341, type='context', text='Missouri River', normalized_text='missouri river')]], aligned_nps=[(Entity(start_offset=38, end_offset=60, type='question', text='the louisiana purchase', normalized_text='louisiana purchase'), Entity(start_offset=394, end_offset=435, type='context', text='the recently completed Louisiana Purchase', normalized_text='recently completed louisiana purchase'))], explanation_type='single_sentence'),\n",
       " 3394342679382237403: QEDExample(example_id=3394342679382237403, title='Taylor (surname)', question='where did the last name taylor originate from', passage=\"Taylor is a surname used in the British Isles of French and Latin origin which originated as a Norman occupational surname ( meaning tailor ) in France It is derived from the Old French tailleur ( `` cutter '' ) , which is in turn derived from the Late Latin taliator , from taliare ( `` to cut '' ) . The first historical evidence of the surname dates to the County of Somerset , South West England in 1182 . `` Taylor '' is the fifth-most common surname in England , the 11th-most common in Scotland and the 22nd-most common in Wales . It is also common in other English speaking countries ( especially Australia , Canada , New Zealand , and the United States , where it was the tenth most frequently encountered surname in the 2000 US Census ) , but has a low incidence in Ireland , where it is mostly concentrated in the North . It is often the anglicized form of the German surname Schneider .\", sentence_starts=[0, 302, 410, 538, 833], selected_sent={'start': 0, 'end': 302, 'string': \"Taylor is a surname used in the British Isles of French and Latin origin which originated as a Norman occupational surname ( meaning tailor ) in France It is derived from the Old French tailleur ( `` cutter '' ) , which is in turn derived from the Late Latin taliator , from taliare ( `` to cut '' ) . \"}, answer=[Entity(start_offset=145, end_offset=151, type='context', text='France', normalized_text='france')], nq_answers=[[Entity(start_offset=175, end_offset=185, type='context', text='Old French', normalized_text='old french')], [Entity(start_offset=93, end_offset=151, type='context', text='a Norman occupational surname ( meaning tailor ) in France', normalized_text='norman occupational surname meaning tailor in france')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 7206245989456268244: QEDExample(example_id=7206245989456268244, title='Lotta Love', question=\"who wrote it's gonna take a lot of love\", passage=\"`` Lotta Love '' is a song written and recorded by Neil Young and released on his 1978 Comes a Time album . `` Lotta Love '' was also covered by Nicolette Larson in 1978 . Larson 's version reached No. 8 on the Billboard Hot 100 chart and No. 8 on the Cash Box Top 100 in February 1979 . It also hit No. 1 on the Easy Listening chart and was a hit in Australia ( No. 11 ) and New Zealand ( No. 22 ) .\", sentence_starts=[0, 108, 172, 288], selected_sent={'start': 0, 'end': 108, 'string': \"`` Lotta Love '' is a song written and recorded by Neil Young and released on his 1978 Comes a Time album . \"}, answer=[Entity(start_offset=51, end_offset=61, type='context', text='Neil Young', normalized_text='neil young')], nq_answers=[[Entity(start_offset=51, end_offset=61, type='context', text='Neil Young', normalized_text='neil young')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text=\"it's gonna take a lot of love\", normalized_text='its gonna take lot of love'), Entity(start_offset=3, end_offset=13, type='context', text='Lotta Love', normalized_text='lotta love'))], explanation_type='single_sentence'),\n",
       " -7581059872074630037: QEDExample(example_id=-7581059872074630037, title='Pocahontas (1995 film)', question='who plays the voice of john smith in pocahontas', passage='Pocahontas is a 1995 American animated musical romantic drama film produced by Walt Disney Feature Animation for Walt Disney Pictures , the 33rd Disney animated feature film . Directed by Mike Gabriel and Eric Goldberg , the film is inspired by the Native American woman Pocahontas , and portrays a fictionalized account of her historical encounter with Englishman John Smith and the Jamestown settlers that arrived from the Virginia Company . The voice cast stars Irene Bedard and Mel Gibson as Pocahontas and Smith , respectively , with David Ogden Stiers , Russell Means , Christian Bale , Billy Connolly , and Linda Hunt . The musical score was written by Alan Menken , with songs written by Menken and lyricist Stephen Schwartz .', sentence_starts=[0, 176, 444, 627], selected_sent={'start': 444, 'end': 627, 'string': 'The voice cast stars Irene Bedard and Mel Gibson as Pocahontas and Smith , respectively , with David Ogden Stiers , Russell Means , Christian Bale , Billy Connolly , and Linda Hunt . '}, answer=[Entity(start_offset=482, end_offset=492, type='context', text='Mel Gibson', normalized_text='mel gibson')], nq_answers=[[Entity(start_offset=482, end_offset=492, type='context', text='Mel Gibson', normalized_text='mel gibson')]], aligned_nps=[(Entity(start_offset=23, end_offset=33, type='question', text='john smith', normalized_text='john smith'), Entity(start_offset=511, end_offset=516, type='context', text='Smith', normalized_text='smith')), (Entity(start_offset=37, end_offset=47, type='question', text='pocahontas', normalized_text='pocahontas'), Entity(start_offset=444, end_offset=458, type='context', text='The voice cast', normalized_text='voice cast'))], explanation_type='single_sentence'),\n",
       " -4323031873195553996: QEDExample(example_id=-4323031873195553996, title='Siege of Béxar', question='who was the mexican commander who surrendered to the texans at the capturing of san antonio', passage=\"By daylight , only 120 experienced infantry remained in the Mexican garrison . Cos called Sanchez Navarro to the Alamo and gave him orders to `` go save those brave men ... Approach the enemy and obtain the best terms possible '' . Sanchez Navarro first returned to his post at the plaza to inform the soldiers of the imminent surrender . Several officers argued with him , explaining that `` the Morelos Battalion has never surrendered '' , but Sanchez Navarro held firm to his orders . Bugle calls for a parley received no response from the Texians , and at 7 am Sanchez Navarro raised a flag of truce .\", sentence_starts=[0, 79, 232, 339, 488], selected_sent={'start': 488, 'end': 605, 'string': 'Bugle calls for a parley received no response from the Texians , and at 7 am Sanchez Navarro raised a flag of truce .'}, answer=[Entity(start_offset=565, end_offset=580, type='context', text='Sanchez Navarro', normalized_text='sanchez navarro')], nq_answers=[[Entity(start_offset=90, end_offset=105, type='context', text='Sanchez Navarro', normalized_text='sanchez navarro')]], aligned_nps=[(Entity(start_offset=49, end_offset=59, type='question', text='the texans', normalized_text='texans'), Entity(start_offset=539, end_offset=550, type='context', text='the Texians', normalized_text='texians')), (Entity(start_offset=63, end_offset=91, type='question', text='the capturing of san antonio', normalized_text='capturing of san antonio'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -2557364123122254640: QEDExample(example_id=-2557364123122254640, title='List of longest suspension bridge spans', question='distance from one side of a bridge to the other crossword', passage=\"The world 's longest suspension bridges are listed according to the length of their main span ( i.e. the length of suspended roadway between the bridge 's towers ) . The length of main span is the most common method of comparing the sizes of suspension bridges , often correlating with the height of the towers and the engineering complexity involved in designing and constructing the bridge . If one bridge has a longer span than another it does not necessarily mean that the bridge is longer from shore to shore ( or from abutment to abutment ) .\", sentence_starts=[0, 166, 394], selected_sent={'start': 0, 'end': 166, 'string': \"The world 's longest suspension bridges are listed according to the length of their main span ( i.e. the length of suspended roadway between the bridge 's towers ) . \"}, answer=[Entity(start_offset=89, end_offset=93, type='context', text='span', normalized_text='span')], nq_answers=[[Entity(start_offset=89, end_offset=93, type='context', text='span', normalized_text='span')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -7594272775521933661: QEDExample(example_id=-7594272775521933661, title='Adobe Flash', question='what is the primary purpose for adding flash elements to a website', passage='In the early 2000s , Flash was widely installed on desktop computers , and was commonly used to display interactive web pages , online games , and to playback video and audio content . In 2005 , YouTube was founded by former PayPal employees , and it used Flash Player as a means to display compressed video content on the web .', sentence_starts=[0, 185], selected_sent={'start': 0, 'end': 185, 'string': 'In the early 2000s , Flash was widely installed on desktop computers , and was commonly used to display interactive web pages , online games , and to playback video and audio content . '}, answer=[Entity(start_offset=93, end_offset=182, type='context', text='to display interactive web pages , online games , and to playback video and audio content', normalized_text='to display interactive web pages online games and to playback video and audio content')], nq_answers=[[Entity(start_offset=93, end_offset=182, type='context', text='to display interactive web pages , online games , and to playback video and audio content', normalized_text='to display interactive web pages online games and to playback video and audio content')]], aligned_nps=[(Entity(start_offset=39, end_offset=44, type='question', text='flash', normalized_text='flash'), Entity(start_offset=21, end_offset=26, type='context', text='Flash', normalized_text='flash'))], explanation_type='single_sentence'),\n",
       " 2186635546724071017: QEDExample(example_id=2186635546724071017, title='And Then There Were None', question='where is the island in and then there were none', passage='On a hot , early August day sometime in the late 1930s , eight people arrive on a small , isolated island off the Devon coast of England . Each appears to have an invitation tailored to his or her personal circumstances , such as an offer of employment or an unexpected late summer holiday . They are met by Thomas and Ethel Rogers , the butler and cook - housekeeper , who state that their hosts , Mr Ulick Norman Owen and his wife Mrs Una Nancy Owen , whom they have not yet met in person , have not arrived , but left instructions , which strikes all the guests as odd .', sentence_starts=[0, 139, 292], selected_sent={'start': 0, 'end': 139, 'string': 'On a hot , early August day sometime in the late 1930s , eight people arrive on a small , isolated island off the Devon coast of England . '}, answer=[Entity(start_offset=106, end_offset=136, type='context', text='off the Devon coast of England', normalized_text='off devon coast of england')], nq_answers=[[Entity(start_offset=106, end_offset=136, type='context', text='off the Devon coast of England', normalized_text='off devon coast of england')]], aligned_nps=[(Entity(start_offset=9, end_offset=47, type='question', text='the island in and then there were none', normalized_text='island in and then there were none'), Entity(start_offset=80, end_offset=136, type='context', text='a small , isolated island off the Devon coast of England', normalized_text='small isolated island off devon coast of england'))], explanation_type='single_sentence'),\n",
       " 8251044183838767734: QEDExample(example_id=8251044183838767734, title='Rockefeller Center Christmas Tree', question='when do they put the rockefeller tree up', passage=\"The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center , in Midtown Manhattan . The tree is erected in mid November and lit in a public ceremony in late November or early December . Since 1997 , the lighting has been broadcast live , to hundreds of millions , on NBC 's Christmas in Rockefeller Center telecast on a Wednesday after Thanksgiving . The tree lighting ceremony is aired at the end of every broadcast , following live entertainment and the tree is lit by the current Mayor of New York City and special guests . An estimated 125 million people visit the attraction each year .\", sentence_starts=[0, 127, 229, 394, 570], selected_sent={'start': 127, 'end': 229, 'string': 'The tree is erected in mid November and lit in a public ceremony in late November or early December . '}, answer=[Entity(start_offset=150, end_offset=162, type='context', text='mid November', normalized_text='mid november')], nq_answers=[[Entity(start_offset=139, end_offset=226, type='context', text='erected in mid November and lit in a public ceremony in late November or early December', normalized_text='erected in mid november and lit in public ceremony in late november or early december')], [Entity(start_offset=150, end_offset=162, type='context', text='mid November', normalized_text='mid november'), Entity(start_offset=176, end_offset=226, type='context', text='public ceremony in late November or early December', normalized_text='public ceremony in late november or early december')], [Entity(start_offset=195, end_offset=226, type='context', text='late November or early December', normalized_text='late november or early december')], [Entity(start_offset=150, end_offset=162, type='context', text='mid November', normalized_text='mid november')]], aligned_nps=[(Entity(start_offset=17, end_offset=37, type='question', text='the rockefeller tree', normalized_text='rockefeller tree'), Entity(start_offset=127, end_offset=135, type='context', text='The tree', normalized_text='tree'))], explanation_type='single_sentence'),\n",
       " 7882691903232616365: QEDExample(example_id=7882691903232616365, title='Disease', question='which term means the study of the nature and causes of disease', passage='A disease is any condition which results in the disorder of a structure or function in a living organism that is not due to any external injury . The study of disease is called pathology , which includes the study of cause . Disease is often construed as a medical condition associated with specific symptoms and signs . It may be caused by external factors such as pathogens or by internal dysfunctions , particularly of the immune system , such as an immunodeficiency , or by a hypersensitivity , including allergies and autoimmunity .', sentence_starts=[0, 146, 225, 321], selected_sent={'start': 146, 'end': 225, 'string': 'The study of disease is called pathology , which includes the study of cause . '}, answer=[Entity(start_offset=177, end_offset=186, type='context', text='pathology', normalized_text='pathology')], nq_answers=[[Entity(start_offset=177, end_offset=186, type='context', text='pathology', normalized_text='pathology')]], aligned_nps=[(Entity(start_offset=17, end_offset=62, type='question', text='the study of the nature and causes of disease', normalized_text='study of nature and causes of disease'), Entity(start_offset=146, end_offset=166, type='context', text='The study of disease', normalized_text='study of disease'))], explanation_type='single_sentence'),\n",
       " -3956329482216467389: QEDExample(example_id=-3956329482216467389, title='Fulda', question='where is fulda and what is its significance', passage='Fulda ( German pronunciation : ( ˈfʊlda ) ) ( historically in English called Fuld ) is a city in Hesse , Germany ; it is located on the river Fulda and is the administrative seat of the Fulda district ( Kreis ) . In 1990 , the town hosted the 30th Hessentag state festival .', sentence_starts=[0, 213], selected_sent={'start': 0, 'end': 213, 'string': 'Fulda ( German pronunciation : ( ˈfʊlda ) ) ( historically in English called Fuld ) is a city in Hesse , Germany ; it is located on the river Fulda and is the administrative seat of the Fulda district ( Kreis ) . '}, answer=[Entity(start_offset=87, end_offset=210, type='context', text='a city in Hesse , Germany ; it is located on the river Fulda and is the administrative seat of the Fulda district ( Kreis )', normalized_text='city in hesse germany it is located on river fulda and is administrative seat of fulda district kreis')], nq_answers=[[Entity(start_offset=97, end_offset=112, type='context', text='Hesse , Germany', normalized_text='hesse germany'), Entity(start_offset=129, end_offset=147, type='context', text='on the river Fulda', normalized_text='on river fulda'), Entity(start_offset=152, end_offset=210, type='context', text='is the administrative seat of the Fulda district ( Kreis )', normalized_text='is administrative seat of fulda district kreis')]], aligned_nps=[(Entity(start_offset=9, end_offset=14, type='question', text='fulda', normalized_text='fulda'), Entity(start_offset=0, end_offset=83, type='context', text='Fulda ( German pronunciation : ( ˈfʊlda ) ) ( historically in English called Fuld )', normalized_text='fulda german pronunciation ˈfʊlda historically in english called fuld'))], explanation_type='single_sentence'),\n",
       " -8311261765349453370: QEDExample(example_id=-8311261765349453370, title='List of smoking bans in the United States', question='when did the smoking ban in public places start', passage=\"In 1995 , California was the first state to enact a statewide smoking ban ; throughout the early to mid-2000s , especially between 2004 and 2007 , an increasing number of states enacted a statewide smoking ban of some kind . As of July 2017 , the most recent statewide smoking ban is North Dakota 's , which was ratified by voters on November 6 , 2012 .\", sentence_starts=[0, 225], selected_sent={'start': 0, 'end': 225, 'string': 'In 1995 , California was the first state to enact a statewide smoking ban ; throughout the early to mid-2000s , especially between 2004 and 2007 , an increasing number of states enacted a statewide smoking ban of some kind . '}, answer=[Entity(start_offset=3, end_offset=7, type='context', text='1995', normalized_text='1995')], nq_answers=[[Entity(start_offset=3, end_offset=7, type='context', text='1995', normalized_text='1995')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 5695822721888688847: QEDExample(example_id=5695822721888688847, title='History of the Forbidden City', question='who ordered the forbidden city to be built', passage=\"The site of the Forbidden City was situated on the Imperial city during the Mongol Yuan Dynasty . After the collapse of the Yuan Dynasty , the Hongwu Emperor of the Ming Dynasty moved the capital from Beijing in the north to Nanjing in the south , and in 1369 ordered that the Yuan palaces be razed . His son Zhu Di was created Prince of Yan with his seat in Beijing . In 1402 , Zhu Di usurped the throne and became the Yongle Emperor . He made Beijing a secondary capital of the Ming empire , and construction began in 1406 of what would become the Forbidden City . The Forbidden City 's plan was designed by many architects and designers , and then it was examined by the Emperor 's Ministry of Work . The chief architects and engineers include Cai Xin , Nguyen An , a Vietnamese eunuch , Kuai Xiang , Lu Xiang and others .\", sentence_starts=[0, 98, 301, 369, 437, 567, 704], selected_sent={'start': 437, 'end': 567, 'string': 'He made Beijing a secondary capital of the Ming empire , and construction began in 1406 of what would become the Forbidden City . '}, answer=[Entity(start_offset=379, end_offset=385, type='context', text='Zhu Di', normalized_text='zhu di')], nq_answers=[[Entity(start_offset=379, end_offset=385, type='context', text='Zhu Di', normalized_text='zhu di')], [Entity(start_offset=309, end_offset=315, type='context', text='Zhu Di', normalized_text='zhu di')]], aligned_nps=[(Entity(start_offset=12, end_offset=30, type='question', text='the forbidden city', normalized_text='forbidden city'), Entity(start_offset=546, end_offset=564, type='context', text='the Forbidden City', normalized_text='forbidden city'))], explanation_type='single_sentence'),\n",
       " 2670565187885347608: QEDExample(example_id=2670565187885347608, title='Circle of Willis', question='an important function of the circle of willis is to', passage=\"The circle of Willis ( also called Willis ' circle , loop of Willis , cerebral arterial circle , and Willis polygon ) is a circulatory anastomosis that supplies blood to the brain and surrounding structures . It is named after Thomas Willis ( 1621 -- 1675 ) , an English physician .\", sentence_starts=[0, 209], selected_sent={'start': 0, 'end': 209, 'string': \"The circle of Willis ( also called Willis ' circle , loop of Willis , cerebral arterial circle , and Willis polygon ) is a circulatory anastomosis that supplies blood to the brain and surrounding structures . \"}, answer=[Entity(start_offset=152, end_offset=206, type='context', text='supplies blood to the brain and surrounding structures', normalized_text='supplies blood to brain and surrounding structures')], nq_answers=[[Entity(start_offset=152, end_offset=206, type='context', text='supplies blood to the brain and surrounding structures', normalized_text='supplies blood to brain and surrounding structures')]], aligned_nps=[(Entity(start_offset=25, end_offset=45, type='question', text='the circle of willis', normalized_text='circle of willis'), Entity(start_offset=0, end_offset=117, type='context', text=\"The circle of Willis ( also called Willis ' circle , loop of Willis , cerebral arterial circle , and Willis polygon )\", normalized_text='circle of willis also called willis circle loop of willis cerebral arterial circle and willis polygon'))], explanation_type='single_sentence'),\n",
       " -252884797611335797: QEDExample(example_id=-252884797611335797, title='Efren Reyes', question='who was the greatest pool player of all time', passage='Efren Manalang Reyes , OLD , PLH ( born August 26 , 1954 ) , nicknamed the Magician and Bata , is a Filipino professional pool player . A winner of over 70 international titles , Reyes was the first player to win world championships in two different disciplines in pool . Among his numerous titles Reyes is a four - time World Eight - ball Champion , the 1999 WPA World Nine - ball Champion , a three - time US Open winner , a two - time World Pool League winner and a 14 - time Derby City Classic winner -- including an unprecedented five Master of the Table crowns . By defeating Earl Strickland in the inaugural Color of Money event in 1996 , Reyes took home the largest single event purse in pool history . Many analysts , fans , and current and former players consider Reyes to be the greatest pool player of all time .', sentence_starts=[0, 136, 272, 569, 711], selected_sent={'start': 711, 'end': 824, 'string': 'Many analysts , fans , and current and former players consider Reyes to be the greatest pool player of all time .'}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='Efren Manalang Reyes', normalized_text='efren manalang reyes')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='Efren Manalang Reyes', normalized_text='efren manalang reyes')]], aligned_nps=[(Entity(start_offset=8, end_offset=44, type='question', text='the greatest pool player of all time', normalized_text='greatest pool player of all time'), Entity(start_offset=786, end_offset=822, type='context', text='the greatest pool player of all time', normalized_text='greatest pool player of all time'))], explanation_type='single_sentence'),\n",
       " 618673237462258667: QEDExample(example_id=618673237462258667, title='Corn Belt', question='the world famous corn belt is in which country', passage=\"The Corn Belt is a region of the Midwestern United States that , since the 1850s , has dominated corn production in the United States . More generally , the concept of the `` Corn Belt '' connotes the area of the Midwest dominated by farming . Many towns in this area are connected to powerful farm organizations with lobbying power .\", sentence_starts=[0, 136, 244], selected_sent={'start': 0, 'end': 136, 'string': 'The Corn Belt is a region of the Midwestern United States that , since the 1850s , has dominated corn production in the United States . '}, answer=[Entity(start_offset=116, end_offset=133, type='context', text='the United States', normalized_text='united states')], nq_answers=[[Entity(start_offset=116, end_offset=133, type='context', text='the United States', normalized_text='united states')], [Entity(start_offset=44, end_offset=57, type='context', text='United States', normalized_text='united states')]], aligned_nps=[(Entity(start_offset=0, end_offset=26, type='question', text='the world famous corn belt', normalized_text='world famous corn belt'), Entity(start_offset=0, end_offset=13, type='context', text='The Corn Belt', normalized_text='corn belt'))], explanation_type='single_sentence'),\n",
       " 4684008146287743969: QEDExample(example_id=4684008146287743969, title='Early world maps', question='who were the the continent of the americas named after logically', passage='The cartographers Martin Waldseemüller and Matthias Ringmann from southern Germany , supported by the mapping friend René II , Duke of Lorraine , collected map data over several years , including information on the most recent discoveries , to build up a new collective work of geography and cartography . Along with a book they further incorporated , for the first time in history , the name America on a map , holding the strong opinion that it was a new continent that Amerigo Vespucci had discovered on his voyage and not only a few smaller islands as Christopher Columbus did in the West Indies .', sentence_starts=[0, 306], selected_sent={'start': 306, 'end': 601, 'string': 'Along with a book they further incorporated , for the first time in history , the name America on a map , holding the strong opinion that it was a new continent that Amerigo Vespucci had discovered on his voyage and not only a few smaller islands as Christopher Columbus did in the West Indies .'}, answer=[Entity(start_offset=472, end_offset=488, type='context', text='Amerigo Vespucci', normalized_text='amerigo vespucci')], nq_answers=[[Entity(start_offset=472, end_offset=488, type='context', text='Amerigo Vespucci', normalized_text='amerigo vespucci')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -1707804792683840190: QEDExample(example_id=-1707804792683840190, title='Texhoma, Oklahoma', question='towns on the border of texas and oklahoma', passage=\"Texhoma is a town in Texas County , Oklahoma , United States . The population was 926 at the 2010 census . Texhoma is a divided city with the Texas -- Oklahoma state border separating the town from Texhoma , Texas . The name of the town is a portmanteau of Texas and Oklahoma . Founded around the Rock Island Railroad laying tracks through the area , much of the town 's local economy is from ranching and livestock .\", sentence_starts=[0, 63, 107, 216, 278], selected_sent={'start': 107, 'end': 216, 'string': 'Texhoma is a divided city with the Texas -- Oklahoma state border separating the town from Texhoma , Texas . '}, answer=[Entity(start_offset=107, end_offset=114, type='context', text='Texhoma', normalized_text='texhoma')], nq_answers=[[Entity(start_offset=0, end_offset=7, type='context', text='Texhoma', normalized_text='texhoma')]], aligned_nps=[(Entity(start_offset=9, end_offset=41, type='question', text='the border of texas and oklahoma', normalized_text='border of texas and oklahoma'), Entity(start_offset=138, end_offset=172, type='context', text='the Texas -- Oklahoma state border', normalized_text='texas oklahoma state border'))], explanation_type='single_sentence'),\n",
       " 5148818660629258377: QEDExample(example_id=5148818660629258377, title='The Quiet Man', question='what year does the quiet man take place', passage=\"In the 1920s , Sean Thornton ( John Wayne ) , an Irish - born American from Pittsburgh , travels to Ireland to reclaim his family 's farm and his birthplace in Inisfree . He meets and falls in love with the fiery Mary Kate Danaher ( Maureen O'Hara ) , the sister of the bullying , loud - mouthed landowner Squire `` Red '' Will Danaher ( Victor McLaglen ) . Danaher , who had wanted the farm himself , is angry that the Widow Tillane ( angered by Danaher 's admission that he had discussed her in the local pub ) accepts Sean 's bid , and retaliates by refusing consent for his sister to marry . Several town locals , including the Catholic priest , Father Lonergan ( Ward Bond ) and the village matchmaker ( and bookmaker ) Michaleen Oge Flynn ( Barry Fitzgerald ) , conspire to trick him into believing that the wealthy Widow Tillane ( Mildred Natwick ) wants to marry him , but only if Mary Kate is no longer living in his house . After learning the truth on Sean and Mary Kate 's wedding day , an enraged Will refuses to give his sister her dowry which is made up of a large sum of money and her family possessions passed down from her mother .\", sentence_starts=[0, 171, 358, 596, 934], selected_sent={'start': 0, 'end': 171, 'string': \"In the 1920s , Sean Thornton ( John Wayne ) , an Irish - born American from Pittsburgh , travels to Ireland to reclaim his family 's farm and his birthplace in Inisfree . \"}, answer=[Entity(start_offset=3, end_offset=12, type='context', text='the 1920s', normalized_text='1920s')], nq_answers=[[Entity(start_offset=3, end_offset=12, type='context', text='the 1920s', normalized_text='1920s')], [Entity(start_offset=0, end_offset=12, type='context', text='In the 1920s', normalized_text='in 1920s')]], aligned_nps=[(Entity(start_offset=15, end_offset=28, type='question', text='the quiet man', normalized_text='quiet man'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 426530127367719144: QEDExample(example_id=426530127367719144, title='A Bend in the Road', question='who killed missy in a bend in the road', passage=\"Is Jonah 's second grade teacher . She used to live at Baltimore but moved to New Bern in the hope of starting over after a really difficult divorce . She was not able to have children which was the reason why her marriage did n't work . Due to her kindness she offered to tutor Jonah after school . She loved Miles and enjoyed spending times with Jonah . After she discovered that her brother , Brian , was Missy 's killer she was torn apart .\", sentence_starts=[0, 35, 151, 238, 300, 356], selected_sent={'start': 356, 'end': 444, 'string': \"After she discovered that her brother , Brian , was Missy 's killer she was torn apart .\"}, answer=[Entity(start_offset=396, end_offset=401, type='context', text='Brian', normalized_text='brian')], nq_answers=[[Entity(start_offset=396, end_offset=401, type='context', text='Brian', normalized_text='brian')]], aligned_nps=[(Entity(start_offset=11, end_offset=16, type='question', text='missy', normalized_text='missy'), Entity(start_offset=408, end_offset=413, type='context', text='Missy', normalized_text='missy')), (Entity(start_offset=20, end_offset=38, type='question', text='a bend in the road', normalized_text='bend in road'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 837987629649092236: QEDExample(example_id=837987629649092236, title='One-child policy', question='when did one child policy end in china', passage=\"The one - child policy , a part of the family planning policy , was a population planning policy of China . It was introduced in 1979 and began to be formally phased out near the end of 2015 and the beginning of 2016 . The policy was only enforced on Han Chinese and allowed exceptions for many groups , including ethnic minorities . In 2007 , 36 % of China 's population was subject to a strict one - child restriction , with an additional 53 % being allowed to have a second child if the first child was a girl . Provincial governments imposed fines for violations , and the local and national governments created commissions to raise awareness and carry out registration and inspection work .\", sentence_starts=[0, 108, 219, 334, 515], selected_sent={'start': 108, 'end': 219, 'string': 'It was introduced in 1979 and began to be formally phased out near the end of 2015 and the beginning of 2016 . '}, answer=[Entity(start_offset=170, end_offset=216, type='context', text='near the end of 2015 and the beginning of 2016', normalized_text='near end of 2015 and beginning of 2016')], nq_answers=[[Entity(start_offset=170, end_offset=216, type='context', text='near the end of 2015 and the beginning of 2016', normalized_text='near end of 2015 and beginning of 2016')]], aligned_nps=[(Entity(start_offset=9, end_offset=25, type='question', text='one child policy', normalized_text='one child policy'), Entity(start_offset=108, end_offset=110, type='context', text='It', normalized_text='it')), (Entity(start_offset=33, end_offset=38, type='question', text='china', normalized_text='china'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -120593119776464649: QEDExample(example_id=-120593119776464649, title='2017 ICC Champions Trophy', question='who won the world cup in cricket 2017', passage='The 2017 ICC Champions Trophy was the eighth ICC Champions Trophy , a cricket tournament for the eight top - ranked One Day International ( ODI ) teams in the world . It was held in England and Wales from 1 June to 18 June 2017 . Pakistan won the competition for the first time with a 180 - run victory over India in the final at The Oval . The margin of victory was the largest by any team in the final of an ICC ODI tournament in terms of runs .', sentence_starts=[0, 167, 230, 341], selected_sent={'start': 230, 'end': 341, 'string': 'Pakistan won the competition for the first time with a 180 - run victory over India in the final at The Oval . '}, answer=[Entity(start_offset=230, end_offset=238, type='context', text='Pakistan', normalized_text='pakistan')], nq_answers=[[Entity(start_offset=230, end_offset=238, type='context', text='Pakistan', normalized_text='pakistan')]], aligned_nps=[(Entity(start_offset=8, end_offset=37, type='question', text='the world cup in cricket 2017', normalized_text='world cup in cricket 2017'), Entity(start_offset=243, end_offset=258, type='context', text='the competition', normalized_text='competition'))], explanation_type='single_sentence'),\n",
       " -5039045537721106027: QEDExample(example_id=-5039045537721106027, title='Nashville (season 6)', question='how many episodes are there in season six of nashville', passage='The sixth and final season of the American television drama series Nashville , created by Callie Khouri , premiered on January 4 , 2018 , on CMT . The season will consist of 16 episodes .', sentence_starts=[0, 147], selected_sent={'start': 147, 'end': 187, 'string': 'The season will consist of 16 episodes .'}, answer=[Entity(start_offset=174, end_offset=185, type='context', text='16 episodes', normalized_text='16 episodes')], nq_answers=[[Entity(start_offset=174, end_offset=185, type='context', text='16 episodes', normalized_text='16 episodes')], [Entity(start_offset=174, end_offset=176, type='context', text='16', normalized_text='16')]], aligned_nps=[(Entity(start_offset=31, end_offset=54, type='question', text='season six of nashville', normalized_text='season six of nashville'), Entity(start_offset=147, end_offset=157, type='context', text='The season', normalized_text='season'))], explanation_type='single_sentence'),\n",
       " -1985459647494342298: QEDExample(example_id=-1985459647494342298, title='Major League Baseball rosters', question='how many pitchers does a major league team have', passage=\"Typically , in modern - day play , an active roster will consist of five starting pitchers , seven relief pitchers , two catchers , six infielders , and five outfielders . Teams can vary this somewhat according to preference and circumstance , and indeed the `` typical '' roster makeup has changed somewhat over the years . ( Starting rotations used to consist of four pitchers , not five , well into the 1970s ; third - string catchers used to be much more common ; many other minor variations exist . ) In the American League , a full - time designated hitter is usually classified as either an infielder or an outfielder , not a DH , because most DHs do play defensive positions from time to time .\", sentence_starts=[0, 172, 325, 506], selected_sent={'start': 0, 'end': 172, 'string': 'Typically , in modern - day play , an active roster will consist of five starting pitchers , seven relief pitchers , two catchers , six infielders , and five outfielders . '}, answer=[Entity(start_offset=68, end_offset=114, type='context', text='five starting pitchers , seven relief pitchers', normalized_text='five starting pitchers seven relief pitchers')], nq_answers=[[Entity(start_offset=68, end_offset=90, type='context', text='five starting pitchers', normalized_text='five starting pitchers'), Entity(start_offset=93, end_offset=114, type='context', text='seven relief pitchers', normalized_text='seven relief pitchers')]], aligned_nps=[(Entity(start_offset=23, end_offset=42, type='question', text='a major league team', normalized_text='major league team'), Entity(start_offset=35, end_offset=51, type='context', text='an active roster', normalized_text='active roster'))], explanation_type='single_sentence'),\n",
       " 57534108542742158: QEDExample(example_id=57534108542742158, title='NFL International Series', question='where is the nfl game in london played', passage='Initially , all games in the International Series were held in London . Wembley Stadium was the exclusive home stadium for International Series games from 2007 to 2015 and will continue to host NFL games through at least 2020 ; beginning in 2016 , the series began expanding to more stadiums , first to Twickenham Stadium , London ( 2016 -- 18 ) and to Estadio Azteca , Mexico City ( 2016 -- ) and will eventually expand to the still under construction new stadium at Northumberland Park also in London ( 2018 -- 27 ) , with possible future plans to expand the series to Germany and / or Canada .', sentence_starts=[0, 72], selected_sent={'start': 72, 'end': 596, 'string': 'Wembley Stadium was the exclusive home stadium for International Series games from 2007 to 2015 and will continue to host NFL games through at least 2020 ; beginning in 2016 , the series began expanding to more stadiums , first to Twickenham Stadium , London ( 2016 -- 18 ) and to Estadio Azteca , Mexico City ( 2016 -- ) and will eventually expand to the still under construction new stadium at Northumberland Park also in London ( 2018 -- 27 ) , with possible future plans to expand the series to Germany and / or Canada .'}, answer=[Entity(start_offset=72, end_offset=345, type='context', text='Wembley Stadium was the exclusive home stadium for International Series games from 2007 to 2015 and will continue to host NFL games through at least 2020 ; beginning in 2016 , the series began expanding to more stadiums , first to Twickenham Stadium , London ( 2016 -- 18 )', normalized_text='wembley stadium was exclusive home stadium for international series games from 2007 to 2015 and will continue to host nfl games through at least 2020 beginning in 2016 series began expanding to more stadiums first to twickenham stadium london 2016 18')], nq_answers=[[Entity(start_offset=72, end_offset=87, type='context', text='Wembley Stadium', normalized_text='wembley stadium'), Entity(start_offset=303, end_offset=321, type='context', text='Twickenham Stadium', normalized_text='twickenham stadium')], [Entity(start_offset=303, end_offset=321, type='context', text='Twickenham Stadium', normalized_text='twickenham stadium')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -9062168222628747722: QEDExample(example_id=-9062168222628747722, title='Pudding Pop', question='when did they stop making jello pudding pops', passage='Pudding Pops originated in Baton Rouge , Louisiana in the 1970s in the United States of America . In its first year , it earned $100,000,000 , and after 5 years , it was earning $300,000,000 a year . Despite strong sales into the 90s , Pudding Pops were eventually discontinued due to not being profitable .', sentence_starts=[0, 98, 200], selected_sent={'start': 200, 'end': 307, 'string': 'Despite strong sales into the 90s , Pudding Pops were eventually discontinued due to not being profitable .'}, answer=[Entity(start_offset=226, end_offset=233, type='context', text='the 90s', normalized_text='90s')], nq_answers=[[Entity(start_offset=226, end_offset=233, type='context', text='the 90s', normalized_text='90s')]], aligned_nps=[(Entity(start_offset=26, end_offset=44, type='question', text='jello pudding pops', normalized_text='jello pudding pops'), Entity(start_offset=236, end_offset=248, type='context', text='Pudding Pops', normalized_text='pudding pops'))], explanation_type='single_sentence'),\n",
       " -3752184728420593959: QEDExample(example_id=-3752184728420593959, title='Super Bowl LII', question='who are the two teams in super bowl 2018', passage='Super Bowl LII was an American football game played to determine the champion of the National Football League ( NFL ) for the 2017 season . The National Football Conference ( NFC ) champion Philadelphia Eagles defeated the American Football Conference ( AFC ) and defending Super Bowl LI champion New England Patriots , 41 -- 33 , to win their first Super Bowl and their first NFL title since 1960 . The game was played on February 4 , 2018 , at U.S. Bank Stadium in Minneapolis , Minnesota . This was the second time that a Super Bowl was played in Minneapolis , the northernmost city to ever host the event , after Super Bowl XXVI at the Metrodome during the 1991 season , and the sixth Super Bowl held in a cold - weather city .', sentence_starts=[0, 140, 400, 493], selected_sent={'start': 140, 'end': 400, 'string': 'The National Football Conference ( NFC ) champion Philadelphia Eagles defeated the American Football Conference ( AFC ) and defending Super Bowl LI champion New England Patriots , 41 -- 33 , to win their first Super Bowl and their first NFL title since 1960 . '}, answer=[Entity(start_offset=140, end_offset=317, type='context', text='The National Football Conference ( NFC ) champion Philadelphia Eagles defeated the American Football Conference ( AFC ) and defending Super Bowl LI champion New England Patriots', normalized_text='national football conference nfc champion philadelphia eagles defeated american football conference afc and defending super bowl li champion new england patriots')], nq_answers=[[Entity(start_offset=190, end_offset=209, type='context', text='Philadelphia Eagles', normalized_text='philadelphia eagles'), Entity(start_offset=297, end_offset=317, type='context', text='New England Patriots', normalized_text='new england patriots')], [Entity(start_offset=140, end_offset=209, type='context', text='The National Football Conference ( NFC ) champion Philadelphia Eagles', normalized_text='national football conference nfc champion philadelphia eagles'), Entity(start_offset=219, end_offset=317, type='context', text='the American Football Conference ( AFC ) and defending Super Bowl LI champion New England Patriots', normalized_text='american football conference afc and defending super bowl li champion new england patriots')]], aligned_nps=[(Entity(start_offset=25, end_offset=40, type='question', text='super bowl 2018', normalized_text='super bowl 2018'), Entity(start_offset=338, end_offset=360, type='context', text='their first Super Bowl', normalized_text='their first super bowl'))], explanation_type='single_sentence'),\n",
       " 7984467382413205263: QEDExample(example_id=7984467382413205263, title='John Quincy Adams', question='who is the sixth president of the united states', passage='John Quincy Adams ( / ˈkwɪnzi / ( listen ) ; July 11 , 1767 -- February 23 , 1848 ) was an American statesman who served as a diplomat , minister and ambassador to foreign nations , and treaty negotiator , United States Senator , U.S. Representative ( Congressman ) from Massachusetts , and the sixth President of the United States from 1825 to 1829 . He was a member of the Federalists like his famous influential father , but later switched to the Jeffersonian Democratic - Republican , National Republican , and later the Anti-Masonic and Whig parties when they were organized . He was the son of second President John Adams ( 1735 - 1826 , served 1797 - 1801 ) , and his wife , Abigail Adams .', sentence_starts=[0, 352, 582], selected_sent={'start': 0, 'end': 352, 'string': 'John Quincy Adams ( / ˈkwɪnzi / ( listen ) ; July 11 , 1767 -- February 23 , 1848 ) was an American statesman who served as a diplomat , minister and ambassador to foreign nations , and treaty negotiator , United States Senator , U.S. Representative ( Congressman ) from Massachusetts , and the sixth President of the United States from 1825 to 1829 . '}, answer=[Entity(start_offset=0, end_offset=17, type='context', text='John Quincy Adams', normalized_text='john quincy adams')], nq_answers=[[Entity(start_offset=0, end_offset=17, type='context', text='John Quincy Adams', normalized_text='john quincy adams')]], aligned_nps=[(Entity(start_offset=7, end_offset=47, type='question', text='the sixth president of the united states', normalized_text='sixth president of united states'), Entity(start_offset=291, end_offset=331, type='context', text='the sixth President of the United States', normalized_text='sixth president of united states'))], explanation_type='single_sentence'),\n",
       " -6687867009117829006: QEDExample(example_id=-6687867009117829006, title='Beorn', question='who turns into a bear in the hobbit', passage=\"Beorn is a fictional character created by J.R.R. Tolkien . He appears in The Hobbit as a `` skin - changer '' , a man who could assume the form of a great black bear .\", sentence_starts=[0, 49, 59], selected_sent={'start': 59, 'end': 167, 'string': \"He appears in The Hobbit as a `` skin - changer '' , a man who could assume the form of a great black bear .\"}, answer=[Entity(start_offset=0, end_offset=5, type='context', text='Beorn', normalized_text='beorn')], nq_answers=[[Entity(start_offset=0, end_offset=5, type='context', text='Beorn', normalized_text='beorn')]], aligned_nps=[(Entity(start_offset=25, end_offset=35, type='question', text='the hobbit', normalized_text='hobbit'), Entity(start_offset=73, end_offset=83, type='context', text='The Hobbit', normalized_text='hobbit'))], explanation_type='single_sentence'),\n",
       " -1100776571922066473: QEDExample(example_id=-1100776571922066473, title='Reba McEntire', question='when did reba mcentire record back to god', passage=\"On December 15 , 2016 , McEntire announced that she was releasing her first Gospel album titled Sing It Now : Songs of Faith & Hope . It was released by Nash Icon / Rockin ' R Records on February 3 , 2017 , and consists of two discs . Disc one contains traditional hymns while disc two contains original tracks . `` Softly and Tenderly '' , featuring Kelly Clarkson and Trisha Yearwood , was the first track off the album released . Another track on the album , `` In the Garden / Wonderful Peace '' , features The Isaacs . Jay DeMarcus of the Rascal Flatts produced the album . The first single off the album is `` Back to God '' . She also headlined the C2C : Country to Country festival in the UK alongside Brad Paisley and Zac Brown Band in March .\", sentence_starts=[0, 134, 235, 313, 433, 524, 579, 633], selected_sent={'start': 579, 'end': 633, 'string': \"The first single off the album is `` Back to God '' . \"}, answer=[Entity(start_offset=187, end_offset=204, type='context', text='February 3 , 2017', normalized_text='february 3 2017')], nq_answers=[[Entity(start_offset=187, end_offset=204, type='context', text='February 3 , 2017', normalized_text='february 3 2017')], [Entity(start_offset=200, end_offset=204, type='context', text='2017', normalized_text='2017')]], aligned_nps=[(Entity(start_offset=30, end_offset=41, type='question', text='back to god', normalized_text='back to god'), Entity(start_offset=616, end_offset=627, type='context', text='Back to God', normalized_text='back to god')), (Entity(start_offset=9, end_offset=22, type='question', text='reba mcentire', normalized_text='reba mcentire'), Entity(start_offset=600, end_offset=609, type='context', text='the album', normalized_text='album'))], explanation_type='single_sentence'),\n",
       " 6563592320308552203: QEDExample(example_id=6563592320308552203, title='X-ray', question='what is the wave length of x rays', passage='X-rays make up X-radiation , a form of electromagnetic radiation . Most X-rays have a wavelength ranging from 0.01 to 10 nanometers , corresponding to frequencies in the range 30 petahertz to 30 exahertz ( 3 × 10 Hz to 3 × 10 Hz ) and energies in the range 100 eV to 100 keV . X-ray wavelengths are shorter than those of UV rays and typically longer than those of gamma rays . In many languages , X-radiation is referred to with terms meaning Röntgen radiation , after the German scientist Wilhelm Röntgen , who usually is credited as its discoverer , and who named it X-radiation to signify an unknown type of radiation . Spelling of X-ray ( s ) in the English language includes the variants x-ray ( s ) , xray ( s ) , and X ray ( s ) .', sentence_starts=[0, 67, 277, 377, 623], selected_sent={'start': 67, 'end': 277, 'string': 'Most X-rays have a wavelength ranging from 0.01 to 10 nanometers , corresponding to frequencies in the range 30 petahertz to 30 exahertz ( 3 × 10 Hz to 3 × 10 Hz ) and energies in the range 100 eV to 100 keV . '}, answer=[Entity(start_offset=110, end_offset=131, type='context', text='0.01 to 10 nanometers', normalized_text='001 to 10 nanometers')], nq_answers=[[Entity(start_offset=105, end_offset=131, type='context', text='from 0.01 to 10 nanometers', normalized_text='from 001 to 10 nanometers')], [Entity(start_offset=105, end_offset=274, type='context', text='from 0.01 to 10 nanometers , corresponding to frequencies in the range 30 petahertz to 30 exahertz ( 3 × 10 Hz to 3 × 10 Hz ) and energies in the range 100 eV to 100 keV', normalized_text='from 001 to 10 nanometers corresponding to frequencies in range 30 petahertz to 30 exahertz 3 × 10 hz to 3 × 10 hz and energies in range 100 ev to 100 kev')], [Entity(start_offset=97, end_offset=131, type='context', text='ranging from 0.01 to 10 nanometers', normalized_text='ranging from 001 to 10 nanometers')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -8036273344877520260: QEDExample(example_id=-8036273344877520260, title='Separation of church and state in the United States', question='word that means separation of church and state', passage=\"In contrast to separationism , the Supreme Court of the United States in Zorach v. Clauson upheld accommodationism , holding that the nation 's `` institutions presuppose a Supreme Being '' and that government recognition of God does not constitute the establishment of a state church as the Constitution 's authors intended to prohibit . As such , the Court has not always interpreted the constitutional principle as absolute , and the proper extent of separation between government and religion in the U.S. remains an ongoing subject of impassioned debate .\", sentence_starts=[0, 339], selected_sent={'start': 0, 'end': 339, 'string': \"In contrast to separationism , the Supreme Court of the United States in Zorach v. Clauson upheld accommodationism , holding that the nation 's `` institutions presuppose a Supreme Being '' and that government recognition of God does not constitute the establishment of a state church as the Constitution 's authors intended to prohibit . \"}, answer=[Entity(start_offset=15, end_offset=28, type='context', text='separationism', normalized_text='separationism')], nq_answers=[[Entity(start_offset=15, end_offset=28, type='context', text='separationism', normalized_text='separationism')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -7441664959761486909: QEDExample(example_id=-7441664959761486909, title='History of mobile phones', question='where was the first cell phone call made', passage='Prior to 1973 , mobile telephony was limited to phones installed in cars and other vehicles . Motorola was the first company to produce a handheld mobile phone . On April 3 , 1973 , Martin Cooper , a Motorola researcher and executive , made the first mobile telephone call from handheld subscriber equipment , placing a call to Dr. Joel S. Engel of Bell Labs , his rival . The prototype handheld phone used by Dr. Cooper weighed 1.1 kg ( 2.42 lb ) and measured 23 cm long , 13 cm deep and 4.45 cm wide . The prototype offered a talk time of just 30 minutes and took 10 hours to re-charge .', sentence_starts=[0, 94, 162, 373, 504], selected_sent={'start': 162, 'end': 373, 'string': 'On April 3 , 1973 , Martin Cooper , a Motorola researcher and executive , made the first mobile telephone call from handheld subscriber equipment , placing a call to Dr. Joel S. Engel of Bell Labs , his rival . '}, answer=[Entity(start_offset=165, end_offset=179, type='context', text='April 3 , 1973', normalized_text='april 3 1973')], nq_answers=[[Entity(start_offset=165, end_offset=179, type='context', text='April 3 , 1973', normalized_text='april 3 1973')]], aligned_nps=[(Entity(start_offset=10, end_offset=35, type='question', text='the first cell phone call', normalized_text='first cell phone call'), Entity(start_offset=241, end_offset=272, type='context', text='the first mobile telephone call', normalized_text='first mobile telephone call'))], explanation_type='single_sentence'),\n",
       " 4510033582697563667: QEDExample(example_id=4510033582697563667, title='The Karate Kid (2010 film)', question='where does the karate kid 2010 take place', passage=\"The Karate Kid is a 2010 family martial arts drama film directed by Harald Zwart . It stars Jaden Smith , Taraji P. Henson and Jackie Chan in lead roles , and it was produced by Jerry Weintraub , James Lassiter , Ken Stovitz and Jaden 's parents Will Smith and Jada Pinkett Smith . The screenplay by Christopher Murphey was from the story written by Robert Mark Kamen for the original The Karate Kid . Unlike the original , this remake is set in China , and features Kung Fu instead of Okinawan Karate . The film 's music was composed by James Horner . It is an international co-production between China , Hong Kong , and the United States .\", sentence_starts=[0, 83, 282, 402, 504, 553], selected_sent={'start': 402, 'end': 504, 'string': 'Unlike the original , this remake is set in China , and features Kung Fu instead of Okinawan Karate . '}, answer=[Entity(start_offset=446, end_offset=451, type='context', text='China', normalized_text='china')], nq_answers=[[Entity(start_offset=446, end_offset=451, type='context', text='China', normalized_text='china')]], aligned_nps=[(Entity(start_offset=11, end_offset=30, type='question', text='the karate kid 2010', normalized_text='karate kid 2010'), Entity(start_offset=424, end_offset=435, type='context', text='this remake', normalized_text='this remake'))], explanation_type='single_sentence'),\n",
       " -5633085462284184713: QEDExample(example_id=-5633085462284184713, title='Sex differences in humans', question='which body system differentiates a male from a female', passage=\"Sex differences in humans , or gender differences in humans , have been studied in a variety of fields . In humans , biological sex is determined by five factors present at birth : the presence or absence of a Y chromosome , the type of gonads , the sex hormones , the internal reproductive anatomy ( such as the uterus in females ) , and the external genitalia . Genetic sex is determined solely by the presence or absence of a Y chromosome . A child 's presumed sex is determined at birth by observation of the external genitalia .\", sentence_starts=[0, 105, 364, 444], selected_sent={'start': 105, 'end': 364, 'string': 'In humans , biological sex is determined by five factors present at birth : the presence or absence of a Y chromosome , the type of gonads , the sex hormones , the internal reproductive anatomy ( such as the uterus in females ) , and the external genitalia . '}, answer=[Entity(start_offset=181, end_offset=361, type='context', text='the presence or absence of a Y chromosome , the type of gonads , the sex hormones , the internal reproductive anatomy ( such as the uterus in females ) , and the external genitalia', normalized_text='presence or absence of y chromosome type of gonads sex hormones internal reproductive anatomy such as uterus in females and external genitalia')], nq_answers=[[Entity(start_offset=181, end_offset=222, type='context', text='the presence or absence of a Y chromosome', normalized_text='presence or absence of y chromosome'), Entity(start_offset=225, end_offset=243, type='context', text='the type of gonads', normalized_text='type of gonads'), Entity(start_offset=246, end_offset=262, type='context', text='the sex hormones', normalized_text='sex hormones'), Entity(start_offset=265, end_offset=332, type='context', text='the internal reproductive anatomy ( such as the uterus in females )', normalized_text='internal reproductive anatomy such as uterus in females'), Entity(start_offset=339, end_offset=361, type='context', text='the external genitalia', normalized_text='external genitalia')], [Entity(start_offset=278, end_offset=290, type='context', text='reproductive', normalized_text='reproductive')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -2615988099636476869: QEDExample(example_id=-2615988099636476869, title='United States presidential line of succession', question='who comes after the president if he dies', passage=\"The succession follows the order of vice president , Speaker of the House of Representatives , President pro tempore of the Senate , and then the heads of federal executive departments who form the Cabinet of the United States . The Cabinet currently has fifteen members , beginning with the Secretary of State , and followed by the rest in the order of their positions ' creation . Those heads of department who are ineligible to act as president are also ineligible to succeed the president by succession , for example most commonly if they are not a natural - born U.S. citizen .\", sentence_starts=[0, 229, 383], selected_sent={'start': 0, 'end': 229, 'string': 'The succession follows the order of vice president , Speaker of the House of Representatives , President pro tempore of the Senate , and then the heads of federal executive departments who form the Cabinet of the United States . '}, answer=[Entity(start_offset=36, end_offset=50, type='context', text='vice president', normalized_text='vice president')], nq_answers=[[Entity(start_offset=36, end_offset=50, type='context', text='vice president', normalized_text='vice president')]], aligned_nps=[(Entity(start_offset=16, end_offset=29, type='question', text='the president', normalized_text='president'), Entity(start_offset=0, end_offset=14, type='context', text='The succession', normalized_text='succession'))], explanation_type='single_sentence'),\n",
       " -1532176139689397674: QEDExample(example_id=-1532176139689397674, title='Mississippi River', question='what is the width of the mississippi river', passage='In addition to the Ohio River , the major tributaries of the Lower Mississippi River are the White River , flowing in at the White River National Wildlife Refuge in east central Arkansas ; the Arkansas River , joining the Mississippi at Arkansas Post ; the Big Black River in Mississippi ; and the Yazoo River , meeting the Mississippi at Vicksburg , Mississippi . The widest point of the Mississippi River is in the Lower Mississippi portion where it exceeds 1 mile ( 1.6 km ) in width in several places .', sentence_starts=[0, 365], selected_sent={'start': 365, 'end': 506, 'string': 'The widest point of the Mississippi River is in the Lower Mississippi portion where it exceeds 1 mile ( 1.6 km ) in width in several places .'}, answer=[Entity(start_offset=452, end_offset=477, type='context', text='exceeds 1 mile ( 1.6 km )', normalized_text='exceeds 1 mile 16 km')], nq_answers=[[Entity(start_offset=452, end_offset=504, type='context', text='exceeds 1 mile ( 1.6 km ) in width in several places', normalized_text='exceeds 1 mile 16 km in width in several places')], [Entity(start_offset=460, end_offset=477, type='context', text='1 mile ( 1.6 km )', normalized_text='1 mile 16 km')], [Entity(start_offset=449, end_offset=504, type='context', text='it exceeds 1 mile ( 1.6 km ) in width in several places', normalized_text='it exceeds 1 mile 16 km in width in several places')]], aligned_nps=[(Entity(start_offset=21, end_offset=42, type='question', text='the mississippi river', normalized_text='mississippi river'), Entity(start_offset=385, end_offset=406, type='context', text='the Mississippi River', normalized_text='mississippi river'))], explanation_type='single_sentence'),\n",
       " 5404116173326600628: QEDExample(example_id=5404116173326600628, title='Quantum Leap', question='what was the final episode of quantum leap', passage=\"Episodes in the series subsequently follow Sam 's reaction to each leap ( typically ending the cold open with him uttering `` Oh , boy ! '' on discovering his situation ) , and then working with Al and Ziggy to figure out his new identity and whom he needs to help to `` set right what once went wrong '' and trigger the next leap . An episode typically ends as a cliffhanger showing the first few moments of Sam 's next leap ( along with him again uttering `` Oh , boy ! '' on discovering his situation ) , which is repeated in the following episode 's cold open . Though initially Sam 's leaping is believed by Al and the others on the Quantum Leap team to be random , the characters come to believe in later seasons that someone or something is controlling Sam 's leaping , and this is a central focus of the show 's finale episode , `` Mirror Image '' .\", sentence_starts=[0, 140, 333, 475, 566], selected_sent={'start': 566, 'end': 857, 'string': \"Though initially Sam 's leaping is believed by Al and the others on the Quantum Leap team to be random , the characters come to believe in later seasons that someone or something is controlling Sam 's leaping , and this is a central focus of the show 's finale episode , `` Mirror Image '' .\"}, answer=[Entity(start_offset=840, end_offset=852, type='context', text='Mirror Image', normalized_text='mirror image')], nq_answers=[[Entity(start_offset=837, end_offset=855, type='context', text=\"`` Mirror Image ''\", normalized_text='mirror image')]], aligned_nps=[(Entity(start_offset=9, end_offset=42, type='question', text='the final episode of quantum leap', normalized_text='final episode of quantum leap'), Entity(start_offset=808, end_offset=855, type='context', text=\"the show 's finale episode , `` Mirror Image ''\", normalized_text='show s finale episode mirror image'))], explanation_type='single_sentence'),\n",
       " -7779074658565223924: QEDExample(example_id=-7779074658565223924, title='Tam-Tams', question='what time do tam tams start in montreal', passage=\"Thousands of drum players , dancers , vendors and visitors come together every Sunday afternoon throughout the temperate months , occupying much of the open space on the eastern edge of Mount Royal Park ( also known as Fletcher 's Field ) . Jeanne - Mance Park , located directly across Avenue du Parc from where the Tam - Tams take place , serves as the city 's main outdoor sporting ground . As such , the entire area is generally quite popular on Sundays in the summertime , drawing an exceptionally diverse crowd to myriad activities . The Tam - Tams typically start around 10 : 30am and continue until sunset . It is not an officially sanctioned nor sponsored event , simply a regular if technically spontaneous event . As such , it 's difficult to pinpoint when it started or what motivated the first drum circle .\", sentence_starts=[0, 241, 394, 540, 616, 725], selected_sent={'start': 540, 'end': 616, 'string': 'The Tam - Tams typically start around 10 : 30am and continue until sunset . '}, answer=[Entity(start_offset=571, end_offset=587, type='context', text='around 10 : 30am', normalized_text='around 10 30am')], nq_answers=[[Entity(start_offset=571, end_offset=587, type='context', text='around 10 : 30am', normalized_text='around 10 30am')], [Entity(start_offset=578, end_offset=587, type='context', text='10 : 30am', normalized_text='10 30am')], [Entity(start_offset=544, end_offset=587, type='context', text='Tam - Tams typically start around 10 : 30am', normalized_text='tam tams typically start around 10 30am')]], aligned_nps=[(Entity(start_offset=13, end_offset=21, type='question', text='tam tams', normalized_text='tam tams'), Entity(start_offset=540, end_offset=554, type='context', text='The Tam - Tams', normalized_text='tam tams')), (Entity(start_offset=31, end_offset=39, type='question', text='montreal', normalized_text='montreal'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " -3875543356658910705: QEDExample(example_id=-3875543356658910705, title='Train of thought', question='where does the phrase train of thought come from', passage=\"The term `` train of thoughts '' was introduced and elaborated as early as in 1651 by Thomas Hobbes in his Leviathan , though with a somewhat different meaning ( similar to the meaning used by the British associationists ) :\", sentence_starts=[0], selected_sent={'start': 0, 'end': 224, 'string': \"The term `` train of thoughts '' was introduced and elaborated as early as in 1651 by Thomas Hobbes in his Leviathan , though with a somewhat different meaning ( similar to the meaning used by the British associationists ) :\"}, answer=[Entity(start_offset=86, end_offset=116, type='context', text='Thomas Hobbes in his Leviathan', normalized_text='thomas hobbes in his leviathan')], nq_answers=[[Entity(start_offset=37, end_offset=116, type='context', text='introduced and elaborated as early as in 1651 by Thomas Hobbes in his Leviathan', normalized_text='introduced and elaborated as early as in 1651 by thomas hobbes in his leviathan')], [Entity(start_offset=86, end_offset=116, type='context', text='Thomas Hobbes in his Leviathan', normalized_text='thomas hobbes in his leviathan')]], aligned_nps=[(Entity(start_offset=11, end_offset=38, type='question', text='the phrase train of thought', normalized_text='phrase train of thought'), Entity(start_offset=0, end_offset=32, type='context', text=\"The term `` train of thoughts ''\", normalized_text='term train of thoughts'))], explanation_type='single_sentence'),\n",
       " 5019280356001369026: QEDExample(example_id=5019280356001369026, title='The Deserted Village', question='central idea of poem lines from the deserted village', passage='The Deserted Village is a poem by Oliver Goldsmith published in 1770 . It is a work of social commentary , and condemns rural depopulation and the pursuit of excessive wealth .', sentence_starts=[0, 71], selected_sent={'start': 71, 'end': 176, 'string': 'It is a work of social commentary , and condemns rural depopulation and the pursuit of excessive wealth .'}, answer=[Entity(start_offset=111, end_offset=174, type='context', text='condemns rural depopulation and the pursuit of excessive wealth', normalized_text='condemns rural depopulation and pursuit of excessive wealth')], nq_answers=[[Entity(start_offset=87, end_offset=174, type='context', text='social commentary , and condemns rural depopulation and the pursuit of excessive wealth', normalized_text='social commentary and condemns rural depopulation and pursuit of excessive wealth')]], aligned_nps=[(Entity(start_offset=16, end_offset=52, type='question', text='poem lines from the deserted village', normalized_text='poem lines from deserted village'), Entity(start_offset=71, end_offset=73, type='context', text='It', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 360949604618135087: QEDExample(example_id=360949604618135087, title='Oppo', question=\"oppo is sponsor of which country's national cricket team\", passage=\"In 2017 , Oppo successfully won the bid to sponsor the Indian national cricket team and has achieved the rights to display their logo on the team 's kits from 2017 to 2022 . Between this period the Indian national cricket team will play 259 International matches consisting of 62 Tests , 152 ODIs and 45 T20 Internationals . This number also includes the 2019 World Cup in England and 2020 T20 World Cup in Australia . The current base price for bilateral matches involving India has been set at Rs 4.1 crore ( approx . ) and for Asian Cricket Council ( ACC ) and International Cricket Council ( ICC ) matches , it is Rs 1.56 crore ( approx . ) - almost a four-fold increase from its earlier rate .\", sentence_starts=[0, 174, 325, 419, 645], selected_sent={'start': 0, 'end': 174, 'string': \"In 2017 , Oppo successfully won the bid to sponsor the Indian national cricket team and has achieved the rights to display their logo on the team 's kits from 2017 to 2022 . \"}, answer=[Entity(start_offset=51, end_offset=83, type='context', text='the Indian national cricket team', normalized_text='indian national cricket team')], nq_answers=[[Entity(start_offset=51, end_offset=83, type='context', text='the Indian national cricket team', normalized_text='indian national cricket team')], [Entity(start_offset=474, end_offset=479, type='context', text='India', normalized_text='india')]], aligned_nps=[(Entity(start_offset=0, end_offset=4, type='question', text='oppo', normalized_text='oppo'), Entity(start_offset=10, end_offset=14, type='context', text='Oppo', normalized_text='oppo'))], explanation_type='single_sentence'),\n",
       " 1501526022846925044: QEDExample(example_id=1501526022846925044, title='Iodine', question='where is iodine found in the periodic table', passage=\"Iodine is a chemical element with symbol I and atomic number 53 . The heaviest of the stable halogens , it exists as a lustrous , purple - black metallic solid at standard conditions that sublimes readily to form a violet gas . The elemental form was discovered by the French chemist Bernard Courtois in 1811 . It was named two years later by Joseph - Louis Gay - Lussac from this property , after the Greek ἰωδης `` violet - coloured '' .\", sentence_starts=[0, 66, 228, 311], selected_sent={'start': 66, 'end': 228, 'string': 'The heaviest of the stable halogens , it exists as a lustrous , purple - black metallic solid at standard conditions that sublimes readily to form a violet gas . '}, answer=[Entity(start_offset=86, end_offset=101, type='context', text='stable halogens', normalized_text='stable halogens')], nq_answers=[[Entity(start_offset=70, end_offset=101, type='context', text='heaviest of the stable halogens', normalized_text='heaviest of stable halogens')]], aligned_nps=[(Entity(start_offset=9, end_offset=15, type='question', text='iodine', normalized_text='iodine'), Entity(start_offset=104, end_offset=106, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " 2666768182570875881: QEDExample(example_id=2666768182570875881, title='Cradle of civilization', question='where is the oldest civilization known to man', passage=\"The term `` cradle of civilization '' refers to locations where , according to current archeological data , civilization is understood to have emerged . Current thinking is that there was no single `` cradle '' , but several civilizations that developed independently , with the Fertile Crescent ( Mesopotamia and Ancient Egypt ) understood to be the earliest . Other civilizations arose in Asia among cultures situated along large river valleys , such as Indo - Gangetic Plain in the Indian subcontinent and the Yellow River in China . The extent to which there was significant influence between the early civilizations of the Near East and those of East Asia is disputed . Scholars accept that the civilizations of Mesoamerica , mainly in modern Mexico , and Norte Chico in present - day Peru emerged independently from those in Eurasia .\", sentence_starts=[0, 153, 362, 537, 675], selected_sent={'start': 153, 'end': 362, 'string': \"Current thinking is that there was no single `` cradle '' , but several civilizations that developed independently , with the Fertile Crescent ( Mesopotamia and Ancient Egypt ) understood to be the earliest . \"}, answer=[Entity(start_offset=275, end_offset=329, type='context', text='the Fertile Crescent ( Mesopotamia and Ancient Egypt )', normalized_text='fertile crescent mesopotamia and ancient egypt')], nq_answers=[[Entity(start_offset=279, end_offset=329, type='context', text='Fertile Crescent ( Mesopotamia and Ancient Egypt )', normalized_text='fertile crescent mesopotamia and ancient egypt')], [Entity(start_offset=275, end_offset=329, type='context', text='the Fertile Crescent ( Mesopotamia and Ancient Egypt )', normalized_text='fertile crescent mesopotamia and ancient egypt')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -3709961361146680521: QEDExample(example_id=-3709961361146680521, title='Epithelium', question='where do we find epithelial cells in humans', passage='Epithelium ( epi - + thele + - ium ) is one of the four basic types of animal tissue , along with connective tissue , muscle tissue and nervous tissue . Epithelial tissues line the cavities and surfaces of blood vessels and organs throughout the body .', sentence_starts=[0, 153], selected_sent={'start': 153, 'end': 252, 'string': 'Epithelial tissues line the cavities and surfaces of blood vessels and organs throughout the body .'}, answer=[Entity(start_offset=177, end_offset=250, type='context', text='the cavities and surfaces of blood vessels and organs throughout the body', normalized_text='cavities and surfaces of blood vessels and organs throughout body')], nq_answers=[[Entity(start_offset=177, end_offset=250, type='context', text='the cavities and surfaces of blood vessels and organs throughout the body', normalized_text='cavities and surfaces of blood vessels and organs throughout body')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 4580667860381630553: QEDExample(example_id=4580667860381630553, title='Mississippi', question='what are some special products made in mississippi', passage=\"Clearing of the land altered the Delta 's ecology , increasing the severity of flooding along the Mississippi . Much land is now held by agribusinesses . A largely rural state with agricultural areas dominated by industrial farms , Mississippi is ranked low or last among the states in such measures as health , educational attainment , and median household income . The state 's catfish aquaculture farms produce the majority of farm - raised catfish consumed in the United States .\", sentence_starts=[0, 112, 154, 367], selected_sent={'start': 367, 'end': 483, 'string': \"The state 's catfish aquaculture farms produce the majority of farm - raised catfish consumed in the United States .\"}, answer=[Entity(start_offset=430, end_offset=451, type='context', text='farm - raised catfish', normalized_text='farm raised catfish')], nq_answers=[[Entity(start_offset=430, end_offset=451, type='context', text='farm - raised catfish', normalized_text='farm raised catfish')]], aligned_nps=[(Entity(start_offset=39, end_offset=50, type='question', text='mississippi', normalized_text='mississippi'), Entity(start_offset=367, end_offset=376, type='context', text='The state', normalized_text='state'))], explanation_type='single_sentence'),\n",
       " 2704065110162515680: QEDExample(example_id=2704065110162515680, title='Extensor pollicis longus muscle', question='where is the extensor pollicis longus tendon located', passage='In human anatomy , the extensor pollicis longus muscle ( EPL ) is a skeletal muscle located dorsally on the forearm . It is much larger than the extensor pollicis brevis , the origin of which it partly covers and acts to stretch the thumb together with this muscle .', sentence_starts=[0, 118], selected_sent={'start': 0, 'end': 118, 'string': 'In human anatomy , the extensor pollicis longus muscle ( EPL ) is a skeletal muscle located dorsally on the forearm . '}, answer=[Entity(start_offset=92, end_offset=115, type='context', text='dorsally on the forearm', normalized_text='dorsally on forearm')], nq_answers=[[Entity(start_offset=92, end_offset=115, type='context', text='dorsally on the forearm', normalized_text='dorsally on forearm')], [Entity(start_offset=84, end_offset=115, type='context', text='located dorsally on the forearm', normalized_text='located dorsally on forearm')]], aligned_nps=[(Entity(start_offset=9, end_offset=44, type='question', text='the extensor pollicis longus tendon', normalized_text='extensor pollicis longus tendon'), Entity(start_offset=19, end_offset=62, type='context', text='the extensor pollicis longus muscle ( EPL )', normalized_text='extensor pollicis longus muscle epl'))], explanation_type='single_sentence'),\n",
       " 3624266518328727040: QEDExample(example_id=3624266518328727040, title='Printing press', question='who invented the printing press and what year', passage=\"Johannes Gutenberg , a goldsmith by profession , developed , circa 1439 , a printing system by adapting existing technologies to printing purposes , as well as making inventions of his own . Printing in East Asia had been prevalent since the Tang dynasty , and in Europe , woodblock printing based on existing screw presses was common by the 14th century . Gutenberg 's most important innovation was the development of hand - molded metal printing matrices , thus producing a movable type based printing press system . His newly devised hand mould made possible the precise and rapid creation of metal movable type in large quantities . Movable type had been hitherto unknown in Europe . In Europe , the two inventions , the hand mould and the printing press , together drastically reduced the cost of printing books and other documents , particularly in short print runs .\", sentence_starts=[0, 191, 357, 519, 637, 688], selected_sent={'start': 357, 'end': 519, 'string': \"Gutenberg 's most important innovation was the development of hand - molded metal printing matrices , thus producing a movable type based printing press system . \"}, answer=[Entity(start_offset=0, end_offset=71, type='context', text='Johannes Gutenberg , a goldsmith by profession , developed , circa 1439', normalized_text='johannes gutenberg goldsmith by profession developed circa 1439')], nq_answers=[[Entity(start_offset=0, end_offset=18, type='context', text='Johannes Gutenberg', normalized_text='johannes gutenberg'), Entity(start_offset=61, end_offset=71, type='context', text='circa 1439', normalized_text='circa 1439')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -2576507331893021303: QEDExample(example_id=-2576507331893021303, title='Gambling in New Jersey', question='how many casinos are in atlantic city new jersey', passage=\"To address Christie 's concerns , new legislation was drafted that prohibits businesses other than Atlantic City casinos from advertising online gambling , or allowing their facilities to be used for online gambling . On February 26 , 2013 , a revised bill permitting Internet gambling was overwhelming approved by the New Jersey Legislature , and then signed into law by Chris Christie . The law legalizes online casino gambling for a 10 - year trial period , restricts the operation of the websites to Atlantic City 's eleven casinos , and imposes a 15 % tax on online gambling revenue , instead of the 8 % currently imposed on casinos .\", sentence_starts=[0, 218, 389], selected_sent={'start': 389, 'end': 639, 'string': \"The law legalizes online casino gambling for a 10 - year trial period , restricts the operation of the websites to Atlantic City 's eleven casinos , and imposes a 15 % tax on online gambling revenue , instead of the 8 % currently imposed on casinos .\"}, answer=[Entity(start_offset=521, end_offset=527, type='context', text='eleven', normalized_text='eleven')], nq_answers=[[Entity(start_offset=521, end_offset=527, type='context', text='eleven', normalized_text='eleven')]], aligned_nps=[(Entity(start_offset=24, end_offset=48, type='question', text='atlantic city new jersey', normalized_text='atlantic city new jersey'), Entity(start_offset=504, end_offset=517, type='context', text='Atlantic City', normalized_text='atlantic city'))], explanation_type='single_sentence'),\n",
       " 4015175761191110741: QEDExample(example_id=4015175761191110741, title=\"Bob's your uncle\", question=\"where does saying bob's your uncle come from\", passage=\"... And Bob 's your uncle is an expression of unknown origin , that means `` and there it is '' or `` and there you have it . '' It is commonly used in United Kingdom and Commonwealth countries . Typically , someone says it to conclude a set of simple instructions or when a result is reached . The meaning is similar to that of the French expression `` et voilà ! ''\", sentence_starts=[0, 129, 196, 295], selected_sent={'start': 0, 'end': 129, 'string': \"... And Bob 's your uncle is an expression of unknown origin , that means `` and there it is '' or `` and there you have it . '' \"}, answer=[Entity(start_offset=46, end_offset=60, type='context', text='unknown origin', normalized_text='unknown origin')], nq_answers=[[Entity(start_offset=46, end_offset=60, type='context', text='unknown origin', normalized_text='unknown origin')]], aligned_nps=[(Entity(start_offset=11, end_offset=34, type='question', text=\"saying bob's your uncle\", normalized_text='saying bobs your uncle'), Entity(start_offset=0, end_offset=25, type='context', text=\"... And Bob 's your uncle\", normalized_text='and bob s your uncle'))], explanation_type='single_sentence'),\n",
       " -6147777366028203410: QEDExample(example_id=-6147777366028203410, title='Blood sugar level', question='what is the normal range for plasma glucose concentration', passage='The normal blood glucose level ( tested while fasting ) for non-diabetics , should be between 3.9 and 5.5 mmol / L ( 70 to 100 mg / dL ) . The mean normal blood glucose level in humans is about 5.5 mmol / L ( 100 mg / dL ) ; however , this level fluctuates throughout the day . Blood sugar levels for those without diabetes and who are not fasting should be below 6.9 mmol / L ( 125 mg / dL ) . The blood glucose target range for diabetics , according to the American Diabetes Association , should be 5.0 -- 7.2 mmol / l ( 90 -- 130 mg / dL ) before meals , and less than 10 mmol / L ( 180 mg / dL ) after meals ( as measured by a blood glucose monitor ) .', sentence_starts=[0, 139, 278, 395], selected_sent={'start': 0, 'end': 139, 'string': 'The normal blood glucose level ( tested while fasting ) for non-diabetics , should be between 3.9 and 5.5 mmol / L ( 70 to 100 mg / dL ) . '}, answer=[Entity(start_offset=86, end_offset=136, type='context', text='between 3.9 and 5.5 mmol / L ( 70 to 100 mg / dL )', normalized_text='between 39 and 55 mmol l 70 to 100 mg dl')], nq_answers=[[Entity(start_offset=94, end_offset=136, type='context', text='3.9 and 5.5 mmol / L ( 70 to 100 mg / dL )', normalized_text='39 and 55 mmol l 70 to 100 mg dl')]], aligned_nps=[(Entity(start_offset=8, end_offset=57, type='question', text='the normal range for plasma glucose concentration', normalized_text='normal range for plasma glucose concentration'), Entity(start_offset=0, end_offset=73, type='context', text='The normal blood glucose level ( tested while fasting ) for non-diabetics', normalized_text='normal blood glucose level tested while fasting for nondiabetics'))], explanation_type='single_sentence'),\n",
       " -7203299715877045438: QEDExample(example_id=-7203299715877045438, title='Shea butter', question='where is shea butter gotten from in nigeria', passage='Shea butter ( / ʃiː / , / ˈʃiːə / , or / ʃeɪ / ) is a fat extracted from the nut of the African shea tree ( Vitellaria paradoxa ) . It is usually yellow in color when raw , with Unrefined , Refined , and Ultra-Refined Shea butter being ivory or white in color . Shea butter is a triglyceride ( fat ) derived mainly from stearic acid and oleic acid . It is widely used in cosmetics as a moisturizer , salve or lotion . Shea butter is edible and is used in food preparation in some African countries . Occasionally , the chocolate industry uses shea butter mixed with other oils as a substitute for cocoa butter , although the taste is noticeably different .', sentence_starts=[0, 132, 262, 350, 418, 500], selected_sent={'start': 0, 'end': 132, 'string': 'Shea butter ( / ʃiː / , / ˈʃiːə / , or / ʃeɪ / ) is a fat extracted from the nut of the African shea tree ( Vitellaria paradoxa ) . '}, answer=[Entity(start_offset=73, end_offset=105, type='context', text='the nut of the African shea tree', normalized_text='nut of african shea tree')], nq_answers=[[Entity(start_offset=73, end_offset=105, type='context', text='the nut of the African shea tree', normalized_text='nut of african shea tree')]], aligned_nps=[(Entity(start_offset=9, end_offset=20, type='question', text='shea butter', normalized_text='shea butter'), Entity(start_offset=0, end_offset=48, type='context', text='Shea butter ( / ʃiː / , / ˈʃiːə / , or / ʃeɪ / )', normalized_text='shea butter ʃiː ˈʃiːə or ʃeɪ'))], explanation_type='single_sentence'),\n",
       " 1012541351190124000: QEDExample(example_id=1012541351190124000, title='Touchback', question='what is the new touchback rule in the nfl', passage='On March 23 , 2016 , the NFL announced that it would award a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard line and much discussion and analysis on the impact of this change has emerged . This new rule was to be re-evaluated after the 2016 NFL season .', sentence_starts=[0, 220], selected_sent={'start': 0, 'end': 220, 'string': 'On March 23 , 2016 , the NFL announced that it would award a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard line and much discussion and analysis on the impact of this change has emerged . '}, answer=[Entity(start_offset=59, end_offset=143, type='context', text='a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard line', normalized_text='touchback on kickoffs at 25 yard line instead of previous 20 yard line')], nq_answers=[[Entity(start_offset=59, end_offset=143, type='context', text='a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard line', normalized_text='touchback on kickoffs at 25 yard line instead of previous 20 yard line')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 2326758035558088175: QEDExample(example_id=2326758035558088175, title='Bias', question='what is the meaning of to have a bias', passage='Bias is prejudice in favour of or against one thing , person , or group compared with another , usually in a way considered to be unfair .', sentence_starts=[0], selected_sent={'start': 0, 'end': 138, 'string': 'Bias is prejudice in favour of or against one thing , person , or group compared with another , usually in a way considered to be unfair .'}, answer=[Entity(start_offset=8, end_offset=136, type='context', text='prejudice in favour of or against one thing , person , or group compared with another , usually in a way considered to be unfair', normalized_text='prejudice in favour of or against one thing person or group compared with another usually in way considered to be unfair')], nq_answers=[[Entity(start_offset=8, end_offset=136, type='context', text='prejudice in favour of or against one thing , person , or group compared with another , usually in a way considered to be unfair', normalized_text='prejudice in favour of or against one thing person or group compared with another usually in way considered to be unfair')]], aligned_nps=[(Entity(start_offset=31, end_offset=37, type='question', text='a bias', normalized_text='bias'), Entity(start_offset=0, end_offset=4, type='context', text='Bias', normalized_text='bias'))], explanation_type='single_sentence'),\n",
       " 5884155447534797486: QEDExample(example_id=5884155447534797486, title='Anatomy', question='branch of science that deals with the structure of human body parts', passage=\"Anatomy ( Greek anatomē , `` dissection '' ) is the branch of biology concerned with the study of the structure of organisms and their parts . Anatomy is a branch of natural science dealing with the structural organization of living things . It is an old science , having its beginnings in prehistoric times . Anatomy is inherently tied to embryology , comparative anatomy , evolutionary biology , and phylogeny , as these are the processes by which anatomy is generated over immediate ( embryology ) and long ( evolution ) timescales . Human anatomy is one of the basic essential sciences of medicine . Anatomy and physiology , which study ( respectively ) the structure and function of organisms and their parts , make a natural pair of related disciplines , and they are often studied together .\", sentence_starts=[0, 143, 242, 310, 537, 604], selected_sent={'start': 0, 'end': 143, 'string': \"Anatomy ( Greek anatomē , `` dissection '' ) is the branch of biology concerned with the study of the structure of organisms and their parts . \"}, answer=[Entity(start_offset=0, end_offset=7, type='context', text='Anatomy', normalized_text='anatomy')], nq_answers=[[Entity(start_offset=0, end_offset=7, type='context', text='Anatomy', normalized_text='anatomy')], [Entity(start_offset=537, end_offset=550, type='context', text='Human anatomy', normalized_text='human anatomy')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -5741796887997028481: QEDExample(example_id=-5741796887997028481, title='Three wise monkeys', question='where does see no evil speak no evil come from', passage=\"The three wise monkeys ( Japanese : 三猿 , Hepburn : san'en or sanzaru , alternatively 三 匹 の 猿 sanbiki no saru , literally `` three monkeys '' ) , sometimes called the three mystic apes , are a pictorial maxim . Together they embody the proverbial principle `` see no evil , hear no evil , speak no evil '' . The three monkeys are Mizaru , covering his eyes , who sees no evil ; Kikazaru , covering his ears , who hears no evil ; and Iwazaru , covering his mouth , who speaks no evil .\", sentence_starts=[0, 210, 307], selected_sent={'start': 210, 'end': 307, 'string': \"Together they embody the proverbial principle `` see no evil , hear no evil , speak no evil '' . \"}, answer=[Entity(start_offset=0, end_offset=183, type='context', text=\"The three wise monkeys ( Japanese : 三猿 , Hepburn : san'en or sanzaru , alternatively 三 匹 の 猿 sanbiki no saru , literally `` three monkeys '' ) , sometimes called the three mystic apes\", normalized_text='three wise monkeys japanese 三猿 hepburn sanen or sanzaru alternatively 三 匹 の 猿 sanbiki no saru literally three monkeys sometimes called three mystic apes')], nq_answers=[[Entity(start_offset=0, end_offset=183, type='context', text=\"The three wise monkeys ( Japanese : 三猿 , Hepburn : san'en or sanzaru , alternatively 三 匹 の 猿 sanbiki no saru , literally `` three monkeys '' ) , sometimes called the three mystic apes\", normalized_text='three wise monkeys japanese 三猿 hepburn sanen or sanzaru alternatively 三 匹 の 猿 sanbiki no saru literally three monkeys sometimes called three mystic apes')]], aligned_nps=[(Entity(start_offset=11, end_offset=36, type='question', text='see no evil speak no evil', normalized_text='see no evil speak no evil'), Entity(start_offset=231, end_offset=304, type='context', text=\"the proverbial principle `` see no evil , hear no evil , speak no evil ''\", normalized_text='proverbial principle see no evil hear no evil speak no evil'))], explanation_type='single_sentence'),\n",
       " 6965345213102068647: QEDExample(example_id=6965345213102068647, title='Tom Brady', question='how long has tom brady been playing professional football', passage='A lightly regarded prospect coming out of college , Brady was selected by the New England Patriots with the 199th overall pick in the sixth round of 2000 NFL Draft and has since spent his entire 18 - season career with the Patriots . Since Brady became their starting quarterback in 2001 , the Patriots have never had a losing season and have won 14 division titles . The Patriots played in eleven AFC Championship Games from 2001 to 2016 -- including six in a row from 2011 to 2016 -- and won seven of them . Brady and Patriots head coach Bill Belichick have combined to form the most successful quarterback - head coach tandem in NFL history , winning more regular season games and postseason games than any other such duo as well as appearing in seven Super Bowls . All of these events set new NFL records .', sentence_starts=[0, 234, 368, 510, 769], selected_sent={'start': 0, 'end': 234, 'string': 'A lightly regarded prospect coming out of college , Brady was selected by the New England Patriots with the 199th overall pick in the sixth round of 2000 NFL Draft and has since spent his entire 18 - season career with the Patriots . '}, answer=[Entity(start_offset=195, end_offset=206, type='context', text='18 - season', normalized_text='18 season')], nq_answers=[[Entity(start_offset=195, end_offset=213, type='context', text='18 - season career', normalized_text='18 season career')]], aligned_nps=[(Entity(start_offset=13, end_offset=22, type='question', text='tom brady', normalized_text='tom brady'), Entity(start_offset=52, end_offset=57, type='context', text='Brady', normalized_text='brady'))], explanation_type='single_sentence'),\n",
       " -2675458162784621957: QEDExample(example_id=-2675458162784621957, title='Parallax', question='is parallax more pronounced with nearby stars or with distant stars', passage=\"Parallax is a displacement or difference in the apparent position of an object viewed along two different lines of sight , and is measured by the angle or semi-angle of inclination between those two lines . The term is derived from Ancient Greek παράλλαξις ( parallaxis ) , meaning ' alternation ' . Due to foreshortening , nearby objects show a larger parallax than farther objects when observed from different positions , so parallax can be used to determine distances .\", sentence_starts=[0, 207, 300], selected_sent={'start': 300, 'end': 472, 'string': 'Due to foreshortening , nearby objects show a larger parallax than farther objects when observed from different positions , so parallax can be used to determine distances .'}, answer=[Entity(start_offset=324, end_offset=421, type='context', text='nearby objects show a larger parallax than farther objects when observed from different positions', normalized_text='nearby objects show larger parallax than farther objects when observed from different positions')], nq_answers=[[Entity(start_offset=324, end_offset=382, type='context', text='nearby objects show a larger parallax than farther objects', normalized_text='nearby objects show larger parallax than farther objects')], [Entity(start_offset=324, end_offset=330, type='context', text='nearby', normalized_text='nearby')], [Entity(start_offset=324, end_offset=338, type='context', text='nearby objects', normalized_text='nearby objects')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 9087528790356333569: QEDExample(example_id=9087528790356333569, title='Fertile Crescent', question='the fertile crescent is located between what two bodies of water', passage='The Fertile Crescent includes Mesopotamia , the land in and around the Tigris and Euphrates rivers ; and the Levant , the eastern coast of the Mediterranean Sea . The modern - day countries with significant territory within the Fertile Crescent are Iraq , Syria , Lebanon , Cyprus , Jordan , Israel , Palestine , Egypt , as well as the southeastern fringe of Turkey and the western fringes of Iran .', sentence_starts=[0, 163], selected_sent={'start': 0, 'end': 163, 'string': 'The Fertile Crescent includes Mesopotamia , the land in and around the Tigris and Euphrates rivers ; and the Levant , the eastern coast of the Mediterranean Sea . '}, answer=[Entity(start_offset=67, end_offset=98, type='context', text='the Tigris and Euphrates rivers', normalized_text='tigris and euphrates rivers')], nq_answers=[[Entity(start_offset=71, end_offset=98, type='context', text='Tigris and Euphrates rivers', normalized_text='tigris and euphrates rivers')], [Entity(start_offset=71, end_offset=77, type='context', text='Tigris', normalized_text='tigris'), Entity(start_offset=82, end_offset=91, type='context', text='Euphrates', normalized_text='euphrates')]], aligned_nps=[(Entity(start_offset=0, end_offset=20, type='question', text='the fertile crescent', normalized_text='fertile crescent'), Entity(start_offset=0, end_offset=20, type='context', text='The Fertile Crescent', normalized_text='fertile crescent'))], explanation_type='single_sentence'),\n",
       " -947899001492255867: QEDExample(example_id=-947899001492255867, title='European Cup and UEFA Champions League history', question='who was the first british team to win the european cup', passage='In 1967 , Celtic became the first British team to win the competition , coming back from 1 -- 0 down after a Sandro Mazzola penalty to beat Internazionale 2 -- 1 in the Estádio Nacional in Lisbon , with goals from Tommy Gemmell and Stevie Chalmers . The team , which became known as the Lisbon Lions , managed by Jock Stein , were unique as they were all born within 30 miles ( 48 km ) of Celtic Park in Glasgow .', sentence_starts=[0, 250], selected_sent={'start': 0, 'end': 250, 'string': 'In 1967 , Celtic became the first British team to win the competition , coming back from 1 -- 0 down after a Sandro Mazzola penalty to beat Internazionale 2 -- 1 in the Estádio Nacional in Lisbon , with goals from Tommy Gemmell and Stevie Chalmers . '}, answer=[Entity(start_offset=10, end_offset=16, type='context', text='Celtic', normalized_text='celtic')], nq_answers=[[Entity(start_offset=10, end_offset=16, type='context', text='Celtic', normalized_text='celtic')]], aligned_nps=[(Entity(start_offset=8, end_offset=54, type='question', text='the first british team to win the european cup', normalized_text='first british team to win european cup'), Entity(start_offset=24, end_offset=69, type='context', text='the first British team to win the competition', normalized_text='first british team to win competition'))], explanation_type='single_sentence'),\n",
       " -3422482453881148813: QEDExample(example_id=-3422482453881148813, title='List of Rugrats episodes', question='how many seasons of the rugrats are there', passage=\"The series premiered on Sunday , August 11 , 1991 , as the second Nicktoon after Doug and preceding The Ren & Stimpy Show . Production initially halted in 1993 after 65 episodes , with the last episode airing on May 22 , 1994 . From 1995 to 1996 , the only new episodes broadcast were `` A Rugrats Passover '' and `` A Rugrats Chanukah '' , two Jewish - themed episodes that received critical acclaim ; during this time , well - after the end of the show 's production run , Rugrats began to receive a boost in ratings and popularity , due to constant reruns on Nickelodeon . In 1996 , Klasky Csupo Animation began producing new episodes , and the show 's fourth season began airing in 1997 . As a result of the show 's popularity , a series of theatrical films were released ; The Rugrats Movie , which introduced Tommy 's younger brother Dil , was released in 1998 , Rugrats in Paris : The Movie , which introduced Kimi and Kira , released in 2000 , and Rugrats Go Wild , a crossover film with fellow Klasky Csupo series The Wild Thornberrys , released in 2003 . The final episode aired on August 1 , 2004 , bringing the series to a total of 172 episodes and 9 seasons during a 12 - year run .\", sentence_starts=[0, 124, 228, 576, 693, 1065], selected_sent={'start': 1065, 'end': 1195, 'string': 'The final episode aired on August 1 , 2004 , bringing the series to a total of 172 episodes and 9 seasons during a 12 - year run .'}, answer=[Entity(start_offset=1161, end_offset=1162, type='context', text='9', normalized_text='9')], nq_answers=[[Entity(start_offset=1161, end_offset=1162, type='context', text='9', normalized_text='9')], [Entity(start_offset=1161, end_offset=1170, type='context', text='9 seasons', normalized_text='9 seasons')], [Entity(start_offset=687, end_offset=688, type='context', text='9', normalized_text='9')]], aligned_nps=[(Entity(start_offset=20, end_offset=31, type='question', text='the rugrats', normalized_text='rugrats'), Entity(start_offset=1119, end_offset=1129, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " -6553353802049563745: QEDExample(example_id=-6553353802049563745, title='Twenty One Pilots', question='when did the twenty one pilots hiatus start', passage=\"In an interview with Alternative Press in November 2016 , Twenty One Pilots stated that after their last show , they will be `` going dark '' to focus on new music . Joseph stated that he would like to focus on lyrical content of the music , and bring the music back to the `` authenticity , lyrics , delivery , and fearlessness of songwriting '' similar to that of the self - titled album . The band is currently taking a self - described hiatus ; their last activity came in July 2017 in the form of posts on social media depicting an eye closing over lyrics from several of their songs .\", sentence_starts=[0, 166, 392], selected_sent={'start': 392, 'end': 590, 'string': 'The band is currently taking a self - described hiatus ; their last activity came in July 2017 in the form of posts on social media depicting an eye closing over lyrics from several of their songs .'}, answer=[Entity(start_offset=477, end_offset=486, type='context', text='July 2017', normalized_text='july 2017')], nq_answers=[[Entity(start_offset=477, end_offset=486, type='context', text='July 2017', normalized_text='july 2017')], [Entity(start_offset=42, end_offset=55, type='context', text='November 2016', normalized_text='november 2016')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='the twenty one pilots hiatus', normalized_text='twenty one pilots hiatus'), Entity(start_offset=421, end_offset=446, type='context', text='a self - described hiatus', normalized_text='self described hiatus'))], explanation_type='single_sentence'),\n",
       " -7675585242740496397: QEDExample(example_id=-7675585242740496397, title='Ibuprofen', question='when did ibuprofen become available over the counter', passage=\"Ibuprofen was derived from propionic acid by the research arm of Boots Group during the 1960s . Its discovery was the result of research during the 1950s and 1960s to find a safer alternative to aspirin . It was discovered by a team led by Stewart Adams and the patent application was filed in 1961 . Adams initially tested the drug as treatment for his hangover . The drug was launched as a treatment for rheumatoid arthritis in the United Kingdom in 1969 , and in the United States in 1974 . Later , in 1983 and 1984 , it became the first NSAID ( other than aspirin ) to be available over the counter ( OTC ) in these two countries . Dr. Adams was subsequently awarded an OBE in 1987 . Boots was awarded the Queen 's Award for Technical Achievement for the development of the drug in 1987 .\", sentence_starts=[0, 96, 205, 301, 365, 494, 636, 688], selected_sent={'start': 494, 'end': 636, 'string': 'Later , in 1983 and 1984 , it became the first NSAID ( other than aspirin ) to be available over the counter ( OTC ) in these two countries . '}, answer=[Entity(start_offset=505, end_offset=509, type='context', text='1983', normalized_text='1983')], nq_answers=[[Entity(start_offset=505, end_offset=509, type='context', text='1983', normalized_text='1983')], [Entity(start_offset=514, end_offset=518, type='context', text='1984', normalized_text='1984')]], aligned_nps=[(Entity(start_offset=9, end_offset=18, type='question', text='ibuprofen', normalized_text='ibuprofen'), Entity(start_offset=521, end_offset=523, type='context', text='it', normalized_text='it'))], explanation_type='single_sentence'),\n",
       " -6708405865399636227: QEDExample(example_id=-6708405865399636227, title='International Baccalaureate', question='what is the full form of ib board', passage='The International Baccalaureate ( IB ) , formerly known as the International Baccalaureate Organization ( IBO ) , is an international educational foundation headquartered in Geneva , Switzerland and founded in 1968 . It offers four educational programs : the IB Diploma Program and the IB Career - related Program for students aged 15 to 18 , the IB Middle Years Program , designed for students aged 11 to 14 , and the IB Primary Years Program for children aged 3 to 12 . To teach these programs , schools need to be authorized by the International Baccalaureate Organization .', sentence_starts=[0, 217, 472], selected_sent={'start': 0, 'end': 217, 'string': 'The International Baccalaureate ( IB ) , formerly known as the International Baccalaureate Organization ( IBO ) , is an international educational foundation headquartered in Geneva , Switzerland and founded in 1968 . '}, answer=[Entity(start_offset=4, end_offset=31, type='context', text='International Baccalaureate', normalized_text='international baccalaureate')], nq_answers=[[Entity(start_offset=4, end_offset=31, type='context', text='International Baccalaureate', normalized_text='international baccalaureate')], [Entity(start_offset=0, end_offset=31, type='context', text='The International Baccalaureate', normalized_text='international baccalaureate')]], aligned_nps=[(Entity(start_offset=25, end_offset=33, type='question', text='ib board', normalized_text='ib board'), Entity(start_offset=0, end_offset=111, type='context', text='The International Baccalaureate ( IB ) , formerly known as the International Baccalaureate Organization ( IBO )', normalized_text='international baccalaureate ib formerly known as international baccalaureate organization ibo'))], explanation_type='single_sentence'),\n",
       " 5591012279983312305: QEDExample(example_id=5591012279983312305, title='1977 Convair CV-240 crash', question=\"when did lynyrd skynyrd's plane crash happen\", passage='On October 20 , 1977 , a Convair CV - 240 chartered by the rock band Lynyrd Skynyrd from L&J Company of Addison , Texas , ran out of fuel and crashed in Gillsburg , Mississippi , near the end of its flight from Greenville , South Carolina , to Baton Rouge , Louisiana .', sentence_starts=[0], selected_sent={'start': 0, 'end': 269, 'string': 'On October 20 , 1977 , a Convair CV - 240 chartered by the rock band Lynyrd Skynyrd from L&J Company of Addison , Texas , ran out of fuel and crashed in Gillsburg , Mississippi , near the end of its flight from Greenville , South Carolina , to Baton Rouge , Louisiana .'}, answer=[Entity(start_offset=3, end_offset=20, type='context', text='October 20 , 1977', normalized_text='october 20 1977')], nq_answers=[[Entity(start_offset=3, end_offset=20, type='context', text='October 20 , 1977', normalized_text='october 20 1977')]], aligned_nps=[(Entity(start_offset=9, end_offset=23, type='question', text='lynyrd skynyrd', normalized_text='lynyrd skynyrd'), Entity(start_offset=55, end_offset=83, type='context', text='the rock band Lynyrd Skynyrd', normalized_text='rock band lynyrd skynyrd'))], explanation_type='single_sentence'),\n",
       " 4545658360788980127: QEDExample(example_id=4545658360788980127, title='Salary cap', question='when did the nfl adopt a salary cap', passage=\"The cap was first introduced for the 1994 season and was initially $34.6 million . Both the cap and the floor are adjusted annually based on the league 's revenues , and they have increased each year . In 2009 , the final capped year under that agreement , the cap was $128 million per team , while the floor was 87.6 % of the cap . Using the formula provided in the league 's collective bargaining agreement , the floor in 2009 was $112.1 million . Under the NFL 's agreement with the NFLPA , the effects on the salary cap of guaranteed payments ( such as signing bonuses ) are , with a few rare exceptions , prorated evenly over the term of the contract .\", sentence_starts=[0, 83, 202, 333, 450], selected_sent={'start': 0, 'end': 83, 'string': 'The cap was first introduced for the 1994 season and was initially $34.6 million . '}, answer=[Entity(start_offset=33, end_offset=48, type='context', text='the 1994 season', normalized_text='1994 season')], nq_answers=[[Entity(start_offset=29, end_offset=48, type='context', text='for the 1994 season', normalized_text='for 1994 season')], [Entity(start_offset=37, end_offset=41, type='context', text='1994', normalized_text='1994')], [Entity(start_offset=37, end_offset=48, type='context', text='1994 season', normalized_text='1994 season')], [Entity(start_offset=33, end_offset=48, type='context', text='the 1994 season', normalized_text='1994 season')]], aligned_nps=[(Entity(start_offset=9, end_offset=16, type='question', text='the nfl', normalized_text='nfl'), Entity(start_offset=18, end_offset=28, type='context', text='introduced', normalized_text='introduced'))], explanation_type='single_sentence'),\n",
       " 3813463163833368875: QEDExample(example_id=3813463163833368875, title='Coat of arms of South Africa', question='who unveiled the new coat of arms on 27 april 2000', passage=\"The present coat of arms of South Africa was introduced on Freedom Day 27 April 2000 . It replaced the earlier national arms , which had been in use since 1910 . The motto ǃke e : ǀxarra ǁke is written in the Khoisan language of the ǀXam people and translates literally to `` diverse people unite '' . The previous motto , in Latin , was Ex Unitate Vires , translated as `` From unity , strength '' .\", sentence_starts=[0, 87, 162, 302], selected_sent={'start': 0, 'end': 87, 'string': 'The present coat of arms of South Africa was introduced on Freedom Day 27 April 2000 . '}, answer=[Entity(start_offset=28, end_offset=40, type='context', text='South Africa', normalized_text='south africa')], nq_answers=[[Entity(start_offset=28, end_offset=40, type='context', text='South Africa', normalized_text='south africa')]], aligned_nps=[(Entity(start_offset=37, end_offset=50, type='question', text='27 april 2000', normalized_text='27 april 2000'), Entity(start_offset=59, end_offset=84, type='context', text='Freedom Day 27 April 2000', normalized_text='freedom day 27 april 2000'))], explanation_type='single_sentence'),\n",
       " -9044027905927172037: QEDExample(example_id=-9044027905927172037, title='Winnie-the-Pooh', question='how many winnie the pooh books are there', passage=\"The first collection of stories about the character was the book Winnie - the - Pooh ( 1926 ) , and this was followed by The House at Pooh Corner ( 1928 ) . Milne also included a poem about the bear in the children 's verse book When We Were Very Young ( 1924 ) and many more in Now We Are Six ( 1927 ) . All four volumes were illustrated by E.H. Shepard .\", sentence_starts=[0, 157, 305, 347], selected_sent={'start': 305, 'end': 347, 'string': 'All four volumes were illustrated by E.H. '}, answer=[Entity(start_offset=309, end_offset=313, type='context', text='four', normalized_text='four')], nq_answers=[[Entity(start_offset=309, end_offset=313, type='context', text='four', normalized_text='four')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text='winnie the pooh books', normalized_text='winnie pooh books'), Entity(start_offset=305, end_offset=321, type='context', text='All four volumes', normalized_text='all four volumes'))], explanation_type='single_sentence'),\n",
       " -9040998025357365895: QEDExample(example_id=-9040998025357365895, title='Advance Auto Parts Clash', question='who gets to race in the daytona clash', passage='The 2018 Clash at Daytona will not be a predetermined number of cars ; rather , the field is limited to drivers who meet more exclusive criteria . Only drivers who were Daytona Pole Award winners , former Clash race winners , former Daytona 500 pole winners who competed full - time in 2017 , and drivers who qualified for the 2017 Playoffs are eligible .', sentence_starts=[0, 147], selected_sent={'start': 147, 'end': 355, 'string': 'Only drivers who were Daytona Pole Award winners , former Clash race winners , former Daytona 500 pole winners who competed full - time in 2017 , and drivers who qualified for the 2017 Playoffs are eligible .'}, answer=[Entity(start_offset=169, end_offset=340, type='context', text='Daytona Pole Award winners , former Clash race winners , former Daytona 500 pole winners who competed full - time in 2017 , and drivers who qualified for the 2017 Playoffs', normalized_text='daytona pole award winners former clash race winners former daytona 500 pole winners who competed full time in 2017 and drivers who qualified for 2017 playoffs')], nq_answers=[[Entity(start_offset=169, end_offset=195, type='context', text='Daytona Pole Award winners', normalized_text='daytona pole award winners'), Entity(start_offset=198, end_offset=223, type='context', text='former Clash race winners', normalized_text='former clash race winners'), Entity(start_offset=226, end_offset=290, type='context', text='former Daytona 500 pole winners who competed full - time in 2017', normalized_text='former daytona 500 pole winners who competed full time in 2017'), Entity(start_offset=297, end_offset=340, type='context', text='drivers who qualified for the 2017 Playoffs', normalized_text='drivers who qualified for 2017 playoffs')], [Entity(start_offset=152, end_offset=195, type='context', text='drivers who were Daytona Pole Award winners', normalized_text='drivers who were daytona pole award winners'), Entity(start_offset=198, end_offset=223, type='context', text='former Clash race winners', normalized_text='former clash race winners'), Entity(start_offset=226, end_offset=290, type='context', text='former Daytona 500 pole winners who competed full - time in 2017', normalized_text='former daytona 500 pole winners who competed full time in 2017'), Entity(start_offset=297, end_offset=340, type='context', text='drivers who qualified for the 2017 Playoffs', normalized_text='drivers who qualified for 2017 playoffs')]], aligned_nps=[(Entity(start_offset=20, end_offset=37, type='question', text='the daytona clash', normalized_text='daytona clash'), Entity(start_offset=345, end_offset=353, type='context', text='eligible', normalized_text='eligible'))], explanation_type='single_sentence'),\n",
       " -2552145293528378476: QEDExample(example_id=-2552145293528378476, title='Woolly mammoth', question='what kind of food did the woolly mammoth eat', passage='The woolly mammoth was roughly the same size as modern African elephants . Males reached shoulder heights between 2.7 and 3.4 m ( 8.9 and 11.2 ft ) and weighed up to 6 metric tons ( 6.6 short tons ) . Females reached 2.6 -- 2.9 m ( 8.5 -- 9.5 ft ) in shoulder heights and weighed up to 4 metric tons ( 4.4 short tons ) . A newborn calf weighed about 90 kilograms ( 200 lb ) . The woolly mammoth was well adapted to the cold environment during the last ice age . It was covered in fur , with an outer covering of long guard hairs and a shorter undercoat . The colour of the coat varied from dark to light . The ears and tail were short to minimise frostbite and heat loss . It had long , curved tusks and four molars , which were replaced six times during the lifetime of an individual . Its behaviour was similar to that of modern elephants , and it used its tusks and trunk for manipulating objects , fighting , and foraging . The diet of the woolly mammoth was mainly grass and sedges . Individuals could probably reach the age of 60 . Its habitat was the mammoth steppe , which stretched across northern Eurasia and North America .', sentence_starts=[0, 75, 201, 321, 376, 462, 555, 606, 673, 787, 928, 989, 1038], selected_sent={'start': 928, 'end': 989, 'string': 'The diet of the woolly mammoth was mainly grass and sedges . '}, answer=[Entity(start_offset=970, end_offset=986, type='context', text='grass and sedges', normalized_text='grass and sedges')], nq_answers=[[Entity(start_offset=970, end_offset=986, type='context', text='grass and sedges', normalized_text='grass and sedges')]], aligned_nps=[(Entity(start_offset=22, end_offset=40, type='question', text='the woolly mammoth', normalized_text='woolly mammoth'), Entity(start_offset=940, end_offset=958, type='context', text='the woolly mammoth', normalized_text='woolly mammoth'))], explanation_type='single_sentence'),\n",
       " 1540025849450629445: QEDExample(example_id=1540025849450629445, title='Hot Coffee mod', question='what is the hot coffee mod in san andreas', passage='Hot Coffee is a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas , developed by Rockstar North . Public awareness of the existence of the mini-game arrived with the release of the Hot Coffee mod , created for the Microsoft Windows port of GTA : San Andreas in 2005 . This mod enables access to the mini-game .', sentence_starts=[0, 134, 304], selected_sent={'start': 0, 'end': 134, 'string': 'Hot Coffee is a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas , developed by Rockstar North . '}, answer=[Entity(start_offset=14, end_offset=47, type='context', text='a normally inaccessible mini-game', normalized_text='normally inaccessible minigame')], nq_answers=[[Entity(start_offset=14, end_offset=47, type='context', text='a normally inaccessible mini-game', normalized_text='normally inaccessible minigame')], [Entity(start_offset=14, end_offset=101, type='context', text='a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas', normalized_text='normally inaccessible minigame in 2004 video game grand theft auto san andreas')]], aligned_nps=[(Entity(start_offset=8, end_offset=41, type='question', text='the hot coffee mod in san andreas', normalized_text='hot coffee mod in san andreas'), Entity(start_offset=0, end_offset=10, type='context', text='Hot Coffee', normalized_text='hot coffee'))], explanation_type='single_sentence'),\n",
       " -57851775253204850: QEDExample(example_id=-57851775253204850, title=\"Tom Clancy's Rainbow Six Siege\", question='when does the dlc for rainbow six siege come out', passage='At launch , the game featured 11 maps and 5 different gameplay modes . With the downloadable content ( DLC ) -- an additional four maps from season one and the first map from season two -- there are currently 16 maps with two more slated for release by January 2018 . The gameplay modes featured include :', sentence_starts=[0, 71, 268], selected_sent={'start': 71, 'end': 268, 'string': 'With the downloadable content ( DLC ) -- an additional four maps from season one and the first map from season two -- there are currently 16 maps with two more slated for release by January 2018 . '}, answer=[Entity(start_offset=253, end_offset=265, type='context', text='January 2018', normalized_text='january 2018')], nq_answers=[[Entity(start_offset=253, end_offset=265, type='context', text='January 2018', normalized_text='january 2018')]], aligned_nps=[(Entity(start_offset=10, end_offset=39, type='question', text='the dlc for rainbow six siege', normalized_text='dlc for rainbow six siege'), Entity(start_offset=76, end_offset=108, type='context', text='the downloadable content ( DLC )', normalized_text='downloadable content dlc'))], explanation_type='single_sentence'),\n",
       " -3389723371168293793: QEDExample(example_id=-3389723371168293793, title='List of Olympic medalists in figure skating', question='who has the most olympic medals in figure skating', passage='Canadian ice dancers Tessa Virtue and Scott Moir are the only figure skaters to win five Olympic medals ( 3 gold , 2 silver ) . Swedish figure skater Gillis Grafström ( 3 gold , 1 silver ) and Russian figure skater Evgeni Plushenko ( 2 gold , 2 silver ) each have four medals . Seventeen figure skaters have won three medals .', sentence_starts=[0, 128, 278], selected_sent={'start': 0, 'end': 128, 'string': 'Canadian ice dancers Tessa Virtue and Scott Moir are the only figure skaters to win five Olympic medals ( 3 gold , 2 silver ) . '}, answer=[Entity(start_offset=0, end_offset=48, type='context', text='Canadian ice dancers Tessa Virtue and Scott Moir', normalized_text='canadian ice dancers tessa virtue and scott moir')], nq_answers=[[Entity(start_offset=0, end_offset=48, type='context', text='Canadian ice dancers Tessa Virtue and Scott Moir', normalized_text='canadian ice dancers tessa virtue and scott moir')], [Entity(start_offset=21, end_offset=33, type='context', text='Tessa Virtue', normalized_text='tessa virtue'), Entity(start_offset=38, end_offset=48, type='context', text='Scott Moir', normalized_text='scott moir')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 87252239919269673: QEDExample(example_id=87252239919269673, title='Mitosis', question='state the process that divides one nucleus into two genetically identical nuclei', passage='In cell biology , mitosis is a part of the cell cycle when replicated chromosomes are separated into two new nuclei . In general , mitosis ( division of the nucleus ) is preceded by the S stage of interphase ( during which the DNA is replicated ) and is often accompanied or followed by cytokinesis , which divides the cytoplasm , organelles and cell membrane into two new cells containing roughly equal shares of these cellular components . Mitosis and cytokinesis together define the mitotic ( M ) phase of an animal cell cycle -- the division of the mother cell into two daughter cells genetically identical to each other .', sentence_starts=[0, 118, 442], selected_sent={'start': 0, 'end': 118, 'string': 'In cell biology , mitosis is a part of the cell cycle when replicated chromosomes are separated into two new nuclei . '}, answer=[Entity(start_offset=18, end_offset=25, type='context', text='mitosis', normalized_text='mitosis')], nq_answers=[[Entity(start_offset=18, end_offset=25, type='context', text='mitosis', normalized_text='mitosis')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 4971790537761733656: QEDExample(example_id=4971790537761733656, title='PDCA', question='who is the originator of the plan-do-check-act model of performance improvement', passage=\"PDCA was made popular by W. Edwards Deming , who is considered by many to be the father of modern quality control ; however , he always referred to it as the `` Shewhart cycle '' . Later in Deming 's career , he modified PDCA to `` Plan , Do , Study , Act '' ( PDSA ) because he felt that `` check '' emphasized inspection over analysis . The PDSA cycle was used to create the model of know - how transfer process , and other models .\", sentence_starts=[0, 181, 339], selected_sent={'start': 0, 'end': 181, 'string': \"PDCA was made popular by W. Edwards Deming , who is considered by many to be the father of modern quality control ; however , he always referred to it as the `` Shewhart cycle '' . \"}, answer=[Entity(start_offset=25, end_offset=42, type='context', text='W. Edwards Deming', normalized_text='w edwards deming')], nq_answers=[[Entity(start_offset=25, end_offset=42, type='context', text='W. Edwards Deming', normalized_text='w edwards deming')]], aligned_nps=[(Entity(start_offset=25, end_offset=79, type='question', text='the plan-do-check-act model of performance improvement', normalized_text='plandocheckact model of performance improvement'), Entity(start_offset=0, end_offset=4, type='context', text='PDCA', normalized_text='pdca'))], explanation_type='single_sentence'),\n",
       " 806479489230635414: QEDExample(example_id=806479489230635414, title='Stevia', question='where does stevia in the raw come from', passage='Stevia ( / ˈstiːviə , ˈstɛviə / ) is a sweetener and sugar substitute extracted from the leaves of the plant species Stevia rebaudiana .', sentence_starts=[0], selected_sent={'start': 0, 'end': 136, 'string': 'Stevia ( / ˈstiːviə , ˈstɛviə / ) is a sweetener and sugar substitute extracted from the leaves of the plant species Stevia rebaudiana .'}, answer=[Entity(start_offset=85, end_offset=134, type='context', text='the leaves of the plant species Stevia rebaudiana', normalized_text='leaves of plant species stevia rebaudiana')], nq_answers=[[Entity(start_offset=85, end_offset=134, type='context', text='the leaves of the plant species Stevia rebaudiana', normalized_text='leaves of plant species stevia rebaudiana')], [Entity(start_offset=99, end_offset=134, type='context', text='the plant species Stevia rebaudiana', normalized_text='plant species stevia rebaudiana')]], aligned_nps=[(Entity(start_offset=11, end_offset=28, type='question', text='stevia in the raw', normalized_text='stevia in raw'), Entity(start_offset=0, end_offset=33, type='context', text='Stevia ( / ˈstiːviə , ˈstɛviə / )', normalized_text='stevia ˈstiːviə ˈstɛviə'))], explanation_type='single_sentence'),\n",
       " 7965511165361018261: QEDExample(example_id=7965511165361018261, title='Joseph N. Welch', question='who said have you no sense of decency', passage=\"Joseph Nye Welch ( October 22 , 1890 -- October 6 , 1960 ) was an American lawyer who served as the chief counsel for the United States Army while it was under investigation for Communist activities by Senator Joseph McCarthy 's Senate Permanent Subcommittee on Investigations , an investigation known as the Army -- McCarthy hearings . His confrontation with McCarthy during the hearings , in which he famously asked McCarthy `` At long last , have you left no sense of decency ? '' is seen as a turning point in the history of McCarthyism .\", sentence_starts=[0, 337], selected_sent={'start': 337, 'end': 542, 'string': \"His confrontation with McCarthy during the hearings , in which he famously asked McCarthy `` At long last , have you left no sense of decency ? '' is seen as a turning point in the history of McCarthyism .\"}, answer=[Entity(start_offset=0, end_offset=16, type='context', text='Joseph Nye Welch', normalized_text='joseph nye welch')], nq_answers=[[Entity(start_offset=0, end_offset=16, type='context', text='Joseph Nye Welch', normalized_text='joseph nye welch')]], aligned_nps=[(Entity(start_offset=9, end_offset=37, type='question', text='have you no sense of decency', normalized_text='have you no sense of decency'), Entity(start_offset=430, end_offset=480, type='context', text='At long last , have you left no sense of decency ?', normalized_text='at long last have you left no sense of decency'))], explanation_type='single_sentence'),\n",
       " -913341107960536245: QEDExample(example_id=-913341107960536245, title='The Skye Boat Song', question='who sings the skye boat song on outlander', passage=\"Bear McCreary adapted the song as the opening titles of the 2014 TV series Outlander , sung by Raya Yarbrough , changing the text of Robert Louis Stevenson 's poem Sing Me a Song of a Lad That Is Gone ( 1892 ) to fit the story .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 228, 'string': \"Bear McCreary adapted the song as the opening titles of the 2014 TV series Outlander , sung by Raya Yarbrough , changing the text of Robert Louis Stevenson 's poem Sing Me a Song of a Lad That Is Gone ( 1892 ) to fit the story .\"}, answer=[Entity(start_offset=95, end_offset=109, type='context', text='Raya Yarbrough', normalized_text='raya yarbrough')], nq_answers=[[Entity(start_offset=95, end_offset=109, type='context', text='Raya Yarbrough', normalized_text='raya yarbrough')], [Entity(start_offset=0, end_offset=13, type='context', text='Bear McCreary', normalized_text='bear mccreary')]], aligned_nps=[(Entity(start_offset=10, end_offset=28, type='question', text='the skye boat song', normalized_text='skye boat song'), Entity(start_offset=22, end_offset=30, type='context', text='the song', normalized_text='song')), (Entity(start_offset=32, end_offset=41, type='question', text='outlander', normalized_text='outlander'), Entity(start_offset=56, end_offset=84, type='context', text='the 2014 TV series Outlander', normalized_text='2014 tv series outlander'))], explanation_type='single_sentence'),\n",
       " 1191475065742248285: QEDExample(example_id=1191475065742248285, title='De Beers', question=\"how much of the world's diamonds does de beers own\", passage=\"In 2000 , the De Beers business model changed because of factors such as the decision by producers in Canada and Australia to distribute diamonds outside the De Beers channel , as well as rising awareness of blood diamonds that forced De Beers to `` avoid the risk of bad publicity '' by limiting sales to its own mined products . De Beers ' market share of rough diamonds fell from as high as 90 % in the 1980s to 33 % in 2013 , because of a more fragmented diamond market bringing greater competition , as well as more transparency and greater liquidity . In November 2011 , the Oppenheimer family announced its intention to sell all its 40 % stake in De Beers to Anglo American plc , thereby increasing Anglo American 's ownership of the company to 85 % ( the other 15 % is owned by the Government of the Republic of Botswana ) . The transaction was worth £ 3.2 billion ( US $5.1 billion ) in cash and ended the Oppenheimer dynasty 's 80 - year ownership of De Beers .\", sentence_starts=[0, 331, 558, 833], selected_sent={'start': 331, 'end': 558, 'string': \"De Beers ' market share of rough diamonds fell from as high as 90 % in the 1980s to 33 % in 2013 , because of a more fragmented diamond market bringing greater competition , as well as more transparency and greater liquidity . \"}, answer=[Entity(start_offset=415, end_offset=427, type='context', text='33 % in 2013', normalized_text='33 in 2013')], nq_answers=[[Entity(start_offset=415, end_offset=427, type='context', text='33 % in 2013', normalized_text='33 in 2013')]], aligned_nps=[(Entity(start_offset=38, end_offset=46, type='question', text='de beers', normalized_text='de beers'), Entity(start_offset=331, end_offset=339, type='context', text='De Beers', normalized_text='de beers'))], explanation_type='single_sentence'),\n",
       " -1288756836147893929: QEDExample(example_id=-1288756836147893929, title='Fender amplifier', question='when did fender start making amps in mexico', passage=\"The Red Knob amplifiers were produced from 1987 until 1993 . These were some of the first models produced by the newly formed Fender Musical Instrument Corporation . These amplifiers , named for their bright red control knobs , have a slightly similar appearance to the older Blackface cosmetics , having black control panels with white lettering and the late 1970s `` scripted tailless '' Fender logo . Many of these models were simply refitted with black knobs and early 1970s `` unscripted tailless '' Fender logos in 1996 when most Fender amplifier manufacturing moved to the Ensenada factory in Mexico . This series of amplifiers all used printed circuit board construction and can be difficult for amateur amp techs to service . The Red Knob amps , with their high - gain channels , had their own sound , not much like the older classic Blackface and Silverface designs .\", sentence_starts=[0, 61, 166, 404, 609, 735], selected_sent={'start': 404, 'end': 609, 'string': \"Many of these models were simply refitted with black knobs and early 1970s `` unscripted tailless '' Fender logos in 1996 when most Fender amplifier manufacturing moved to the Ensenada factory in Mexico . \"}, answer=[Entity(start_offset=521, end_offset=525, type='context', text='1996', normalized_text='1996')], nq_answers=[[Entity(start_offset=521, end_offset=525, type='context', text='1996', normalized_text='1996')]], aligned_nps=[(Entity(start_offset=9, end_offset=15, type='question', text='fender', normalized_text='fender'), Entity(start_offset=536, end_offset=542, type='context', text='Fender', normalized_text='fender')), (Entity(start_offset=37, end_offset=43, type='question', text='mexico', normalized_text='mexico'), Entity(start_offset=600, end_offset=606, type='context', text='Mexico', normalized_text='mexico'))], explanation_type='single_sentence'),\n",
       " 2053640931063416368: QEDExample(example_id=2053640931063416368, title='John Cooper Clarke', question='known as the punk poet who used poetry in their music', passage=\"John Cooper Clarke ( born 25 January 1949 ) is an English performance poet who first became famous during the punk rock era of the late 1970s when he became known as a `` punk poet '' . He released several albums in the late 1970s and early 1980s , and continues to perform regularly .\", sentence_starts=[0, 186], selected_sent={'start': 0, 'end': 186, 'string': \"John Cooper Clarke ( born 25 January 1949 ) is an English performance poet who first became famous during the punk rock era of the late 1970s when he became known as a `` punk poet '' . \"}, answer=[Entity(start_offset=0, end_offset=18, type='context', text='John Cooper Clarke', normalized_text='john cooper clarke')], nq_answers=[[Entity(start_offset=0, end_offset=18, type='context', text='John Cooper Clarke', normalized_text='john cooper clarke')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " 9136127341375337308: QEDExample(example_id=9136127341375337308, title='Roxette', question='who sang it must have been love but its over now', passage=\"Roxette are a Swedish pop rock duo , consisting of Marie Fredriksson ( vocals ) and Per Gessle ( vocals and guitar ) . Formed in 1986 , the duo became an international act in the late 1980s , when they released their breakthrough album Look Sharp ! Their third album Joyride , which was released in 1991 , became just as successful as its predecessor . Roxette went on to achieve nineteen UK Top 40 hits and several US Hot 100 hits , including four US number - ones with `` The Look , '' `` Listen to Your Heart , '' `` It Must Have Been Love , '' and `` Joyride . '' Other hits include `` Dangerous , '' `` Fading Like a Flower , '' `` Spending My Time , '' `` How Do You Do ! '' and `` Sleeping in My Car . ''\", sentence_starts=[0, 119, 249, 353, 568], selected_sent={'start': 353, 'end': 568, 'string': \"Roxette went on to achieve nineteen UK Top 40 hits and several US Hot 100 hits , including four US number - ones with `` The Look , '' `` Listen to Your Heart , '' `` It Must Have Been Love , '' and `` Joyride . '' \"}, answer=[Entity(start_offset=353, end_offset=360, type='context', text='Roxette', normalized_text='roxette')], nq_answers=[[Entity(start_offset=0, end_offset=7, type='context', text='Roxette', normalized_text='roxette')]], aligned_nps=[(Entity(start_offset=9, end_offset=48, type='question', text='it must have been love but its over now', normalized_text='it must have been love but its over now'), Entity(start_offset=520, end_offset=542, type='context', text='It Must Have Been Love', normalized_text='it must have been love'))], explanation_type='single_sentence'),\n",
       " -2282501421613384225: QEDExample(example_id=-2282501421613384225, title='Fibula', question='where is the tibia and fibula bone located', passage='The fibula or calf bone is a leg bone located on the lateral side of the tibia , with which it is connected above and below . It is the smaller of the two bones , and , in proportion to its length , the slenderest of all the long bones . Its upper extremity is small , placed toward the back of the head of the tibia , below the level of the knee joint , and excluded from the formation of this joint . Its lower extremity inclines a little forward , so as to be on a plane anterior to that of the upper end ; it projects below the tibia , and forms the lateral part of the ankle - joint .', sentence_starts=[0, 126, 238, 403], selected_sent={'start': 0, 'end': 126, 'string': 'The fibula or calf bone is a leg bone located on the lateral side of the tibia , with which it is connected above and below . '}, answer=[Entity(start_offset=29, end_offset=32, type='context', text='leg', normalized_text='leg')], nq_answers=[[Entity(start_offset=29, end_offset=32, type='context', text='leg', normalized_text='leg')]], aligned_nps=[(Entity(start_offset=23, end_offset=34, type='question', text='fibula bone', normalized_text='fibula bone'), Entity(start_offset=0, end_offset=23, type='context', text='The fibula or calf bone', normalized_text='fibula or calf bone')), (Entity(start_offset=9, end_offset=18, type='question', text='the tibia', normalized_text='tibia'), Entity(start_offset=69, end_offset=78, type='context', text='the tibia', normalized_text='tibia'))], explanation_type='single_sentence'),\n",
       " -9012928126702403111: QEDExample(example_id=-9012928126702403111, title=\"He Thinks He'll Keep Her\", question=\"who sings he thinks he'll keep her\", passage=\"`` He Thinks He 'll Keep Her '' is a song co-written and recorded by American country music artist Mary Chapin Carpenter . It was released in December 1993 as the sixth single from the album Come On Come On . The song peaked at No. 2 on the Billboard Hot Country Songs chart . It was written by Carpenter and Don Schlitz .\", sentence_starts=[0, 123, 209, 277], selected_sent={'start': 0, 'end': 123, 'string': \"`` He Thinks He 'll Keep Her '' is a song co-written and recorded by American country music artist Mary Chapin Carpenter . \"}, answer=[Entity(start_offset=99, end_offset=120, type='context', text='Mary Chapin Carpenter', normalized_text='mary chapin carpenter')], nq_answers=[[Entity(start_offset=69, end_offset=120, type='context', text='American country music artist Mary Chapin Carpenter', normalized_text='american country music artist mary chapin carpenter')], [Entity(start_offset=99, end_offset=120, type='context', text='Mary Chapin Carpenter', normalized_text='mary chapin carpenter')]], aligned_nps=[(Entity(start_offset=10, end_offset=34, type='question', text=\"he thinks he'll keep her\", normalized_text='he thinks hell keep her'), Entity(start_offset=3, end_offset=28, type='context', text=\"He Thinks He 'll Keep Her\", normalized_text='he thinks he ll keep her'))], explanation_type='single_sentence'),\n",
       " 7354980942032766409: QEDExample(example_id=7354980942032766409, title='Dust Bowl', question='what states were most affected by the dust bowl', passage='The drought and erosion of the Dust Bowl affected 100,000,000 acres ( 400,000 km ) that centered on the panhandles of Texas and Oklahoma and touched adjacent sections of New Mexico , Colorado , and Kansas .', sentence_starts=[0], selected_sent={'start': 0, 'end': 206, 'string': 'The drought and erosion of the Dust Bowl affected 100,000,000 acres ( 400,000 km ) that centered on the panhandles of Texas and Oklahoma and touched adjacent sections of New Mexico , Colorado , and Kansas .'}, answer=[Entity(start_offset=118, end_offset=136, type='context', text='Texas and Oklahoma', normalized_text='texas and oklahoma')], nq_answers=[[Entity(start_offset=118, end_offset=123, type='context', text='Texas', normalized_text='texas'), Entity(start_offset=128, end_offset=136, type='context', text='Oklahoma', normalized_text='oklahoma'), Entity(start_offset=170, end_offset=180, type='context', text='New Mexico', normalized_text='new mexico'), Entity(start_offset=183, end_offset=191, type='context', text='Colorado', normalized_text='colorado'), Entity(start_offset=198, end_offset=204, type='context', text='Kansas', normalized_text='kansas')]], aligned_nps=[(Entity(start_offset=34, end_offset=47, type='question', text='the dust bowl', normalized_text='dust bowl'), Entity(start_offset=27, end_offset=40, type='context', text='the Dust Bowl', normalized_text='dust bowl'))], explanation_type='single_sentence'),\n",
       " -5222261265502563302: QEDExample(example_id=-5222261265502563302, title='Carbonic acid', question='give the formula for the following substance carbonic acid', passage='Carbonic acid is a chemical compound with the chemical formula H CO ( equivalently OC ( OH ) ) . It is also a name sometimes given to solutions of carbon dioxide in water ( carbonated water ) , because such solutions contain small amounts of H CO . In physiology , carbonic acid is described as volatile acid or respiratory acid , because it is the only acid excreted as a gas by the lungs . It plays an important role in the bicarbonate buffer system to maintain acid -- base homeostasis .', sentence_starts=[0, 97, 249, 392], selected_sent={'start': 0, 'end': 97, 'string': 'Carbonic acid is a chemical compound with the chemical formula H CO ( equivalently OC ( OH ) ) . '}, answer=[Entity(start_offset=63, end_offset=92, type='context', text='H CO ( equivalently OC ( OH )', normalized_text='h co equivalently oc oh')], nq_answers=[[Entity(start_offset=63, end_offset=94, type='context', text='H CO ( equivalently OC ( OH ) )', normalized_text='h co equivalently oc oh')]], aligned_nps=[(Entity(start_offset=45, end_offset=58, type='question', text='carbonic acid', normalized_text='carbonic acid'), Entity(start_offset=0, end_offset=13, type='context', text='Carbonic acid', normalized_text='carbonic acid'))], explanation_type='single_sentence'),\n",
       " 8677748858763094212: QEDExample(example_id=8677748858763094212, title='Table of contents', question='where is the table of contents found in a book', passage=\"A table of contents , usually headed simply `` Contents '' and abbreviated informally as TOC , is a list , usually found on a page before the start of a written work , of its chapter or section titles or brief descriptions with their commencing page numbers .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 259, 'string': \"A table of contents , usually headed simply `` Contents '' and abbreviated informally as TOC , is a list , usually found on a page before the start of a written work , of its chapter or section titles or brief descriptions with their commencing page numbers .\"}, answer=[Entity(start_offset=107, end_offset=165, type='context', text='usually found on a page before the start of a written work', normalized_text='usually found on page before start of written work')], nq_answers=[[Entity(start_offset=107, end_offset=165, type='context', text='usually found on a page before the start of a written work', normalized_text='usually found on page before start of written work')], [Entity(start_offset=121, end_offset=257, type='context', text='on a page before the start of a written work , of its chapter or section titles or brief descriptions with their commencing page numbers', normalized_text='on page before start of written work of its chapter or section titles or brief descriptions with their commencing page numbers')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text='the table of contents', normalized_text='table of contents'), Entity(start_offset=0, end_offset=92, type='context', text=\"A table of contents , usually headed simply `` Contents '' and abbreviated informally as TOC\", normalized_text='table of contents usually headed simply contents and abbreviated informally as toc'))], explanation_type='single_sentence'),\n",
       " 6989804983941668854: QEDExample(example_id=6989804983941668854, title='Joseph Kearns', question='who plays mr wilson in dennis the menace', passage=\"Joseph Sherrard Kearns ( February 12 , 1907 -- February 17 , 1962 ) was an American actor , who is best remembered for his role as George Wilson ( `` Mr. Wilson '' ) in the CBS television series Dennis the Menace from 1959 until his death in 1962 , and for providing the voice of the Doorknob in the animated Disney film , Alice in Wonderland .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 344, 'string': \"Joseph Sherrard Kearns ( February 12 , 1907 -- February 17 , 1962 ) was an American actor , who is best remembered for his role as George Wilson ( `` Mr. Wilson '' ) in the CBS television series Dennis the Menace from 1959 until his death in 1962 , and for providing the voice of the Doorknob in the animated Disney film , Alice in Wonderland .\"}, answer=[Entity(start_offset=0, end_offset=22, type='context', text='Joseph Sherrard Kearns', normalized_text='joseph sherrard kearns')], nq_answers=[[Entity(start_offset=0, end_offset=22, type='context', text='Joseph Sherrard Kearns', normalized_text='joseph sherrard kearns')]], aligned_nps=[(Entity(start_offset=10, end_offset=19, type='question', text='mr wilson', normalized_text='mr wilson'), Entity(start_offset=131, end_offset=165, type='context', text=\"George Wilson ( `` Mr. Wilson '' )\", normalized_text='george wilson mr wilson')), (Entity(start_offset=23, end_offset=40, type='question', text='dennis the menace', normalized_text='dennis menace'), Entity(start_offset=169, end_offset=212, type='context', text='the CBS television series Dennis the Menace', normalized_text='cbs television series dennis menace'))], explanation_type='single_sentence'),\n",
       " -1287211595405752354: QEDExample(example_id=-1287211595405752354, title='Junior doctor', question='when do you stop being a junior doctor', passage='In the United Kingdom , junior doctors are qualified medical practitioners working whilst engaged in postgraduate training . The period of being a junior doctor starts when they qualify as a medical practitioner following graduation with a Bachelor of Medicine , Bachelor of Surgery degree and start the UK Foundation Programme , it culminates in a post as a Consultant , a General Practitioner ( GP ) , or some other non-training post , such as a Staff grade or Associate Specialist post .', sentence_starts=[0, 125], selected_sent={'start': 125, 'end': 490, 'string': 'The period of being a junior doctor starts when they qualify as a medical practitioner following graduation with a Bachelor of Medicine , Bachelor of Surgery degree and start the UK Foundation Programme , it culminates in a post as a Consultant , a General Practitioner ( GP ) , or some other non-training post , such as a Staff grade or Associate Specialist post .'}, answer=[Entity(start_offset=330, end_offset=488, type='context', text='it culminates in a post as a Consultant , a General Practitioner ( GP ) , or some other non-training post , such as a Staff grade or Associate Specialist post', normalized_text='it culminates in post as consultant general practitioner gp or some other nontraining post such as staff grade or associate specialist post')], nq_answers=[[Entity(start_offset=330, end_offset=488, type='context', text='it culminates in a post as a Consultant , a General Practitioner ( GP ) , or some other non-training post , such as a Staff grade or Associate Specialist post', normalized_text='it culminates in post as consultant general practitioner gp or some other nontraining post such as staff grade or associate specialist post')]], aligned_nps=[(Entity(start_offset=23, end_offset=38, type='question', text='a junior doctor', normalized_text='junior doctor'), Entity(start_offset=145, end_offset=160, type='context', text='a junior doctor', normalized_text='junior doctor'))], explanation_type='single_sentence'),\n",
       " 6566044826284732272: QEDExample(example_id=6566044826284732272, title='Breakup of Yugoslavia', question='bosnia and herzegovina croatia macedonia and slovenia all used to be parts of', passage=\"After the Allied victory in World War II , Yugoslavia was set up as a federation of six republics , with borders drawn along ethnic and historical lines : Bosnia and Herzegovina , Croatia , Macedonia , Montenegro , Serbia and Slovenia . In addition , two autonomous provinces were established within Serbia : Vojvodina and Kosovo . Each of the republics had its own branch of the League of Communists of Yugoslavia party and a ruling elite , and any tensions were solved on the federal level . The Yugoslav model of state organization , as well as a `` middle way '' between planned and liberal economy , had been a relative success , and the country experienced a period of strong economic growth and relative political stability up to the 1980s , under the rule of president - for - life Josip Broz Tito . After his death in 1980 , the weakened system of federal government was left unable to cope with rising economic and political challenges .\", sentence_starts=[0, 237, 332, 494, 808], selected_sent={'start': 0, 'end': 237, 'string': 'After the Allied victory in World War II , Yugoslavia was set up as a federation of six republics , with borders drawn along ethnic and historical lines : Bosnia and Herzegovina , Croatia , Macedonia , Montenegro , Serbia and Slovenia . '}, answer=[Entity(start_offset=43, end_offset=53, type='context', text='Yugoslavia', normalized_text='yugoslavia')], nq_answers=[[Entity(start_offset=43, end_offset=53, type='context', text='Yugoslavia', normalized_text='yugoslavia')]], aligned_nps=[(Entity(start_offset=0, end_offset=22, type='question', text='bosnia and herzegovina', normalized_text='bosnia and herzegovina'), Entity(start_offset=155, end_offset=177, type='context', text='Bosnia and Herzegovina', normalized_text='bosnia and herzegovina')), (Entity(start_offset=23, end_offset=30, type='question', text='croatia', normalized_text='croatia'), Entity(start_offset=180, end_offset=187, type='context', text='Croatia', normalized_text='croatia')), (Entity(start_offset=31, end_offset=40, type='question', text='macedonia', normalized_text='macedonia'), Entity(start_offset=190, end_offset=199, type='context', text='Macedonia', normalized_text='macedonia')), (Entity(start_offset=45, end_offset=53, type='question', text='slovenia', normalized_text='slovenia'), Entity(start_offset=226, end_offset=234, type='context', text='Slovenia', normalized_text='slovenia'))], explanation_type='single_sentence'),\n",
       " -3020013667493270694: QEDExample(example_id=-3020013667493270694, title='History of democracy', question='where did the idea of democracy come from', passage='The concepts ( and name ) of democracy and constitution as a form of government originated in ancient Athens circa 508 B.C. In ancient Greece , where there were many city - states with different forms of government , democracy was contrasted with governance by elites ( aristocracy ) , by one person ( monarchy ) , by tyrants ( tyranny ) , etc. ,', sentence_starts=[0, 124], selected_sent={'start': 0, 'end': 124, 'string': 'The concepts ( and name ) of democracy and constitution as a form of government originated in ancient Athens circa 508 B.C. '}, answer=[Entity(start_offset=94, end_offset=123, type='context', text='ancient Athens circa 508 B.C.', normalized_text='ancient athens circa 508 bc')], nq_answers=[[Entity(start_offset=91, end_offset=123, type='context', text='in ancient Athens circa 508 B.C.', normalized_text='in ancient athens circa 508 bc')]], aligned_nps=[(Entity(start_offset=10, end_offset=31, type='question', text='the idea of democracy', normalized_text='idea of democracy'), Entity(start_offset=0, end_offset=79, type='context', text='The concepts ( and name ) of democracy and constitution as a form of government', normalized_text='concepts and name of democracy and constitution as form of government'))], explanation_type='single_sentence'),\n",
       " -5728504822585102060: QEDExample(example_id=-5728504822585102060, title='Classical order', question='doric ionic and corinthian orders all refer to types of', passage='An order in architecture is a certain assemblage of parts subject to uniform established proportions , regulated by the office that each part has to perform `` . Coming down to the present from Ancient Greek and Ancient Roman civilization , the architectural orders are the styles of classical architecture , each distinguished by its proportions and characteristic profiles and details , and most readily recognizable by the type of column employed . The three orders of architecture -- the Doric , Ionic , and Corinthian -- originated in Greece . To these the Romans added , in practice if not in name , the Tuscan , which they made simpler than Doric , and the Composite , which was more ornamental than the Corinthian . The architectural order of a classical building is akin to the mode or key of classical music , the grammar or rhetoric of a written composition . It is established by certain modules like the intervals of music , and it raises certain expectations in an audience attuned to its language .', sentence_starts=[0, 162, 452, 549, 724, 871], selected_sent={'start': 452, 'end': 549, 'string': 'The three orders of architecture -- the Doric , Ionic , and Corinthian -- originated in Greece . '}, answer=[Entity(start_offset=472, end_offset=484, type='context', text='architecture', normalized_text='architecture')], nq_answers=[[Entity(start_offset=274, end_offset=449, type='context', text='styles of classical architecture , each distinguished by its proportions and characteristic profiles and details , and most readily recognizable by the type of column employed', normalized_text='styles of classical architecture each distinguished by its proportions and characteristic profiles and details and most readily recognizable by type of column employed')], [Entity(start_offset=472, end_offset=484, type='context', text='architecture', normalized_text='architecture')]], aligned_nps=[(Entity(start_offset=0, end_offset=33, type='question', text='doric ionic and corinthian orders', normalized_text='doric ionic and corinthian orders'), Entity(start_offset=452, end_offset=522, type='context', text='The three orders of architecture -- the Doric , Ionic , and Corinthian', normalized_text='three orders of architecture doric ionic and corinthian'))], explanation_type='single_sentence'),\n",
       " -6500826823871433949: QEDExample(example_id=-6500826823871433949, title='George Barnes (musician)', question='who made the first to record with the electric guitar', passage='George Warren Barnes ( July 17 , 1921 -- September 5 , 1977 ) was an American swing jazz guitarist who played the first electric guitar in 1931 . He made the first commercial recording of an electric guitar on March 1 , 1938 , in sessions with Big Bill Broonzy .', sentence_starts=[0, 146], selected_sent={'start': 146, 'end': 262, 'string': 'He made the first commercial recording of an electric guitar on March 1 , 1938 , in sessions with Big Bill Broonzy .'}, answer=[Entity(start_offset=0, end_offset=20, type='context', text='George Warren Barnes', normalized_text='george warren barnes')], nq_answers=[[Entity(start_offset=0, end_offset=20, type='context', text='George Warren Barnes', normalized_text='george warren barnes')]], aligned_nps=[(Entity(start_offset=34, end_offset=53, type='question', text='the electric guitar', normalized_text='electric guitar'), Entity(start_offset=188, end_offset=206, type='context', text='an electric guitar', normalized_text='electric guitar'))], explanation_type='single_sentence'),\n",
       " 6147480559877930832: QEDExample(example_id=6147480559877930832, title='South Korean won', question='what is the money called in south korea', passage=\"The won ( / wʌn / ; Korean : 원 , Korean pronunciation : ( wʌn ) ; symbol : ₩ ; code : KRW ) or the Korean Republic Won is the currency of South Korea . A single won is divided into 100 jeon , the monetary subunit . The jeon is no longer used for everyday transactions , and appears only in foreign exchange rates . The won is issued by the Bank of Korea , based in the capital city of Seoul . The official currency of North Korea , issued by the Central Bank of the Democratic People 's Republic of Korea which is based in its capital city , Pyongyang , is divided into the same number of units , and is known as the North Korean won .\", sentence_starts=[0, 152, 215, 315, 393], selected_sent={'start': 0, 'end': 152, 'string': 'The won ( / wʌn / ; Korean : 원 , Korean pronunciation : ( wʌn ) ; symbol : ₩ ; code : KRW ) or the Korean Republic Won is the currency of South Korea . '}, answer=[Entity(start_offset=4, end_offset=7, type='context', text='won', normalized_text='won')], nq_answers=[[Entity(start_offset=4, end_offset=7, type='context', text='won', normalized_text='won')], [Entity(start_offset=0, end_offset=7, type='context', text='The won', normalized_text='won')]], aligned_nps=[(Entity(start_offset=28, end_offset=39, type='question', text='south korea', normalized_text='south korea'), Entity(start_offset=138, end_offset=149, type='context', text='South Korea', normalized_text='south korea')), (Entity(start_offset=8, end_offset=17, type='question', text='the money', normalized_text='money'), Entity(start_offset=122, end_offset=149, type='context', text='the currency of South Korea', normalized_text='currency of south korea'))], explanation_type='single_sentence'),\n",
       " -7791738085698184855: QEDExample(example_id=-7791738085698184855, title='Love & Basketball', question='who played young monica in love and basketball', passage=\"The film spans roughly thirteen years of friendship between childhood sweethearts Monica Wright and Quincy McCall . The first quarter of the story begins in 1981 , when Monica ( played as a youth by Kyla Pratt ) and her family moved to Los Angeles in 1981 from Atlanta , Georgia , and quickly became acquainted with their new neighbors the McCalls , a wealthy family due to the success of Quincy 's father Zeke , the star shooting guard for the Los Angeles Clippers . Quincy and Monica are drawn to each other instantly , sharing a love of the game : basketball . Quincy ( played as a youth by Glendon Chattman ) is shocked that a girl could ever love basketball as much as he did , and he is even more shocked when Monica plays so well . Although their first interaction results in Quincy angrily knocking her down during game point and accidentally scarring her face , they share their first kiss on the first day of school and end the `` first quarter '' of the story fighting in the grass .\", sentence_starts=[0, 116, 468, 564, 739], selected_sent={'start': 116, 'end': 468, 'string': \"The first quarter of the story begins in 1981 , when Monica ( played as a youth by Kyla Pratt ) and her family moved to Los Angeles in 1981 from Atlanta , Georgia , and quickly became acquainted with their new neighbors the McCalls , a wealthy family due to the success of Quincy 's father Zeke , the star shooting guard for the Los Angeles Clippers . \"}, answer=[Entity(start_offset=199, end_offset=209, type='context', text='Kyla Pratt', normalized_text='kyla pratt')], nq_answers=[[Entity(start_offset=199, end_offset=209, type='context', text='Kyla Pratt', normalized_text='kyla pratt')]], aligned_nps=[(Entity(start_offset=27, end_offset=46, type='question', text='love and basketball', normalized_text='love and basketball'), Entity(start_offset=137, end_offset=146, type='context', text='the story', normalized_text='story')), (Entity(start_offset=11, end_offset=23, type='question', text='young monica', normalized_text='young monica'), Entity(start_offset=169, end_offset=211, type='context', text='Monica ( played as a youth by Kyla Pratt )', normalized_text='monica played as youth by kyla pratt'))], explanation_type='single_sentence'),\n",
       " 2494243668474038245: QEDExample(example_id=2494243668474038245, title='Eighth Amendment to the United States Constitution', question='how does the eighth amendment protect people found guilty of crimes', passage=\"The Eighth Amendment ( Amendment VIII ) of the United States Constitution prohibits the federal government from imposing excessive bail , excessive fines , or cruel and unusual punishment . The U.S. Supreme Court has ruled that this amendment 's Cruel and Unusual Punishment Clause also applies to the states . The phrases in this amendment originated in the English Bill of Rights of 1689 . This amendment was adopted on December 15 , 1791 , along with the rest of the United States Bill of Rights .\", sentence_starts=[0, 190, 311, 392], selected_sent={'start': 0, 'end': 190, 'string': 'The Eighth Amendment ( Amendment VIII ) of the United States Constitution prohibits the federal government from imposing excessive bail , excessive fines , or cruel and unusual punishment . '}, answer=[Entity(start_offset=74, end_offset=187, type='context', text='prohibits the federal government from imposing excessive bail , excessive fines , or cruel and unusual punishment', normalized_text='prohibits federal government from imposing excessive bail excessive fines or cruel and unusual punishment')], nq_answers=[[Entity(start_offset=74, end_offset=187, type='context', text='prohibits the federal government from imposing excessive bail , excessive fines , or cruel and unusual punishment', normalized_text='prohibits federal government from imposing excessive bail excessive fines or cruel and unusual punishment')]], aligned_nps=[(Entity(start_offset=9, end_offset=29, type='question', text='the eighth amendment', normalized_text='eighth amendment'), Entity(start_offset=0, end_offset=73, type='context', text='The Eighth Amendment ( Amendment VIII ) of the United States Constitution', normalized_text='eighth amendment amendment viii of united states constitution'))], explanation_type='single_sentence'),\n",
       " -5706868364310168474: QEDExample(example_id=-5706868364310168474, title='The King and I (1956 film)', question='when was the movie the king and i made', passage=\"The King and I is a 1956 American musical film made by 20th Century Fox , directed by Walter Lang and produced by Charles Brackett and Darryl F. Zanuck . The screenplay by Ernest Lehman is based on the Richard Rodgers and Oscar Hammerstein II musical The King and I , based in turn on the novel Anna and the King of Siam by Margaret Landon . That novel in turn was based on memoirs written by Anna Leonowens , who became school teacher to the children of King Mongkut of Siam in the early 1860s . Leonowens ' stories were autobiographical , although various elements of them have been called into question . The film stars Deborah Kerr and Yul Brynner .\", sentence_starts=[0, 154, 342, 497, 608], selected_sent={'start': 0, 'end': 154, 'string': 'The King and I is a 1956 American musical film made by 20th Century Fox , directed by Walter Lang and produced by Charles Brackett and Darryl F. Zanuck . '}, answer=[Entity(start_offset=20, end_offset=24, type='context', text='1956', normalized_text='1956')], nq_answers=[[Entity(start_offset=20, end_offset=24, type='context', text='1956', normalized_text='1956')]], aligned_nps=[(Entity(start_offset=9, end_offset=33, type='question', text='the movie the king and i', normalized_text='movie king and i'), Entity(start_offset=0, end_offset=14, type='context', text='The King and I', normalized_text='king and i'))], explanation_type='single_sentence'),\n",
       " -6164847228915369993: QEDExample(example_id=-6164847228915369993, title='Tyrosine kinase', question='why does overexpression of rtks lead to cancer development', passage=\"By 2004 , 58 receptor tyrosine kinases ( RTKs ) were known , grouped into 20 subfamilies . They play pivotal roles in diverse cellular activities including growth ( by signaling neurotrophins ) , differentiation , metabolism , adhesion , motility , death . RTKs are composed of an extracellular domain , which is able to bind a specific ligand , a transmembrane domain , and an intracellular catalytic domain , which is able to bind and phosphorylate selected substrates . Binding of a ligand to the extracellular region causes a series of structural rearrangements in the RTK that lead to its enzymatic activation . In particular , movement of some parts of the kinase domain gives free access to adenosine triphosphate ( ATP ) and the substrate to the active site . This triggers a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus , causing changes in gene expression . Many RTKs are involved in oncogenesis , either by gene mutation , or chromosome translocation , or simply by over-expression . In every case , the result is a hyper - active kinase , that confers an aberrant , ligand - independent , non-regulated growth stimulus to the cancer cells .\", sentence_starts=[0, 91, 257, 473, 617, 768, 976, 1103], selected_sent={'start': 1103, 'end': 1260, 'string': 'In every case , the result is a hyper - active kinase , that confers an aberrant , ligand - independent , non-regulated growth stimulus to the cancer cells .'}, answer=[Entity(start_offset=1133, end_offset=1258, type='context', text='a hyper - active kinase , that confers an aberrant , ligand - independent , non-regulated growth stimulus to the cancer cells', normalized_text='hyper active kinase that confers aberrant ligand independent nonregulated growth stimulus to cancer cells')], nq_answers=[[Entity(start_offset=1133, end_offset=1258, type='context', text='a hyper - active kinase , that confers an aberrant , ligand - independent , non-regulated growth stimulus to the cancer cells', normalized_text='hyper active kinase that confers aberrant ligand independent nonregulated growth stimulus to cancer cells')]], aligned_nps=[(Entity(start_offset=9, end_offset=31, type='question', text='overexpression of rtks', normalized_text='overexpression of rtks'), Entity(start_offset=1103, end_offset=1116, type='context', text='In every case', normalized_text='in every case'))], explanation_type='single_sentence'),\n",
       " 3902038636144368771: QEDExample(example_id=3902038636144368771, title='Arms and the Man', question='when does the first act of arms and the man take place', passage=\"The play takes place during the 1885 Serbo - Bulgarian War . Its heroine , Raina Petkoff , is a young Bulgarian woman engaged to Sergius Saranoff , one of the heroes of that war , whom she idolizes . On the night after the Battle of Slivnitza , a Swiss mercenary soldier in the Serbian army , Captain Bluntschli , climbs in through her bedroom balcony window and threatens to shoot Raina if she gives the alarm . When Russian and Bulgarian troops burst in to search the house for him , Raina hides him so that he wo n't be killed . He asks her to remember that `` nine soldiers out of ten are born fools . '' In a conversation after the soldiers have left , Bluntschli 's pragmatic and cynical attitude towards war and soldiering shocks the idealistic Raina , especially after he admits that he uses his ammunition pouches to carry chocolates rather than cartridges for his pistol . When the search dies down , Raina and her mother Catherine sneak Bluntschli out of the house , disguised in one of Raina 's father 's old coats .\", sentence_starts=[0, 61, 200, 413, 532, 609, 883], selected_sent={'start': 0, 'end': 61, 'string': 'The play takes place during the 1885 Serbo - Bulgarian War . '}, answer=[Entity(start_offset=21, end_offset=58, type='context', text='during the 1885 Serbo - Bulgarian War', normalized_text='during 1885 serbo bulgarian war')], nq_answers=[[Entity(start_offset=21, end_offset=58, type='context', text='during the 1885 Serbo - Bulgarian War', normalized_text='during 1885 serbo bulgarian war')], [Entity(start_offset=203, end_offset=242, type='context', text='the night after the Battle of Slivnitza', normalized_text='night after battle of slivnitza')]], aligned_nps=[(Entity(start_offset=27, end_offset=43, type='question', text='arms and the man', normalized_text='arms and man'), Entity(start_offset=0, end_offset=8, type='context', text='The play', normalized_text='play'))], explanation_type='single_sentence'),\n",
       " -3162843475189712099: QEDExample(example_id=-3162843475189712099, title='Battle of the Sexes (tennis)', question='who won battle of the sexes tennis game', passage=\"In tennis , `` Battle of the Sexes '' is a term that has been used to describe various exhibition matches played between a man and a woman ( or , in one case , a doubles match between two men and two women ) . Most famously , the term is used for a nationally televised match in 1973 , held at the Houston Astrodome , between 55 - year - old Bobby Riggs and 29 - year - old Billie Jean King , which King won in three sets . The match attracted massive attention and was viewed by an estimated 90 million people around the world ; King 's win is considered a milestone in public acceptance of women 's tennis .\", sentence_starts=[0, 210, 424], selected_sent={'start': 210, 'end': 424, 'string': 'Most famously , the term is used for a nationally televised match in 1973 , held at the Houston Astrodome , between 55 - year - old Bobby Riggs and 29 - year - old Billie Jean King , which King won in three sets . '}, answer=[Entity(start_offset=399, end_offset=403, type='context', text='King', normalized_text='king')], nq_answers=[[Entity(start_offset=374, end_offset=390, type='context', text='Billie Jean King', normalized_text='billie jean king')]], aligned_nps=[(Entity(start_offset=8, end_offset=39, type='question', text='battle of the sexes tennis game', normalized_text='battle of sexes tennis game'), Entity(start_offset=247, end_offset=390, type='context', text='a nationally televised match in 1973 , held at the Houston Astrodome , between 55 - year - old Bobby Riggs and 29 - year - old Billie Jean King', normalized_text='nationally televised match in 1973 held at houston astrodome between 55 year old bobby riggs and 29 year old billie jean king'))], explanation_type='single_sentence'),\n",
       " -7675299797121221951: QEDExample(example_id=-7675299797121221951, title='Results of the War of 1812', question='what was the result of the war 1812', passage=\"Results of the War of 1812 between Great Britain and the United States , 1812 - 1815 , involved with no geographical changes . The main result of the war was two centuries of peace between the United States and Britain . All the causes of the war had disappeared with the end of the war between Britain and France and with the destruction of the power of Indians to block American expansion into the Northwest . American fears of the Native Americans ended , as did British plans to create a buffer Native American state . The American quest for honor after its humiliations by the British were satisfied . The final collapse of the opposition Federalist Party opened an `` Era of good feelings '' with lessened partisanship and an exuberant spirit . The British paid little attention to the war , concentrating instead on their final defeat of Napoleon in 1815 . The U.S. failed to gain any territory from British North America , contrary to many American politicians ' hopes and expectations , but it did gain land from Spain .\", sentence_starts=[0, 127, 221, 412, 523, 607, 751, 864], selected_sent={'start': 127, 'end': 221, 'string': 'The main result of the war was two centuries of peace between the United States and Britain . '}, answer=[Entity(start_offset=158, end_offset=218, type='context', text='two centuries of peace between the United States and Britain', normalized_text='two centuries of peace between united states and britain')], nq_answers=[[Entity(start_offset=158, end_offset=218, type='context', text='two centuries of peace between the United States and Britain', normalized_text='two centuries of peace between united states and britain')]], aligned_nps=[(Entity(start_offset=9, end_offset=35, type='question', text='the result of the war 1812', normalized_text='result of war 1812'), Entity(start_offset=127, end_offset=153, type='context', text='The main result of the war', normalized_text='main result of war'))], explanation_type='single_sentence'),\n",
       " 4839932048409627408: QEDExample(example_id=4839932048409627408, title='Abigail Hawk', question='who is the actress who plays baker on blue bloods', passage=\"Abigail Hawk ( born Abigail Diane Gustafson ) is an American actress known for playing Samantha Bonner in the 1995 TV series Reality Check , Detective Abigail Baker in Blue Bloods , Riley Thomas in the 2016 holiday TV movie , A Christmas in Vermont , and Ellie in Domenica Cameron - Scorsese 's 2017 directorial debut , Almost Paris . For her performance in Almost Paris , Hawk won the `` Best Actress '' award at the 2017 Golden Door Film Festival .\", sentence_starts=[0, 335], selected_sent={'start': 0, 'end': 335, 'string': \"Abigail Hawk ( born Abigail Diane Gustafson ) is an American actress known for playing Samantha Bonner in the 1995 TV series Reality Check , Detective Abigail Baker in Blue Bloods , Riley Thomas in the 2016 holiday TV movie , A Christmas in Vermont , and Ellie in Domenica Cameron - Scorsese 's 2017 directorial debut , Almost Paris . \"}, answer=[Entity(start_offset=0, end_offset=12, type='context', text='Abigail Hawk', normalized_text='abigail hawk')], nq_answers=[[Entity(start_offset=0, end_offset=12, type='context', text='Abigail Hawk', normalized_text='abigail hawk')], [Entity(start_offset=0, end_offset=45, type='context', text='Abigail Hawk ( born Abigail Diane Gustafson )', normalized_text='abigail hawk born abigail diane gustafson')]], aligned_nps=[(Entity(start_offset=29, end_offset=34, type='question', text='baker', normalized_text='baker'), Entity(start_offset=141, end_offset=164, type='context', text='Detective Abigail Baker', normalized_text='detective abigail baker')), (Entity(start_offset=38, end_offset=49, type='question', text='blue bloods', normalized_text='blue bloods'), Entity(start_offset=168, end_offset=179, type='context', text='Blue Bloods', normalized_text='blue bloods'))], explanation_type='single_sentence'),\n",
       " -8846507630412060967: QEDExample(example_id=-8846507630412060967, title='Call Me by Your Name (film)', question='where is the villa in call me by your name', passage=\"The main location for the Perlmans ' residence was an uninhabited 17th - century mansion in Moscazzano . The director initially wanted to buy the house but could not afford it , so he made a film at the place instead . Six weeks before production , the crew -- including production designer Samuel Dehors and first - time set decorator Violante Visconti di Modrone -- gradually decorated the house with furniture , objects , and decoration inspired by the characters . Much of the furniture , including the dishes and glassware from the ' 50s , belonged to Guadagnino and Visconti 's parents . `` That made it cozy and personal , '' Visconti said , `` I wanted to give it the sense of time passing by . ''\", sentence_starts=[0, 105, 219, 469, 594], selected_sent={'start': 0, 'end': 105, 'string': \"The main location for the Perlmans ' residence was an uninhabited 17th - century mansion in Moscazzano . \"}, answer=[Entity(start_offset=51, end_offset=102, type='context', text='an uninhabited 17th - century mansion in Moscazzano', normalized_text='uninhabited 17th century mansion in moscazzano')], nq_answers=[[Entity(start_offset=92, end_offset=102, type='context', text='Moscazzano', normalized_text='moscazzano')], [Entity(start_offset=51, end_offset=102, type='context', text='an uninhabited 17th - century mansion in Moscazzano', normalized_text='uninhabited 17th century mansion in moscazzano')]], aligned_nps=[(Entity(start_offset=9, end_offset=42, type='question', text='the villa in call me by your name', normalized_text='villa in call me by your name'), Entity(start_offset=22, end_offset=46, type='context', text=\"the Perlmans ' residence\", normalized_text='perlmans residence'))], explanation_type='single_sentence'),\n",
       " -3310624671723052836: QEDExample(example_id=-3310624671723052836, title='Glory (religion)', question='what is the definition of glory in the bible', passage=\"Glory ( from the Latin gloria , `` fame , renown '' ) is used to describe the manifestation of God 's presence as perceived by humans according to the Abrahamic religions .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 172, 'string': \"Glory ( from the Latin gloria , `` fame , renown '' ) is used to describe the manifestation of God 's presence as perceived by humans according to the Abrahamic religions .\"}, answer=[Entity(start_offset=74, end_offset=133, type='context', text=\"the manifestation of God 's presence as perceived by humans\", normalized_text='manifestation of god s presence as perceived by humans')], nq_answers=[[Entity(start_offset=74, end_offset=133, type='context', text=\"the manifestation of God 's presence as perceived by humans\", normalized_text='manifestation of god s presence as perceived by humans')]], aligned_nps=[(Entity(start_offset=26, end_offset=44, type='question', text='glory in the bible', normalized_text='glory in bible'), Entity(start_offset=0, end_offset=53, type='context', text=\"Glory ( from the Latin gloria , `` fame , renown '' )\", normalized_text='glory from latin gloria fame renown'))], explanation_type='single_sentence'),\n",
       " -5662976269536958974: QEDExample(example_id=-5662976269536958974, title='Agents of S.H.I.E.L.D. (season 5)', question='when does agents of shield season five start', passage=\"The fifth season is set to begin airing on December 1 , 2017 , after Marvel 's Inhumans has finished airing its episodes , and run for 22 episodes .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 148, 'string': \"The fifth season is set to begin airing on December 1 , 2017 , after Marvel 's Inhumans has finished airing its episodes , and run for 22 episodes .\"}, answer=[Entity(start_offset=43, end_offset=60, type='context', text='December 1 , 2017', normalized_text='december 1 2017')], nq_answers=[[Entity(start_offset=43, end_offset=60, type='context', text='December 1 , 2017', normalized_text='december 1 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=38, type='question', text='agents of shield season five', normalized_text='agents of shield season five'), Entity(start_offset=0, end_offset=16, type='context', text='The fifth season', normalized_text='fifth season'))], explanation_type='single_sentence'),\n",
       " 312616814646574456: QEDExample(example_id=312616814646574456, title='Nucleotide', question='what are the monomer building blocks of dna and rna', passage='Nucleotides are organic molecules that serve as the monomer units for forming the nucleic acid polymers deoxyribonucleic acid ( DNA ) and ribonucleic acid ( RNA ) , both of which are essential biomolecules in all life - forms on Earth . Nucleotides are the building blocks of nucleic acids ; they are composed of three subunit molecules : a nitrogenous base , a five - carbon sugar ( ribose or deoxyribose ) , and at least one phosphate group . They are also known as phosphate nucleotides .', sentence_starts=[0, 237, 445], selected_sent={'start': 0, 'end': 237, 'string': 'Nucleotides are organic molecules that serve as the monomer units for forming the nucleic acid polymers deoxyribonucleic acid ( DNA ) and ribonucleic acid ( RNA ) , both of which are essential biomolecules in all life - forms on Earth . '}, answer=[Entity(start_offset=0, end_offset=11, type='context', text='Nucleotides', normalized_text='nucleotides')], nq_answers=[[Entity(start_offset=0, end_offset=11, type='context', text='Nucleotides', normalized_text='nucleotides')]], aligned_nps=[(Entity(start_offset=9, end_offset=51, type='question', text='the monomer building blocks of dna and rna', normalized_text='monomer building blocks of dna and rna'), Entity(start_offset=48, end_offset=162, type='context', text='the monomer units for forming the nucleic acid polymers deoxyribonucleic acid ( DNA ) and ribonucleic acid ( RNA )', normalized_text='monomer units for forming nucleic acid polymers deoxyribonucleic acid dna and ribonucleic acid rna'))], explanation_type='single_sentence'),\n",
       " -4002287809711138581: QEDExample(example_id=-4002287809711138581, title='University of Michigan School of Public Health', question='university of michigan school of public health ranking', passage=\"According to the US News & World Report 's report on graduate programs , the University of Michigan School of Public Health was ranked as the # 4 School of Public Health in the country and also had the # 1 Healthcare Management program in the country in 2011 .\", sentence_starts=[0], selected_sent={'start': 0, 'end': 260, 'string': \"According to the US News & World Report 's report on graduate programs , the University of Michigan School of Public Health was ranked as the # 4 School of Public Health in the country and also had the # 1 Healthcare Management program in the country in 2011 .\"}, answer=[Entity(start_offset=144, end_offset=145, type='context', text='4', normalized_text='4')], nq_answers=[[Entity(start_offset=142, end_offset=145, type='context', text='# 4', normalized_text='4')], [Entity(start_offset=142, end_offset=184, type='context', text='# 4 School of Public Health in the country', normalized_text='4 school of public health in country')]], aligned_nps=[(Entity(start_offset=0, end_offset=46, type='question', text='university of michigan school of public health', normalized_text='university of michigan school of public health'), Entity(start_offset=73, end_offset=123, type='context', text='the University of Michigan School of Public Health', normalized_text='university of michigan school of public health'))], explanation_type='single_sentence'),\n",
       " 5458457305393794764: QEDExample(example_id=5458457305393794764, title='Walter Egan', question='who sings you are a magnet and i am steel', passage=\"Walter Egan ( born July 12 , 1948 ) is an American rock musician , best known for his 1978 gold status hit single `` Magnet and Steel '' from his second album release , Not Shy , produced by Lindsey Buckingham and Richard Dashut . The song reached # 8 on the Billboard Hot 100 and # 18 on the Easy Listening chart . Overseas , it peaked at # 32 on the Australian Singles Chart , Kent Music Report .\", sentence_starts=[0, 231, 316], selected_sent={'start': 0, 'end': 231, 'string': \"Walter Egan ( born July 12 , 1948 ) is an American rock musician , best known for his 1978 gold status hit single `` Magnet and Steel '' from his second album release , Not Shy , produced by Lindsey Buckingham and Richard Dashut . \"}, answer=[Entity(start_offset=0, end_offset=11, type='context', text='Walter Egan', normalized_text='walter egan')], nq_answers=[[Entity(start_offset=0, end_offset=11, type='context', text='Walter Egan', normalized_text='walter egan')]], aligned_nps=[(Entity(start_offset=10, end_offset=41, type='question', text='you are a magnet and i am steel', normalized_text='you are magnet and i am steel'), Entity(start_offset=82, end_offset=228, type='context', text=\"his 1978 gold status hit single `` Magnet and Steel '' from his second album release , Not Shy , produced by Lindsey Buckingham and Richard Dashut\", normalized_text='his 1978 gold status hit single magnet and steel from his second album release not shy produced by lindsey buckingham and richard dashut'))], explanation_type='single_sentence'),\n",
       " -6933377434468493740: QEDExample(example_id=-6933377434468493740, title=\"I Don't Feel at Home in This World Anymore\", question='who wrote i can feel at home in this world anymore', passage=\"I Do n't Feel at Home in This World Anymore ( often stylized I do n't feel at home in this world anymore . ) is a 2017 American comedy thriller film written and directed by Macon Blair in his directorial debut . It stars Melanie Lynskey , Elijah Wood , David Yow , Jane Levy and Devon Graye .\", sentence_starts=[0, 212], selected_sent={'start': 0, 'end': 212, 'string': \"I Do n't Feel at Home in This World Anymore ( often stylized I do n't feel at home in this world anymore . ) is a 2017 American comedy thriller film written and directed by Macon Blair in his directorial debut . \"}, answer=[Entity(start_offset=173, end_offset=184, type='context', text='Macon Blair', normalized_text='macon blair')], nq_answers=[[Entity(start_offset=173, end_offset=184, type='context', text='Macon Blair', normalized_text='macon blair')]], aligned_nps=[(Entity(start_offset=10, end_offset=50, type='question', text='i can feel at home in this world anymore', normalized_text='i can feel at home in this world anymore'), Entity(start_offset=0, end_offset=108, type='context', text=\"I Do n't Feel at Home in This World Anymore ( often stylized I do n't feel at home in this world anymore . )\", normalized_text='i do nt feel at home in this world anymore often stylized i do nt feel at home in this world anymore'))], explanation_type='single_sentence'),\n",
       " 2491905025544292544: QEDExample(example_id=2491905025544292544, title='Jacques Cartier', question='explorer who led an early voyage to the coast of newfoundland', passage='Jacques Cartier Island , located on the tip of the Great Northern Peninsula in Newfoundland and Labrador in the town of Quirpon , is said to have been named by Jacques Cartier himself on one of his voyages through the Strait of Belle Isle during the 1530s .', sentence_starts=[0], selected_sent={'start': 0, 'end': 257, 'string': 'Jacques Cartier Island , located on the tip of the Great Northern Peninsula in Newfoundland and Labrador in the town of Quirpon , is said to have been named by Jacques Cartier himself on one of his voyages through the Strait of Belle Isle during the 1530s .'}, answer=[Entity(start_offset=160, end_offset=175, type='context', text='Jacques Cartier', normalized_text='jacques cartier')], nq_answers=[[Entity(start_offset=0, end_offset=15, type='context', text='Jacques Cartier', normalized_text='jacques cartier')]], aligned_nps=[(Entity(start_offset=49, end_offset=61, type='question', text='newfoundland', normalized_text='newfoundland'), Entity(start_offset=79, end_offset=91, type='context', text='Newfoundland', normalized_text='newfoundland'))], explanation_type='single_sentence'),\n",
       " -4282172075713153249: QEDExample(example_id=-4282172075713153249, title='The Canterbury Tales', question='where does the journey start in the canterbury tales', passage=\"The Canterbury Tales ( Middle English : Tales of Caunterbury ) is a collection of 24 stories that runs to over 17,000 lines written in Middle English by Geoffrey Chaucer between 1387 and 1400 . In 1386 , Chaucer became Controller of Customs and Justice of Peace and , in 1389 , Clerk of the King 's work . It was during these years that Chaucer began working on his most famous text , The Canterbury Tales . The tales ( mostly written in verse , although some are in prose ) are presented as part of a story - telling contest by a group of pilgrims as they travel together on a journey from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral . The prize for this contest is a free meal at the Tabard Inn at Southwark on their return .\", sentence_starts=[0, 194, 306, 408, 681], selected_sent={'start': 408, 'end': 681, 'string': 'The tales ( mostly written in verse , although some are in prose ) are presented as part of a story - telling contest by a group of pilgrims as they travel together on a journey from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral . '}, answer=[Entity(start_offset=591, end_offset=597, type='context', text='London', normalized_text='london')], nq_answers=[[Entity(start_offset=591, end_offset=597, type='context', text='London', normalized_text='london')]], aligned_nps=[(Entity(start_offset=11, end_offset=52, type='question', text='the journey start in the canterbury tales', normalized_text='journey start in canterbury tales'), Entity(start_offset=576, end_offset=678, type='context', text='a journey from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral', normalized_text='journey from london to canterbury to visit shrine of saint thomas becket at canterbury cathedral'))], explanation_type='single_sentence'),\n",
       " 4547252852518822825: QEDExample(example_id=4547252852518822825, title=\"World's tallest thermometer\", question=\"where is the world's largest thermometer located\", passage=\"The World 's Tallest Thermometer is a landmark located in Baker , California , USA . It is an electric sign that commemorates the record 134 degrees Fahrenheit ( 57 degrees Celsius ) recorded in nearby Death Valley on July 10 , 1913 .\", sentence_starts=[0, 85], selected_sent={'start': 0, 'end': 85, 'string': \"The World 's Tallest Thermometer is a landmark located in Baker , California , USA . \"}, answer=[Entity(start_offset=58, end_offset=82, type='context', text='Baker , California , USA', normalized_text='baker california usa')], nq_answers=[[Entity(start_offset=58, end_offset=82, type='context', text='Baker , California , USA', normalized_text='baker california usa')], [Entity(start_offset=58, end_offset=76, type='context', text='Baker , California', normalized_text='baker california')]], aligned_nps=[(Entity(start_offset=9, end_offset=40, type='question', text=\"the world's largest thermometer\", normalized_text='worlds largest thermometer'), Entity(start_offset=0, end_offset=32, type='context', text=\"The World 's Tallest Thermometer\", normalized_text='world s tallest thermometer'))], explanation_type='single_sentence'),\n",
       " 6825646691617297520: QEDExample(example_id=6825646691617297520, title='Gene', question='the complete collection of dna and genes is called', passage='The total complement of genes in an organism or cell is known as its genome , which may be stored on one or more chromosomes . A chromosome consists of a single , very long DNA helix on which thousands of genes are encoded . The region of the chromosome at which a particular gene is located is called its locus . Each locus contains one allele of a gene ; however , members of a population may have different alleles at the locus , each with a slightly different gene sequence .', sentence_starts=[0, 127, 225, 314], selected_sent={'start': 0, 'end': 127, 'string': 'The total complement of genes in an organism or cell is known as its genome , which may be stored on one or more chromosomes . '}, answer=[Entity(start_offset=69, end_offset=75, type='context', text='genome', normalized_text='genome')], nq_answers=[[Entity(start_offset=69, end_offset=75, type='context', text='genome', normalized_text='genome')], [Entity(start_offset=129, end_offset=139, type='context', text='chromosome', normalized_text='chromosome')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " -7170779167971049436: QEDExample(example_id=-7170779167971049436, title='Many happy returns (greeting)', question='many many happy returns of the day meaning', passage=\"`` Many happy returns '' is a greeting which is used by some on birthdays , and by others in response to `` Merry Christmas '' and `` Happy New Year '' . Since the 18th century this has been used as a salutation to offer the hope that a happy day being marked would recur many more times . It is now primarily used , by some , on birthdays . Prior to the mid-19th century , it was used at any celebratory or festive event . The phrase is more common in British English , Indian English , Hiberno English and to some degree in Canadian English than in American English .\", sentence_starts=[0, 154, 290, 342, 424], selected_sent={'start': 154, 'end': 290, 'string': 'Since the 18th century this has been used as a salutation to offer the hope that a happy day being marked would recur many more times . '}, answer=[Entity(start_offset=199, end_offset=287, type='context', text='a salutation to offer the hope that a happy day being marked would recur many more times', normalized_text='salutation to offer hope that happy day being marked would recur many more times')], nq_answers=[[Entity(start_offset=199, end_offset=287, type='context', text='a salutation to offer the hope that a happy day being marked would recur many more times', normalized_text='salutation to offer hope that happy day being marked would recur many more times')], [Entity(start_offset=191, end_offset=287, type='context', text='used as a salutation to offer the hope that a happy day being marked would recur many more times', normalized_text='used as salutation to offer hope that happy day being marked would recur many more times')], [Entity(start_offset=212, end_offset=287, type='context', text='to offer the hope that a happy day being marked would recur many more times', normalized_text='to offer hope that happy day being marked would recur many more times')]], aligned_nps=[(Entity(start_offset=0, end_offset=34, type='question', text='many many happy returns of the day', normalized_text='many many happy returns of day'), Entity(start_offset=177, end_offset=181, type='context', text='this', normalized_text='this'))], explanation_type='single_sentence'),\n",
       " -4715318055561835785: QEDExample(example_id=-4715318055561835785, title='Celebrity Big Brother (U.S. TV series)', question='when is winter big brother going to start', passage='Celebrity Big Brother , also known as Big Brother : Celebrity Edition , is a spin - off series of the American reality television series Big Brother . This season will air during the winter of the 2017 -- 18 network television season on CBS and will be the second U.S. Big Brother season to air outside the usual summer television season , the first being Big Brother 9 in 2008 . Julie Chen will return as host , with Allison Grodner and Rich Meehan returning as executive producers . The season will be produced by Fly on the Wall Entertainment in association with Endemol Shine North America . CBS announced that the series is set to premiere on February 7 , 2018 and conclude on February 25 , 2018 .', sentence_starts=[0, 151, 380, 485, 596], selected_sent={'start': 596, 'end': 702, 'string': 'CBS announced that the series is set to premiere on February 7 , 2018 and conclude on February 25 , 2018 .'}, answer=[Entity(start_offset=648, end_offset=665, type='context', text='February 7 , 2018', normalized_text='february 7 2018')], nq_answers=[[Entity(start_offset=648, end_offset=665, type='context', text='February 7 , 2018', normalized_text='february 7 2018')], [Entity(start_offset=629, end_offset=665, type='context', text='set to premiere on February 7 , 2018', normalized_text='set to premiere on february 7 2018')]], aligned_nps=[(Entity(start_offset=8, end_offset=26, type='question', text='winter big brother', normalized_text='winter big brother'), Entity(start_offset=615, end_offset=625, type='context', text='the series', normalized_text='series'))], explanation_type='single_sentence'),\n",
       " 7493884540814755566: QEDExample(example_id=7493884540814755566, title='United States Air Force Academy', question='where is the air force academy located at', passage='The United States Air Force Academy ( also known as USAFA , the Air Force Academy , or the Academy ) , is a military academy for officer cadets of the United States Air Force . Its campus is located in the western United States in Colorado , immediately north of Colorado Springs in El Paso County .', sentence_starts=[0, 177], selected_sent={'start': 177, 'end': 299, 'string': 'Its campus is located in the western United States in Colorado , immediately north of Colorado Springs in El Paso County .'}, answer=[Entity(start_offset=206, end_offset=297, type='context', text='western United States in Colorado , immediately north of Colorado Springs in El Paso County', normalized_text='western united states in colorado immediately north of colorado springs in el paso county')], nq_answers=[[Entity(start_offset=199, end_offset=297, type='context', text='in the western United States in Colorado , immediately north of Colorado Springs in El Paso County', normalized_text='in western united states in colorado immediately north of colorado springs in el paso county')], [Entity(start_offset=199, end_offset=299, type='context', text='in the western United States in Colorado , immediately north of Colorado Springs in El Paso County .', normalized_text='in western united states in colorado immediately north of colorado springs in el paso county')], [Entity(start_offset=202, end_offset=297, type='context', text='the western United States in Colorado , immediately north of Colorado Springs in El Paso County', normalized_text='western united states in colorado immediately north of colorado springs in el paso county')], [Entity(start_offset=199, end_offset=279, type='context', text='in the western United States in Colorado , immediately north of Colorado Springs', normalized_text='in western united states in colorado immediately north of colorado springs')], [Entity(start_offset=228, end_offset=297, type='context', text='in Colorado , immediately north of Colorado Springs in El Paso County', normalized_text='in colorado immediately north of colorado springs in el paso county')]], aligned_nps=[(Entity(start_offset=9, end_offset=30, type='question', text='the air force academy', normalized_text='air force academy'), Entity(start_offset=177, end_offset=180, type='context', text='Its', normalized_text='its'))], explanation_type='single_sentence'),\n",
       " -7041482472551901963: QEDExample(example_id=-7041482472551901963, title=\"Mark Sloan (Grey's Anatomy)\", question=\"when does sloan come into grey's anatomy\", passage=\"Mark first appears in season two , introduced as a highly respected otolaryngologist sub-specialized in plastic surgery and the childhood best friend of neurosurgeon Derek Shepherd ( Patrick Dempsey ) . In his first appearance , he flirts with Meredith Grey , and Derek punches him in the face . Derek explains that Mark had an affair with his wife , Addison ( Kate Walsh ) while they were living in New York . Mark travels to Seattle , intent on convincing Addison to return with him , but his offer is rejected and Derek declines to renew their friendship . Mark returns during season three at Addison 's drunken behest , but she again rejects him once sober . Undeterred , Mark sells his successful private practice ( which he previously shared with Derek ) and takes over the plastics program at Seattle Grace Hospital . During Meredith 's morphine rampage , Mark finds out about his nickname McSteamy which was given to him by her during his first trip to Seattle back when he attempted to get Addison back and earn Derek 's friendship back . It is later revealed that Mark has at some point slept with all of Derek 's sisters . Mark has a brief fling with Addison 's friend , orthopedic surgeon Callie Torres ( Sara Ramirez ) , and develops a friendship with Derek 's girlfriend , intern Meredith Grey ( Ellen Pompeo ) . It is revealed that after Derek left New York , Mark and Addison continued their relationship for two months , during which she conceived and aborted his child . Just weeks after moving to Seattle he quickly observes that Derek 's true love was Meredith and tries to convince Addison that her marriage with Derek was over . Mark enters into a sixty - day abstinence pact with Addison , agreeing that if they can remain celibate for that time , Addison will give their relationship another chance . Addison ultimately breaks the pact by having sex with intern Alex Karev ( Justin Chambers ) , and soon thereafter departs from Seattle to work in Los Angeles .\", sentence_starts=[0, 203, 296, 411, 560, 663, 825, 1048, 1134, 1327, 1489, 1651, 1825], selected_sent={'start': 0, 'end': 203, 'string': 'Mark first appears in season two , introduced as a highly respected otolaryngologist sub-specialized in plastic surgery and the childhood best friend of neurosurgeon Derek Shepherd ( Patrick Dempsey ) . '}, answer=[Entity(start_offset=22, end_offset=32, type='context', text='season two', normalized_text='season two')], nq_answers=[[Entity(start_offset=22, end_offset=32, type='context', text='season two', normalized_text='season two')]], aligned_nps=[(Entity(start_offset=10, end_offset=15, type='question', text='sloan', normalized_text='sloan'), Entity(start_offset=0, end_offset=4, type='context', text='Mark', normalized_text='mark')), (Entity(start_offset=26, end_offset=40, type='question', text=\"grey's anatomy\", normalized_text='greys anatomy'), Entity(start_offset=-1, end_offset=-1, type='context', text='', normalized_text=''))], explanation_type='single_sentence'),\n",
       " 180254285981266034: QEDExample(example_id=180254285981266034, title='Nancy Cartwright', question='who does the voice of nelson on simpsons', passage='Nancy Jean Cartwright ( born October 25 , 1957 ) is an American actress , voice actress and comedian , known for her long - running role as Bart Simpson on the animated television series The Simpsons . Cartwright also voices other characters for the show , including Nelson Muntz , Ralph Wiggum , Todd Flanders , Kearney and Database .', sentence_starts=[0, 202], selected_sent={'start': 202, 'end': 335, 'string': 'Cartwright also voices other characters for the show , including Nelson Muntz , Ralph Wiggum , Todd Flanders , Kearney and Database .'}, answer=[Entity(start_offset=0, end_offset=21, type='context', text='Nancy Jean Cartwright', normalized_text='nancy jean cartwright')], nq_answers=[[Entity(start_offset=0, end_offset=21, type='context', text='Nancy Jean Cartwright', normalized_text='nancy jean cartwright')]], aligned_nps=[(Entity(start_offset=32, end_offset=40, type='question', text='simpsons', normalized_text='simpsons'), Entity(start_offset=246, end_offset=254, type='context', text='the show', normalized_text='show')), (Entity(start_offset=22, end_offset=28, type='question', text='nelson', normalized_text='nelson'), Entity(start_offset=267, end_offset=279, type='context', text='Nelson Muntz', normalized_text='nelson muntz'))], explanation_type='single_sentence'),\n",
       " -7876488844834691314: QEDExample(example_id=-7876488844834691314, title='Oakland Raiders relocation to Las Vegas', question='when is oakland raiders going to las vegas', passage=\"The Oakland Raiders relocation to Las Vegas was a successful effort by the owner of the Oakland Raiders ( Mark Davis ) to relocate the American football club from its current and longtime home of Oakland , California to Las Vegas , Nevada . The team is scheduled to begin play as the Las Vegas Raiders for the 2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium ) , playing home games at the Las Vegas Stadium . NFL team owners voted 31 -- 1 to approve the move , which was announced at the annual league meetings in Phoenix , Arizona on March 27 , 2017 . The Raiders became the third NFL franchise to relocate in the 2010s , following the Rams ' move from St. Louis , Missouri to Los Angeles , California on January 12 , 2016 , and the Chargers ' move from San Diego , California to Los Angeles on January 12 , 2017 . The Raiders ' move to Las Vegas comes after years of failed efforts to renovate or replace the Oakland -- Alameda County Coliseum , which has been rated by multiple sources as one of the worst stadiums in the NFL .\", sentence_starts=[0, 241, 487, 631, 894], selected_sent={'start': 241, 'end': 487, 'string': 'The team is scheduled to begin play as the Las Vegas Raiders for the 2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium ) , playing home games at the Las Vegas Stadium . '}, answer=[Entity(start_offset=253, end_offset=438, type='context', text='scheduled to begin play as the Las Vegas Raiders for the 2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )', normalized_text='scheduled to begin play as las vegas raiders for 2020 national football league nfl season although move to las vegas could happen as soon as 2019 with sam boyd stadium')], nq_answers=[[Entity(start_offset=302, end_offset=438, type='context', text='for the 2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )', normalized_text='for 2020 national football league nfl season although move to las vegas could happen as soon as 2019 with sam boyd stadium')], [Entity(start_offset=306, end_offset=438, type='context', text='the 2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )', normalized_text='2020 national football league nfl season although move to las vegas could happen as soon as 2019 with sam boyd stadium')], [Entity(start_offset=302, end_offset=354, type='context', text='for the 2020 National Football League ( NFL ) season', normalized_text='for 2020 national football league nfl season')], [Entity(start_offset=386, end_offset=414, type='context', text='could happen as soon as 2019', normalized_text='could happen as soon as 2019')], [Entity(start_offset=241, end_offset=354, type='context', text='The team is scheduled to begin play as the Las Vegas Raiders for the 2020 National Football League ( NFL ) season', normalized_text='team is scheduled to begin play as las vegas raiders for 2020 national football league nfl season')]], aligned_nps=[(Entity(start_offset=8, end_offset=23, type='question', text='oakland raiders', normalized_text='oakland raiders'), Entity(start_offset=241, end_offset=249, type='context', text='The team', normalized_text='team')), (Entity(start_offset=33, end_offset=42, type='question', text='las vegas', normalized_text='las vegas'), Entity(start_offset=376, end_offset=385, type='context', text='Las Vegas', normalized_text='las vegas'))], explanation_type='single_sentence'),\n",
       " -497599261993763142: QEDExample(example_id=-497599261993763142, title='Duluth model', question='the duluth model is an intervention program that emphasizes', passage=\"The feminist theory underlying the Duluth Model is that men use violence within relationships to exercise power and control . This is illustrated by the `` Power and Control Wheel , '' a graphic typically displayed as a poster in participating locations . According to the Duluth Model , `` women and children are vulnerable to violence because of their unequal social , economic , and political status in society . '' Treatment of abusive men is focused on re-education , as `` we do not see men 's violence against women as stemming from individual pathology , but rather from a socially reinforced sense of entitlement . '' The program 's philosophy is intended to help batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship .\", sentence_starts=[0, 126, 256, 419, 627], selected_sent={'start': 419, 'end': 627, 'string': \"Treatment of abusive men is focused on re-education , as `` we do not see men 's violence against women as stemming from individual pathology , but rather from a socially reinforced sense of entitlement . '' \"}, answer=[Entity(start_offset=458, end_offset=470, type='context', text='re-education', normalized_text='reeducation')], nq_answers=[[Entity(start_offset=458, end_offset=470, type='context', text='re-education', normalized_text='reeducation')]], aligned_nps=[(Entity(start_offset=0, end_offset=16, type='question', text='the duluth model', normalized_text='duluth model'), Entity(start_offset=419, end_offset=443, type='context', text='Treatment of abusive men', normalized_text='treatment of abusive men'))], explanation_type='single_sentence'),\n",
       " 1420146296895908944: QEDExample(example_id=1420146296895908944, title='Battle of Issus', question='where did the battle of issus take place', passage=\"The Battle of Issus occurred in southern Anatolia , on November 5 , 333 BC between the Hellenic League led by Alexander the Great and the Achaemenid Empire , led by Darius III , in the second great battle of Alexander 's conquest of Asia . The invading Macedonian troops defeated Persia . After the Hellenic League soundly defeated the Persian satraps of Asia Minor ( led by Greek mercenary Memnon of Rhodes ) at the Battle of the Granicus , Darius took personal command of his army . He gathered reinforcements and led his men in a surprise march behind the Hellenic advance to cut their line of supply . This forced Alexander to countermarch , setting the stage for the battle near the mouth of the Pinarus River and the town of Issus .\", sentence_starts=[0, 240, 289, 485, 606], selected_sent={'start': 0, 'end': 240, 'string': \"The Battle of Issus occurred in southern Anatolia , on November 5 , 333 BC between the Hellenic League led by Alexander the Great and the Achaemenid Empire , led by Darius III , in the second great battle of Alexander 's conquest of Asia . \"}, answer=[Entity(start_offset=32, end_offset=49, type='context', text='southern Anatolia', normalized_text='southern anatolia')], nq_answers=[[Entity(start_offset=32, end_offset=49, type='context', text='southern Anatolia', normalized_text='southern anatolia')], [Entity(start_offset=29, end_offset=49, type='context', text='in southern Anatolia', normalized_text='in southern anatolia')]], aligned_nps=[(Entity(start_offset=10, end_offset=29, type='question', text='the battle of issus', normalized_text='battle of issus'), Entity(start_offset=0, end_offset=19, type='context', text='The Battle of Issus', normalized_text='battle of issus'))], explanation_type='single_sentence'),\n",
       " -1344850267781439277: QEDExample(example_id=-1344850267781439277, title='Adventure Time (season 9)', question='when does the new adventure time come out', passage='The ninth and final season of Adventure Time , an American animated television series created by Pendleton Ward , premiered on Cartoon Network on April 21 , 2017 . It is set to conclude sometime in 2018 . The season was produced by Cartoon Network Studios and Frederator Studios . The season will follow the adventures of Finn , a human boy , and his best friend and adoptive brother Jake , a dog with magical powers to change shape and size at will . Finn and Jake live in the post-apocalyptic Land of Ooo , where they interact with the other main characters of the show : Princess Bubblegum , The Ice King , Marceline the Vampire Queen , Lumpy Space Princess , BMO , and Flame Princess .', sentence_starts=[0, 164, 205, 281, 452], selected_sent={'start': 0, 'end': 164, 'string': 'The ninth and final season of Adventure Time , an American animated television series created by Pendleton Ward , premiered on Cartoon Network on April 21 , 2017 . '}, answer=[Entity(start_offset=146, end_offset=161, type='context', text='April 21 , 2017', normalized_text='april 21 2017')], nq_answers=[[Entity(start_offset=146, end_offset=161, type='context', text='April 21 , 2017', normalized_text='april 21 2017')], [Entity(start_offset=114, end_offset=163, type='context', text='premiered on Cartoon Network on April 21 , 2017 .', normalized_text='premiered on cartoon network on april 21 2017')]], aligned_nps=[(Entity(start_offset=10, end_offset=32, type='question', text='the new adventure time', normalized_text='new adventure time'), Entity(start_offset=0, end_offset=111, type='context', text='The ninth and final season of Adventure Time , an American animated television series created by Pendleton Ward', normalized_text='ninth and final season of adventure time american animated television series created by pendleton ward'))], explanation_type='single_sentence'),\n",
       " -3946017874137223688: QEDExample(example_id=-3946017874137223688, title='Capsid', question='what is the function of a viral capsid', passage='The virion must assemble a stable , protective protein shell to protect the genome from lethal chemical and physical agents . These include forms of natural radiation , extremes of pH or temperature and proteolytic and nucleolytic enzymes . Delivery of the genome is also important by specific binding to external receptors of the host cell , transmission of specific signals that induce uncoating of the genome , and induction of fusion with host cell membranes .', sentence_starts=[0, 126, 241], selected_sent={'start': 0, 'end': 126, 'string': 'The virion must assemble a stable , protective protein shell to protect the genome from lethal chemical and physical agents . '}, answer=[Entity(start_offset=61, end_offset=123, type='context', text='to protect the genome from lethal chemical and physical agents', normalized_text='to protect genome from lethal chemical and physical agents')], nq_answers=[[Entity(start_offset=61, end_offset=123, type='context', text='to protect the genome from lethal chemical and physical agents', normalized_text='to protect genome from lethal chemical and physical agents')]], aligned_nps=[(Entity(start_offset=24, end_offset=38, type='question', text='a viral capsid', normalized_text='viral capsid'), Entity(start_offset=25, end_offset=60, type='context', text='a stable , protective protein shell', normalized_text='stable protective protein shell'))], explanation_type='single_sentence'),\n",
       " 7659819210182055332: QEDExample(example_id=7659819210182055332, title='Cell division', question='who discovered cells divide to make new cells', passage='A cell division under microscope was first discovered by German botanist Hugo von Mohl in 1835 as he worked over Green algae Cladophora glomerata .', sentence_starts=[0], selected_sent={'start': 0, 'end': 147, 'string': 'A cell division under microscope was first discovered by German botanist Hugo von Mohl in 1835 as he worked over Green algae Cladophora glomerata .'}, answer=[Entity(start_offset=73, end_offset=86, type='context', text='Hugo von Mohl', normalized_text='hugo von mohl')], nq_answers=[[Entity(start_offset=73, end_offset=86, type='context', text='Hugo von Mohl', normalized_text='hugo von mohl')], [Entity(start_offset=57, end_offset=86, type='context', text='German botanist Hugo von Mohl', normalized_text='german botanist hugo von mohl')]], aligned_nps=[], explanation_type='single_sentence'),\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/qed-dev.jsonlines\") as f:\n",
    "    first_line = f.readline().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_id': -3290814144789249484,\n",
       " 'title_text': 'List of Nobel laureates in Physics',\n",
       " 'url': 'https://en.wikipedia.org//w/index.php?title=List_of_Nobel_laureates_in_Physics&amp;oldid=838175212',\n",
       " 'question_text': 'who got the first nobel prize in physics',\n",
       " 'paragraph_text': 'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . John Bardeen is the only laureate to win the prize twice -- in 1956 and 1972 . Maria Skłodowska - Curie also won two Nobel Prizes , for physics in 1903 and chemistry in 1911 . William Lawrence Bragg was , until October 2014 , the youngest ever Nobel laureate ; he won the prize in 1915 at the age of 25 . Two women have won the prize : Curie and Maria Goeppert - Mayer ( 1963 ) . As of 2017 , the prize has been awarded to 206 individuals . There have been six years in which the Nobel Prize in Physics was not awarded ( 1916 , 1931 , 1934 , 1940 -- 1942 ) .',\n",
       " 'sentence_starts': [0, 172, 251, 348, 477, 552, 613],\n",
       " 'original_nq_answers': [[{'start': 56,\n",
       "    'end': 91,\n",
       "    'string': 'Wilhelm Conrad Röntgen , of Germany'}],\n",
       "  [{'start': 56, 'end': 78, 'string': 'Wilhelm Conrad Röntgen'}]],\n",
       " 'annotation': {'referential_equalities': [{'question_reference': {'start': 8,\n",
       "     'end': 40,\n",
       "     'string': 'the first nobel prize in physics'},\n",
       "    'sentence_reference': {'start': 0,\n",
       "     'end': 32,\n",
       "     'bridge': False,\n",
       "     'string': 'The first Nobel Prize in Physics'}}],\n",
       "  'answer': [{'sentence_reference': {'start': 56,\n",
       "     'end': 78,\n",
       "     'bridge': False,\n",
       "     'string': 'Wilhelm Conrad Röntgen'},\n",
       "    'paragraph_reference': {'start': 56,\n",
       "     'end': 78,\n",
       "     'string': 'Wilhelm Conrad Röntgen'}}],\n",
       "  'explanation_type': 'single_sentence',\n",
       "  'selected_sentence': {'start': 0,\n",
       "   'end': 172,\n",
       "   'string': 'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . '}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "J = json.loads(first_line)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0,\n",
       " 'end': 172,\n",
       " 'string': 'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . '}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J['annotation'].get('selected_sentence', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = annotation_dict[-3290814144789249484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0,\n",
       " 'end': 172,\n",
       " 'string': 'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . '}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.selected_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TFIDF_mod\n",
    "res = TFIDF_mod.tfidf_qa(M.passage, M.question, M.sentence_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 172, 251, 348, 477, 552, 613]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.sentence_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_idx = TFIDF_mod.get_true_sent_idx(M.selected_sent, M.sentence_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = TFIDF_mod.criterion(true_idx, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who got the first nobel prize in physics'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 172, 251, 348, 477, 552, 613]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.sentence_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = M.passage\n",
    "characters = list(passage)\n",
    "sentence_starts = [0, 172, 251, 348, 477, 552, 613]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'e', ' ', 'f', 'i', 'r', 's', 't', ' ', 'N', 'o', 'b', 'e', 'l', ' ', 'P', 'r', 'i', 'z', 'e', ' ', 'i', 'n', ' ', 'P', 'h', 'y', 's', 'i', 'c', 's', ' ', 'w', 'a', 's', ' ', 'a', 'w', 'a', 'r', 'd', 'e', 'd', ' ', 'i', 'n', ' ', '1', '9', '0', '1', ' ', 't', 'o', ' ', 'W', 'i', 'l', 'h', 'e', 'l', 'm', ' ', 'C', 'o', 'n', 'r', 'a', 'd', ' ', 'R', 'ö', 'n', 't', 'g', 'e', 'n', ' ', ',', ' ', 'o', 'f', ' ', 'G', 'e', 'r', 'm', 'a', 'n', 'y', ' ', ',', ' ', 'w', 'h', 'o', ' ', 'r', 'e', 'c', 'e', 'i', 'v', 'e', 'd', ' ', '1', '5', '0', ',', '7', '8', '2', ' ', 'S', 'E', 'K', ' ', ',', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'i', 's', ' ', 'e', 'q', 'u', 'a', 'l', ' ', 't', 'o', ' ', '7', ',', '7', '3', '1', ',', '0', '0', '4', ' ', 'S', 'E', 'K', ' ', 'i', 'n', ' ', 'D', 'e', 'c', 'e', 'm', 'b', 'e', 'r', ' ', '2', '0', '0', '7', ' ', '.', ' ', 'J', 'o', 'h', 'n', ' ', 'B', 'a', 'r', 'd', 'e', 'e', 'n', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'o', 'n', 'l', 'y', ' ', 'l', 'a', 'u', 'r', 'e', 'a', 't', 'e', ' ', 't', 'o', ' ', 'w', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'i', 'z', 'e', ' ', 't', 'w', 'i', 'c', 'e', ' ', '-', '-', ' ', 'i', 'n', ' ', '1', '9', '5', '6', ' ', 'a', 'n', 'd', ' ', '1', '9', '7', '2', ' ', '.', ' ', 'M', 'a', 'r', 'i', 'a', ' ', 'S', 'k', 'ł', 'o', 'd', 'o', 'w', 's', 'k', 'a', ' ', '-', ' ', 'C', 'u', 'r', 'i', 'e', ' ', 'a', 'l', 's', 'o', ' ', 'w', 'o', 'n', ' ', 't', 'w', 'o', ' ', 'N', 'o', 'b', 'e', 'l', ' ', 'P', 'r', 'i', 'z', 'e', 's', ' ', ',', ' ', 'f', 'o', 'r', ' ', 'p', 'h', 'y', 's', 'i', 'c', 's', ' ', 'i', 'n', ' ', '1', '9', '0', '3', ' ', 'a', 'n', 'd', ' ', 'c', 'h', 'e', 'm', 'i', 's', 't', 'r', 'y', ' ', 'i', 'n', ' ', '1', '9', '1', '1', ' ', '.', ' ', 'W', 'i', 'l', 'l', 'i', 'a', 'm', ' ', 'L', 'a', 'w', 'r', 'e', 'n', 'c', 'e', ' ', 'B', 'r', 'a', 'g', 'g', ' ', 'w', 'a', 's', ' ', ',', ' ', 'u', 'n', 't', 'i', 'l', ' ', 'O', 'c', 't', 'o', 'b', 'e', 'r', ' ', '2', '0', '1', '4', ' ', ',', ' ', 't', 'h', 'e', ' ', 'y', 'o', 'u', 'n', 'g', 'e', 's', 't', ' ', 'e', 'v', 'e', 'r', ' ', 'N', 'o', 'b', 'e', 'l', ' ', 'l', 'a', 'u', 'r', 'e', 'a', 't', 'e', ' ', ';', ' ', 'h', 'e', ' ', 'w', 'o', 'n', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'i', 'z', 'e', ' ', 'i', 'n', ' ', '1', '9', '1', '5', ' ', 'a', 't', ' ', 't', 'h', 'e', ' ', 'a', 'g', 'e', ' ', 'o', 'f', ' ', '2', '5', ' ', '.', ' ', 'T', 'w', 'o', ' ', 'w', 'o', 'm', 'e', 'n', ' ', 'h', 'a', 'v', 'e', ' ', 'w', 'o', 'n', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'i', 'z', 'e', ' ', ':', ' ', 'C', 'u', 'r', 'i', 'e', ' ', 'a', 'n', 'd', ' ', 'M', 'a', 'r', 'i', 'a', ' ', 'G', 'o', 'e', 'p', 'p', 'e', 'r', 't', ' ', '-', ' ', 'M', 'a', 'y', 'e', 'r', ' ', '(', ' ', '1', '9', '6', '3', ' ', ')', ' ', '.', ' ', 'A', 's', ' ', 'o', 'f', ' ', '2', '0', '1', '7', ' ', ',', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'i', 'z', 'e', ' ', 'h', 'a', 's', ' ', 'b', 'e', 'e', 'n', ' ', 'a', 'w', 'a', 'r', 'd', 'e', 'd', ' ', 't', 'o', ' ', '2', '0', '6', ' ', 'i', 'n', 'd', 'i', 'v', 'i', 'd', 'u', 'a', 'l', 's', ' ', '.', ' ', 'T', 'h', 'e', 'r', 'e', ' ', 'h', 'a', 'v', 'e', ' ', 'b', 'e', 'e', 'n', ' ', 's', 'i', 'x', ' ', 'y', 'e', 'a', 'r', 's', ' ', 'i', 'n', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 't', 'h', 'e', ' ', 'N', 'o', 'b', 'e', 'l', ' ', 'P', 'r', 'i', 'z', 'e', ' ', 'i', 'n', ' ', 'P', 'h', 'y', 's', 'i', 'c', 's', ' ', 'w', 'a', 's', ' ', 'n', 'o', 't', ' ', 'a', 'w', 'a', 'r', 'd', 'e', 'd', ' ', '(', ' ', '1', '9', '1', '6', ' ', ',', ' ', '1', '9', '3', '1', ' ', ',', ' ', '1', '9', '3', '4', ' ', ',', ' ', '1', '9', '4', '0', ' ', '-', '-', ' ', '1', '9', '4', '2', ' ', ')', ' ', '.']\n"
     ]
    }
   ],
   "source": [
    "print(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'e', ' ', 'f', 'i', 'r', 's', 't', ' ', 'N', 'o', 'b', 'e', 'l', ' ', 'P', 'r', 'i', 'z', 'e', ' ', 'i', 'n', ' ', 'P', 'h', 'y', 's', 'i', 'c', 's', ' ', 'w', 'a', 's', ' ', 'a', 'w', 'a', 'r', 'd', 'e', 'd', ' ', 'i', 'n', ' ', '1', '9', '0', '1', ' ', 't', 'o', ' ', 'W', 'i', 'l', 'h', 'e', 'l', 'm', ' ', 'C', 'o', 'n', 'r', 'a', 'd', ' ', 'R', 'ö', 'n', 't', 'g', 'e', 'n', ' ', ',', ' ', 'o', 'f', ' ', 'G', 'e', 'r', 'm', 'a', 'n', 'y', ' ', ',', ' ', 'w', 'h', 'o', ' ', 'r', 'e', 'c', 'e', 'i', 'v', 'e', 'd', ' ', '1', '5', '0', ',', '7', '8', '2', ' ', 'S', 'E', 'K', ' ', ',', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'i', 's', ' ', 'e', 'q', 'u', 'a', 'l', ' ', 't', 'o', ' ', '7', ',', '7', '3', '1', ',', '0', '0', '4', ' ', 'S', 'E', 'K', ' ', 'i', 'n', ' ', 'D', 'e', 'c', 'e', 'm', 'b', 'e', 'r', ' ', '2', '0', '0', '7', ' ', '.', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(characters[0:172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen , of Germany , who received 150,782 SEK , which is equal to 7,731,004 SEK in December 2007 . '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_string = ''.join(characters[0:172])\n",
    "result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "\n",
    "model_name = \"SpanBERT/spanbert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(M.question, M.passage, truncation=True, padding='max_length', max_length=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TFIDF_mod\n",
    "import utils\n",
    "\n",
    "train_dat = utils.load_data(\"./Data/qed-dev.jsonlines\")\n",
    "sample_ids = list(train_dat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_dat[sample_ids[1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QEDExample(example_id=-4627264087519762286, title='Glycogenin', question='explain the role of glycogenin in glycogen synthesis', passage='Glycogenin is an enzyme involved in converting glucose to glycogen . It acts as a primer , by polymerizing the first few glucose molecules , after which other enzymes take over . It is a homodimer of 37 - kDa subunits and is classified as a glycosyltransferase .', sentence_starts=[0, 69, 179], selected_sent={'start': 69, 'end': 179, 'string': 'It acts as a primer , by polymerizing the first few glucose molecules , after which other enzymes take over . '}, answer=[Entity(start_offset=80, end_offset=138, type='context', text='a primer , by polymerizing the first few glucose molecules', normalized_text='primer by polymerizing first few glucose molecules')], nq_answers=[[Entity(start_offset=72, end_offset=138, type='context', text='acts as a primer , by polymerizing the first few glucose molecules', normalized_text='acts as primer by polymerizing first few glucose molecules')]], aligned_nps=[], explanation_type='single_sentence')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Service Aircraft First flight Note Antonov An - 225 Mriya 19881221 ! 21 December 1988 Generally acknowledged as the largest airplane in the world , the single Antonov An - 225 is the world 's heaviest aircraft ever ( maximum takeoff weight greater than 640 tons ) and the largest heavier - than - air aircraft ( in length and wingspan ) ever entering operational service . Airbus A380 - 800 20050427 ! 27 April 2005 The largest passenger aircraft ever made . Capable of carrying 850 passengers Airbus A340 - 600 20010423 ! 23 April 2001 The A340 - 600 has been in production since 2001 , with a length of 75.30 m , the longest commercial aircraft , until surpassed by the Boeing 747 - 8 . Antonov An - 124 19820000 ! 26 December 1982 Was the largest mass - produced aircraft in the world until the Airbus A380 was produced . Remains the world 's largest military aircraft currently in service . Antonov An - 22 19650227 ! 27 February 1965 World 's largest turboprop - powered airplane Boeing 747 - 8 20100208 ! 8 February 2010 ( F variant ) Lengthened version of 747 with increased wingspan . World 's longest passenger aircraft at 76.4 m ( 0.9 m / 3 ft longer than Airbus A340 ) capacity of 650 passengers . Boeing 747 19690209 ! 9 February 1969 Highest - capacity passenger aircraft until surpassed by Airbus A380 Boeing 747 `` Dreamlifter '' 20060909 ! 9 September 2006 747 with enlarged fuselage for transporting Boeing 787 Dreamliner sub-assemblies ( 1,800 cubic metres ( 65,000 cu ft ) ) Tupolev Maksim Gorki 19340519 ! 19 May 1934 Physically the largest aircraft , and heaviest land - based aircraft of the 1930s era ( 63 meter / 206.7 ft wingspan , 53 tonne MTOW ) , required eight 900 hp Mikulin V12 engines for flight Dornier Do X 19290712 ! 12 July 1929 Largest successful flying boat and heaviest aircraft in the world from 1929 until 1942 when the Boeing B - 29 Superfortress first flew . Antonov An - 2 19470831 ! 31 August 1947 Largest mass - produced single - engine biplane .\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which one is the biggest airplane in the world'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0,\n",
       " 'end': 1995,\n",
       " 'string': \"In Service Aircraft First flight Note Antonov An - 225 Mriya 19881221 ! 21 December 1988 Generally acknowledged as the largest airplane in the world , the single Antonov An - 225 is the world 's heaviest aircraft ever ( maximum takeoff weight greater than 640 tons ) and the largest heavier - than - air aircraft ( in length and wingspan ) ever entering operational service . Airbus A380 - 800 20050427 ! 27 April 2005 The largest passenger aircraft ever made . Capable of carrying 850 passengers Airbus A340 - 600 20010423 ! 23 April 2001 The A340 - 600 has been in production since 2001 , with a length of 75.30 m , the longest commercial aircraft , until surpassed by the Boeing 747 - 8 . Antonov An - 124 19820000 ! 26 December 1982 Was the largest mass - produced aircraft in the world until the Airbus A380 was produced . Remains the world 's largest military aircraft currently in service . Antonov An - 22 19650227 ! 27 February 1965 World 's largest turboprop - powered airplane Boeing 747 - 8 20100208 ! 8 February 2010 ( F variant ) Lengthened version of 747 with increased wingspan . World 's longest passenger aircraft at 76.4 m ( 0.9 m / 3 ft longer than Airbus A340 ) capacity of 650 passengers . Boeing 747 19690209 ! 9 February 1969 Highest - capacity passenger aircraft until surpassed by Airbus A380 Boeing 747 `` Dreamlifter '' 20060909 ! 9 September 2006 747 with enlarged fuselage for transporting Boeing 787 Dreamliner sub-assemblies ( 1,800 cubic metres ( 65,000 cu ft ) ) Tupolev Maksim Gorki 19340519 ! 19 May 1934 Physically the largest aircraft , and heaviest land - based aircraft of the 1930s era ( 63 meter / 206.7 ft wingspan , 53 tonne MTOW ) , required eight 900 hp Mikulin V12 engines for flight Dornier Do X 19290712 ! 12 July 1929 Largest successful flying boat and heaviest aircraft in the world from 1929 until 1942 when the Boeing B - 29 Superfortress first flew . Antonov An - 2 19470831 ! 31 August 1947 Largest mass - produced single - engine biplane .\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.selected_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = m.sentence_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.extend([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.sentence_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m.sentence_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1995]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_starts = []\n",
    "if len(m.sentence_starts) == 0:\n",
    "    sentence_starts = [0, m.selected_sent['end']]\n",
    "else: \n",
    "    sentence_starts = m.sentence_starts\n",
    "\n",
    "pred = TFIDF_mod.tfidf_qa(m.passage, m.question, sentence_starts)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_idx = TFIDF_mod.get_true_sent_idx(m.selected_sent, sentence_starts)\n",
    "true_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import TFIDF_mod\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dat = utils.load_data(\"./Data/qed-train.jsonlines\")\n",
    "dev_dat = utils.load_data(\"./Data/qed-dev.jsonlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load SpanBERT Tokenizer and Model\n",
    "tokenizer = AutoTokenizer.from_pretrained('SpanBERT/spanbert-base-cased')\n",
    "model = AutoModel.from_pretrained('SpanBERT/spanbert-base-cased')\n",
    "\n",
    "text = \"Alice drove to the supermarket. She bought oranges.\"\n",
    "question = \"Who bought oranges?\"\n",
    "\n",
    "encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "encoded_question = tokenizer(question, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_embeddings = model(**encoded_text).last_hidden_state\n",
    "    question_embeddings = model(**encoded_question).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "she_embedding = text_embeddings[0, 4:9]\n",
    "print(she_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = she_embedding.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "annotation_dict = utils.load_data(\"./Data/qed-dev.jsonlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = annotation_dict[-3290814144789249484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = M.passage\n",
    "question = M.question\n",
    "coreference = M.aligned_nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who got the first nobel prize in physics'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_question = tokenizer(question, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1150, 1400, 1103, 1148, 1185, 8511, 4716, 1107, 7094,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_embeddings = model(**encoded_question).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 1024])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert coreference[0][0].type == 'question'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert coreference[0][1].type == 'context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first Nobel Prize in Physics'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(text)\n",
    "''.join(text[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = list(question)\n",
    "U = ''.join(question[8:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the first nobel prize in physics'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1103, 1148, 1185, 8511, 4716, 1107, 7094, 102]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = tokenizer(U)['input_ids']\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] the first nobel prize in physics [SEP]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = '[CLS] the first nobel prize in physics [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'the', 'first', 'nobel', 'prize', 'in', 'physics', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "k = K.split(' ')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = k[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'first', 'nobel', 'prize', 'in', 'physics']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the first nobel prize in physics'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
